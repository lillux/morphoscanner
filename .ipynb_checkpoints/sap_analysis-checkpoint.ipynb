{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import plotly\n",
    "#import plotly.express as px\n",
    "\n",
    "from mpl_toolkits import mplot3d\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "#from functools import lru_cache\n",
    "#import re\n",
    "import networkx as nx\n",
    "from networkx.algorithms import approximation\n",
    "\n",
    "import MDAnalysis as mda\n",
    "\n",
    "#import scipy\n",
    "#import sklearn\n",
    "#import skimage\n",
    "\n",
    "#import xml.etree.ElementTree as et\n",
    "#from Bio.PDB import *\n",
    "#import nglview as nv\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "\n",
    "\n",
    "# http://nglviewer.org/nglview/latest/api.html\n",
    "# https://biopython.org/wiki/The_Biopython_Structural_Bioinformatics_FAQ\n",
    "# https://ambermd.org/tutorials/analysis/tutorial_notebooks/nglview_notebook/index.html\n",
    "# https://amber-md.github.io/pytraj/latest/_api/pytraj.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contact_matrix = np.loadtxt('/home/lillo/TesiCNTE/CNTE/dataset/contact_matrix.txt')   #laptop\n",
    "#contact_matrix = np.loadtxt('/home/lillo/Code/Tesi/dataset/contact_matrix.txt')        #fisso\n",
    "#contact_matrix_single = contact_matrix.reshape(100,100,12,12)\n",
    "\n",
    "#gromacs_output = open('/home/lillo/Code/Tesi/dataset/dm4500Compl_mix1_K2_1%4500ns.gro') #fisso\n",
    "#gromacs_output = open('/home/lillo/TesiCNTE/CNTE/dataset/dm4500Compl_mix1_K2_1%4500ns.gro') #laptop\n",
    "\n",
    "#path = '/home/lillo/Code/Tesi/dataset/dm4500Compl_mix1_K2_1%4500ns.gro' #fisso\n",
    "#path = '/home/lillo/TesiCNTE/CNTE/dataset/dm4500Compl_mix1_K2_1%4500ns.gro' #laptop\n",
    "\n",
    "# import 2mxu file (beta sheet)\n",
    "\n",
    "#path_to_mmCIF = open('/home/lillo/TesiCNTE/pdb/2mxu/2mxu.cif')  ## laptop\n",
    "#path_to_pdb = '/home/lillo/TesiCNTE/pdb/2mxu/2mxu.pdb'  ## laptop\n",
    "#pa_to_pdb = '/home/lillo/TesiCNTE/pdb/2mxu/2mxu.pdb'  ## laptop\n",
    "\n",
    "#path_to_mmCIF = open('/home/lillo/Code/Tesi/pdb/2mxu/2mxu.cif')  ## fisso\n",
    "#path_to_pdb = '/home/lillo/Code/Tesi/pdb/2mxu/2mxu.pdb'  ## fisso\n",
    "#pa_to_pdb = '/home/lillo/Code/Tesi/pdb/2mxu/2mxu.pdb'  ## fisso\n",
    "\n",
    "#seed_1_path = '/home/lillo/TesiCNTE/from_cluster/aggregate1.gro' # laptop\n",
    "#seed_1_path = '/home/lillo/Code/Tesi/dataset/aggregate1.gro'    # Fisso\n",
    "\n",
    "#prod_gro = '/home/lillo/TesiCNTE/from_cluster/prod/prod_part1/min.gro'            # laptop\n",
    "#prod_xtc = '/home/lillo/TesiCNTE/from_cluster/prod/prod_part1/prod.xtc'           # laptop\n",
    "#prod1_xtc = '/home/lillo/TesiCNTE/from_cluster/prod/prod_part2/prod-compl.xtc'    # laptop\n",
    "\n",
    "prod_gro = '/home/lillo/Code/Tesi/dataset/prod/prod_part1/min.gro'           #fisso\n",
    "prod_xtc = '/home/lillo/Code/Tesi/dataset/prod/prod_part1/prod.xtc'          #fisso\n",
    "prod1_xtc = '/home/lillo/Code/Tesi/dataset/prod/prod_part2/prod-compl.xtc'   #fisso\n",
    "\n",
    "\n",
    "#trj_xtc = '/home/lillo/TesiCNTE/CNTE/trajectory/prd-LDLK12-100mer-out-mol.xtc'  #laptop\n",
    "#trj_gro = '/home/lillo/TesiCNTE/CNTE/trajectory/min-LDLK12-100mer-out-c.gro'    #laptop\n",
    "\n",
    "trj_gro = '/home/lillo/Code/Tesi/dataset/trajectory_6_12_19/min-LDLK12-100mer-out-c.gro'     #fisso\n",
    "trj_xtc = '/home/lillo/Code/Tesi/dataset/trajectory_6_12_19/prd-LDLK12-100mer-out-mol.xtc'   #fisso\n",
    "\n",
    "lipase = '/home/lillo/Documenti/PDB/lipase/3d2c.pdb'\n",
    "lipase1 = '/home/lillo/Documenti/PDB/lipase/1gpl.pdb'\n",
    "\n",
    "\n",
    "#p73_2per_wat_seed_1_gro = '/home/lillo/TesiCNTE/from_cluster/peptide_73/MARTINI/2%/WATER/2%/seed_1/prod/73prod.gro'     # laptop\n",
    "#p73_2per_wat_seed_1_xtc = '/home/lillo/TesiCNTE/from_cluster/peptide_73/MARTINI/2%/WATER/2%/seed_1/prod/73prod.xtc'     # laptop\n",
    "#p73_2per_wat_seed_1_trr = '/home/lillo/TesiCNTE/from_cluster/peptide_73/MARTINI/2%/WATER/2%/seed_1/prod/73prod.trr'     # laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj.number_of_BB_atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import morphoscanner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj = morphoscanner.trajectory.trajectory(trj_gro, trj_xtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj.compose_database(peptide_length=12, interval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj.analyze_inLoop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj.get_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj.database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj.frames.get(150).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot.plot_peptide_list(trj.frames.get(150).get('frame_dict'), trj.frames.get(150).get('subgraphs_full')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni = morphoscanner.backend.topology.make_universe(trj_gro,trj_xtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fareclasse frame, in cui ogni frame è un oggetto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_coordinate_dict_from_trajectory(trj_gro, trj_xtc, peptide_length=None, start_from=0, interval=1):\n",
    "#    '''Parse coordinate from a .gro topology and a .xtc trajectory.\n",
    "    \n",
    "#    Arguments:  .gro topology file path,\n",
    "            \n",
    "#                .xtc trajectory file path,\n",
    "                \n",
    "                \n",
    "#                optional:\n",
    "                    \n",
    "#                    peptide_length, default=None.   You can set the length of the peptide\n",
    "#                                                    Useful if you have to analyze simulation in which\n",
    "#                                                    there are premade aggregate\n",
    "                                    \n",
    "#                    start_from, default=0.    You can chose from which frame start the counter.\n",
    "#                                                Useful if you are working with a simulation\n",
    "#                                                made of different part. Eg. If part 1 end at\n",
    "#                                                frame 500, you can set start_from=500 and analyze\n",
    "#                                                part 2 of the simulation. Use it expecially\n",
    "#                                                if you are sampling (interval != 1)\n",
    "#                                                \n",
    "#                    interval, default=1     Interval between sample. If you want all the frame,\n",
    "#                                            interval=1 (default).\n",
    "#                                            If you want to skip sample, this parameter let you\n",
    "#                                            choose the interval between 2 sample frame.\n",
    "    \n",
    "    \n",
    "#    '''\n",
    "from morphoscanner.backend.topology import get_peptide_length_list\n",
    "from morphoscanner.backend.topology import make_universe\n",
    "import tqdm\n",
    "\n",
    "\n",
    "\n",
    "peptide_length=12\n",
    "start_from=0\n",
    "interval=50\n",
    "\n",
    "peptides_list = get_peptide_length_list(trj_gro)\n",
    "\n",
    "universe = make_universe(trj_gro, trj_xtc)\n",
    "\n",
    "\n",
    "if peptide_length == None:\n",
    "\n",
    "\n",
    "    n_pep = len(peptides_list)\n",
    "\n",
    "\n",
    "else:\n",
    "\n",
    "    n_pep = sum([(e // peptide_length) for e in peptides_list])\n",
    "\n",
    "\n",
    "\n",
    "trj_dict = {}\n",
    "\n",
    "for index_ts, ts in tqdm.tqdm(enumerate(universe.trajectory)):\n",
    "\n",
    "    updated_index = (index_ts + start_from)\n",
    "\n",
    "    if (updated_index % interval) == 0:\n",
    "\n",
    "        frm = frame(peptide_length, universe, peptides_list, n_pep)\n",
    "        trj_dict[updated_index] = frm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot.plot_peptide_list(trj_dict.get(150), [i for i in trj_dict.get(0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj_dict[0].peptides[0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, atom in enumerate(universe.atoms):\n",
    "    \n",
    "    \n",
    "    atom_type = str(atom).split()[2]\n",
    "\n",
    "    if atom_type == 'BB':\n",
    "\n",
    "        atom_number = (int(str(atom).split()[1].split(':')[0]) - 1)\n",
    "        \n",
    "        residue_name = (str(atom).split()[8].split(',')[0])\n",
    "\n",
    "        coordinate = universe.atoms[atom_number].position\n",
    "\n",
    "        #position = len(trj_dict[updated_index][peptide])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        print(residue_name)\n",
    "        #print((str(atom).split()[8].split(',')[0]))\n",
    "\n",
    "\n",
    "\n",
    "       # trj_dict[updated_index][peptide][position] = coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_gro = get_gro()\n",
    "_xtc = get_xtc()\n",
    "\n",
    "trj = trajectory(_gro, _xtc)\n",
    "\n",
    "print('Your trajectory has %d frames' % trj.number_of_frames)\n",
    "print('Your trajectory has %d BB atoms' % trj.number_of_BB_atoms)\n",
    "\n",
    "\n",
    "peptide_length = peptide_length(sentence='Set the number of aminoacids in one peptide (int): ')\n",
    "interval = get_interval(sentence='Set the interval between sampled frames (int): ')\n",
    "start_from = start_from(sentence='Set the index from which you want to start.\\n\\n0 if you have a single simulation.\\n0 if you are analyzing split1.\\nlen(split1) if you are analyzing split2.\\ninteger: ')\n",
    "\n",
    "output_path, file_name = get_destination_dir_and_name()\n",
    "\n",
    "\n",
    "trj.compose_database(peptide_length=peptide_length, interval=interval)\n",
    "trj.analyze_inLoop()\n",
    "trj.get_data()\n",
    "trj.get_database()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero = trj_dict.get(0).get(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.stack([torch.from_numpy(zero[e]) for e in zero])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.backend.distance_tensor.compute_euclidean_norm_torch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_euclidean_norm(peptide1, peptide2):\n",
    "\n",
    "    x_norm = torch.pow(peptide1, 2).sum(1).view(-1,1)\n",
    "    y_t = torch.transpose(peptide2, 0, 1)\n",
    "    y_norm = torch.pow(peptide2, 2).sum(1).view(1,-1)\n",
    "\n",
    "    dist = torch.sqrt(x_norm + y_norm - 2.0 * torch.mm(peptide1, y_t))\n",
    "    dist[torch.isnan(dist)] = 0\n",
    "\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_dist = compute_euclidean_norm(t, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(t_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# working\n",
    "\n",
    "class frame:\n",
    "    \n",
    "    '''Class that parse the trajectory and gives back frames with data.\n",
    "    \n",
    "    This class is used to represent data in an intuitive way to the user\n",
    "    \n",
    "    \n",
    "    '''\n",
    "\n",
    "    def __init__(self, peptide_length, universe, peptides_list, n_pep):\n",
    "        \n",
    "        # cosa vuoi aggiungere?\n",
    "        \n",
    "        # forse è meglio se si fa una classe frames dentro la classe trajectory\n",
    "        # e poi si istanzia la classe frame ad ogni frame campionato\n",
    "        # e dentro si mettono anche i risultati dell'analisi\n",
    "        # \n",
    "        # prendo a riferimento i frames, quindi la traiettoria\n",
    "        # oppure prendo a riferimento il tipo di peptide?\n",
    "        # forse meglio il frame, e poi posso tracciare le famiglie di peptidi tra\n",
    "        # i frames.\n",
    "        # \n",
    "        # devo anche individuare quali sono le sequenze\n",
    "        # e raggruppare i peptidi con sequenza uguale\n",
    "        # \n",
    "        #\n",
    "\n",
    "    \n",
    "        self.peptides = {}\n",
    "\n",
    "        for peptide in range(n_pep):\n",
    "\n",
    "            self.peptides[peptide] = {}\n",
    "\n",
    "\n",
    "            if peptide == 0:\n",
    "\n",
    "                counter = 0\n",
    "\n",
    "            else:\n",
    "                \n",
    "                # if to check peptide_length\n",
    "                if peptide_length == None:\n",
    "\n",
    "                    counter += peptides_list[peptide - 1]\n",
    "\n",
    "                else:\n",
    "                    counter += peptide_length\n",
    "                \n",
    "\n",
    "        \n",
    "\n",
    "            pep = single_peptide(universe, counter, peptide, peptide_length, peptides_list)\n",
    "            \n",
    "            self.peptides[peptide] = pep\n",
    "        \n",
    "        return\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = morphoscanner.trajectory.trajectory(trj_gro, trj_xtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from morphoscanner import backend\n",
    "from timeit import default_timer as timer\n",
    "import pandas as pd\n",
    "\n",
    "class trajectory:\n",
    "\n",
    "    '''Class to operate on trajectory files.\n",
    "\n",
    "    It makes an object that contain the trajectory of the simulation'''\n",
    "\n",
    "\n",
    "\n",
    "    def __init__(self, trj_gro, trj_xtc):\n",
    "        \n",
    "        \n",
    "\n",
    "        self.trj_gro = trj_gro\n",
    "        self.trj_xtc = trj_xtc\n",
    "        self.universe = backend.topology.make_universe(self.trj_gro, self.trj_xtc)\n",
    "        self.number_of_frames = len(self.universe.trajectory)\n",
    "        self.number_of_BB_atoms = len(self.universe.select_atoms('name BB'))\n",
    "        self.frames = {}\n",
    "        \n",
    "        peptide_length_list = backend.topology.get_peptide_length_list(self.trj_gro)\n",
    "        self.len_dict = backend.topology.get_peptide_length_dict(peptide_length_list)\n",
    "\n",
    "\n",
    "\n",
    "    def compose_database(self, peptide_length=None, start_from=0, interval=1):\n",
    "\n",
    "        self.peptide_length = peptide_length\n",
    "        self.start_from = start_from\n",
    "        self.interval = interval\n",
    "\n",
    "        self.data = backend.topology.get_coordinate_dict_from_trajectory(self.trj_gro, self.trj_xtc, peptide_length=self.peptide_length, start_from=self.start_from, interval=self.interval)\n",
    "        self.sampled_frames = [key for key in self.data.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atom_list = morphoscanner.backend.readGro.clean_gro(trj_gro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atom_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atoms_list = morphoscanner.backend.readGro.clean_gro(trj_gro)\n",
    "unique_peptide = {}\n",
    "\n",
    "peptide_length_list = []\n",
    "peptide_residue_list = []\n",
    "temporary_list = []\n",
    "temporary_residue_list = []\n",
    "\n",
    "# iterate trough topology\n",
    "for atom in atoms_list:\n",
    "\n",
    "    # if temporary list just started, add aminoacid position in chain\n",
    "    if len(temporary_list) == 0:\n",
    "        temporary_list.append(int(atom[1]))\n",
    "        temporary_residue_list.append(atom[2])\n",
    "\n",
    "    else:\n",
    "        # if position of actual residue is less than last residue\n",
    "        if temporary_list[-1] > int(atom[1]):\n",
    "\n",
    "            # append length of last peptide to peptide length list\n",
    "            peptide_length_list.append(len(temporary_list))\n",
    "            peptide_residue_list.append(temporary_residue_list)\n",
    "\n",
    "            # empty temporary list\n",
    "            temporary_list = []\n",
    "            temporary_residue_list = []\n",
    "\n",
    "            # append actual residue position\n",
    "            temporary_list.append(int(atom[1]))\n",
    "\n",
    "        # if position of actual residue is higher than last residue, ad current residue position\n",
    "        else:\n",
    "            temporary_list.append(int(atom[1]))\n",
    "            temporary_residue_list.append(atom[2])\n",
    "\n",
    "\n",
    "# append last peptide lenght to lenght stack\n",
    "peptide_length_list.append(len(temporary_list))\n",
    "peptide_residue_list.append(temporary_residue_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peptide_residue_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work in new trajectory management\n",
    "class single_peptide():\n",
    "    \n",
    "    ''' Class that define peptides\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, universe, counter, peptide, peptide_length, peptides_list):\n",
    "        \n",
    "        self.peptide_sequence = {}\n",
    "        \n",
    "        self.peptide_coordinates = {}\n",
    "        \n",
    "        \n",
    "        if peptide_length == None:\n",
    "\n",
    "            for res in range(peptides_list[peptide]):\n",
    "\n",
    "                for index, atom in enumerate(universe.residues[res + (counter)].atoms):\n",
    "\n",
    "                    atom_type = str(atom).split()[2]\n",
    "\n",
    "                    if atom_type == 'BB':\n",
    "\n",
    "                        atom_number = (int(str(atom).split()[1].split(':')[0]) - 1)\n",
    "\n",
    "                        residue_name = (str(atom).split()[8].split(',')[0])\n",
    "\n",
    "                        coordinate = universe.atoms[atom_number].position\n",
    "\n",
    "                        position = len(self.peptide_coordinates)\n",
    "\n",
    "\n",
    "                        self.peptide_coordinates[position] = coordinate\n",
    "                        \n",
    "                        self.peptide_sequence[position] = residue_name\n",
    "                    \n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "\n",
    "        else:\n",
    "\n",
    "            for res in range(peptide_length):\n",
    "\n",
    "                for index, atom in enumerate(universe.residues[res + (counter)].atoms):\n",
    "\n",
    "                    atom_type = str(atom).split()[2]\n",
    "\n",
    "                    if atom_type == 'BB':\n",
    "\n",
    "                        atom_number = (int(str(atom).split()[1].split(':')[0]) - 1)\n",
    "\n",
    "                        residue_name = (str(atom).split()[8].split(',')[0])\n",
    "\n",
    "                        coordinate = universe.atoms[atom_number].position\n",
    "\n",
    "                        position = len(self.peptide_coordinates)\n",
    "\n",
    "\n",
    "                        self.peptide_coordinates[position] = coordinate\n",
    "                        \n",
    "                        self.peptide_sequence[position] = residue_name\n",
    "\n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class database:\n",
    "\n",
    "    '''Class that parse the trajectory and gives back frames with data.\n",
    "\n",
    "    This class is used to represent data in an intuitive way to the user\n",
    "\n",
    "\n",
    "    '''\n",
    "\n",
    "\n",
    "    def __init__(self, peptide_length=None, start_from = 0, interval = 1):\n",
    "\n",
    "        # cosa vuoi aggiungere?\n",
    "\n",
    "        # forse è meglio se si fa una classe frames dentro la classe trajectory\n",
    "        # e poi si istanzia la classe frame ad ogni frame campionato\n",
    "        # e dentro si mettono anche i risultati dell'analisi\n",
    "        # \n",
    "        # prendo a riferimento i frames, quindi la traiettoria\n",
    "        # oppure prendo a riferimento il tipo di peptide?\n",
    "        # forse meglio il frame, e poi posso tracciare le famiglie di peptidi tra\n",
    "        # i frames.\n",
    "        # \n",
    "        # devo anche individuare quali sono le sequenze\n",
    "        # e raggruppare i peptidi con sequenza uguale\n",
    "        # \n",
    "        #\n",
    "\n",
    "        self.frames = {}\n",
    "        self.peptide_length = peptide_length\n",
    "        self.start_from = start_from\n",
    "        self.interval = interval\n",
    "\n",
    "        peptides_list = backend.topology.get_peptide_length_list(trj_gro)\n",
    "\n",
    "        universe = backend.topology.make_universe(trj_gro, trj_xtc)\n",
    "\n",
    "\n",
    "        if peptide_length == None:\n",
    "\n",
    "\n",
    "            n_pep = len(peptides_list)\n",
    "\n",
    "\n",
    "        else:\n",
    "\n",
    "            n_pep = sum([(e // peptide_length) for e in peptides_list])\n",
    "\n",
    "\n",
    "\n",
    "        self.frames = {}\n",
    "\n",
    "        for index_ts, ts in tqdm.tqdm(enumerate(universe.trajectory)):\n",
    "\n",
    "            updated_index = (index_ts + start_from)\n",
    "\n",
    "            if (updated_index % interval) == 0:\n",
    "\n",
    "                peptides = {}\n",
    "\n",
    "                for peptide in range(n_pep):\n",
    "\n",
    "                    peptides[peptide] = {}\n",
    "\n",
    "\n",
    "                    if peptide == 0:\n",
    "\n",
    "                        counter = 0\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        # if to check peptide_length\n",
    "                        if peptide_length == None:\n",
    "\n",
    "                            counter += peptides_list[peptide - 1]\n",
    "\n",
    "                        else:\n",
    "                            counter += peptide_length\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    pep = single_peptide(universe, counter, peptide, peptide_length, peptides_list)\n",
    "\n",
    "                    peptides[peptide] = pep\n",
    "\n",
    "                self.frames[updated_index] = peptides\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from morphoscanner import backend\n",
    "\n",
    "class trajectory:\n",
    "\n",
    "    '''Class to operate on trajectory files.\n",
    "\n",
    "    It makes an object that contain the trajectory of the simulation'''\n",
    "\n",
    "\n",
    "\n",
    "    def __init__(self, trj_gro, trj_xtc):\n",
    "        \n",
    "        \n",
    "\n",
    "        self.trj_gro = trj_gro\n",
    "        self.trj_xtc = trj_xtc\n",
    "        self.universe = backend.topology.make_universe(self.trj_gro, self.trj_xtc)\n",
    "        self.number_of_frames = len(self.universe.trajectory)\n",
    "        self.number_of_BB_atoms = len(self.universe.select_atoms('name BB'))\n",
    "        #self.frames = {}\n",
    "        \n",
    "        peptide_length_list = backend.topology.get_peptide_length_list(self.trj_gro)\n",
    "        self.len_dict = backend.topology.get_peptide_length_dict(peptide_length_list)\n",
    "        \n",
    "        return\n",
    "\n",
    "    \n",
    "    def compose_database(self, peptide_length=None, start_from=0, interval=1):\n",
    "\n",
    "        self.peptide_length = peptide_length\n",
    "        self.start_from = start_from\n",
    "        self.interval = interval\n",
    "\n",
    "        self.database = database(peptide_length, start_from, interval)\n",
    "\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj_new = trajectory(trj_gro, trj_xtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj_new.compose_database(peptide_length=12, start_from=0, interval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj_new.database.frames[0][55].peptide_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_peptide_length_list(topology):\n",
    "topology = trj_gro\n",
    "topology = clean_gro(topology)\n",
    "\n",
    "peptide_length_list = []\n",
    "\n",
    "temporary_list = []\n",
    "\n",
    "# iterate trough topology\n",
    "for residue in topology:\n",
    "\n",
    "    # if temporary list just started, add aminoacid position in chain\n",
    "    if len(temporary_list) == 0:\n",
    "        temporary_list.append(int(residue[1]))\n",
    "\n",
    "    else:\n",
    "        # if position of actual residue is less than last residue\n",
    "        if temporary_list[-1] > int(residue[1]):\n",
    "\n",
    "            # append lenght of last peptide to peptide length list\n",
    "            peptide_length_list.append(len(temporary_list))\n",
    "\n",
    "            # empty temporary list\n",
    "            temporary_list = []\n",
    "\n",
    "            # append actual residue position\n",
    "            temporary_list.append(int(residue[1]))\n",
    "\n",
    "        # if position of actual residue is higher than last residue, ad current residue position\n",
    "        else:\n",
    "            temporary_list.append(int(residue[1]))\n",
    "\n",
    "# append last peptide lenght to lenght stack\n",
    "peptide_length_list.append(len(temporary_list))\n",
    "\n",
    "#    return peptide_length_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.backend.topology.get_peptide_length_list((trj_gro))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = morphoscanner.backend.readGro.clean_gro(trj_gro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class single_peptide():\n",
    "    \n",
    "    ''' Class that define peptides\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.sequence\n",
    "        self.coordinates\n",
    "        \n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dispatch_data(atom):\n",
    "    \n",
    "    if type(atom) != list:\n",
    "        \n",
    "        raise ValueError(\"%s is not a list, it is of type %s...\\n \" % (str(atom), type(atom)))\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        atom_number = check_int_and_return(atom[0])\n",
    "        \n",
    "        residue_number = check_int_and_return(atom[1])\n",
    "        \n",
    "        residue_name = atom[2]\n",
    "        \n",
    "        x = float(atom[3])\n",
    "        \n",
    "        y = float(atom[4])\n",
    "        \n",
    "        z = float(atom[5])\n",
    "        \n",
    "    \n",
    "    \n",
    "        return atom_number, residue_number, residue_name, x, y, z\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatch_data(cleaned[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(cleaned[0]) == list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "def isInt(s):\n",
    "    '''Check if s is type int and return bool.\n",
    "    \n",
    "    Input: object\n",
    "    \n",
    "    Output: bool'''\n",
    "    \n",
    "    try:\n",
    "        return float(str(s)).is_integer()\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "    \n",
    "    \n",
    "def check_int_and_return(value):\n",
    "    \n",
    "    '''Check int and return value, else raise ValueError and print object type\n",
    "    \n",
    "    Input = object\n",
    "    \n",
    "    Output = int'''\n",
    "\n",
    "    if isInt(value):\n",
    "\n",
    "        return int(value)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"%s is not an integer, it is of type %s...\\n \" % (str(value), type(value))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.isdigit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isInt_float(s):\n",
    "    try:\n",
    "        return float(str(s)).is_integer()\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isInt_float(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isInt_float('21')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isInt_float('2564.887')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_int_and_return(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {'a':32, 'b':28}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map on input file to get data\n",
    "\n",
    "start = timer()\n",
    "%timeit a = map(check_int_and_return, (i[0] for i in cleaned))\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in a:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe = morphoscanner.backend.topology.make_universe(trj_gro, trj_xtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero = universe.trajectory[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pep_73 = morphoscanner.trajectory.trajectory(p73_2per_wat_seed_1_gro, p73_2per_wat_seed_1_trr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pep_73.number_of_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pep_73.number_of_BB_atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pep_73.universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni73 = pep_73.universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(uni73.trajectory[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_coordinate_dict_from_mda_traj_frame():\n",
    "\n",
    "\n",
    "pep_73.len_d\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_list = morphoscanner.backend.topology.get_peptide_length_list (p73_2per_wat_seed_1_gro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_list = morphoscanner.backend.topology.get_peptide_length_list (p73_2per_wat_seed_1_gro)\n",
    "total_residues = sum(length_list)\n",
    "universe = morphoscanner.backend.topology.make_universe(p73_2per_wat_seed_1_gro, p73_2per_wat_seed_1_trr)\n",
    "grain_to_select = 'BB'\n",
    "\n",
    "coordinate_dict = {}\n",
    "\n",
    "res_counter = 0\n",
    "\n",
    "\n",
    "for peptide in length_list:\n",
    "    \n",
    "    coordinate_dict[peptide] = {}\n",
    "    \n",
    "    \n",
    "    for idx, actual_atom in enumerate(range(peptide)):\n",
    "        \n",
    "    #for res in range(total_residues):\n",
    "\n",
    "        actual_res = universe.residues[res_counter]\n",
    "\n",
    "        for index, atom in enumerate(actual_res.atoms):\n",
    "\n",
    "            atom_type = str(atom).split()[2]\n",
    "\n",
    "            if atom_type == 'BB':\n",
    "\n",
    "                atom_number = (int(str(atom).split()[1].split(':')[0]) - 1)\n",
    "\n",
    "                residue_name = (str(atom).split()[8].split(',')[0])\n",
    "\n",
    "                coordinate = universe.atoms[atom_number].position\n",
    "\n",
    "                coo\n",
    "                \n",
    "                coordinate_dict[peptide][index] = coordinate\n",
    "                \n",
    "                \n",
    "                res_counter += 1\n",
    "\n",
    "    \n",
    "            #position = len(trj_dict[updated_index][peptide])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class atom:\n",
    "    \n",
    "    def __init__(coordinates, atom_number=None, residue_name=None, atom_type=None):\n",
    "        \n",
    "        self.coordinates = coordinates\n",
    "        self.atom_number = atom_number\n",
    "        self.atom_type = atom_type\n",
    "        self.residue_name = residue_name\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinate_from_first_trajectory_frame(gro, trj_data, grain_to_select='BB'):\n",
    "    \n",
    "    length_list = morphoscanner.backend.topology.get_peptide_length_list(gro)\n",
    "    total_residues = sum(length_list)\n",
    "    universe = morphoscanner.backend.topology.make_universe(gro, trj_data)\n",
    "    \n",
    "    coordinate_dict = {}\n",
    "    res_counter = 0\n",
    "    \n",
    "    for pep_index, peptide in enumerate(length_list):\n",
    "\n",
    "        coordinate_dict[pep_index] = {}\n",
    "\n",
    "        for res in range(peptide):\n",
    "\n",
    "            actual_res = universe.residues[res_counter]\n",
    "\n",
    "            for index, atom in enumerate(actual_res.atoms):\n",
    "\n",
    "                atom_type = str(atom).split()[2]\n",
    "\n",
    "                if atom_type == grain_to_select:\n",
    "\n",
    "                    atom_number = (int(str(atom).split()[1].split(':')[0]) - 1)\n",
    "\n",
    "                    #residue_name = (str(atom).split()[8].split(',')[0])\n",
    "\n",
    "                    coordinate = universe.atoms[atom_number].position\n",
    "\n",
    "                    coordinate_dict[pep_index][res] = coordinate\n",
    "\n",
    "                    res_counter += 1\n",
    "                    \n",
    "    return coordinate_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes in dev\n",
    "\n",
    "class single_peptide():\n",
    "    \n",
    "    ''' Class that define peptides\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, seq, atom_n, coord):\n",
    "        \n",
    "        self.sequence = seq\n",
    "        self.atom_numbers = atom_n\n",
    "        self.frame_coordinates = coord\n",
    "        \n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate universe and peptide list\n",
    "universe = morphoscanner.backend.topology.make_universe(trj_gro,trj_xtc)\n",
    "peptide_length_list = morphoscanner.backend.topology.get_peptide_length_list(trj_gro)\n",
    "\n",
    "\n",
    "# Get first frame exploratory data\n",
    "\n",
    "## WORKING NICELY FAST\n",
    "def get_data_from_trajectory_frame(universe, frame, peptide_length_list, atom_to_select='BB'):\n",
    "#def get_data_from_trajectory_frame(universe, peptide_length_list, atom_to_select='BB'):\n",
    "\n",
    "    # move universe frame to memory\n",
    "    universe.trajectory[frame]\n",
    "\n",
    "    # count number of residues from a .gro topology file\n",
    "    total_residues = sum(peptide_length_list)\n",
    " \n",
    "    coordinate_dict = {}\n",
    "    residues_dict = {}\n",
    "    atom_number_dict = {}\n",
    "    \n",
    "    res_counter = 0\n",
    "\n",
    "    #print(length_list)\n",
    "    for pep_index, peptide in enumerate(peptide_length_list):\n",
    "\n",
    "        coordinate_dict[pep_index] = {}\n",
    "        residues_dict[pep_index] = {}\n",
    "        atom_number_dict[pep_index] = {}\n",
    "\n",
    "        \n",
    "        ### SEPARA QUA\n",
    "        # PARTE SOPRA INIZIALIZZA\n",
    "        # PARTE SOTTO DISTRIBUISCE\n",
    "        \n",
    "        \n",
    "        #print(pep_index)\n",
    "        for res in range(peptide):\n",
    "\n",
    "            actual_res = universe.residues[res_counter]\n",
    "            \n",
    "            for index, atom in enumerate(actual_res.atoms):\n",
    "\n",
    "                atom_type = str(atom).split()[2]\n",
    "\n",
    "                if atom_type == atom_to_select:\n",
    "                    \n",
    "                    atom_number = (int(str(atom).split()[1].split(':')[0]) - 1)\n",
    "\n",
    "                    residue_name = (str(atom).split()[8].split(',')[0])\n",
    "\n",
    "                    coordi = universe.atoms[atom_number].position\n",
    "\n",
    "                    #coordi = universe.trajectory[frame][atom_number]\n",
    "                    \n",
    "\n",
    "                    coordinate_dict[pep_index][res] = coordi\n",
    "                    residues_dict[pep_index][res] = residue_name\n",
    "                    atom_number_dict[pep_index][res] = atom_number\n",
    "                    \n",
    "                    res_counter += 1\n",
    "                    \n",
    "    return coordinate_dict, residues_dict, atom_number_dict\n",
    "    #return residues_dict, atom_number_dict\n",
    "\n",
    "\n",
    "# get data from frame 0\n",
    "start = timer()\n",
    "c_0, r_0, an_0 = get_data_from_trajectory_frame(universe, 0, peptide_length_list)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "\n",
    "peptides_dict = {}\n",
    "for seq, coord, atm_n in zip(r_0, an_0, c_0):\n",
    "    \n",
    "    peptides_dict[seq] = single_peptide(r_0.get(seq), an_0.get(atm_n), c_0.get(coord))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot.plot_peptide_list(c_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peptide_length_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "c_2, r_2 = get_data_from_first_trajectory_frame(universe, 48, peptide_length_list)\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "an_1[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot.plot_peptide_list(c_1, [p for p in c_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from morphoscanner import backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Mi serve un oggetto peptide con sequenza ed atom_number.\n",
    "### La sequenza la prendo una volta sola e sarà sempre la stessa\n",
    "### L'atom_number mi serve perché così posso prendermi le coordinate\n",
    "### dai timestep quando voglio, anche per singolo peptide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class single_peptide():\n",
    "    \n",
    "    ''' Class that define peptides\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, seq, atom_n, coord):\n",
    "        \n",
    "        self.sequence = seq\n",
    "        self.atom_numbers = atom_n\n",
    "        self.frame_coordinates = coord\n",
    "        \n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class frame_coordinate():\n",
    "    ''' Class that contains coordinates\n",
    "    \n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_1, r_1, an_1 = get_data_from_first_trajectory_frame(universe, 0, peptide_length_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "peptides_dict = {}\n",
    "for seq, coord, atm_n in zip(r_1, c_1, an_1):\n",
    "    \n",
    "    peptides_dict[seq] = single_peptide(r_1.get(seq), an_1.get(atm_n), c_1.get(coord))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peptides_dict[21].atom_numbers.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_list = {}\n",
    "for idx, i in enumerate(peptides_dict[21].atom_numbers.values()):\n",
    "    p = universe.atoms[i].position\n",
    "    c_list[idx] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_peptide_from_trajectory_frame(c_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot.plot_single_peptide(c_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot from trajectory positions  ### WORKING BUT YOU NEED TO:\n",
    "# make_universe\n",
    "# positions = universe.select_atoms('name BB').positions\n",
    "def plot_peptide_from_trajectory_frame(positions, peptide_list=None, centroid=False):\n",
    "    \n",
    "    '''\n",
    "    Plot atoms from universe.trajectory[frame]\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    if peptide_list == None:\n",
    "        \n",
    "        peptide_list = [e for e in range(len(positions))]\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "    x_median = float\n",
    "    y_median = float\n",
    "    z_median = float\n",
    "\n",
    "\n",
    "    for peptide in range(len(peptide_list)):\n",
    "        x.append([peptide])\n",
    "        y.append([peptide])\n",
    "        z.append([peptide])\n",
    "\n",
    "        point = positions[peptide_list[peptide]]\n",
    "        #print(peptide, point)\n",
    "        x[peptide].append(point[0])\n",
    "        y[peptide].append(point[1])\n",
    "        z[peptide].append(point[2])\n",
    "\n",
    "        del x[peptide][0]\n",
    "        del y[peptide][0]\n",
    "        del z[peptide][0]\n",
    "\n",
    "\n",
    "    fig = plt.figure()\n",
    "\n",
    "    ax = plt.axes(projection='3d')\n",
    "\n",
    "\n",
    "    for pep in range(len(x)):\n",
    "\n",
    "        # scatter points, making list from torch tensor item\n",
    "        ax.scatter3D([e.item() for e in x[pep]],[e.item() for e in y[pep]],[e.item() for e in z[pep]])\n",
    "\n",
    "    #return  plt.show(), [x,y,z], [x_median, y_median, z_median]         \n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from morphoscanner import backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class trajectory:\n",
    "\n",
    "    '''Class to operate on trajectory files.\n",
    "\n",
    "    It makes an object that contain the trajectory of the simulation'''\n",
    "\n",
    "\n",
    "\n",
    "    def __init__(self, trj_gro, trj_xtc):\n",
    "        \n",
    "        \n",
    "\n",
    "        self.trj_gro = trj_gro\n",
    "        self.trj_xtc = trj_xtc\n",
    "        self.universe = backend.topology.make_universe(self.trj_gro, self.trj_xtc)\n",
    "        self.number_of_frames = len(self.universe.trajectory)\n",
    "        self.number_of_BB_atoms = len(self.universe.select_atoms('name BB'))\n",
    "       \n",
    "        self.peptide_length_list = backend.topology.get_peptide_length_list(self.trj_gro)\n",
    "        self.len_dict = backend.topology.get_peptide_length_dict(self.peptide_length_list)\n",
    "        \n",
    "        self.coordinate, self.sequences = get_data_from_first_trajectory_frame(self.universe, 0, self.peptide_length_list)\n",
    "\n",
    "\n",
    "\n",
    "    def compose_database(self, peptide_length=None, start_from=0, interval=1):\n",
    "\n",
    "        self.peptide_length = peptide_length\n",
    "        self.start_from = start_from\n",
    "        self.interval = interval\n",
    "\n",
    "        self.data = backend.topology.get_coordinate_dict_from_trajectory(self.trj_gro, self.trj_xtc, peptide_length=self.peptide_length, start_from=self.start_from, interval=self.interval)\n",
    "        self.sampled_frames = [key for key in self.data.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "trj = trajectory(trj_gro,trj_xtc)\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj.sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe = mda.Universe(trj_gro, trj_xtc, in_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = universe.trajectory[150].positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = universe.trajectory[150].positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe.trajectory.dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe.trajectory.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_peptide_list(coordinate_dict, peptide_list=None, centroid=False):\n",
    "    '''Plot peptides from a trajectory frame.\n",
    "        Using jupyter-notebook, use '%matplotlib notebook' to\n",
    "        plot the points cloud in 3D.\n",
    "    \n",
    "    Inputs:     coordinate_dict, dict   Is the dict that contains all the coordinate\n",
    "                                        of the atoms of a single frame.\n",
    "                                        A single frame of the output of \n",
    "                                        backend.topology.get_coordinate_dict_from_trajectory \n",
    "                                        is a coordinate_dict.\n",
    "    \n",
    "                peptide_list, list.     is a list of int. Put here the index of the peptide\n",
    "                                        or peptides that you want to plot\n",
    "                                \n",
    "                centroid,   bool.       default=False \n",
    "                                        The centroid of a peptide can be plotted\n",
    "                                        in red together with the selected peptide.\n",
    "                                           \n",
    "                                        \n",
    "    Return:     show a 3D plot\n",
    "    '''\n",
    "    \n",
    "    # if there is only a single peptide to show\n",
    "    # use the single peptide function to normalize axis    \n",
    "    \n",
    "    if peptide_list == None:\n",
    "        peptide_list = [p for p in coordinate_dict]\n",
    "    \n",
    "    \n",
    "    if len(peptide_list) == 1:\n",
    "        \n",
    "        return plot_single_peptide(coordinate_dict[peptide_list[0]])\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        x = []\n",
    "        y = []\n",
    "        z = []\n",
    "        x_median = float\n",
    "        y_median = float\n",
    "        z_median = float\n",
    "\n",
    "\n",
    "        for peptide in range(len(peptide_list)):\n",
    "            x.append([peptide])\n",
    "            y.append([peptide])\n",
    "            z.append([peptide])\n",
    "            for aminoacid in coordinate_dict[peptide_list[peptide]]:\n",
    "\n",
    "                point = coordinate_dict[peptide_list[peptide]][aminoacid]\n",
    "                x[peptide].append(point[0])\n",
    "                y[peptide].append(point[1])\n",
    "                z[peptide].append(point[2])\n",
    "\n",
    "            del x[peptide][0]\n",
    "            del y[peptide][0]\n",
    "            del z[peptide][0]\n",
    "\n",
    "        if centroid == True:\n",
    "\n",
    "            def assemble_coordinate(axis_coordinate_list):\n",
    "                median_list = []\n",
    "                for coordinate_set in axis_coordinate_list:\n",
    "                    median = np.median(coordinate_set)\n",
    "                    median_list.append(median)\n",
    "                return median_list\n",
    "\n",
    "            x_median = assemble_coordinate(x)\n",
    "            y_median = assemble_coordinate(y)\n",
    "            z_median = assemble_coordinate(z)\n",
    "\n",
    "\n",
    "        #%matplotlib notebook\n",
    "\n",
    "        fig = plt.figure()\n",
    "\n",
    "        ax = plt.axes(projection='3d')\n",
    "\n",
    "\n",
    "        for pep in range(len(x)):\n",
    "\n",
    "            ax.scatter3D(x[pep],y[pep],z[pep])\n",
    "\n",
    "            if centroid == True:\n",
    "\n",
    "                ax.scatter3D(x_median[pep], y_median[pep], z_median[pep], c='red')\n",
    "\n",
    "\n",
    "        #return  plt.show(), [x,y,z], [x_median, y_median, z_median]         \n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = [i for i in range(100,1001,100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = [i for i in range(10,101,10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_for_compatibility(to_split,split_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from morphoscanner.backend.check_val import check_int_and_return, isInt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_dict = morphoscanner.backend.topology.get_peptide_length_dict(peptide_length_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_dict.get(96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_for_splitting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_split = check_input_multiple_int_recursive_with_sentence('Write the length of the peptides that you want to split (as an integer): ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_for_splitting(limit=5):\n",
    "\n",
    "    answer = input(\"Do you want to split peptides? Write 'yes' or 'no': \")\n",
    "    \n",
    "    if answer not in {'n','no','y','yes'}:\n",
    "        print('This is not a valid answer, please write yes or no.\\n'\n",
    "            '%d trial left.' % limit)\n",
    "        limit -= 1\n",
    "        if limit == 0:\n",
    "            raise sys.exit('Too many wrong inputs. Closing...')\n",
    "        else:\n",
    "            return ask_for_splitting(limit=limit)\n",
    "\n",
    "\n",
    "    elif answer in {'n', 'no'}:\n",
    "        print('The .gro topology file is set as reference for the analysis')\n",
    "        return False\n",
    "\n",
    "    elif answer in {'y', 'yes'}:\n",
    "        return True\n",
    "\n",
    "\n",
    "\n",
    "def check_input_multiple_int_recursive_with_sentence(sentence, limit=5):\n",
    "    \n",
    "    value = input(sentence)\n",
    "    input_list = value.split()\n",
    "    \n",
    "    if len(input_list) == 0:\n",
    "        limit -= 1\n",
    "        \n",
    "        if limit == 0:\n",
    "            raise sys.exit(\"Too many empty inputs. Closing...\")\n",
    "        else:\n",
    "            print('%d trial left.\\n'\n",
    "                  'You forgot to insert a value...please retry.' % limit)\n",
    "            return check_input_multiple_int_recursive_with_sentence(sentence=sentence, limit=limit)\n",
    "    \n",
    "    else:\n",
    "        va_list = []\n",
    "        for val in input_list:\n",
    "            \n",
    "            if isInt(val):\n",
    "                va_list.append(int(val))\n",
    "        \n",
    "                \n",
    "            else:\n",
    "                limit -= 1\n",
    "                print('%d trial left.' % (limit))\n",
    "                if limit == 0:\n",
    "                    raise sys.exit(\"%s is not an integer, it is of type %s...\\nClosing... \" % (str(val), type(val))) \n",
    "                else:\n",
    "                    print(\"%s is not an integer, it is of type %s...\\n \" % (str(val), type(val)))\n",
    "                    return check_input_multiple_int_recursive_with_sentence(sentence=sentence, limit=limit)\n",
    "        \n",
    "        return va_list\n",
    "    \n",
    "    \n",
    "def check_for_compatibility(list1, list2):\n",
    "    if len(list1) == len(list2):\n",
    "        \n",
    "        for e1, e2 in zip(list1, list2):\n",
    "            if e1%e2 != 0:\n",
    "                print('%d is not multiple of %d' % (e1,e2))\n",
    "                return False\n",
    "            \n",
    "        \n",
    "        else:\n",
    "            return True\n",
    "    \n",
    "    else:\n",
    "        raise ValueError('Your lists are of different len! list1 len = %d, list2 len = %d.' % (len(list1), len(list2)))\n",
    "\n",
    "\n",
    "def get_splitting_dict(to_split, split_size):\n",
    "    \n",
    "    splitting_dict = {}\n",
    "    \n",
    "    for length, split_dim in zip(to_split, split_size):\n",
    "        #check for divisibility\n",
    "        if (length%split_dim) == 0:\n",
    "            splitting_dict[length] = split_dim\n",
    "    \n",
    "    return splitting_dict\n",
    "\n",
    "def get_new_peptides_length(peptide_length_list, splitting_dict):\n",
    "    new_peptide_list = []\n",
    "    for pep_length in peptide_length_list:\n",
    "        if pep_length in splitting_dict.keys():\n",
    "            new_size = splitting_dict[pep_length]\n",
    "            new_peptide_list.extend([splitting_dict[pep_length] for p in range((pep_length//new_size))])\n",
    "        else:\n",
    "            new_peptide_list.append(pep_length)\n",
    "    \n",
    "    return new_peptide_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitting_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(new_peptide_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(peptide_length_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe = morphoscanner.backend.topology.make_universe(trj_gro,trj_xtc)\n",
    "peptide_length_list = morphoscanner.backend.topology.get_peptide_length_list(trj_gro)\n",
    "len_dict = morphoscanner.backend.topology.get_peptide_length_dict(peptide_length_list)\n",
    "morphoscanner.backend.topology.print_peptides_length(len_dict)\n",
    "have_to_split = ask_for_splitting()\n",
    "if have_to_split:\n",
    "    to_split = check_input_multiple_int_recursive_with_sentence('Write the length of the peptides that you want to split (as integer or list of integer separated by a space): ')\n",
    "    split_size = check_input_multiple_int_recursive_with_sentence('\\nWrite the length in which you want to split your peptides (as integer or list of integer separated by a space).\\n'\n",
    "                                                                 'The list should be of the same length of the list above, \\nthe numbers have to be divisors of the numbers inserted above. ')\n",
    "    compatible = check_for_compatibility(to_split, split_size)\n",
    "    if compatible:\n",
    "        splitting_dict = get_splitting_dict(to_split, split_size)\n",
    "        new_peptides_length = get_new_peptides_length(peptide_length_list, splitting_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "have_to_split = ask_for_splitting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(new_peptides_length) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from morphoscanner import backend\n",
    "from morphoscanner.backend.check_val import isInt\n",
    "import sys\n",
    "class trajectory:\n",
    "\n",
    "    '''Class to operate on trajectory files.\n",
    "\n",
    "    It makes an object that contain the trajectory of the simulation'''\n",
    "\n",
    "\n",
    "\n",
    "    def __init__(self, trj_gro, trj_xtc):\n",
    "        \n",
    "        self.trj_gro = trj_gro\n",
    "        self.trj_xtc = trj_xtc\n",
    "        self.universe = backend.topology.make_universe(self.trj_gro, self.trj_xtc)\n",
    "        self.number_of_frames = len(self.universe.trajectory)\n",
    "        self.number_of_BB_atoms = len(self.universe.select_atoms('name BB'))\n",
    "       \n",
    "        self.peptide_length_list = backend.topology.get_peptide_length_list(self.trj_gro)\n",
    "        self.len_dict = backend.topology.get_peptide_length_dict(self.peptide_length_list)\n",
    "        morphoscanner.backend.topology.print_peptides_length(self.len_dict)\n",
    "        \n",
    "        \n",
    "    def split(self, to_split, split_size):\n",
    "        '''Manually split peptide_length_list in case of seeds.\n",
    "        \n",
    "        Input:\n",
    "            to_split: list\n",
    "                list of int or ints.\n",
    "                Each int refers to the length of a peptides seed\n",
    "                from self.len_dict.keys() that you want to split in single peptide.\n",
    "                For example if in len dict there are seeds of length 96 that you want to split,\n",
    "                to_split = [96]\n",
    "                \n",
    "            split_size: list\n",
    "                list of int or ints.\n",
    "                This is the size in which you want to split your to_split seeds.\n",
    "                For example if you want to split your seeds of length 96 in peptides of length 12,\n",
    "                split_size = [12]\n",
    "                \n",
    "        Output:\n",
    "            Change the original self.peptide_length_list with a new list of splitted peptides.\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        splitting_dict = get_splitting_dict(to_split, split_size)\n",
    "        self.peptide_length_list = get_new_peptides_length(self.peptide_length_list, splitting_dict)\n",
    "        \n",
    "        #### TO USE IN MAIN.py\n",
    "        #have_to_split = ask_for_splitting()\n",
    "        \n",
    "        #if have_to_split:\n",
    "        #    to_split = check_input_multiple_int_recursive_with_sentence('Write the length of the peptides that you want to split (as integer or list of integer separated by a space): ')\n",
    "        #    split_size = check_input_multiple_int_recursive_with_sentence('\\nWrite the length in which you want to split your peptides (as integer or list of integer separated by a space).\\n'\n",
    "                                                                         'The list should be of the same length of the list above, \\nthe numbers have to be divisors of the numbers inserted above. ')\n",
    "        #    compatible = check_for_compatibility(to_split, split_size)\n",
    "        #    if compatible:\n",
    "        #        splitting_dict = get_splitting_dict(to_split, split_size)\n",
    "        #        self.peptide_length_list = get_new_peptides_length(self.peptide_length_list, splitting_dict)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test = trajectory(trj_gro, trj_xtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test.peptide_length_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly as px \n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_protein(coordinate_dict):\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "\n",
    "    for residue in coordinate_dict:\n",
    "        point = coordinate_dict[residue]\n",
    "        x.append(point[0])\n",
    "        y.append(point[1])\n",
    "        z.append(point[2])\n",
    "\n",
    "\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    z = np.asarray(z)\n",
    "\n",
    "    fig = go.Figure(data = [go.Scatter3d (x = x, y = y, z= z)])\n",
    "    return fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test.universe.trajectory.frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly as px \n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_protein(coordinate_dict):\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "\n",
    "    for residue in coordinate_dict:\n",
    "        point = coordinate_dict[residue]\n",
    "        x.append(point[0])\n",
    "        y.append(point[1])\n",
    "        z.append(point[2])\n",
    "\n",
    "\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    z = np.asarray(z)\n",
    "\n",
    "    fig = go.Figure(data = [go.Scatter3d (x = x, y = y, z= z)])\n",
    "    return fig.show()\n",
    "\n",
    "def heatmap2d(arr: np.ndarray):\n",
    "    plt.imshow(arr, cmap = 'viridis', interpolation = 'nearest')\n",
    "    plt.colorbar()\n",
    "    return plt.show()\n",
    "\n",
    "def get_euclidean_distance(point_1, point_2):\n",
    "\n",
    "    euclidean_distance = np.sqrt(np.sum([((point_1[0] - point_2[0])**2), ((point_1[1] - point_2[1])**2), ((point_1[2] - point_2[2])**2)]))\n",
    "\n",
    "    return euclidean_distance\n",
    "\n",
    "def compute_distance_map(coordinate_dict):\n",
    "    i = 0\n",
    "    distance_map = np.zeros((len(coordinate_dict),len(coordinate_dict)))\n",
    "    for  i  in range(i, len(coordinate_dict)-1):\n",
    "        coordinate_1 = coordinate_dict[i] \n",
    "        for j in range(0, len(coordinate_dict)-1):\n",
    "            coordinate_2 = coordinate_dict[j]\n",
    "            euclidean_distance = get_euclidean_distance(coordinate_1, coordinate_2)\n",
    "            distance_map[i][j] = euclidean_distance\n",
    "            distance_map[j][i] = euclidean_distance\n",
    "    return distance_map\n",
    "\n",
    "def contact_map_helix(distance_map):\n",
    "    contact_map = np.zeros((len(distance_map),len(distance_map)))\n",
    "    for i in range(1, len(distance_map)-1):\n",
    "        for j in range(1, len(distance_map)-1):\n",
    "            if 0.45 < distance_map[i][j] < 0.46:\n",
    "                contact_map[i][j] = 1\n",
    "            elif 0.52 < distance_map[i][j] < 0.56:\n",
    "                contact_map[i][j] = 2\n",
    "    return contact_map\n",
    "        \n",
    "\n",
    "\n",
    "#file = input(\"Select the pdb file: \")\n",
    "#file = lipase1\n",
    "#coordinate_dict = {}\n",
    "#atom = 0 \n",
    "#with open(file) as pdbfile:\n",
    "#    for line in pdbfile:\n",
    "#        if line[:4] == 'ATOM' or line[:6] == 'HETATM':\n",
    "#            #print (line)\n",
    "#            # Split the line\n",
    "#            splitted_line = [line[:6], line[6:11], line[12:16], line[17:20], line[21], line[22:26], line[30:38], line[38:46], line[46:54]]\n",
    "#            #print (splitted_line)\n",
    "#            type = splitted_line[2]\n",
    "#            residue = splitted_line[3]\n",
    "#            x = splitted_line[6]\n",
    "#            y = splitted_line[7]\n",
    "#            z = splitted_line[8]\n",
    "#            if type == ' CA ':\n",
    "#                #print (type)\n",
    "#                #print (x)\n",
    "#                coordinate_dict[atom] = [float(x)/10, float(y)/10, float(z)/10]\n",
    "#                atom = atom + 1 \n",
    "\t    # To format again the pdb file with the fields extracted\n",
    "                #print(\"%-6s%5s %4s %3s %s%4s    %8s%8s%8s\\n\"%tuple(splitted_line))\n",
    "#print (coordinate_dict[0][1])\n",
    "#print (len(coordinate_dict))\n",
    "#start = timer()\n",
    "#distance_map = compute_distance_map(coordinate_dict)\n",
    "#end = timer()\n",
    "#print(end-start)\n",
    "#contact_map = contact_map_helix(distance_map)\n",
    "#print (\"Minimum distance\", np.min(distance_map))\n",
    "#print (\"Maximum distance\", np.max(distance_map))\n",
    "#heatmap2d(distance_map)\n",
    "#heatmap2d(contact_map)\n",
    "#plot_protein(coordinate_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(distance_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(distance_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinate_from_pdb_initial(file):\n",
    "    coordinate_dict = {}\n",
    "    atom = 0\n",
    "    with open(file) as pdbfile:\n",
    "        for line in pdbfile:\n",
    "            if line[:4] == 'ATOM' or line[:6] == 'HETATM':\n",
    "                splitted_line = [line[:6], line[6:11], line[12:16], line[17:20], line[21], line[22:26], line[30:38], line[38:46], line[46:54]]\n",
    "                #_type = splitted_line[2]\n",
    "                _type = splitted_line[2].split()[0]\n",
    "                residue = splitted_line[3]\n",
    "                x = splitted_line[6]\n",
    "                y = splitted_line[7]\n",
    "                z = splitted_line[8]\n",
    "                #if _type == ' CA ':\n",
    "                if _type == 'CA'\n",
    "                    coordinate_dict[atom] = [float(x)/10, float(y)/10, float(z)/10]\n",
    "                    atom = atom + 1\n",
    "                    print(line)\n",
    "    \n",
    "    return coordinate_dict\n",
    "\n",
    "# type è una keyword in python\n",
    "# https://docs.python.org/3/library/functions.html#type\n",
    "#\n",
    "# type(variabile) ti dice di che data_type è l'argomento, ad esempio:\n",
    "# \n",
    "# type(8)\n",
    "# int\n",
    "#\n",
    "# si può sotituire con atom_type\n",
    "\n",
    "# ho rilevato un altra cosa quando si cerca 'CA'\n",
    "# usando lo split tale e quale, python cerca una stringa\n",
    "# che è esattamente uguale a quella inserita, spazi compresi.\n",
    "# ad esempio cercando _type == ' CA '\n",
    "# si trova questo atomo\n",
    "\n",
    "# ATOM   4113  CA  CYS A 449      28.234  26.178   2.996  1.00 32.35           C  \n",
    "\n",
    "# ma non questo\n",
    "#\n",
    "# HETATM 4120 CA    CA A 500      26.340  21.588  57.755  1.00 12.58          CA  \n",
    "#\n",
    "# Perché CA si trova spostato di uno spazio a sx.\n",
    "# Ho usato .split() come metodo per levare gli spazi,\n",
    "# ed in questo modo trova anche questi CA\n",
    "#\n",
    "# Non so adesso a cosa si riferisca questo CA in HETATM\n",
    "# farò ricerche in merito, per capire se è un carbonio-alfa e va effettivamente preso\n",
    "#\n",
    "# In ogni caso l'implementazione multichain fixa questi comportamenti\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(coordinate_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fede_dict = get_coordinate_from_pdb_initial(lipase1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fede_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = get_coordinate_from_pdb(lipase1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "433"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance_map(coordinate_dict):\n",
    "    #i = 0\n",
    "    distance_map = np.zeros((len(coordinate_dict),len(coordinate_dict)))\n",
    "    for  i  in range(len(coordinate_dict)-1):\n",
    "        coordinate_1 = coordinate_dict[i] \n",
    "        for j in range(0, len(coordinate_dict)-1):\n",
    "            coordinate_2 = coordinate_dict[j]\n",
    "            euclidean_distance = get_euclidean_distance(coordinate_1, coordinate_2)\n",
    "            distance_map[i][j] = euclidean_distance\n",
    "            distance_map[j][i] = euclidean_distance\n",
    "    return distance_map\n",
    "\n",
    "\n",
    "# in python non è necessario instanziare una variabile per contare i cicli\n",
    "# inoltre dichiarando:\n",
    "#    for  i  in range(i, len(coordinate_dict)-1):\n",
    "#\n",
    "# è equivalente a cambiare ad ogni ciclo il punto di partenza avanti di +1\n",
    "# che è quello che effettivamente è implicito nel ciclo, quindi ridondante\n",
    "# ed equivalente a scrivere:\n",
    "#    for  i  in range(len(coordinate_dict)-1):\n",
    "\n",
    "\n",
    "# Altra nota:\n",
    "# python si ferma sempre prima del numero specificato alla fine di un ciclo\n",
    "# per esempio, se scrivi:\n",
    "# [i for i in range(10)]\n",
    "# [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "# \n",
    "# va da 0 a 10-1, cioè 9\n",
    "#\n",
    "# Nel caso della funzione compute_distance_map\n",
    "# se printi 'i' e 'j'\n",
    "# ti accorgi che non arrivano all fine del dizionario, ma si fermano al penultimo punto\n",
    "# a causa di len(coordinate_dict)-1\n",
    "#\n",
    "# quindi se len(coordinate_dict) == 100\n",
    "# range(len(coordinate_dict)) va da 0 a 99, che sono effettivamente 100 elementi\n",
    "# \n",
    "# se però scrivi:\n",
    "# range(len(coordinate_dict)-1) va da 0 a 98, che sono 99 elementi\n",
    "# quindi perdi sempre l'ultima coppia di punti\n",
    "#\n",
    "# Te ne accorgi dal fatto che se guardi ogni mappa, l'ultima distanza è sempre uno 0\n",
    "# dato dallo 0 di np.zeros()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.065043390000028\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "fed_dist = compute_distance_map(my_dict)\n",
    "end = timer()\n",
    "print(end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "fede_dist = compute_distance_map(my_dict)\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(433, 433)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fed_dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance_map_fix(coordinate_dict):\n",
    "    '''\n",
    "    Compute pointwise distance map on a dict of coordinate\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    coordinate_dict : dict\n",
    "        The dict of coordinate, in the form {atom : [x, y, z]}.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    distance_map : numpy.ndarray\n",
    "        numpy.ndarray of shape (len(coordinate_dict), len(coordinate_dict))\n",
    "        each element i,j is the distance between the corresponding elements in\n",
    "        coordinate_dict[i] and coordinate_dict[j]\n",
    "\n",
    "    '''\n",
    "    # create zeros map\n",
    "    distance_map = np.zeros((len(coordinate_dict),len(coordinate_dict)))\n",
    "    # iterate through each dict element\n",
    "    for value1 in coordinate_dict:\n",
    "        # get element coordinate\n",
    "        coordinate_1 = coordinate_dict[value1]\n",
    "        # iterate in the upper triangle\n",
    "        # skip main diagonal because is 0 already (np.zeros)\n",
    "        for value2 in range(value1+1, len(coordinate_dict)):\n",
    "            # get secod element coordinate\n",
    "            coordinate_2 = coordinate_dict[value2]\n",
    "            # calculate distance\n",
    "            euclidean_distance = get_euclidean_distance(coordinate_1, coordinate_2)\n",
    "            # fill array with distance\n",
    "            distance_map[value1][value2] = euclidean_distance\n",
    "            # fill lower triangle with distance\n",
    "            distance_map[value2][value1] = euclidean_distance\n",
    "            \n",
    "    return distance_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dist = compute_distance_map_fix(my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(my_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fed_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fede_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  3.80248024,  7.04329532, 10.30477448, 13.67308663,\n",
       "       16.72574737, 18.47234628, 16.29406573, 13.7984273 , 10.07216769,\n",
       "        8.30680522,  5.61915794,  5.85328728,  7.14845564, 10.9280528 ,\n",
       "       13.17339675, 11.23991824, 10.88811173, 11.8916271 , 15.11031783,\n",
       "       18.69635713, 18.78192565, 15.56651306, 15.11431709, 13.4241022 ,\n",
       "        9.66159531,  9.08091323,  8.06818028, 11.17713331, 13.17953596,\n",
       "       14.58714451, 17.30422252, 19.79203916, 19.37616956, 19.66885632,\n",
       "       22.51801799, 23.35281298, 27.09025162, 29.621553  , 33.05849673,\n",
       "       35.72234385, 38.96814141, 41.65830705, 45.2332748 , 46.22864624,\n",
       "       44.07978668, 43.81812367, 43.91690271, 41.48353692, 38.25442267,\n",
       "       37.41117151, 33.92629886, 32.33917409, 29.18046252, 27.76624461,\n",
       "       27.36759334, 31.13700188, 33.28442332, 36.26928619, 35.35122429,\n",
       "       35.4419016 , 38.77486518, 40.52622198, 39.75873641, 41.73355711,\n",
       "       39.14557422, 41.46239454, 40.61493117, 43.38294837, 42.06418013,\n",
       "       39.31226119, 36.14190826, 34.71206571, 31.53497814, 31.30975019,\n",
       "       27.98086512, 28.16799865, 25.86586156, 24.73709963, 26.45881316,\n",
       "       28.53749453, 29.20684998, 30.17863514, 33.31519398, 34.5611928 ,\n",
       "       38.03389114, 37.2458849 , 35.34711536, 38.11599671, 40.72189333,\n",
       "       39.39916545, 39.66328799, 43.19668771, 44.28953697, 42.96096116,\n",
       "       45.07530319, 48.08251804, 47.70211202, 46.05475678, 45.05665041,\n",
       "       41.25695114, 38.48819281, 36.81076688, 33.37286284, 31.89999014,\n",
       "       28.16267581, 27.41889241, 23.87609114, 25.09858791, 22.67963053,\n",
       "       19.95522553, 22.29395961, 23.46818114, 20.1784543 , 19.93853463,\n",
       "       19.8454355 , 16.36451276, 15.22478381, 17.93971134, 16.85080324,\n",
       "       13.41913712, 15.47942809, 17.80245652, 15.21792266, 15.81769291,\n",
       "       19.49547265, 19.97294958, 18.69886577, 20.94699773, 23.88800272,\n",
       "       23.36533103, 23.50859179, 26.76610618, 28.21144252, 27.19785117,\n",
       "       29.07435311, 32.01036357, 32.21719459, 31.9128508 , 33.81416122,\n",
       "       36.15157337, 36.78255853, 36.11920558, 35.18143091, 32.28723173,\n",
       "       34.6852624 , 36.42480004, 33.4292931 , 33.18918556, 30.35625884,\n",
       "       31.2600024 , 28.65436759, 29.13714428, 26.8112429 , 23.19530198,\n",
       "       24.98839831, 25.93079345, 22.40435844, 21.70327489, 24.70771562,\n",
       "       23.21608117, 19.94289944, 22.31532469, 24.57027696, 21.9721425 ,\n",
       "       20.78424081, 24.52609624, 25.02609864, 27.38442088, 29.94457644,\n",
       "       30.15847055, 33.623248  , 32.93015316, 30.50854157, 32.16773345,\n",
       "       30.19193386, 31.86526564, 31.21608646, 27.52959428, 25.52036244,\n",
       "       25.29490652, 22.51343885, 18.98009718, 20.8157922 , 23.66633436,\n",
       "       23.11719494, 19.77727405, 19.70198361, 21.34338368, 18.21790476,\n",
       "       17.24380596, 20.90170141, 24.13978055, 26.16001229, 29.26036466,\n",
       "       27.47785106, 25.96050308, 29.36332997, 32.90559629, 34.11272909,\n",
       "       32.27891648, 34.48512076, 33.32303031, 35.37432011, 34.61008635,\n",
       "       36.217412  , 34.39267489, 33.22806388, 34.14517064, 31.90704803,\n",
       "       29.86813201, 30.71682401, 33.64189427, 34.80983472, 32.15722664,\n",
       "       31.96351121, 29.32985346, 29.44673051, 28.87325411, 31.81380182,\n",
       "       30.80386747, 31.61433047, 29.15053373, 31.57485989, 34.60213291,\n",
       "       36.7400952 , 35.8840407 , 38.43994426, 39.06322057, 41.43287827,\n",
       "       43.37491802, 41.49468147, 38.19229603, 38.62589146, 41.17228425,\n",
       "       42.13058834, 45.67939278, 45.85068161, 42.62307794, 44.00377372,\n",
       "       42.72489847, 39.84592584, 36.3624721 , 34.74254346, 37.99632235,\n",
       "       37.26574793, 33.86324028, 35.49638362, 38.33811796, 36.35979697,\n",
       "       36.4413411 , 40.13243063, 41.17973906, 39.42883454, 40.9740668 ,\n",
       "       44.42275032, 44.04502116, 44.11141147, 47.67867028, 48.64280093,\n",
       "       47.3070753 , 50.3935122 , 49.66702577, 46.66004981, 47.55048057,\n",
       "       45.23621293, 46.87089726, 45.35548422, 45.33728361, 43.6974366 ,\n",
       "       43.44083049, 44.60392831, 46.97031065, 48.82862966, 48.87561474,\n",
       "       50.41958549, 53.01355262, 54.26150579, 52.77111151, 50.72929596,\n",
       "       53.34983346, 54.4715922 , 52.02719917, 51.70347847, 53.84627601,\n",
       "       51.29965857, 51.022505  , 48.24946579, 45.15369295, 44.93220859,\n",
       "       41.90496401, 40.05365717, 40.61585624, 42.82070977, 41.24325455,\n",
       "       40.5603007 , 44.35567082, 44.45082323, 45.76192803, 43.68156312,\n",
       "       40.42013618, 37.91307612, 40.08495821, 38.18577981, 35.05855388,\n",
       "       34.97291841, 38.62480092, 39.47837508, 41.96152466, 43.73741745,\n",
       "       45.85274251, 46.81944582, 46.97157091, 48.83836257, 47.56455442,\n",
       "       47.82149832, 49.90847185, 48.29803618, 47.58233922, 49.41149022,\n",
       "       51.39176927, 53.51807535, 54.19259335, 57.74463931, 59.38513775,\n",
       "       62.90258527, 65.35645309, 68.45771219, 71.66086975, 73.63366916,\n",
       "       77.40021531, 79.88572931, 80.04556747, 77.43658497, 75.95019872,\n",
       "       72.72863662, 70.61875611, 67.95018635, 68.23317968, 66.46725692,\n",
       "       66.39025258, 65.83252923, 65.21107518, 67.08885116, 66.36768064,\n",
       "       66.72581214, 63.50672022, 64.01502331, 64.42824507, 61.93156391,\n",
       "       62.36122407, 63.92887805, 61.65762708, 62.71755401, 63.07660332,\n",
       "       64.35652733, 65.41913009, 67.82207306, 70.83336964, 72.13470439,\n",
       "       74.41312601, 76.55132745, 75.4942646 , 72.00917601, 69.03166397,\n",
       "       65.94291741, 62.80894418, 59.82287989, 56.95719447, 56.09891295,\n",
       "       54.06906988, 56.27072217, 55.21137886, 57.53420497, 57.98101051,\n",
       "       61.808494  , 62.11229068, 65.01751481, 66.60989577, 70.1770756 ,\n",
       "       70.95492776, 69.52266545, 70.69178709, 71.0923545 , 71.85340106,\n",
       "       71.66702233, 71.92347435, 73.52075145, 71.74633416, 75.23439297,\n",
       "       78.1326603 , 80.49893368, 83.97500812, 84.95972219, 83.37972597,\n",
       "       81.34041518, 80.34702079, 77.2992376 , 76.53983795, 74.27161186,\n",
       "       76.30179244, 73.2611502 , 69.76611936, 67.26889737, 64.22221275,\n",
       "       61.41013315, 58.96670177, 55.30676   , 56.68280484, 58.89949902,\n",
       "       62.2300515 , 64.81666614, 67.46998501, 70.46291746, 72.44077718,\n",
       "       75.70653416, 78.02246361, 81.44102512, 81.38323725, 80.07769975,\n",
       "       79.38858231, 79.51492716, 76.57781667, 74.726258  , 76.46184905,\n",
       "       74.61358939, 75.65739076, 74.96405774, 74.65041313, 75.51740742,\n",
       "       74.33869071, 75.80727945,  0.        ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fed_dist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "d_m = distance_matrix_from_2d_tensor(t_d)\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(d_m.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb_dict = get_coordinate_from_pdb(lipase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_dict['A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@author: lillo\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def get_coordinate_from_pdb(file):\n",
    "    '''\n",
    "    Parse a pdb file. Support single chain and multiple chain\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file : str\n",
    "        The path of the .pdb file in your system.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    coordinate_dict : dict\n",
    "        A dict of dict with the coordinate of each atom of the pdb file.\n",
    "        \n",
    "        Depending on the input file it has different levels of nesting:\n",
    "            \n",
    "            for single chain:\n",
    "                atom_index : [x,y,z]\n",
    "                \n",
    "            for multiple chain:\n",
    "                \n",
    "                chain_index : {atom index : [x,y,z]}\n",
    "    '''\n",
    "    \n",
    "    with open(file) as pdbfile:\n",
    "\n",
    "        coordinate_dict = {}\n",
    "        atom_count_dict = {}\n",
    "        start = 0\n",
    "\n",
    "        for line in pdbfile:\n",
    "            \n",
    "            # split line\n",
    "            splitted_line = [line[:6], line[6:11], line[12:16], line[17:20], line[21], line[22:26], line[30:38], line[38:46], line[46:54]]\n",
    "            # get line header\n",
    "            line_id = splitted_line[0].split()[0]\n",
    "            \n",
    "            #check for atom and heteroatom\n",
    "            if line_id in {'ATOM', 'HETATM'}:\n",
    "                \n",
    "                # get CA atom only\n",
    "                if splitted_line[2].split()[0] in {'CA'}:\n",
    "                    \n",
    "                    # get atom num for indexing\n",
    "                    atom_num = int(splitted_line[5])\n",
    "                    # get protein chain for indexing\n",
    "                    chain = splitted_line[4]\n",
    "                    # get coordinates\n",
    "                    x, y, z = float(splitted_line[6]), float(splitted_line[7]), float(splitted_line[8])\n",
    "                    \n",
    "                    # check if actual chain already has an entry in coordinate_dict\n",
    "                    if chain not in coordinate_dict.keys():\n",
    "                        \n",
    "                        # index from 'start'\n",
    "                        atom_count_dict[chain] = start\n",
    "                        # create key for new chain\n",
    "                        coordinate_dict[chain] = {}\n",
    "                        # put actual atom coordinates in coordinate_dict\n",
    "                        coordinate_dict[chain][atom_count_dict[chain]] = np.array([x,y,z])\n",
    "                    # if actual chain already in coordinate_dict\n",
    "                    else:\n",
    "                        # move index forward\n",
    "                        atom_count_dict[chain] += 1\n",
    "                        # add the atom coordinates\n",
    "                        coordinate_dict[chain][atom_count_dict[chain]] = np.array([x,y,z])\n",
    "\n",
    "    # if there is only one chain, flat the dict\n",
    "    if len(coordinate_dict) == 1:\n",
    "        coordinate_dict = coordinate_dict.get([k for k in coordinate_dict][0])\n",
    "\n",
    "    return coordinate_dict\n",
    "\n",
    "\n",
    "def get_coordinate_tensor_from_dict(coordinate_dict, device='cuda'):\n",
    "    '''\n",
    "        Convert a coordinate_dict to a torch.tensor, for parallel euclidean distance calculation.\n",
    "        Works on dict in the form {atom_key : [x, y, z]}\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    coordinate_dict : dict\n",
    "        Is the coordinate_dict in the form {key : [x, y, z]}.\n",
    "        It also works for N-dimensional points.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    zero : torch.tensor\n",
    "        Returns a torch.tensor of shape n x m\n",
    "        'n'  are the keys in coordinate_dict al len(coordinate_dict)\n",
    "        'm' is the number of dimensions of your data points\n",
    "        \n",
    "        It save on gpu if torch.cuda.is_available(), else on cpu\n",
    "        If you want to move your data on cpu, e.g. for visualization,\n",
    "        you need to output_tensor.cpu()\n",
    "    '''\n",
    "    \n",
    "\n",
    "    #variables wit dict dimension\n",
    "    dim0 = len(coordinate_dict)\n",
    "    first_key = [k for k in coordinate_dict.keys()][0]\n",
    "    dim1 = len(coordinate_dict[first_key])\n",
    "\n",
    "    #initialize a 0s tensor\n",
    "    #device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    zero = torch.zeros([dim0,dim1], dtype=torch.float32, device=device)\n",
    "\n",
    "    for index, peptide in enumerate(coordinate_dict):\n",
    "            \n",
    "        zero[index] = torch.tensor(coordinate_dict[peptide], device=device)\n",
    "                \n",
    "    return zero\n",
    "\n",
    "\n",
    "def get_tensors_from_multichain_dict(coordinate_dict):\n",
    "    '''\n",
    "    Generate tensor from multichain coordinate dict.\n",
    "    Your coordinate_dict is in the form:\n",
    "        \n",
    "        {chain : {atom : [x, y, z] }}\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    coordinate_dict : dict\n",
    "        Your coordinate_dict.\n",
    "        It is in the form:\n",
    "        {chain : {atom : [x, y, z] }}.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tensor_dict : dict\n",
    "        It is a dict of tensor, one tensor per chain.\n",
    "\n",
    "    '''\n",
    "    tensor_dict = {}\n",
    "    for chain in coordinate_dict:\n",
    "        tensor_dict[chain] = get_coordinate_tensor_from_dict(coordinate_dict[chain])\n",
    "    return tensor_dict\n",
    "\n",
    "\n",
    "def distance_matrix_from_2d_tensor(peptide1_tensor, peptide2_tensor=None, device='cpu'):\n",
    "    '''\n",
    "    Minimal function to calculate euclidean distance between two set of points\n",
    "    using quadratic expansion. Thanks to:\n",
    "            https://discuss.pytorch.org/t/efficient-distance-matrix-computation/9065\n",
    "            https://github.com/pytorch/pytorch/pull/25799\n",
    "            https://github.com/pytorch/pytorch/issues/15253\n",
    "    \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    peptide1_tensor : torch.tensor\n",
    "        torch.tensor of shape n x d.\n",
    "        \n",
    "    peptide2_tensor : torch.tensor, optional\n",
    "        The default is None.\n",
    "        torch.tensor for which you want to calculate te distance from peptide1_tensor\n",
    "        shape m x p\n",
    "        \n",
    "    device : str, optional\n",
    "        The default is 'cpu'.\n",
    "        Is the device on which to compute the calculation\n",
    "        You can set it to 'cuda' if you have an Nvidia GPU and CUDA driver installed\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    distance_map : torch.tensor\n",
    "        shape n x p\n",
    "        tensor with the distances data\n",
    "\n",
    "    '''\n",
    "    \n",
    "\n",
    "    if peptide2_tensor == None:\n",
    "        peptide2_tensor = peptide1_tensor\n",
    "\n",
    "    # calculate distance\n",
    "    x_norm = torch.pow(peptide1_tensor, 2).sum(1).view(-1,1)\n",
    "    y_t = torch.transpose(peptide2_tensor, 0, 1)\n",
    "    y_norm = torch.pow(peptide2_tensor, 2).sum(1).view(1,-1)\n",
    "    \n",
    "    distance_map = torch.sqrt(x_norm + y_norm - 2.0 * torch.mm(peptide1_tensor, y_t))\n",
    "    \n",
    "    # convert nan to 0  (using this instead of torch.clamp())       \n",
    "    distance_map[torch.isnan(distance_map)] = 0\n",
    "    \n",
    "    # if you are calculating pointwise distance a single tensor\n",
    "    # main diagonal is 0, to fix stability errors\n",
    "    if peptide1_tensor is peptide2_tensor:\n",
    "        distance_map = distance_map.fill_diagonal_(0)\n",
    "    \n",
    "    return distance_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lip = get_coordinate_from_pdb(lipase1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_lip = get_coordinate_tensor_from_dict(lip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "t_dist = distance_matrix_from_2d_tensor(t_lip)\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(t_dist.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_dict_key = {k for k in coordinate_dict.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lip_key = {k for k in lip.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in c_dict_key:\n",
    "    if i not in lip_key:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in lip_key:\n",
    "    if i not in c_dict_key:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "fede_distance = compute_distance_map(lip)\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "t_lip = get_coordinate_tensor_from_dict(lip)\n",
    "end = timer()\n",
    "print(end - start)\n",
    "\n",
    "start = timer()\n",
    "my_dist = distance_matrix_from_2d_tensor(t_lip)\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Zero out negative values\n",
    "    #res.clamp_min_(1e-30).sqrt_()\n",
    "    #res.sqrt()\n",
    "    #res[res < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_cdist(x1, x2):\n",
    "    adjustment = x1.mean(-2, keepdim=True)\n",
    "    x1 = x1 - adjustment\n",
    "    x2 = x2 - adjustment  # x1 and x2 should be identical in all dims except -2 at this point\n",
    "\n",
    "    # Compute squared distance matrix using quadratic expansion\n",
    "    # But be clever and do it with a single matmul call\n",
    "    x1_norm = x1.pow(2).sum(dim=-1, keepdim=True)\n",
    "    x1_pad = torch.ones_like(x1_norm)\n",
    "    x2_norm = x2.pow(2).sum(dim=-1, keepdim=True)\n",
    "    x2_pad = torch.ones_like(x2_norm)\n",
    "    x1_ = torch.cat([-2. * x1, x1_norm, x1_pad], dim=-1)\n",
    "    x2_ = torch.cat([x2, x2_pad, x2_norm], dim=-1)\n",
    "    res = x1_.matmul(x2_.transpose(-2, -1))\n",
    "\n",
    "    # Zero out negative values\n",
    "    #res.clamp_min_(1e-30).sqrt_()\n",
    "    res = res.sqrt()\n",
    "    res[torch.isnan(res)]=0\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "f_dist = fast_cdist(t_lip, t_lip)\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinate_dict = get_coordinate_from_pdb(lipase1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def compute_distance_map(coordinate_dict):\n",
    "i = 0\n",
    "distance_map = np.zeros((len(coordinate_dict),len(coordinate_dict)))\n",
    "for i in range(i, len(coordinate_dict)-1):\n",
    "    coordinate_1 = coordinate_dict[i] \n",
    "    for j in range(0, len(coordinate_dict)-1):\n",
    "        coordinate_2 = coordinate_dict[j]\n",
    "        euclidean_distance = get_euclidean_distance(coordinate_1, coordinate_2)\n",
    "        distance_map[i][j] = euclidean_distance\n",
    "        distance_map[j][i] = euclidean_distance\n",
    " #   return distance_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(coordinate_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in coordinate_dict:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_tens = get_coordinate_tensor_from_dict(coordinate_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_dist = distance_matrix_from_2d_tensor(c_tens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance_map_fix(coordinate_dict):\n",
    "    distance_map = np.zeros((len(coordinate_dict),len(coordinate_dict)))\n",
    "    for value1 in coordinate_dict:\n",
    "        coordinate_1 = coordinate_dict[value1] \n",
    "        for value2 in range(value1+1, len(coordinate_dict)):\n",
    "            coordinate_2 = coordinate_dict[value2]\n",
    "            euclidean_distance = get_euclidean_distance(coordinate_1, coordinate_2)\n",
    "            distance_map[value1][value2] = euclidean_distance\n",
    "            distance_map[value2][value1] = euclidean_distance\n",
    "    return distance_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "distance_map = compute_distance_map(coordinate_dict)\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(distance_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

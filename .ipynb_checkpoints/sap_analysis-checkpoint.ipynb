{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "\n",
    "from mpl_toolkits import mplot3d\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "#from functools import lru_cache\n",
    "#import re\n",
    "import networkx as nx\n",
    "from networkx.algorithms import approximation\n",
    "\n",
    "import MDAnalysis as mda\n",
    "\n",
    "import scipy\n",
    "import sklearn\n",
    "import skimage\n",
    "\n",
    "#import xml.etree.ElementTree as et\n",
    "from Bio.PDB import *\n",
    "import nglview as nv\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "\n",
    "\n",
    "# http://nglviewer.org/nglview/latest/api.html\n",
    "# https://biopython.org/wiki/The_Biopython_Structural_Bioinformatics_FAQ\n",
    "# https://ambermd.org/tutorials/analysis/tutorial_notebooks/nglview_notebook/index.html\n",
    "# https://amber-md.github.io/pytraj/latest/_api/pytraj.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contact_matrix = np.loadtxt('/home/lillo/TesiCNTE/CNTE/dataset/contact_matrix.txt')   #laptop\n",
    "#contact_matrix = np.loadtxt('/home/lillo/Code/Tesi/dataset/contact_matrix.txt')        #fisso\n",
    "#contact_matrix_single = contact_matrix.reshape(100,100,12,12)\n",
    "\n",
    "#gromacs_output = open('/home/lillo/Code/Tesi/dataset/dm4500Compl_mix1_K2_1%4500ns.gro') #fisso\n",
    "#gromacs_output = open('/home/lillo/TesiCNTE/CNTE/dataset/dm4500Compl_mix1_K2_1%4500ns.gro') #laptop\n",
    "\n",
    "path = '/home/lillo/Code/Tesi/dataset/dm4500Compl_mix1_K2_1%4500ns.gro' #fisso\n",
    "#path = '/home/lillo/TesiCNTE/CNTE/dataset/dm4500Compl_mix1_K2_1%4500ns.gro' #laptop\n",
    "\n",
    "# import 2mxu file (beta sheet)\n",
    "\n",
    "#path_to_mmCIF = open('/home/lillo/TesiCNTE/pdb/2mxu/2mxu.cif')  ## laptop\n",
    "#path_to_pdb = '/home/lillo/TesiCNTE/pdb/2mxu/2mxu.pdb'  ## laptop\n",
    "#pa_to_pdb = '/home/lillo/TesiCNTE/pdb/2mxu/2mxu.pdb'  ## laptop\n",
    "\n",
    "#path_to_mmCIF = open('/home/lillo/Code/Tesi/pdb/2mxu/2mxu.cif')  ## fisso\n",
    "path_to_pdb = '/home/lillo/Code/Tesi/pdb/2mxu/2mxu.pdb'  ## fisso\n",
    "#pa_to_pdb = '/home/lillo/Code/Tesi/pdb/2mxu/2mxu.pdb'  ## fisso\n",
    "\n",
    "#seed_1_path = '/home/lillo/TesiCNTE/from_cluster/aggregate1.gro' # laptop\n",
    "seed_1_path = '/home/lillo/Code/Tesi/dataset/aggregate1.gro' # Fisso\n",
    "\n",
    "trj_xtc = '/home/lillo/TesiCNTE/CNTE/trajectory/prd-LDLK12-100mer-out-mol.xtc'  #laptop\n",
    "trj_gro = '/home/lillo/TesiCNTE/CNTE/trajectory/min-LDLK12-100mer-out-c.gro'  #laptop\n",
    "\n",
    "trj_xtc = '/home/lillo/Code/Tesi/dataset/trajectory_6_12_19/prd-LDLK12-100mer-out-mol.xtc'  #fisso\n",
    "trj_gro = '/home/lillo/Code/Tesi/dataset/trajectory_6_12_19/min-LDLK12-100mer-out-c.gro'  #fisso\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ .gro FILE AND PREPROCESSING\n",
    "\n",
    "def clean_gro(path):\n",
    "    \n",
    "    \n",
    "    # open file .gro and return a list with one element per line of the .gro file\n",
    "    def read_gro(path):\n",
    "        gromacs_output = open(path)\n",
    "\n",
    "        gro_file = []\n",
    "        for line in tqdm.tqdm(gromacs_output):\n",
    "            gro_file.append(line)\n",
    "\n",
    "\n",
    "\n",
    "        gromacs_output.close()        \n",
    "\n",
    "        return gro_file\n",
    "\n",
    "\n",
    "\n",
    "    # return string in a string with numbers\n",
    "    def return_if_string(string):\n",
    "        digits = []\n",
    "        for i in string:\n",
    "            if not i.isdigit():\n",
    "                digits.append(i)\n",
    "\n",
    "        string = ''.join(digits)\n",
    "\n",
    "        return string\n",
    "\n",
    "\n",
    "    # return numbers in a string with numbers\n",
    "    def return_if_digit(string):\n",
    "        digits = []\n",
    "        for i in string:\n",
    "            if i.isdigit():\n",
    "                digits.append(i)\n",
    "\n",
    "        string = ''.join(digits)\n",
    "\n",
    "        return string\n",
    "\n",
    "\n",
    "    # remove first, second and last lines from gro_file and reorder information\n",
    "    def clean_gro_file(gro_file):\n",
    "        cleaned_gro_file = []\n",
    "        for aminoacid in tqdm.tqdm(gro_file[2:-1]):\n",
    "            splitted = aminoacid.split()\n",
    "            position_in_peptide = return_if_digit(splitted[0])\n",
    "            residue = return_if_string(splitted[0])\n",
    "            index = splitted[2]\n",
    "            x = splitted[3]\n",
    "            y = splitted[4]\n",
    "            z = splitted[5]\n",
    "            cleaned_gro_file.append([index, position_in_peptide, residue, x, y, z])\n",
    "        return cleaned_gro_file\n",
    "    \n",
    "    \n",
    "    \n",
    "    gro_file = read_gro(path)\n",
    "    cleaned_gro_file = clean_gro_file(gro_file)\n",
    "\n",
    "    return cleaned_gro_file\n",
    "\n",
    "\n",
    "# create coordinate dict from cleaned_gro_file\n",
    "def get_coordinate_dict_from_cleaned_gro(cleaned_gro_file):\n",
    "    \n",
    "    peptide_lenght_list = []\n",
    "\n",
    "    temporary_list = []\n",
    "\n",
    "    # iterate trough cleaned_gro_file\n",
    "    for residue in cleaned_gro_file:\n",
    "\n",
    "        # if temporary list just started, add aminoacid position in chain\n",
    "        if len(temporary_list) == 0:\n",
    "            temporary_list.append(int(residue[1]))\n",
    "\n",
    "        else:\n",
    "            # if position of actual residue is less than last residue\n",
    "            if temporary_list[-1] > int(residue[1]):\n",
    "\n",
    "                # append lenght of last peptide to peptide lenght list\n",
    "                peptide_lenght_list.append(len(temporary_list))\n",
    "\n",
    "                # empty temporary list\n",
    "                temporary_list = []\n",
    "\n",
    "                # append actual residue position\n",
    "                temporary_list.append(int(residue[1]))\n",
    "\n",
    "            # if position of actual residue is higher than last residue, ad current residue position\n",
    "            else:\n",
    "                temporary_list.append(int(residue[1]))\n",
    "\n",
    "    # append last peptide lenght to lenght stack\n",
    "    peptide_lenght_list.append(len(temporary_list))\n",
    "\n",
    "    # create empty dict for coordinate\n",
    "    peptide_coordinate_dict = {}\n",
    "\n",
    "    # create an entry in dict for every peptide in the file\n",
    "    for peptide in range(len(peptide_lenght_list)):\n",
    "        peptide_coordinate_dict[peptide] = {}\n",
    "\n",
    "        # for every residue in lenght peptide, add coordinate x, y, z\n",
    "        for residue in range(peptide_lenght_list[peptide]):\n",
    "            peptide_coordinate_dict[peptide][residue] = [float(coordinate) for coordinate in cleaned_gro_file[(peptide * peptide_lenght_list[peptide])+residue][3:]]\n",
    "\n",
    "    return peptide_coordinate_dict\n",
    "\n",
    "\n",
    "# compute euclidean distance\n",
    "def get_euclidean_distance(point_1, point_2):\n",
    "    \n",
    "    euclidean_distance = np.sqrt(np.sum([((point_1[0] - point_2[0])**2), ((point_1[1] - point_2[1])**2), ((point_1[2] - point_2[2])**2)]))\n",
    "\n",
    "    return euclidean_distance\n",
    "\n",
    "# compute distance map between two peptides\n",
    "def compute_distance_map(coordinate_dict, peptide_1, peptide_2):\n",
    "\n",
    "    distance_map = []\n",
    "    for amino_1 in coordinate_dict[peptide_1]:\n",
    "        coordinate_1 = coordinate_dict[peptide_1][amino_1]\n",
    "        \n",
    "        distance_map.append([amino_1])\n",
    "        \n",
    "        for amino_2 in coordinate_dict[peptide_2]:\n",
    "            coordinate_2 = coordinate_dict[peptide_2][amino_2]\n",
    "            \n",
    "            euclidean_distance = get_euclidean_distance(coordinate_1, coordinate_2)\n",
    "            distance_map[amino_1].append(euclidean_distance)\n",
    "        \n",
    "        del distance_map[amino_1][0]\n",
    "\n",
    "    distance_map = np.asarray(distance_map)\n",
    "    \n",
    "    return distance_map\n",
    "\n",
    "# compute distance map and return a n_peptide x n_peptide x n_res x n_res array\n",
    "def compute_distance_maps_from_coordinate_dict(coordinate_dict):\n",
    "    \n",
    "    aggregate_distance_map = []\n",
    "\n",
    "    #for peptide_1 in tqdm.tqdm(coordinate_dict):\n",
    "    for peptide_1 in coordinate_dict:\n",
    "        aggregate_distance_map.append([peptide_1])\n",
    "        \n",
    "        #for peptide_2 in tqdm.tqdm(coordinate_dict):\n",
    "        for peptide_2 in coordinate_dict:\n",
    "            distance_map = compute_distance_map(coordinate_dict, peptide_1, peptide_2)\n",
    "            \n",
    "            aggregate_distance_map[peptide_1].append(distance_map)\n",
    "\n",
    "        del aggregate_distance_map[peptide_1][0]\n",
    "\n",
    "    aggregate_distance_array = np.asarray(aggregate_distance_map)\n",
    "    \n",
    "    return aggregate_distance_array\n",
    "\n",
    "\n",
    "# COMPUTE CONTACT MAPS\n",
    "# TO DO: parametrize the threshold distance in a better way (e.g. )\n",
    "def compute_contact_maps_as_array(distance_maps_array):\n",
    "    \n",
    "# distance between the first and the second aminoacid of the first chain\n",
    "    intrapeptide_minimum_distance = distance_maps_array[0][0][0][1] \n",
    "\n",
    "    contact_map_list = []\n",
    "\n",
    "    # contact is in a distance uo to 138% of the intrapeptide_minimum_distance\n",
    "    threshold_distance = (intrapeptide_minimum_distance * 1.5)\n",
    "\n",
    "    for model_1 in range(distance_maps_array.shape[0]):\n",
    "        contact_map_list.append([])\n",
    "        for model_2 in range(distance_maps_array[model_1].shape[0]):\n",
    "\n",
    "            contact_map_list[model_1].append([])\n",
    "\n",
    "            if model_1 == model_2:\n",
    "\n",
    "                contact_map_list[model_1][model_2].extend(np.zeros((distance_maps_array.shape[2], distance_maps_array.shape[3])))\n",
    "\n",
    "            else:\n",
    "\n",
    "                contact_map = np.zeros((distance_maps_array.shape[2], distance_maps_array.shape[3]))\n",
    "\n",
    "                for chain_1 in range(distance_maps_array[model_1][model_2].shape[0]):\n",
    "\n",
    "                    for chain_2 in range(distance_maps_array[model_1][model_2][chain_1].shape[0]):\n",
    "\n",
    "                        distance = distance_maps_array[model_1][model_2][chain_1][chain_2]\n",
    "\n",
    "                        if distance < threshold_distance:\n",
    "                            contact_map[chain_1][chain_2] = 1 #True\n",
    "                        else:\n",
    "                            pass\n",
    "\n",
    "                contact_map_list[model_1][model_2].extend(contact_map)\n",
    "    \n",
    "    contact_array = np.asarray(contact_map_list)\n",
    "            \n",
    "    return contact_array\n",
    "\n",
    "\n",
    "#### ANALYSIS\n",
    "\n",
    "def shift_library_maker(contact_map_to_analyze):\n",
    "    \n",
    "    ''' riceve numero di righe e di colonne\n",
    "    restituisce un array shape((((row + col)*2)-2),row,col).\n",
    "    ogni slice è una diagonale. Lo stack copre le diagonali su tutta la matrice'''\n",
    "    \n",
    "    row = contact_map_to_analyze.shape[0]\n",
    "    col = contact_map_to_analyze.shape[1]\n",
    "    \n",
    "    kron_dict = {}\n",
    "    kron_list_parallel = []\n",
    "    kron_list_antiparallel = []\n",
    "    \n",
    "    for e in range(-row+1, col):\n",
    "        array = np.eye(row, col, e)\n",
    "        kron_list_parallel.append(array)\n",
    "        kron_list_antiparallel.append(np.fliplr(array))\n",
    "        \n",
    "    kron_array_parallel = np.asarray(kron_list_parallel)\n",
    "    kron_array_antiparallel = np.asarray(kron_list_antiparallel)\n",
    "    \n",
    "    kron_dict['parallel'] = kron_array_parallel\n",
    "    kron_dict['antiparallel'] = kron_array_antiparallel\n",
    "    \n",
    "    return kron_dict\n",
    "\n",
    "\n",
    "def normalized_cross_correlation_function(contact_map):\n",
    "    '''\n",
    "    Calculate normalized cross correlation function between a contact map and an ideal map.\n",
    "    \n",
    "    Arguments : contact map, as output from get_contact_maps function\n",
    "                shift_matrix_stack, as output from shift_matrix_maker function\n",
    "                \n",
    "    Return : a list [ncc_value, index (in the shift_matrix_stack) of the shift matrix\n",
    "                that is matching the contact map\n",
    "            \n",
    "            '''\n",
    "    shift_matrix_library = shift_library_maker(contact_map)\n",
    "    \n",
    "    cross_correlation_values = []\n",
    "    max_val = []\n",
    "    sum_contact_map = np.sum(contact_map)\n",
    "    \n",
    "    if sum_contact_map < 2:\n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "        for sense in shift_matrix_library:\n",
    "            for index, z in enumerate(shift_matrix_library[sense]):\n",
    "\n",
    "                shift_matrix = shift_matrix_library[sense][index]\n",
    "                sum_shift_matrix = np.sum(shift_matrix)\n",
    "                ncc_value = (np.sum((contact_map * shift_matrix))/((np.sqrt(sum_contact_map))*(np.sqrt(sum_shift_matrix))))  # normalized cross correlation function of contact matrix and shift matrix\n",
    "                cross_correlation_values.append([ncc_value, index, sum_contact_map, sense])\n",
    "\n",
    "            max_val = max(cross_correlation_values) # get only the best match (highest value of ncc)\n",
    "\n",
    "    return max_val\n",
    "\n",
    "\n",
    "\n",
    "def normalized_cross_correlation_for_dataset(contact_array):\n",
    "    '''Calculate normalized cross correlation function between the full contacts map and and the .\n",
    "    \n",
    "    Arguments : contact map, as output from get_contact_maps function\n",
    "                shift_matrix_stack, as output from shift_matrix_maker function\n",
    "                \n",
    "    Return : a list [ncc_value, index (in the shift_matrix_stack) of the shift matrix that is matching the contact map'''\n",
    "    \n",
    "    contact_dict = {}\n",
    "    \n",
    "    #for row in tqdm.tqdm(range(contact_array.shape[0])):\n",
    "    for row in range(contact_array.shape[0]):\n",
    "    \n",
    "        for col in range((row+1), contact_array.shape[1]):\n",
    "        #for col in range(contact_array.shape[1]):\n",
    "\n",
    "            best_match = []\n",
    "            best_match = normalized_cross_correlation_function(contact_array[row][col])\n",
    "            \n",
    "            if len(best_match) == 0:\n",
    "                pass\n",
    "            \n",
    "            else:\n",
    "                if row in contact_dict:\n",
    "                    contact_dict[row].append([row, col, best_match])\n",
    "                \n",
    "                else:\n",
    "                    contact_dict[row] = [[row, col, best_match]]\n",
    "    \n",
    "    return contact_dict\n",
    "\n",
    "\n",
    "#denoise dataset\n",
    "def denoise_full_dataset(contact_maps, normalized_cross_correlation_results):\n",
    "    \n",
    "    '''Denoise the contact_maps dataset using the shift_matrix\n",
    "    \n",
    "    Arguments : contact_maps, normalized_cross_correlation_result\n",
    "    \n",
    "    return : a dict with key:value = row : row, col, denoised_map\n",
    "    \n",
    "    '''\n",
    "\n",
    "    denoised_dict = {}\n",
    "\n",
    "    for peptide_1 in normalized_cross_correlation_results:\n",
    "        denoised_dict[peptide_1] = {}\n",
    "        for index, peptide_2 in enumerate(normalized_cross_correlation_results[peptide_1]):\n",
    "\n",
    "            row = peptide_2[0]\n",
    "            col = peptide_2[1]\n",
    "\n",
    "\n",
    "\n",
    "            contact_map = contact_maps[row][col]\n",
    "            sense = peptide_2[2][3]\n",
    "            shift_matrix_index = normalized_cross_correlation_results[peptide_1][index][2][1]\n",
    "\n",
    "            shift_matrix = shift_library_maker(contact_map)\n",
    "            shift_matrix = shift_matrix[sense][shift_matrix_index]\n",
    "            denoised_map = contact_map * shift_matrix\n",
    "\n",
    "            denoised_dict[row][col] = denoised_map\n",
    "            \n",
    "    return denoised_dict\n",
    "\n",
    "\n",
    "#create a dict that contains the peptide couples contact and the specular peptide couples contact\n",
    "def reconstruct_full_matrix(denoised_dict):\n",
    "    full_denoised_dict = {}\n",
    "    for peptide_1 in tqdm.tqdm(denoised_dict):\n",
    "        for peptide_2 in denoised_dict[peptide_1]:\n",
    "            contact_map = denoised_dict[peptide_1][peptide_2]\n",
    "\n",
    "            if peptide_1 in full_denoised_dict:\n",
    "                full_denoised_dict[peptide_1][peptide_2] = contact_map\n",
    "\n",
    "            if peptide_1 not in full_denoised_dict:\n",
    "                full_denoised_dict[peptide_1] = {peptide_2:contact_map}\n",
    "\n",
    "            if peptide_2 in full_denoised_dict:\n",
    "                full_denoised_dict[peptide_2][peptide_1] = contact_map.T\n",
    "\n",
    "            if peptide_2 not in full_denoised_dict:\n",
    "                full_denoised_dict[peptide_2] = {peptide_1:contact_map.T}\n",
    "    \n",
    "    return full_denoised_dict\n",
    "\n",
    "\n",
    "# take array, return vector with sum along columns\n",
    "def get_row_vector(array):\n",
    "    row_vector = np.sum(array, axis=0)\n",
    "    return row_vector\n",
    "\n",
    "# take array, return vector with sum along row\n",
    "def get_col_vector(array):\n",
    "    col_vector = np.sum(array, axis=1)\n",
    "    return col_vector\n",
    "\n",
    "# graph clustering\n",
    "def nx_graph_search(denoised_dict):\n",
    "    \n",
    "    graph = nx.MultiGraph()\n",
    "    \n",
    "    for peptide_1 in denoised_dict:\n",
    "        for peptide_2 in denoised_dict[peptide_1]:\n",
    "            array_1 = denoised_dict[peptide_1][peptide_2]\n",
    "            for peptide_3 in denoised_dict[peptide_2]:\n",
    "                if peptide_3 != peptide_1:\n",
    "                    array_2 = denoised_dict[peptide_2][peptide_3]\n",
    "\n",
    "                    vect_1 = get_row_vector(array_1)\n",
    "                    vect_2 = get_col_vector(array_2)\n",
    "\n",
    "                    contacts = np.dot(vect_1, vect_2)\n",
    "                    \n",
    "                    if contacts >= 3:\n",
    "\n",
    "                        graph.add_edge(peptide_1, peptide_2)\n",
    "                     \n",
    "                        graph.add_edge(peptide_2, peptide_3)\n",
    "\n",
    "    return graph\n",
    "\n",
    "#A novel graph clustering algorithm based on discrete-time quantum random walk\n",
    "#S.G. Roya, A. Chakrabarti\n",
    "\n",
    "\n",
    "# working with networkX\n",
    "# if contacts >= target\n",
    "\n",
    "# when you add_edge, nodes are created if they are not there\n",
    "# you can put info in edge (as distance, n of contacts, contact map)\n",
    "# you HAVE TO (but you can not also) put key to index multiple nodes that are joined with a single node\n",
    "# \n",
    "# add edge from pep1 to pep2 (you HAVE TO (###to explore utility of key) put key to index multiple nodes that are joined with a single node)\n",
    "# add edge from pep3 to pep3 ( same as before with key)\n",
    "\n",
    "\n",
    "#FIND SUBGRAPH\n",
    "def find_subgraph(graph):\n",
    "    '''\n",
    "    Find subgraph that have no node in common.\n",
    "    \n",
    "    Argument: NetworkX MultiGraph\n",
    "    \n",
    "    Return: list of subgraph ordered from one end to the other\n",
    "    \n",
    "    '''\n",
    "\n",
    "    subgraph_list = []\n",
    "    \n",
    "    for node in graph:\n",
    "        \n",
    "        # don't explore node that are already in subgraph_list\n",
    "        if node not in set(nod for nod_list in subgraph_list for nod in nod_list):\n",
    "            \n",
    "            # tree is the list of nodes joined to node, starting from node\n",
    "            # using depht first search\n",
    "            tree = [e for e in nx.algorithms.traversal.depth_first_search.dfs_tree(graph, node)]\n",
    "            \n",
    "            # check if the first node of the tree has adjiacency == 1\n",
    "            # so it checks if it is the first or last node of the subgraph\n",
    "            if len(graph[tree[0]]) == 1:\n",
    "                \n",
    "                if len(subgraph_list) == 0:\n",
    "                    subgraph_list.append(tree)\n",
    "                    \n",
    "                else:\n",
    "                    # use generator to check if the tree is already in the subgraph\n",
    "                    if set(tree) not in (set(i) for i in subgraph_list):\n",
    "                        subgraph_list.append(tree)\n",
    "                        \n",
    "    return subgraph_list\n",
    "\n",
    "\n",
    "########## PLOT PEPTIDE LIST\n",
    "# plot a list of peptide point cloud in 3d space.\n",
    "# The box axis have arbitrary scale dependent on the aminoacids distance\n",
    "# you can select to show the centroid\n",
    "def plot_peptide_list(coordinate_dict, peptide_list, centroid=False):\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "    x_median = float\n",
    "    y_median = float\n",
    "    z_median = float\n",
    "    \n",
    "\n",
    "    for peptide in range(len(peptide_list)):\n",
    "        x.append([peptide])\n",
    "        y.append([peptide])\n",
    "        z.append([peptide])\n",
    "        for aminoacid in coordinate_dict[peptide_list[peptide]]:\n",
    "\n",
    "            point = coordinate_dict[peptide_list[peptide]][aminoacid]\n",
    "            x[peptide].append(point[0])\n",
    "            y[peptide].append(point[1])\n",
    "            z[peptide].append(point[2])\n",
    "\n",
    "        del x[peptide][0]\n",
    "        del y[peptide][0]\n",
    "        del z[peptide][0]\n",
    "        \n",
    "    if centroid == True:\n",
    "        \n",
    "        def assemble_coordinate(axis_coordinate_list):\n",
    "            median_list = []\n",
    "            for coordinate_set in axis_coordinate_list:\n",
    "                median = np.median(coordinate_set)\n",
    "                median_list.append(median)\n",
    "            return median_list\n",
    "        \n",
    "        x_median = assemble_coordinate(x)\n",
    "        y_median = assemble_coordinate(y)\n",
    "        z_median = assemble_coordinate(z)\n",
    "        \n",
    "        \n",
    "                \n",
    "        \n",
    "\n",
    "    #%matplotlib notebook\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes(projection='3d')\n",
    "\n",
    "\n",
    "    \n",
    "    for pep in range(len(x)):\n",
    "       \n",
    "        ax.scatter3D(x[pep],y[pep],z[pep])\n",
    "        \n",
    "        if centroid == True:\n",
    "            \n",
    "            ax.scatter3D(x_median[pep], y_median[pep], z_median[pep], c='red')\n",
    "            \n",
    "        \n",
    "    return  plt.show(), [x,y,z], [x_median, y_median, z_median]\n",
    "\n",
    "\n",
    "\n",
    "# get average distance map from distance maps set\n",
    "def get_mean_distance_map(distance_maps):\n",
    "    '''\n",
    "    Calculate mean distance map from distance maps set\n",
    "    \n",
    "    Argument: distance maps set\n",
    "    \n",
    "    return: np.array with average intrapeptide distance\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # create array of zeros of shape number_of_residues * number_of_residues\n",
    "    # depending on peptide residue number ### TO FIX FOR MULTIMONOMERIC ASSEMBLY\n",
    "    base = np.zeros((distance_maps[0][0].shape[0], distance_maps[0][0].shape[1]))\n",
    "    \n",
    "    # initialize counter\n",
    "    counter = 0\n",
    "    \n",
    "    # iterate throught peptides in the aggregate\n",
    "    for peptide_1 in range(distance_maps.shape[0]):\n",
    "        for peptide_2 in range(distance_maps.shape[1]):\n",
    "             \n",
    "            # if peptide index are the same (intrapeptide distance map)\n",
    "            if peptide_1 == peptide_2:\n",
    "                \n",
    "                # intrapeptide distance map\n",
    "                actual_distance_map = distance_maps[peptide_1][peptide_2]\n",
    "                \n",
    "                # sum base and current distance map\n",
    "                base = base + actual_distance_map\n",
    "                \n",
    "                #update counter\n",
    "                counter += 1\n",
    "\n",
    "    #for element in base (every element is the sum of distance_map(i,j) for every distance map)\n",
    "    for row in range(len(base)):\n",
    "        for col in range(len(base)):\n",
    "            \n",
    "            # find the mean for every element of the cumulative distance map\n",
    "            base[row][col] = (base[row][col])/counter\n",
    "            \n",
    "    return base\n",
    "\n",
    "\n",
    "def decompose_distance_map(distance_map):\n",
    "    '''Use Singular value decomposition to get\n",
    "    \n",
    "    distance_map.shape[1] dimensional coordinate\n",
    "    (same n of dimension as the peptide n of residue)\n",
    "    \n",
    "    As described in:\n",
    "    Mathematical Modeling of Protein Structure Using Distance Geometry\n",
    "    Jeong-Mi Yoon, Yash Gad, Zhijun Wu\n",
    "    \n",
    "    Argument: distance map (numpy.array 2D)\n",
    "    return: \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # initialize a zeros matrix of same shape as the input map\n",
    "    D = np.zeros(distance_map.shape)\n",
    "    \n",
    "    #iterate trought row\n",
    "    for i in range(distance_map.shape[0]):\n",
    "        \n",
    "        # iterate trought cols\n",
    "        for j in range(distance_map.shape[1]):\n",
    "            \n",
    "            # distance between point point i and point j \n",
    "            dij = distance_map[i][j]\n",
    "            \n",
    "            # distance between point 0 and point j\n",
    "            d0j = distance_map[0][j]\n",
    "            \n",
    "            #distance between point i and point 0\n",
    "            di0 = distance_map[i][0]\n",
    "\n",
    "            #fill the zeros matrix with the value obtained with this formula\n",
    "            D[i][j] = (d0j**2 + di0**2 - dij**2)/2\n",
    "            \n",
    "    # check rank of matrix (should be of rank 3, but it is of rank distance_map.shape[1])\n",
    "    rank = np.linalg.matrix_rank(D)\n",
    "    \n",
    "    # Singular value decomposition on the D matrix\n",
    "    #svd = np.linalg.svd(D)\n",
    "    \n",
    "    svd = np.linalg.svd(D, full_matrices=False)\n",
    "    \n",
    "    # Calculate distance_map.shape[1] dimensional coordinate, but you need 3\n",
    "    # the non necessary dimension can give data to better reconstruct the peptide structure\n",
    "    X = svd[0]*np.sqrt(svd[1])\n",
    "\n",
    "    \n",
    "    return X, svd, D, rank\n",
    "\n",
    "\n",
    "def get_coordinate_from_decomposition(decomposition):\n",
    "    '''Take decomposition result and convert it into a coordinate vectors dict\n",
    "    \n",
    "    Argument: decomposition results\n",
    "    \n",
    "    return: dict with reconstructed 3d coordinate vector\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # take only the first three value to compose a 3D coordinate vector\n",
    "    coordinate = [e[:3] for e in decomposition]\n",
    "    \n",
    "    # initialize empty dict\n",
    "    reconstructed_coordinate_dict = {}\n",
    "    \n",
    "    # fill the dict with the ccordinate vectors\n",
    "    for index,coordinate_vector in enumerate(coordinate):\n",
    "        reconstructed_coordinate_dict[index] = coordinate_vector\n",
    "    \n",
    "    return reconstructed_coordinate_dict\n",
    "\n",
    "\n",
    "# \n",
    "def get_coordinate_from_distance_map(distance_map):\n",
    "    ''' compute 3d coordinate from distance map\n",
    "    \n",
    "    Argument: distance_map (numpy.array)\n",
    "    \n",
    "    return: dict with 3d coordinate for every alpha-carbon of a peptide\n",
    "    \n",
    "    '''\n",
    "    # perform singular value decomposition on distance_map (preprocessed)\n",
    "    decomposed_mean_distance_map = decompose_distance_map(distance_map)\n",
    "    \n",
    "    \n",
    "    # get 3D coordinate\n",
    "    reconstructed_coordinate_dict = get_coordinate_from_decomposition(decomposed_mean_distance_map[0])\n",
    "    \n",
    "    return reconstructed_coordinate_dict\n",
    "\n",
    "    \n",
    "    \n",
    "def plot_single_peptide(peptide_coordinate_dict, centroid=False):\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "    \n",
    "    for residue in peptide_coordinate_dict:\n",
    "        point = peptide_coordinate_dict[residue]\n",
    "        x.append(point[0])\n",
    "        y.append(point[1])\n",
    "        z.append(point[2])\n",
    "\n",
    "\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    z = np.asarray(z)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes(projection='3d')\n",
    "    ax.scatter3D(x,y,z, c='b')\n",
    "    \n",
    "    if centroid == True:\n",
    "            median_centroid = [np.median(x), np.median(y), np.median(z)]\n",
    "            ax.scatter3D(median_centroid[0], median_centroid[1], median_centroid[2], c='r')\n",
    "            \n",
    "    return plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

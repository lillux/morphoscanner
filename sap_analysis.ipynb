{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import plotly\n",
    "#import plotly.express as px\n",
    "\n",
    "from mpl_toolkits import mplot3d\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "#from functools import lru_cache\n",
    "#import re\n",
    "import networkx as nx\n",
    "from networkx.algorithms import approximation\n",
    "\n",
    "import MDAnalysis as mda\n",
    "\n",
    "#import scipy\n",
    "#import sklearn\n",
    "#import skimage\n",
    "\n",
    "#import xml.etree.ElementTree as et\n",
    "#from Bio.PDB import *\n",
    "#import nglview as nv\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "\n",
    "\n",
    "# http://nglviewer.org/nglview/latest/api.html\n",
    "# https://biopython.org/wiki/The_Biopython_Structural_Bioinformatics_FAQ\n",
    "# https://ambermd.org/tutorials/analysis/tutorial_notebooks/nglview_notebook/index.html\n",
    "# https://amber-md.github.io/pytraj/latest/_api/pytraj.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contact_matrix = np.loadtxt('/home/lillo/TesiCNTE/CNTE/dataset/contact_matrix.txt')   #laptop\n",
    "#contact_matrix = np.loadtxt('/home/lillo/Code/Tesi/dataset/contact_matrix.txt')        #fisso\n",
    "#contact_matrix_single = contact_matrix.reshape(100,100,12,12)\n",
    "\n",
    "#gromacs_output = open('/home/lillo/Code/Tesi/dataset/dm4500Compl_mix1_K2_1%4500ns.gro') #fisso\n",
    "#gromacs_output = open('/home/lillo/TesiCNTE/CNTE/dataset/dm4500Compl_mix1_K2_1%4500ns.gro') #laptop\n",
    "\n",
    "#path = '/home/lillo/Code/Tesi/dataset/dm4500Compl_mix1_K2_1%4500ns.gro' #fisso\n",
    "#path = '/home/lillo/TesiCNTE/CNTE/dataset/dm4500Compl_mix1_K2_1%4500ns.gro' #laptop\n",
    "\n",
    "# import 2mxu file (beta sheet)\n",
    "\n",
    "#path_to_mmCIF = open('/home/lillo/TesiCNTE/pdb/2mxu/2mxu.cif')  ## laptop\n",
    "#path_to_pdb = '/home/lillo/TesiCNTE/pdb/2mxu/2mxu.pdb'  ## laptop\n",
    "#pa_to_pdb = '/home/lillo/TesiCNTE/pdb/2mxu/2mxu.pdb'  ## laptop\n",
    "\n",
    "#path_to_mmCIF = open('/home/lillo/Code/Tesi/pdb/2mxu/2mxu.cif')  ## fisso\n",
    "#path_to_pdb = '/home/lillo/Code/Tesi/pdb/2mxu/2mxu.pdb'  ## fisso\n",
    "#pa_to_pdb = '/home/lillo/Code/Tesi/pdb/2mxu/2mxu.pdb'  ## fisso\n",
    "\n",
    "#seed_1_path = '/home/lillo/TesiCNTE/from_cluster/aggregate1.gro' # laptop\n",
    "#seed_1_path = '/home/lillo/Code/Tesi/dataset/aggregate1.gro'    # Fisso\n",
    "\n",
    "#prod_gro = '/home/lillo/TesiCNTE/from_cluster/prod/prod_part1/min.gro'            # laptop\n",
    "#prod_xtc = '/home/lillo/TesiCNTE/from_cluster/prod/prod_part1/prod.xtc'           # laptop\n",
    "#prod1_xtc = '/home/lillo/TesiCNTE/from_cluster/prod/prod_part2/prod-compl.xtc'    # laptop\n",
    "\n",
    "prod_gro = '/home/lillo/Code/Tesi/dataset/prod/prod_part1/min.gro'           #fisso\n",
    "prod_xtc = '/home/lillo/Code/Tesi/dataset/prod/prod_part1/prod.xtc'          #fisso\n",
    "prod1_xtc = '/home/lillo/Code/Tesi/dataset/prod/prod_part2/prod-compl.xtc'   #fisso\n",
    "\n",
    "\n",
    "#trj_xtc = '/home/lillo/TesiCNTE/CNTE/trajectory/prd-LDLK12-100mer-out-mol.xtc'  #laptop\n",
    "#trj_gro = '/home/lillo/TesiCNTE/CNTE/trajectory/min-LDLK12-100mer-out-c.gro'    #laptop\n",
    "\n",
    "trj_gro = '/home/lillo/Code/Tesi/dataset/trajectory_6_12_19/min-LDLK12-100mer-out-c.gro'     #fisso\n",
    "trj_xtc = '/home/lillo/Code/Tesi/dataset/trajectory_6_12_19/prd-LDLK12-100mer-out-mol.xtc'   #fisso\n",
    "\n",
    "lipase = '/home/lillo/Documenti/PDB/lipase/3d2c.pdb'\n",
    "lipase1 = '/home/lillo/Documenti/PDB/lipase/1gpl.pdb'\n",
    "\n",
    "\n",
    "#p73_2per_wat_seed_1_gro = '/home/lillo/TesiCNTE/from_cluster/peptide_73/MARTINI/2%/WATER/2%/seed_1/prod/73prod.gro'     # laptop\n",
    "#p73_2per_wat_seed_1_xtc = '/home/lillo/TesiCNTE/from_cluster/peptide_73/MARTINI/2%/WATER/2%/seed_1/prod/73prod.xtc'     # laptop\n",
    "#p73_2per_wat_seed_1_trr = '/home/lillo/TesiCNTE/from_cluster/peptide_73/MARTINI/2%/WATER/2%/seed_1/prod/73prod.trr'     # laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj.number_of_BB_atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import morphoscanner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_gro = get_gro()\n",
    "_xtc = get_xtc()\n",
    "\n",
    "trj = trajectory(_gro, _xtc)\n",
    "\n",
    "print('Your trajectory has %d frames' % trj.number_of_frames)\n",
    "print('Your trajectory has %d BB atoms' % trj.number_of_BB_atoms)\n",
    "\n",
    "\n",
    "peptide_length = peptide_length(sentence='Set the number of aminoacids in one peptide (int): ')\n",
    "interval = get_interval(sentence='Set the interval between sampled frames (int): ')\n",
    "start_from = start_from(sentence='Set the index from which you want to start.\\n\\n0 if you have a single simulation.\\n0 if you are analyzing split1.\\nlen(split1) if you are analyzing split2.\\ninteger: ')\n",
    "\n",
    "output_path, file_name = get_destination_dir_and_name()\n",
    "\n",
    "\n",
    "trj.compose_database(peptide_length=peptide_length, interval=interval)\n",
    "trj.analyze_inLoop()\n",
    "trj.get_data()\n",
    "trj.get_database()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.stack([torch.from_numpy(zero[e]) for e in zero])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class database:\n",
    "\n",
    "    '''Class that parse the trajectory and gives back frames with data.\n",
    "\n",
    "    This class is used to represent data in an intuitive way to the user\n",
    "\n",
    "    '''\n",
    "\n",
    "    def __init__(self, peptide_length=None, start_from = 0, interval = 1):\n",
    "\n",
    "        # cosa vuoi aggiungere?\n",
    "\n",
    "        # forse è meglio se si fa una classe frames dentro la classe trajectory\n",
    "        # e poi si istanzia la classe frame ad ogni frame campionato\n",
    "        # e dentro si mettono anche i risultati dell'analisi\n",
    "        # \n",
    "        # prendo a riferimento i frames, quindi la traiettoria\n",
    "        # oppure prendo a riferimento il tipo di peptide?\n",
    "        # forse meglio il frame, e poi posso tracciare le famiglie di peptidi tra\n",
    "        # i frames.\n",
    "        # \n",
    "        # devo anche individuare quali sono le sequenze\n",
    "        # e raggruppare i peptidi con sequenza uguale\n",
    "        # \n",
    "        #\n",
    "\n",
    "        self.frames = {}\n",
    "        self.peptide_length = peptide_length\n",
    "        self.start_from = start_from\n",
    "        self.interval = interval\n",
    "\n",
    "        peptides_list = backend.topology.get_peptide_length_list(trj_gro)\n",
    "\n",
    "        universe = backend.topology.make_universe(trj_gro, trj_xtc)\n",
    "\n",
    "\n",
    "        if peptide_length == None:\n",
    "\n",
    "\n",
    "            n_pep = len(peptides_list)\n",
    "\n",
    "\n",
    "        else:\n",
    "\n",
    "            n_pep = sum([(e // peptide_length) for e in peptides_list])\n",
    "\n",
    "\n",
    "\n",
    "        self.frames = {}\n",
    "\n",
    "        for index_ts, ts in tqdm.tqdm(enumerate(universe.trajectory)):\n",
    "\n",
    "            updated_index = (index_ts + start_from)\n",
    "\n",
    "            if (updated_index % interval) == 0:\n",
    "\n",
    "                peptides = {}\n",
    "\n",
    "                for peptide in range(n_pep):\n",
    "\n",
    "                    peptides[peptide] = {}\n",
    "\n",
    "\n",
    "                    if peptide == 0:\n",
    "\n",
    "                        counter = 0\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        # if to check peptide_length\n",
    "                        if peptide_length == None:\n",
    "\n",
    "                            counter += peptides_list[peptide - 1]\n",
    "\n",
    "                        else:\n",
    "                            counter += peptide_length\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    pep = single_peptide(universe, counter, peptide, peptide_length, peptides_list)\n",
    "\n",
    "                    peptides[peptide] = pep\n",
    "\n",
    "                self.frames[updated_index] = peptides\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.backend.topology.get_peptide_length_list((trj_gro))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = morphoscanner.backend.readGro.clean_gro(trj_gro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class single_peptide():\n",
    "    \n",
    "    ''' Class that define peptides\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.sequence\n",
    "        self.coordinates\n",
    "        \n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dispatch_data(atom):\n",
    "    \n",
    "    if type(atom) != list:\n",
    "        \n",
    "        raise ValueError(\"%s is not a list, it is of type %s...\\n \" % (str(atom), type(atom)))\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        atom_number = check_int_and_return(atom[0])\n",
    "        \n",
    "        residue_number = check_int_and_return(atom[1])\n",
    "        \n",
    "        residue_name = atom[2]\n",
    "        \n",
    "        x = float(atom[3])\n",
    "        \n",
    "        y = float(atom[4])\n",
    "        \n",
    "        z = float(atom[5])\n",
    "        \n",
    "    \n",
    "    \n",
    "        return atom_number, residue_number, residue_name, x, y, z\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatch_data(cleaned[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(cleaned[0]) == list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "def isInt(s):\n",
    "    '''Check if s is type int and return bool.\n",
    "    \n",
    "    Input: object\n",
    "    \n",
    "    Output: bool'''\n",
    "    \n",
    "    try:\n",
    "        return float(str(s)).is_integer()\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "    \n",
    "    \n",
    "def check_int_and_return(value):\n",
    "    \n",
    "    '''Check int and return value, else raise ValueError and print object type\n",
    "    \n",
    "    Input = object\n",
    "    \n",
    "    Output = int'''\n",
    "\n",
    "    if isInt(value):\n",
    "\n",
    "        return int(value)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"%s is not an integer, it is of type %s...\\n \" % (str(value), type(value))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_list = morphoscanner.backend.topology.get_peptide_length_list (p73_2per_wat_seed_1_gro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "c_list = {}\n",
    "for idx, i in enumerate(peptides_dict[21].atom_numbers.values()):\n",
    "    p = universe.atoms[i].position\n",
    "    c_list[idx] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type(peptides_dict[0].frame_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Mi serve un oggetto peptide con sequenza ed atom_number.\n",
    "### La sequenza la prendo una volta sola e sarà sempre la stessa\n",
    "### L'atom_number mi serve perché così posso prendermi le coordinate\n",
    "### dai timestep quando voglio, anche per singolo peptide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_list\n",
    "first_key = [k for k in peptides_dict][0]\n",
    "if type(peptides_dict[first_key].frame_coordinates) is dict:\n",
    "    print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_peptide_list(coordinate_dict, peptide_list=None, centroid=False):\n",
    "    '''\n",
    "    Plot peptides from a trajectory frame.\n",
    "    Using jupyter-notebook, use '%matplotlib notebook' to\n",
    "    plot the points cloud in 3D.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    coordinate_dict : dict\n",
    "        Is the dict that contains all the coordinate\n",
    "        of the atoms of a single frame.\n",
    "        A single frame of the output of \n",
    "        backend.topology.get_coordinate_dict_from_trajectory \n",
    "        is a coordinate_dict.\n",
    "        \n",
    "    peptide_list : list, optional\n",
    "        The default is None. By default all the peptides\n",
    "        will be plotted.\n",
    "            Is a list of int. Put here the index of the peptide\n",
    "            or peptides that you want to plot.\n",
    "            For example [0,2,5,24,1,6] to plot\n",
    "            only these peptides.\n",
    "        \n",
    "    centroid : bool, optional\n",
    "        The default is False.\n",
    "            The centroid of a peptide can be plotted\n",
    "            in red together with the selected peptide.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    3D plot\n",
    "        Return a scattered 3D plot.\n",
    "\n",
    "    '''\n",
    "    \n",
    "      \n",
    "    # if no peptide specified, plot all\n",
    "    if peptide_list == None:\n",
    "        peptide_list = [p for p in coordinate_dict]\n",
    "\n",
    "\n",
    "    # if there is only a single peptide to show\n",
    "    # use the single peptide function to normalize axis        \n",
    "    if len(peptide_list) == 1:\n",
    "        \n",
    "        return plot_single_peptide(coordinate_dict[peptide_list[0]])\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        x = []\n",
    "        y = []\n",
    "        z = []\n",
    "        x_median = float\n",
    "        y_median = float\n",
    "        z_median = float\n",
    "\n",
    "\n",
    "        for peptide in range(len(peptide_list)):\n",
    "            x.append([peptide])\n",
    "            y.append([peptide])\n",
    "            z.append([peptide])\n",
    "            for aminoacid in coordinate_dict[peptide_list[peptide]]:\n",
    "\n",
    "                point = coordinate_dict[peptide_list[peptide]][aminoacid]\n",
    "                x[peptide].append(point[0])\n",
    "                y[peptide].append(point[1])\n",
    "                z[peptide].append(point[2])\n",
    "\n",
    "            del x[peptide][0]\n",
    "            del y[peptide][0]\n",
    "            del z[peptide][0]\n",
    "\n",
    "        if centroid == True:\n",
    "\n",
    "            def assemble_coordinate(axis_coordinate_list):\n",
    "                median_list = []\n",
    "                for coordinate_set in axis_coordinate_list:\n",
    "                    median = np.median(coordinate_set)\n",
    "                    median_list.append(median)\n",
    "                return median_list\n",
    "\n",
    "            x_median = assemble_coordinate(x)\n",
    "            y_median = assemble_coordinate(y)\n",
    "            z_median = assemble_coordinate(z)\n",
    "\n",
    "\n",
    "        #%matplotlib notebook\n",
    "\n",
    "        fig = plt.figure()\n",
    "\n",
    "        ax = plt.axes(projection='3d')\n",
    "\n",
    "\n",
    "        for pep in range(len(x)):\n",
    "\n",
    "            ax.scatter3D(x[pep],y[pep],z[pep])\n",
    "\n",
    "            if centroid == True:\n",
    "\n",
    "                ax.scatter3D(x_median[pep], y_median[pep], z_median[pep], c='red')\n",
    "\n",
    "\n",
    "        #return  plt.show(), [x,y,z], [x_median, y_median, z_median]         \n",
    "    return plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot.plot_single_peptide(c_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_protein(c_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot from trajectory positions  ### WORKING BUT YOU NEED TO:\n",
    "# make_universe\n",
    "# positions = universe.select_atoms('name BB').positions\n",
    "def plot_peptide_from_trajectory_frame(positions, peptide_list=None, centroid=False):\n",
    "    \n",
    "    '''\n",
    "    Plot atoms from universe.trajectory[frame]\n",
    "    '''\n",
    "       \n",
    "    if peptide_list == None:\n",
    "        \n",
    "        peptide_list = [e for e in range(len(positions))]\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "\n",
    "    for peptide in range(len(peptide_list)):\n",
    "        x.append([peptide])\n",
    "        y.append([peptide])\n",
    "        z.append([peptide])\n",
    "\n",
    "        point = positions[peptide_list[peptide]]\n",
    "        #print(peptide, point)\n",
    "        x[peptide].append(point[0])\n",
    "        y[peptide].append(point[1])\n",
    "        z[peptide].append(point[2])\n",
    "\n",
    "        del x[peptide][0]\n",
    "        del y[peptide][0]\n",
    "        del z[peptide][0]\n",
    "\n",
    "    fig = plt.figure()\n",
    "\n",
    "    ax = plt.axes(projection='3d')\n",
    "\n",
    "    for pep in range(len(x)):\n",
    "\n",
    "        # scatter points, making list from torch tensor item\n",
    "        ax.scatter3D([e.item() for e in x[pep]],[e.item() for e in y[pep]],[e.item() for e in z[pep]])\n",
    "\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from morphoscanner import backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe = mda.Universe(trj_gro, trj_xtc, in_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = universe.trajectory[150].positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = universe.trajectory[150].positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_peptide_list(coordinate_dict, peptide_list=None, centroid=False):\n",
    "    '''Plot peptides from a trajectory frame.\n",
    "        Using jupyter-notebook, use '%matplotlib notebook' to\n",
    "        plot the points cloud in 3D.\n",
    "    \n",
    "    Inputs:     coordinate_dict, dict   Is the dict that contains all the coordinate\n",
    "                                        of the atoms of a single frame.\n",
    "                                        A single frame of the output of \n",
    "                                        backend.topology.get_coordinate_dict_from_trajectory \n",
    "                                        is a coordinate_dict.\n",
    "    \n",
    "                peptide_list, list.     is a list of int. Put here the index of the peptide\n",
    "                                        or peptides that you want to plot\n",
    "                                \n",
    "                centroid,   bool.       default=False \n",
    "                                        The centroid of a peptide can be plotted\n",
    "                                        in red together with the selected peptide.\n",
    "                                           \n",
    "    Return:     show a 3D plot\n",
    "    '''\n",
    "    \n",
    "    # if there is only a single peptide to show\n",
    "    # use the single peptide function to normalize axis    \n",
    "    \n",
    "    if peptide_list == None:\n",
    "        peptide_list = [p for p in coordinate_dict]\n",
    "    \n",
    "    \n",
    "    if len(peptide_list) == 1:\n",
    "        \n",
    "        return plot_single_peptide(coordinate_dict[peptide_list[0]])\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        x = []\n",
    "        y = []\n",
    "        z = []\n",
    "        x_median = float\n",
    "        y_median = float\n",
    "        z_median = float\n",
    "\n",
    "\n",
    "        for peptide in range(len(peptide_list)):\n",
    "            x.append([peptide])\n",
    "            y.append([peptide])\n",
    "            z.append([peptide])\n",
    "            for aminoacid in coordinate_dict[peptide_list[peptide]]:\n",
    "\n",
    "                point = coordinate_dict[peptide_list[peptide]][aminoacid]\n",
    "                x[peptide].append(point[0])\n",
    "                y[peptide].append(point[1])\n",
    "                z[peptide].append(point[2])\n",
    "\n",
    "            del x[peptide][0]\n",
    "            del y[peptide][0]\n",
    "            del z[peptide][0]\n",
    "\n",
    "        if centroid == True:\n",
    "\n",
    "            def assemble_coordinate(axis_coordinate_list):\n",
    "                median_list = []\n",
    "                for coordinate_set in axis_coordinate_list:\n",
    "                    median = np.median(coordinate_set)\n",
    "                    median_list.append(median)\n",
    "                return median_list\n",
    "\n",
    "            x_median = assemble_coordinate(x)\n",
    "            y_median = assemble_coordinate(y)\n",
    "            z_median = assemble_coordinate(z)\n",
    "\n",
    "\n",
    "        #%matplotlib notebook\n",
    "\n",
    "        fig = plt.figure()\n",
    "\n",
    "        ax = plt.axes(projection='3d')\n",
    "\n",
    "\n",
    "        for pep in range(len(x)):\n",
    "\n",
    "            ax.scatter3D(x[pep],y[pep],z[pep])\n",
    "\n",
    "            if centroid == True:\n",
    "\n",
    "                ax.scatter3D(x_median[pep], y_median[pep], z_median[pep], c='red')\n",
    "\n",
    "\n",
    "        #return  plt.show(), [x,y,z], [x_median, y_median, z_median]         \n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = [i for i in range(100,1001,100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = [i for i in range(10,101,10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_for_compatibility(to_split,split_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from morphoscanner.backend.check_val import check_int_and_return, isInt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_dict = morphoscanner.backend.topology.get_peptide_length_dict(peptide_length_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_dict.get(96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_for_splitting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly as px \n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_protein(coordinate_dict):\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "\n",
    "    for residue in coordinate_dict:\n",
    "        point = coordinate_dict[residue]\n",
    "        x.append(point[0])\n",
    "        y.append(point[1])\n",
    "        z.append(point[2])\n",
    "\n",
    "\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    z = np.asarray(z)\n",
    "\n",
    "    fig = go.Figure(data = [go.Scatter3d (x = x, y = y, z= z)])\n",
    "    return fig.show()\n",
    "\n",
    "def heatmap2d(arr: np.ndarray):\n",
    "    plt.imshow(arr, cmap = 'viridis', interpolation = 'nearest')\n",
    "    plt.colorbar()\n",
    "    return plt.show()\n",
    "\n",
    "def get_euclidean_distance(point_1, point_2):\n",
    "\n",
    "    euclidean_distance = np.sqrt(np.sum([((point_1[0] - point_2[0])**2), ((point_1[1] - point_2[1])**2), ((point_1[2] - point_2[2])**2)]))\n",
    "\n",
    "    return euclidean_distance\n",
    "\n",
    "def compute_distance_map(coordinate_dict):\n",
    "    i = 0\n",
    "    distance_map = np.zeros((len(coordinate_dict),len(coordinate_dict)))\n",
    "    for  i  in range(i, len(coordinate_dict)-1):\n",
    "        coordinate_1 = coordinate_dict[i] \n",
    "        for j in range(0, len(coordinate_dict)-1):\n",
    "            coordinate_2 = coordinate_dict[j]\n",
    "            euclidean_distance = get_euclidean_distance(coordinate_1, coordinate_2)\n",
    "            distance_map[i][j] = euclidean_distance\n",
    "            distance_map[j][i] = euclidean_distance\n",
    "    return distance_map\n",
    "\n",
    "def contact_map_helix(distance_map):\n",
    "    contact_map = np.zeros((len(distance_map),len(distance_map)))\n",
    "    for i in range(1, len(distance_map)-1):\n",
    "        for j in range(1, len(distance_map)-1):\n",
    "            if 0.45 < distance_map[i][j] < 0.46:\n",
    "                contact_map[i][j] = 1\n",
    "            elif 0.52 < distance_map[i][j] < 0.56:\n",
    "                contact_map[i][j] = 2\n",
    "    return contact_map\n",
    "\n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_split = check_input_multiple_int_recursive_with_sentence('Write the length of the peptides that you want to split (as an integer): ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "def isInt(s):\n",
    "    '''Check if s is type int and return bool.\n",
    "    \n",
    "    Input: object\n",
    "    \n",
    "    Output: bool'''\n",
    "    \n",
    "    try:\n",
    "        return float(str(s)).is_integer()\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "    \n",
    "    \n",
    "def check_int_and_return(value):\n",
    "    \n",
    "    '''Check int and return value, else raise ValueError and print object type\n",
    "    \n",
    "    Input = object\n",
    "    \n",
    "    Output = int'''\n",
    "\n",
    "    if isInt(value):\n",
    "\n",
    "        return int(value)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"%s is not an integer, it is of type %s...\\n \" % (str(value), type(value))) \n",
    "\n",
    "\n",
    "        \n",
    "##############################\n",
    "#############################\n",
    "##############################\n",
    "\n",
    "\n",
    "def ask_for_splitting(limit=5):\n",
    "\n",
    "    answer = input(\"Do you want to split peptides? Write 'yes' or 'no': \")\n",
    "    \n",
    "    if answer not in {'n','no','y','yes'}:\n",
    "        print('This is not a valid answer, please write yes or no.\\n'\n",
    "            '%d trial left.' % limit)\n",
    "        limit -= 1\n",
    "        if limit == 0:\n",
    "            raise sys.exit('Too many wrong inputs. Closing...')\n",
    "        else:\n",
    "            return ask_for_splitting(limit=limit)\n",
    "\n",
    "    elif answer in {'n', 'no'}:\n",
    "        print('The .gro topology file is set as reference for the analysis')\n",
    "        return False\n",
    "\n",
    "    elif answer in {'y', 'yes'}:\n",
    "        return True\n",
    "\n",
    "\n",
    "\n",
    "def check_input_multiple_int_recursive_with_sentence(sentence, limit=5):\n",
    "    \n",
    "    value = input(sentence)\n",
    "    input_list = value.split()\n",
    "    \n",
    "    if len(input_list) == 0:\n",
    "        limit -= 1\n",
    "        \n",
    "        if limit == 0:\n",
    "            raise sys.exit(\"Too many empty inputs. Closing...\")\n",
    "        else:\n",
    "            print('%d trial left.\\n'\n",
    "                  'You forgot to insert a value...please retry.' % limit)\n",
    "            return check_input_multiple_int_recursive_with_sentence(sentence=sentence, limit=limit)\n",
    "    \n",
    "    else:\n",
    "        va_list = []\n",
    "        for val in input_list:\n",
    "            \n",
    "            if isInt(val):\n",
    "                va_list.append(int(val))\n",
    "        \n",
    "                \n",
    "            else:\n",
    "                limit -= 1\n",
    "                print('%d trial left.' % (limit))\n",
    "                if limit == 0:\n",
    "                    raise sys.exit(\"%s is not an integer, it is of type %s...\\nClosing... \" % (str(val), type(val))) \n",
    "                else:\n",
    "                    print(\"%s is not an integer, it is of type %s...\\n \" % (str(val), type(val)))\n",
    "                    return check_input_multiple_int_recursive_with_sentence(sentence=sentence, limit=limit)\n",
    "        \n",
    "        return va_list\n",
    "    \n",
    "    \n",
    "def check_for_compatibility(list1, list2):\n",
    "    if len(list1) == len(list2):\n",
    "        \n",
    "        for e1, e2 in zip(list1, list2):\n",
    "            if e1%e2 != 0:\n",
    "                print('%d is not multiple of %d' % (e1,e2))\n",
    "                return False\n",
    "            \n",
    "        \n",
    "        else:\n",
    "            return True\n",
    "    \n",
    "    else:\n",
    "        raise ValueError('Your lists are of different len! list1 len = %d, list2 len = %d.' % (len(list1), len(list2)))\n",
    "\n",
    "\n",
    "def get_splitting_dict(to_split, split_size):\n",
    "    \n",
    "    splitting_dict = {}\n",
    "    \n",
    "    for length, split_dim in zip(to_split, split_size):\n",
    "        #check for divisibility\n",
    "        if (length%split_dim) == 0:\n",
    "            splitting_dict[length] = split_dim\n",
    "    \n",
    "    return splitting_dict\n",
    "\n",
    "def get_new_peptides_length(peptide_length_list, splitting_dict):\n",
    "    new_peptide_list = []\n",
    "    for pep_length in peptide_length_list:\n",
    "        if pep_length in splitting_dict.keys():\n",
    "            new_size = splitting_dict[pep_length]\n",
    "            new_peptide_list.extend([splitting_dict[pep_length] for p in range((pep_length//new_size))])\n",
    "        else:\n",
    "            new_peptide_list.append(pep_length)\n",
    "    \n",
    "    return new_peptide_list\n",
    "\n",
    "\n",
    "#####################################\n",
    "####################################\n",
    "#####################################\n",
    "\n",
    "class frames(object):\n",
    "    \n",
    "    pass\n",
    "    \n",
    "    \n",
    "    #def __init__(self, coordinates):\n",
    "        \n",
    "        #self.coordinates = coordinates\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "# Classes in dev\n",
    "\n",
    "class single_peptide():\n",
    "    \n",
    "    ''' Class that define peptides\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, seq, atom_n):\n",
    "        \n",
    "        self.sequence = seq\n",
    "        self.atom_numbers = atom_n\n",
    "        #self.frames_coordinates = frames()\n",
    "        \n",
    "        return\n",
    "    \n",
    "    \n",
    "#    def get_coordinate_from_frame(self, frame, coordinates):\n",
    "#        \n",
    "#        name = 'frame_' + str(frame)\n",
    "#\n",
    "#        setattr(self.frames_coordinates, name, coordinates)\n",
    "#        \n",
    "#        return\n",
    "    \n",
    "    def get_coordinate_from_frame(self, frame, coordinates):\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            self.frames[frame] = coordinates\n",
    "        except:\n",
    "            self.frames = {}\n",
    "            self.frames[frame] = coordinates\n",
    "        return\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "## WORKING NICELY FAST\n",
    "def get_data_from_trajectory_frame(universe, frame, peptide_length_list, atom_to_select='BB'):\n",
    "\n",
    "    # move universe frame to memory\n",
    "    universe.trajectory[frame]\n",
    "\n",
    "    coordinate_dict = {}\n",
    "    residues_dict = {}\n",
    "    atom_number_dict = {}\n",
    "    \n",
    "    res_counter = 0\n",
    "\n",
    "    #print(length_list)\n",
    "    for pep_index, peptide in enumerate(peptide_length_list):\n",
    "\n",
    "        coordinate_dict[pep_index] = {}\n",
    "        residues_dict[pep_index] = {}\n",
    "        atom_number_dict[pep_index] = {}\n",
    "        \n",
    "        for res in range(peptide):\n",
    "\n",
    "            actual_res = universe.residues[res_counter]\n",
    "            \n",
    "            for index, atom in enumerate(actual_res.atoms):\n",
    "\n",
    "                atom_type = str(atom).split()[2]\n",
    "\n",
    "                if atom_type == atom_to_select:\n",
    "                    \n",
    "                    atom_number = (int(str(atom).split()[1].split(':')[0]) - 1)\n",
    "\n",
    "                    residue_name = (str(atom).split()[8].split(',')[0])\n",
    "\n",
    "                    coordi = universe.atoms[atom_number].position\n",
    "\n",
    "                    coordinate_dict[pep_index][res] = coordi\n",
    "                    residues_dict[pep_index][res] = residue_name\n",
    "                    atom_number_dict[pep_index][res] = atom_number\n",
    "                    \n",
    "                    res_counter += 1\n",
    "                    \n",
    "    return coordinate_dict, residues_dict, atom_number_dict\n",
    "    #return residues_dict, atom_number_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(new_peptide_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(peptide_length_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe = morphoscanner.backend.topology.make_universe(trj_gro,trj_xtc)\n",
    "peptide_length_list = morphoscanner.backend.topology.get_peptide_length_list(trj_gro)\n",
    "len_dict = morphoscanner.backend.topology.get_peptide_length_dict(peptide_length_list)\n",
    "morphoscanner.backend.topology.print_peptides_length(len_dict)\n",
    "have_to_split = ask_for_splitting()\n",
    "if have_to_split:\n",
    "    to_split = check_input_multiple_int_recursive_with_sentence('Write the length of the peptides that you want to split (as integer or list of integer separated by a space): ')\n",
    "    split_size = check_input_multiple_int_recursive_with_sentence('\\nWrite the length in which you want to split your peptides (as integer or list of integer separated by a space).\\n'\n",
    "                                                                 'The list should be of the same length of the list above, \\nthe numbers have to be divisors of the numbers inserted above. ')\n",
    "    compatible = check_for_compatibility(to_split, split_size)\n",
    "    if compatible:\n",
    "        splitting_dict = get_splitting_dict(to_split, split_size)\n",
    "        new_peptides_length = get_new_peptides_length(peptide_length_list, splitting_dict)\n",
    "        print('Splitting done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "have_to_split = ask_for_splitting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(new_peptides_length) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class results():\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def get_data(self, data_name, data):\n",
    "        \n",
    "        setattr(self, data_name, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from morphoscanner import backend, data_acquisition, trj_object\n",
    "from morphoscanner.backend.check_val import isInt\n",
    "import sys\n",
    "\n",
    "\n",
    "class trajectory:\n",
    "    '''Class to operate on trajectory files.\n",
    "\n",
    "    It makes an object that contain the trajectory of the simulation'''\n",
    "\n",
    "    def __init__(self, trj_gro, trj_xtc):\n",
    "        \n",
    "        self.trj_gro = trj_gro\n",
    "        self.trj_xtc = trj_xtc\n",
    "        self.universe = backend.topology.make_universe(self.trj_gro, self.trj_xtc)\n",
    "        self.number_of_frames = len(self.universe.trajectory)\n",
    "        self.number_of_BB_atoms = len(self.universe.select_atoms('name BB'))\n",
    "       \n",
    "        self.peptide_length_list = backend.topology.get_peptide_length_list(self.trj_gro)\n",
    "        self.len_dict = backend.topology.get_peptide_length_dict(self.peptide_length_list)\n",
    "        \n",
    "        print('In your trajectory there are %d frames.\\n' % self.number_of_frames)\n",
    "        print('In each frame there are %d BB atoms.\\n' % self.number_of_BB_atoms)\n",
    "        morphoscanner.backend.topology.print_peptides_length(self.len_dict)\n",
    "        \n",
    "        return\n",
    "        \n",
    "        \n",
    "    def split(self, to_split: list, split_size: list):\n",
    "        '''Manually split peptide_length_list in case of seeds.\n",
    "        \n",
    "        Input:\n",
    "            to_split: list\n",
    "                list of int or ints.\n",
    "                Each int refers to the length of a peptides seed\n",
    "                from self.len_dict.keys() that you want to split in single peptide.\n",
    "                For example if in len dict there are seeds of length 96 that you want to split,\n",
    "                to_split = [96]\n",
    "                \n",
    "            split_size: list\n",
    "                list of int or ints.\n",
    "                This is the size in which you want to split your to_split seeds.\n",
    "                For example if you want to split your seeds of length 96 in peptides of length 12,\n",
    "                split_size = [12]\n",
    "                \n",
    "        Output:\n",
    "            Change the original self.peptide_length_list with a new list of splitted peptides.\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        splitting_dict = data_acquisition.script_inputs.get_splitting_dict(to_split, split_size)\n",
    "        self.peptide_length_list = data_acquisition.script_inputs.get_new_peptides_length(self.peptide_length_list, splitting_dict)\n",
    "        print('Splitting done.\\n')\n",
    "        print('\"peptide_length_list\" attribute has been updated with the new length.')\n",
    "        \n",
    "        return\n",
    "    \n",
    "    \n",
    "    def explore(self):\n",
    "        \n",
    "        frame = 0\n",
    "        coordinate, sequence, atom_number = backend.topology.get_data_from_trajectory_frame(universe=self.universe, frame=frame, peptide_length_list= self.peptide_length_list)\n",
    "\n",
    "        self.peptide = {}\n",
    "        for seq, coord, atm_n in zip(sequence, coordinate, atom_number):\n",
    "\n",
    "            self.peptide[seq] = trj_object.trj_objects.single_peptide(sequence.get(seq), atom_number.get(atm_n))\n",
    "                \n",
    "            self.peptide[seq].get_coordinate_from_frame(frame=frame, coordinates=coordinate.get(coord))\n",
    "        \n",
    "        print('Exploration of frame %d done.\\n' % frame)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    \n",
    "    def compose_database(self, sampling_interval):\n",
    "        \n",
    "        steps = [s for s in range(self.number_of_frames) if s%sampling_interval==0 and s != 0]\n",
    "        for step in tqdm.tqdm(steps):\n",
    "            self.universe.trajectory[step]\n",
    "\n",
    "            for pep in self.peptide:\n",
    "                c_list = {}\n",
    "\n",
    "                for idx, i in enumerate(self.peptide[pep].atom_numbers.values()):\n",
    "                    p = self.universe.atoms[i].position\n",
    "                    c_list[idx] = p\n",
    "\n",
    "                self.peptide[pep].get_coordinate_from_frame(step, c_list)\n",
    "\n",
    "        return\n",
    "        \n",
    "        \n",
    "    def get_frame(self, frame):\n",
    "        \n",
    "        peptide_dict = {}\n",
    "        for pep in self.peptide:\n",
    "\n",
    "            peptide_dict[pep] = self.peptide[pep].frames[frame]\n",
    "        \n",
    "        return peptide_dict\n",
    "    \n",
    "    \n",
    "    def get_peptide_in_all_frame(self, peptide):\n",
    "    \n",
    "        frame_dict = {}\n",
    "        for frame in self.peptide[peptide].frames:\n",
    "            \n",
    "            frame_dict[frame] = self.peptide[peptide].frames[frame]\n",
    "            \n",
    "        return frame_dict\n",
    "    \n",
    "    def analysis(self, frame):\n",
    "\n",
    "        # WHY len(frame_denoised) is len(frame_dict)-1 ???????\n",
    "\n",
    "        frame = frame\n",
    "        print('Analyzing frame n° ', frame)\n",
    "\n",
    "        frame_dict = self.get_frame(frame)\n",
    "\n",
    "        frame_tensor = backend.distance_tensor.get_coordinate_tensor_from_dict(frame_dict)\n",
    "\n",
    "        start_dist = timer()\n",
    "        frame_distance_maps = backend.distance_tensor.compute_euclidean_norm_torch(frame_tensor)\n",
    "        end_dist = timer()\n",
    "        print('Time to compute distance is: ', (end_dist - start_dist))\n",
    "\n",
    "        start_contc = timer()\n",
    "        frame_contact = backend.pattern_recognition.compute_contact_maps_as_array(frame_distance_maps)\n",
    "        end_contc = timer()\n",
    "        print('Time to compute contact is: ', (end_contc - start_contc))\n",
    "\n",
    "        start_den = timer()\n",
    "        frame_denoised, df = backend.pattern_recognition.denoise_contact_maps(frame_contact)\n",
    "        end_den = timer()\n",
    "        print('Time to denoise: ', (end_den-start_den))\n",
    "\n",
    "        #frame_graph = backend.graph.nx_graph_search(self.frame_denoised)\n",
    "\n",
    "        frame_graph_full = backend.graph.graph_v1(frame_denoised, df)\n",
    "\n",
    "        subgraphs = backend.graph.find_subgraph(frame_graph_full)\n",
    "\n",
    "        self.results[frame] = results.get_data(self, 'graph', frame_graph_full)\n",
    "        self.results[frame].get_data(self, 'subgraph', subgraphs)\n",
    "    \n",
    "        return\n",
    "        \n",
    "        # fare in modo da creare un container in cui inserire i risultati dell'analisi\n",
    "        # cosa mi serve?\n",
    "        # graph, subgraph, df\n",
    "        # then implement function in the original trajectory file\n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In your trajectory there are 151 frames.\n",
      "\n",
      "In each frame there are 1200 BB atoms.\n",
      "\n",
      "Length: 96, Peptides: 10\n",
      "Length: 12, Peptides: 20\n"
     ]
    }
   ],
   "source": [
    "t_test = trajectory(trj_gro, trj_xtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting done.\n",
      "\n",
      "\"peptide_length_list\" attribute has been updated with the new length.\n"
     ]
    }
   ],
   "source": [
    "t_test.split([96],[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploration of frame 0 done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t_test.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:05<00:00, 27.21it/s]\n"
     ]
    }
   ],
   "source": [
    "t_test.compose_database(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing frame n°  0\n",
      "Time to compute distance is:  2.1206867649998458\n",
      "Time to compute contact is:  7.885738296001364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37/37 [00:00<00:00, 59391.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to denoise:  1.4102603009996528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'trajectory' object has no attribute 'results'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-859dda4abb20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-f1e6af2930d3>\u001b[0m in \u001b[0;36manalysis\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0msubgraphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_subgraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_graph_full\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'graph'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_graph_full\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'subgraph'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubgraphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'trajectory' object has no attribute 'results'"
     ]
    }
   ],
   "source": [
    "t_test.analysis(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = t_test.get_frame(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assemble a coordinate dict for each frame for a peptide\n",
    "# assemble a coordinate dict for each peptide in a single frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot.plot_peptide_list(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Instantiate universe and peptide list\n",
    "universe = morphoscanner.backend.topology.make_universe(trj_gro,trj_xtc)\n",
    "peptide_length_list = morphoscanner.backend.topology.get_peptide_length_list(trj_gro)\n",
    "\n",
    "\n",
    "coordinate, sequence, atom_number = get_data_from_trajectory_frame(universe, 0, peptide_length_list)\n",
    "\n",
    "peptides_dict = {}\n",
    "for seq, coord, atm_n in zip(sequence, coordinate, atom_number):\n",
    "\n",
    "    peptides_dict[seq] = single_peptide(sequence.get(seq), atom_number.get(atm_n))\n",
    "    \n",
    "    actual_frame = universe.trajectory.trajectory.frame\n",
    "    \n",
    "    peptides_dict[seq].get_coordinate_from_frame(frame=actual_frame, coordinates=coordinate.get(coord))\n",
    "\n",
    "    \n",
    "start = timer()\n",
    "for step in steps:\n",
    "    universe.trajectory[step]\n",
    "    \n",
    "    for pep in peptides_dict:\n",
    "        c_list = {}\n",
    "        \n",
    "        for idx, i in enumerate(peptides_dict[pep].atom_numbers.values()):\n",
    "            p = universe.atoms[i].position\n",
    "            c_list[idx] = p\n",
    "            \n",
    "        peptides_dict[pep].get_coordinate_from_frame(step, c_list)\n",
    "        \n",
    "end = timer()\n",
    "print(end-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peptides_dict[0].frames.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#steps = [i for i in range(universe.trajectory.n_frames) if i%10 == 0]\n",
    "steps = [i for i in range(universe.trajectory.n_frames)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_process_dict = peptides_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "\n",
    "#multiprocessing.cpu_count()\n",
    "available_cpu = len(os.sched_getaffinity(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test.peptide[0].frames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis(frame):\n",
    "\n",
    "    # WHY len(frame_denoised) is len(frame_dict)-1 ???????\n",
    "    \n",
    "    frame = frame\n",
    "    print('Analyzing frame n° ', frame)\n",
    "\n",
    "    frame_dict = t_test.get_frame(frame)\n",
    "\n",
    "    frame_tensor = backend.distance_tensor.get_coordinate_tensor_from_dict(frame_dict)\n",
    "\n",
    "    start_dist = timer()\n",
    "    frame_distance_maps = backend.distance_tensor.compute_euclidean_norm_torch(frame_tensor)\n",
    "    end_dist = timer()\n",
    "    print('Time to compute distance is: ', (end_dist - start_dist))\n",
    "\n",
    "    start_contc = timer()\n",
    "    frame_contact = backend.pattern_recognition.compute_contact_maps_as_array(frame_distance_maps)\n",
    "    end_contc = timer()\n",
    "    print('Time to compute contact is: ', (end_contc - start_contc))\n",
    "\n",
    "    start_den = timer()\n",
    "    frame_denoised, df = backend.pattern_recognition.denoise_contact_maps(frame_contact)\n",
    "    end_den = timer()\n",
    "    print('Time to denoise: ', (end_den-start_den))\n",
    "\n",
    "    #frame_graph = backend.graph.nx_graph_search(self.frame_denoised)\n",
    "    \n",
    "    frame_graph_full = backend.graph.graph_v1(frame_denoised, df)\n",
    "\n",
    "    subgraphs = backend.graph.find_subgraph(frame_graph_full)\n",
    "\n",
    "    self.results[frame] = results.get_data(self, 'graph', frame_graph_full)\n",
    "    self.results[frame].get_data(self, 'subgraph', subgraphs)\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a_dict.update({'a':1, 'b':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dict.update({'c':3, 'd':4, 'e': {'a':1, 'b':2, 'c':3}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class frames(object):\n",
    "    \n",
    "    pass\n",
    "    \n",
    "    \n",
    "    #def __init__(self, coordinates):\n",
    "        \n",
    "        #self.coordinates = coordinates\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "# Classes in dev\n",
    "\n",
    "class single_peptide():\n",
    "    \n",
    "    ''' Class that define peptides\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, seq, atom_n):\n",
    "        \n",
    "        self.sequence = seq\n",
    "        self.atom_numbers = atom_n\n",
    "        #self.frames_coordinates = frames()\n",
    "        \n",
    "        return\n",
    "    \n",
    "    \n",
    "#    def get_coordinate_from_frame(self, frame, coordinates):\n",
    "#        \n",
    "#        name = 'frame_' + str(frame)\n",
    "#\n",
    "#        setattr(self.frames_coordinates, name, coordinates)\n",
    "#        \n",
    "#        return\n",
    "    \n",
    "    def get_coordinate_from_frame(self, frame, coordinates):\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            self.frames[frame] = coordinates\n",
    "        except:\n",
    "            self.frames = {}\n",
    "            self.frames[frame] = coordinates\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@author: lillo\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def get_coordinate_from_pdb(file):\n",
    "    '''\n",
    "    Parse a pdb file. Support single chain and multiple chain\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file : str\n",
    "        The path of the .pdb file in your system.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    coordinate_dict : dict\n",
    "        A dict of dict with the coordinate of each atom of the pdb file.\n",
    "        \n",
    "        Depending on the input file it has different levels of nesting:\n",
    "            \n",
    "            for single chain:\n",
    "                atom_index : [x,y,z]\n",
    "                \n",
    "            for multiple chain:\n",
    "                \n",
    "                chain_index : {atom index : [x,y,z]}\n",
    "    '''\n",
    "    \n",
    "    with open(file) as pdbfile:\n",
    "\n",
    "        coordinate_dict = {}\n",
    "        atom_count_dict = {}\n",
    "        start = 0\n",
    "\n",
    "        for line in pdbfile:\n",
    "            \n",
    "            # split line\n",
    "            splitted_line = [line[:6], line[6:11], line[12:16], line[17:20], line[21], line[22:26], line[30:38], line[38:46], line[46:54]]\n",
    "            # get line header\n",
    "            line_id = splitted_line[0].split()[0]\n",
    "            \n",
    "            #check for atom and heteroatom\n",
    "            if line_id in {'ATOM', 'HETATM'}:\n",
    "                \n",
    "                # get CA atom only\n",
    "                if splitted_line[2].split()[0] in {'CA'}:\n",
    "                    \n",
    "                    # get atom num for indexing\n",
    "                    atom_num = int(splitted_line[5])\n",
    "                    # get protein chain for indexing\n",
    "                    chain = splitted_line[4]\n",
    "                    # get coordinates\n",
    "                    x, y, z = float(splitted_line[6]), float(splitted_line[7]), float(splitted_line[8])\n",
    "                    \n",
    "                    # check if actual chain already has an entry in coordinate_dict\n",
    "                    if chain not in coordinate_dict.keys():\n",
    "                        \n",
    "                        # index from 'start'\n",
    "                        atom_count_dict[chain] = start\n",
    "                        # create key for new chain\n",
    "                        coordinate_dict[chain] = {}\n",
    "                        # put actual atom coordinates in coordinate_dict\n",
    "                        coordinate_dict[chain][atom_count_dict[chain]] = np.array([x,y,z])\n",
    "                    # if actual chain already in coordinate_dict\n",
    "                    else:\n",
    "                        # move index forward\n",
    "                        atom_count_dict[chain] += 1\n",
    "                        # add the atom coordinates\n",
    "                        coordinate_dict[chain][atom_count_dict[chain]] = np.array([x,y,z])\n",
    "\n",
    "    # if there is only one chain, flat the dict\n",
    "    if len(coordinate_dict) == 1:\n",
    "        coordinate_dict = coordinate_dict.get([k for k in coordinate_dict][0])\n",
    "\n",
    "    return coordinate_dict\n",
    "\n",
    "\n",
    "def get_coordinate_tensor_from_dict(coordinate_dict, device='cuda'):\n",
    "    '''\n",
    "        Convert a coordinate_dict to a torch.tensor, for parallel euclidean distance calculation.\n",
    "        Works on dict in the form {atom_key : [x, y, z]}\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    coordinate_dict : dict\n",
    "        Is the coordinate_dict in the form {key : [x, y, z]}.\n",
    "        It also works for N-dimensional points.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    zero : torch.tensor\n",
    "        Returns a torch.tensor of shape n x m\n",
    "        'n'  are the keys in coordinate_dict al len(coordinate_dict)\n",
    "        'm' is the number of dimensions of your data points\n",
    "        \n",
    "        It save on gpu if torch.cuda.is_available(), else on cpu\n",
    "        If you want to move your data on cpu, e.g. for visualization,\n",
    "        you need to output_tensor.cpu()\n",
    "    '''\n",
    "    \n",
    "\n",
    "    #variables with dict dimension\n",
    "    dim0 = len(coordinate_dict)\n",
    "    first_key = [k for k in coordinate_dict.keys()][0]\n",
    "    dim1 = len(coordinate_dict[first_key])\n",
    "\n",
    "    #initialize a 0s tensor\n",
    "    #device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    zero = torch.zeros([dim0,dim1], dtype=torch.float32, device=device)\n",
    "\n",
    "    for index, peptide in enumerate(coordinate_dict):\n",
    "            \n",
    "        zero[index] = torch.tensor(coordinate_dict[peptide], device=device)\n",
    "                \n",
    "    return zero\n",
    "\n",
    "\n",
    "def get_tensors_from_multichain_dict(coordinate_dict):\n",
    "    '''\n",
    "    Generate tensor from multichain coordinate dict.\n",
    "    Your coordinate_dict is in the form:\n",
    "        \n",
    "        {chain : {atom : [x, y, z] }}\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    coordinate_dict : dict\n",
    "        Your coordinate_dict.\n",
    "        It is in the form:\n",
    "        {chain : {atom : [x, y, z] }}.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tensor_dict : dict\n",
    "        It is a dict of tensor, one tensor per chain.\n",
    "\n",
    "    '''\n",
    "    tensor_dict = {}\n",
    "    for chain in coordinate_dict:\n",
    "        tensor_dict[chain] = get_coordinate_tensor_from_dict(coordinate_dict[chain])\n",
    "    return tensor_dict\n",
    "\n",
    "\n",
    "def distance_matrix_from_2d_tensor(peptide1_tensor, peptide2_tensor=None, device='cpu'):\n",
    "    '''\n",
    "    Minimal function to calculate euclidean distance between two set of points\n",
    "    using quadratic expansion. Thanks to:\n",
    "            https://discuss.pytorch.org/t/efficient-distance-matrix-computation/9065\n",
    "            https://github.com/pytorch/pytorch/pull/25799\n",
    "            https://github.com/pytorch/pytorch/issues/15253\n",
    "    \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    peptide1_tensor : torch.tensor\n",
    "        torch.tensor of shape n x d.\n",
    "        \n",
    "    peptide2_tensor : torch.tensor, optional\n",
    "        The default is None.\n",
    "        torch.tensor for which you want to calculate te distance from peptide1_tensor\n",
    "        shape m x p\n",
    "        \n",
    "    device : str, optional\n",
    "        The default is 'cpu'.\n",
    "        Is the device on which to compute the calculation.\n",
    "        You can set it to 'cuda' if you have an Nvidia GPU and CUDA driver installed\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    distance_map : torch.tensor\n",
    "        shape n x p\n",
    "        tensor with the distances data\n",
    "\n",
    "    '''\n",
    "    \n",
    "\n",
    "    if peptide2_tensor == None:\n",
    "        peptide2_tensor = peptide1_tensor\n",
    "\n",
    "    # calculate distance\n",
    "    x_norm = torch.pow(peptide1_tensor, 2).sum(1).view(-1,1)\n",
    "    y_t = torch.transpose(peptide2_tensor, 0, 1)\n",
    "    y_norm = torch.pow(peptide2_tensor, 2).sum(1).view(1,-1)\n",
    "    \n",
    "    distance_map = torch.sqrt(x_norm + y_norm - 2.0 * torch.mm(peptide1_tensor, y_t))\n",
    "    \n",
    "    # convert nan to 0  (using this instead of torch.clamp())       \n",
    "    distance_map[torch.isnan(distance_map)] = 0\n",
    "    \n",
    "    # if you are calculating pointwise distance a single tensor\n",
    "    # main diagonal is 0, to fix stability errors\n",
    "    if peptide1_tensor is peptide2_tensor:\n",
    "        distance_map = distance_map.fill_diagonal_(0)\n",
    "    \n",
    "    return distance_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_cdist(x1, x2):\n",
    "    adjustment = x1.mean(-2, keepdim=True)\n",
    "    x1 = x1 - adjustment\n",
    "    x2 = x2 - adjustment  # x1 and x2 should be identical in all dims except -2 at this point\n",
    "\n",
    "    # Compute squared distance matrix using quadratic expansion\n",
    "    # But be clever and do it with a single matmul call\n",
    "    x1_norm = x1.pow(2).sum(dim=-1, keepdim=True)\n",
    "    x1_pad = torch.ones_like(x1_norm)\n",
    "    x2_norm = x2.pow(2).sum(dim=-1, keepdim=True)\n",
    "    x2_pad = torch.ones_like(x2_norm)\n",
    "    x1_ = torch.cat([-2. * x1, x1_norm, x1_pad], dim=-1)\n",
    "    x2_ = torch.cat([x2, x2_pad, x2_norm], dim=-1)\n",
    "    res = x1_.matmul(x2_.transpose(-2, -1))\n",
    "\n",
    "    # Zero out negative values\n",
    "    #res.clamp_min_(1e-30).sqrt_()\n",
    "    res = res.sqrt()\n",
    "    res[torch.isnan(res)]=0\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "frame = 0\n",
    "print('Analyzing frame n° ', frame)\n",
    "\n",
    "frame_dict = t_test.get_frame(frame)\n",
    "\n",
    "frame_tensor = backend.distance_tensor.get_coordinate_tensor_from_(frame_dict)\n",
    "\n",
    "start_dist = timer()\n",
    "frame_distance_maps = backend.distance_tensor.compute_euclidean_norm_torch(frame_tensor)\n",
    "end_dist = timer()\n",
    "print('Time to compute distance is: ', (end_dist - start_dist))\n",
    "\n",
    "start_contc = timer()\n",
    "frame_contact = backend.pattern_recognition.compute_contact_maps_as_array(frame_distance_maps)\n",
    "end_contc = timer()\n",
    "print('Time to compute contact is: ', (end_contc - start_contc))\n",
    "\n",
    "start_den = timer()\n",
    "frame_denoised, df = backend.pattern_recognition.denoise_contact_maps(frame_contact)\n",
    "end_den = timer()\n",
    "print('Time to denoise: ', (end_den-start_den))\n",
    "\n",
    "#frame_graph = backend.graph.nx_graph_search(self.frame_denoised)\n",
    "\n",
    "frame_graph_full = backend.graph.graph_v1(frame_denoised, df)\n",
    "\n",
    "subgraphs = backend.graph.find_subgraph(frame_graph_full)\n",
    "\n",
    "self.results[frame] = results.get_data(self, 'graph', frame_graph_full)\n",
    "self.results[frame].get_data(self, 'subgraph', subgraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peptides_dict[0].frame_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

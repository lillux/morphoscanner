{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "#import plotly.express as px\n",
    "\n",
    "from mpl_toolkits import mplot3d\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "#from functools import lru_cache\n",
    "#import re\n",
    "import networkx as nx\n",
    "#from networkx.algorithms import approximation\n",
    "\n",
    "import MDAnalysis as mda\n",
    "\n",
    "import scipy\n",
    "#import sklearn\n",
    "#import skimage\n",
    "\n",
    "#import xml.etree.ElementTree as et\n",
    "#from Bio.PDB import *\n",
    "#import nglview as nv\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# http://nglviewer.org/nglview/latest/api.html\n",
    "# https://biopython.org/wiki/The_Biopython_Structural_Bioinformatics_FAQ\n",
    "# https://ambermd.org/tutorials/analysis/tutorial_notebooks/nglview_notebook/index.html\n",
    "# https://amber-md.github.io/pytraj/latest/_api/pytraj.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laptop\n",
    "#aminoacids_name = '/home/lillo/Documenti/Tesi_CNTE/Martini_ff/Martini_itp/from_fede_cluster/martini_v2.2_aminoacids.itp'\n",
    "#solvents_name = '/home/lillo/Documenti/Tesi_CNTE/Martini_ff/Martini_itp/from_fede_cluster/martini_v2.0_solvents.itp'\n",
    "#ions_name = '/home/lillo/Documenti/Tesi_CNTE/Martini_ff/Martini_itp/from_fede_cluster/martini_v2.0_ions.itp'\n",
    "#water_name = '/home/lillo/Documenti/Tesi_CNTE/Martini_ff/Martini_itp/from_fede_cluster/martini_v2.2.itp'\n",
    "#sugars_name = '/home/lillo/Documenti/Tesi_CNTE/Martini_ff/Martini_itp/05-2020/martini_v2.0_sugars.itp'\n",
    "\n",
    "#Trajectory\n",
    "\n",
    "#contact_matrix = np.loadtxt('/home/lillo/TesiCNTE/CNTE/dataset/contact_matrix.txt')   #laptop\n",
    "#contact_matrix = np.loadtxt('/home/lillo/Code/Tesi/dataset/contact_matrix.txt')        #fisso\n",
    "#contact_matrix_single = contact_matrix.reshape(100,100,12,12)\n",
    "\n",
    "#gromacs_output = open('/home/lillo/Code/Tesi/dataset/dm4500Compl_mix1_K2_1%4500ns.gro') #fisso\n",
    "#gromacs_output = open('/home/lillo/TesiCNTE/CNTE/dataset/dm4500Compl_mix1_K2_1%4500ns.gro') #laptop\n",
    "\n",
    "#path = '/home/lillo/Code/Tesi/dataset/dm4500Compl_mix1_K2_1%4500ns.gro' #fisso\n",
    "#path = '/home/lillo/TesiCNTE/CNTE/dataset/dm4500Compl_mix1_K2_1%4500ns.gro' #laptop\n",
    "\n",
    "# import 2mxu file (beta sheet)\n",
    "\n",
    "#path_to_mmCIF = open('/home/lillo/TesiCNTE/pdb/2mxu/2mxu.cif')  ## laptop\n",
    "#path_to_pdb = '/home/lillo/TesiCNTE/pdb/2mxu/2mxu.pdb'  ## laptop\n",
    "#pa_to_pdb = '/home/lillo/TesiCNTE/pdb/2mxu/2mxu.pdb'  ## laptop\n",
    "\n",
    "#path_to_mmCIF = open('/home/lillo/Code/Tesi/pdb/2mxu/2mxu.cif')  ## fisso\n",
    "#path_to_pdb = '/home/lillo/Code/Tesi/pdb/2mxu/2mxu.pdb'  ## fisso\n",
    "#pa_to_pdb = '/home/lillo/Code/Tesi/pdb/2mxu/2mxu.pdb'  ## fisso\n",
    "\n",
    "#seed_1_path = '/home/lillo/TesiCNTE/from_cluster/aggregate1.gro' # laptop\n",
    "#seed_1_path = '/home/lillo/Code/Tesi/dataset/aggregate1.gro'    # Fisso\n",
    "\n",
    "#prod_gro = '/home/lillo/TesiCNTE/from_cluster/prod/prod_part1/min.gro'            # laptop\n",
    "#prod_xtc = '/home/lillo/TesiCNTE/from_cluster/prod/prod_part1/prod.xtc'           # laptop\n",
    "#prod1_xtc = '/home/lillo/TesiCNTE/from_cluster/prod/prod_part2/prod-compl.xtc'    # laptop\n",
    "\n",
    "prod_gro = '/run/media/lillo/Archivio/from_linux/Code/Tesi/dataset/prod/prod_part1/min.gro'           #fisso\n",
    "prod_xtc = '/run/media/lillo/Archivio/from_linux/Code/Tesi/dataset/prod/prod_part1/prod.xtc'          #fisso\n",
    "prod1_xtc = '/run/media/lillo/Archivio/from_linux/Code/Tesi/dataset/prod/prod_part2/prod-compl.xtc'   #fisso\n",
    "\n",
    "\n",
    "#trj_xtc = '/home/lillo/TesiCNTE/CNTE/trajectory/prd-LDLK12-100mer-out-mol.xtc'  #laptop\n",
    "#trj_gro = '/home/lillo/TesiCNTE/CNTE/trajectory/min-LDLK12-100mer-out-c.gro'    #laptop\n",
    "\n",
    "trj_gro = '/run/media/lillo/Archivio/from_linux/Code/Tesi/dataset/trajectory_6_12_19/min-LDLK12-100mer-out-c.gro'     #fisso\n",
    "trj_xtc = '/run/media/lillo/Archivio/from_linux/Code/Tesi/dataset/trajectory_6_12_19/prd-LDLK12-100mer-out-mol.xtc'   #fisso\n",
    "\n",
    "#lipase = '/home/lillo/Documenti/PDB/lipase/3d2c.pdb'\n",
    "#lipase1 = '/home/lillo/Documenti/PDB/lipase/1gpl.pdb'\n",
    "\n",
    "glico_6bis_gro = '/home/lillo/TesiCNTE/from_cluster/glicosilati_6bis/6bis-gluc/eq-2-out.gro'\n",
    "glico_6bis_trr = '/home/lillo/TesiCNTE/from_cluster/glicosilati_6bis/6bis-gluc/production/prd-6bis-GLUC-40mer-3per-out.trr'\n",
    "glico_6bis_tpr = '/home/lillo/TesiCNTE/from_cluster/glicosilati_6bis/6bis-gluc/production/prd-6bis-GLUC-40mer-3per.tpr'\n",
    "\n",
    "#glico_6bis_gro = '/home/lillo/Documenti/Tesi_CNTE/data/glicosilati_6bis/6bis-gluc/eq-2-out.gro'\n",
    "#glico_6bis_trr = '/home/lillo/Documenti/Tesi_CNTE/data/glicosilati_6bis/6bis-gluc/production/prd-6bis-GLUC-40mer-3per-out.trr'\n",
    "#glico_6bis_tpr = '/home/lillo/Documenti/Tesi_CNTE/data/glicosilati_6bis/6bis-gluc/production/prd-6bis-GLUC-40mer-3per.tpr'\n",
    "\n",
    "#p73_2per_wat_seed_1_gro = '/home/lillo/TesiCNTE/from_cluster/peptide_73/MARTINI/2%/WATER/2%/seed_1/prod/73prod.gro'     # laptop\n",
    "#p73_2per_wat_seed_1_xtc = '/home/lillo/TesiCNTE/from_cluster/peptide_73/MARTINI/2%/WATER/2%/seed_1/prod/73prod.xtc'     # laptop\n",
    "#p73_2per_wat_seed_1_trr = '/home/lillo/TesiCNTE/from_cluster/peptide_73/MARTINI/2%/WATER/2%/seed_1/prod/73prod.trr'     # laptop\n",
    "\n",
    "### LAPTOP GLICOSILATI\n",
    "#glac_1perc_1_gro = '/home/lillo/TesiCNTE/from_cluster/glicosilati_6bis/6bis-GlAC/1perc/6bis-GLAC-1p/equilibration-2/eq-2-out.gro'\n",
    "#glac_1perc_1_trr = '/home/lillo/TesiCNTE/from_cluster/glicosilati_6bis/6bis-GlAC/1perc/6bis-GLAC-1p/production/prd-6bis-GLAC-13mer-1per-out.trr'\n",
    "\n",
    "#glac_1perc_2_gro = '/home/lillo/TesiCNTE/from_cluster/glicosilati_6bis/6bis-GlAC/1perc/6bis-GLAC-1p-2/equilibration-2/eq-2-out.gro'\n",
    "#glac_1perc_2_trr = '/home/lillo/TesiCNTE/from_cluster/glicosilati_6bis/6bis-GlAC/1perc/6bis-GLAC-1p-2/production/prd-6bis-GLAC-13mer-1per-2-out.trr'\n",
    "\n",
    "#glac_1perc_3_gro = '/home/lillo/TesiCNTE/from_cluster/glicosilati_6bis/6bis-GlAC/1perc/6bis-GLAC-1p-3/equilibration-2/eq-2-out.gro'\n",
    "#glac_1perc_3_trr = '/home/lillo/TesiCNTE/from_cluster/glicosilati_6bis/6bis-GlAC/1perc/6bis-GLAC-1p-3/production/prd-6bis-GLAC-13mer-1per-3-out.trr'\n",
    "\n",
    "#glac_3perc_1_gro = '/home/lillo/TesiCNTE/from_cluster/glicosilati_6bis/6bis-GlAC/3perc/6bis-GLAC/equilibration-2/eq-2-out.gro'\n",
    "#glac_3perc_1_trr = '/home/lillo/TesiCNTE/from_cluster/glicosilati_6bis/6bis-GlAC/3perc/6bis-GLAC/production/prd-6bis-GLAC-40mer-3per-out.trr'\n",
    "\n",
    "#glac_3perc_2_gro = '/home/lillo/TesiCNTE/from_cluster/glicosilati_6bis/6bis-GlAC/3perc/6bis-GLAC-2/equilibration-2/eq-2-out.gro'\n",
    "#glac_3perc_2_trr = '/home/lillo/TesiCNTE/from_cluster/glicosilati_6bis/6bis-GlAC/3perc/6bis-GLAC-2/production/prd-6bis-40mer-3per-out.trr'\n",
    "\n",
    "#glac_3perc_3_gro = '/home/lillo/TesiCNTE/from_cluster/glicosilati_6bis/6bis-GlAC/3perc/6bis-GLAC-3/equilibration-2/eq-2-out.gro'\n",
    "#glac_3perc_3_trr = '/home/lillo/TesiCNTE/from_cluster/glicosilati_6bis/6bis-GlAC/3perc/6bis-GLAC-3/production/prd-6bis-GLAC-40mer-3per-out.trr'\n",
    "\n",
    "\n",
    "### FISSO GLICOSILATI\n",
    "glac_3perc_1_gro = '/run/media/lillo/Archivio/Dataset/CNTE/6bis-GlAC/3perc/6bis-GLAC/equilibration-2/eq-2-out.gro'\n",
    "glac_3perc_1_trr = '/run/media/lillo/Archivio/Dataset/CNTE/6bis-GlAC/3perc/6bis-GLAC/production/prd-6bis-GLAC-40mer-3per-out.trr'\n",
    "\n",
    "glac_3perc_2_gro = '/run/media/lillo/Archivio/Dataset/CNTE/6bis-GlAC/3perc/6bis-GLAC-2/equilibration-2/eq-2-out.gro'\n",
    "glac_3perc_2_trr = '/run/media/lillo/Archivio/Dataset/CNTE/6bis-GlAC/3perc/6bis-GLAC-2/production/prd-6bis-40mer-3per-out.trr'\n",
    "\n",
    "glac_3perc_3_gro = '/run/media/lillo/Archivio/Dataset/CNTE/6bis-GlAC/3perc/6bis-GLAC-3/equilibration-2/eq-2-out.gro'\n",
    "glac_3perc_3_trr = '/run/media/lillo/Archivio/Dataset/CNTE/6bis-GlAC/3perc/6bis-GLAC-3/production/prd-6bis-GLAC-40mer-3per-out.trr'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import morphoscanner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Mi serve un oggetto peptide con sequenza ed atom_number.\n",
    "### La sequenza la prendo una volta sola e sarà sempre la stessa\n",
    "### L'atom_number mi serve perché così posso prendermi le coordinate\n",
    "### dai timestep quando voglio, anche per singolo peptide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot from trajectory positions  ### WORKING BUT YOU NEED TO:\n",
    "# make_universe\n",
    "# positions = universe.select_atoms('name BB').positions\n",
    "def plot_peptide_from_trajectory_frame(positions, peptide_list=None, centroid=False):\n",
    "    \n",
    "    '''\n",
    "    Plot atoms from universe.trajectory[frame]\n",
    "    '''\n",
    "       \n",
    "    if peptide_list == None:\n",
    "        \n",
    "        peptide_list = [e for e in range(len(positions))]\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "\n",
    "    for peptide in range(len(peptide_list)):\n",
    "        x.append([peptide])\n",
    "        y.append([peptide])\n",
    "        z.append([peptide])\n",
    "\n",
    "        point = positions[peptide_list[peptide]]\n",
    "        #print(peptide, point)\n",
    "        x[peptide].append(point[0])\n",
    "        y[peptide].append(point[1])\n",
    "        z[peptide].append(point[2])\n",
    "\n",
    "        del x[peptide][0]\n",
    "        del y[peptide][0]\n",
    "        del z[peptide][0]\n",
    "\n",
    "    fig = plt.figure()\n",
    "\n",
    "    ax = plt.axes(projection='3d')\n",
    "\n",
    "    for pep in range(len(x)):\n",
    "\n",
    "        # scatter points, making list from torch tensor item\n",
    "        ax.scatter3D([e.item() for e in x[pep]],[e.item() for e in y[pep]],[e.item() for e in z[pep]])\n",
    "\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly as px \n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_protein(coordinate_dict):\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "\n",
    "    for residue in coordinate_dict:\n",
    "        point = coordinate_dict[residue]\n",
    "        x.append(point[0])\n",
    "        y.append(point[1])\n",
    "        z.append(point[2])\n",
    "\n",
    "\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    z = np.asarray(z)\n",
    "\n",
    "    fig = go.Figure(data = [go.Scatter3d (x = x, y = y, z= z)])\n",
    "    return fig.show()\n",
    "\n",
    "def heatmap2d(arr: np.ndarray):\n",
    "    plt.imshow(arr, cmap = 'viridis', interpolation = 'nearest')\n",
    "    plt.colorbar()\n",
    "    return plt.show()\n",
    "\n",
    "def get_euclidean_distance(point_1, point_2):\n",
    "\n",
    "    euclidean_distance = np.sqrt(np.sum([((point_1[0] - point_2[0])**2), ((point_1[1] - point_2[1])**2), ((point_1[2] - point_2[2])**2)]))\n",
    "\n",
    "    return euclidean_distance\n",
    "\n",
    "def compute_distance_map(coordinate_dict):\n",
    "    i = 0\n",
    "    distance_map = np.zeros((len(coordinate_dict),len(coordinate_dict)))\n",
    "    for  i  in range(i, len(coordinate_dict)-1):\n",
    "        coordinate_1 = coordinate_dict[i] \n",
    "        for j in range(0, len(coordinate_dict)-1):\n",
    "            coordinate_2 = coordinate_dict[j]\n",
    "            euclidean_distance = get_euclidean_distance(coordinate_1, coordinate_2)\n",
    "            distance_map[i][j] = euclidean_distance\n",
    "            distance_map[j][i] = euclidean_distance\n",
    "    return distance_map\n",
    "\n",
    "def contact_map_helix(distance_map):\n",
    "    contact_map = np.zeros((len(distance_map),len(distance_map)))\n",
    "    for i in range(1, len(distance_map)-1):\n",
    "        for j in range(1, len(distance_map)-1):\n",
    "            if 0.45 < distance_map[i][j] < 0.46:\n",
    "                contact_map[i][j] = 1\n",
    "            elif 0.52 < distance_map[i][j] < 0.56:\n",
    "                contact_map[i][j] = 2\n",
    "    return contact_map\n",
    "\n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "\n",
    "#multiprocessing.cpu_count()\n",
    "available_cpu = len(os.sched_getaffinity(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@author: lillo\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def get_coordinate_from_pdb(file):\n",
    "    '''\n",
    "    Parse a pdb file. Support single chain and multiple chain\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file : str\n",
    "        The path of the .pdb file in your system.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    coordinate_dict : dict\n",
    "        A dict of dict with the coordinate of each atom of the pdb file.\n",
    "        \n",
    "        Depending on the input file it has different levels of nesting:\n",
    "            \n",
    "            for single chain:\n",
    "                atom_index : [x,y,z]\n",
    "                \n",
    "            for multiple chain:\n",
    "                \n",
    "                chain_index : {atom index : [x,y,z]}\n",
    "    '''\n",
    "    \n",
    "    with open(file) as pdbfile:\n",
    "\n",
    "        coordinate_dict = {}\n",
    "        atom_count_dict = {}\n",
    "        start = 0\n",
    "\n",
    "        for line in pdbfile:\n",
    "            \n",
    "            # split line\n",
    "            splitted_line = [line[:6], line[6:11], line[12:16], line[17:20], line[21], line[22:26], line[30:38], line[38:46], line[46:54]]\n",
    "            # get line header\n",
    "            line_id = splitted_line[0].split()[0]\n",
    "            \n",
    "            #check for atom and heteroatom\n",
    "            if line_id in {'ATOM', 'HETATM'}:\n",
    "                \n",
    "                # get CA atom only\n",
    "                if splitted_line[2].split()[0] in {'CA'}:\n",
    "                    \n",
    "                    # get atom num for indexing\n",
    "                    atom_num = int(splitted_line[5])\n",
    "                    # get protein chain for indexing\n",
    "                    chain = splitted_line[4]\n",
    "                    # get coordinates\n",
    "                    x, y, z = float(splitted_line[6]), float(splitted_line[7]), float(splitted_line[8])\n",
    "                    \n",
    "                    # check if actual chain already has an entry in coordinate_dict\n",
    "                    if chain not in coordinate_dict.keys():\n",
    "                        \n",
    "                        # index from 'start'\n",
    "                        atom_count_dict[chain] = start\n",
    "                        # create key for new chain\n",
    "                        coordinate_dict[chain] = {}\n",
    "                        # put actual atom coordinates in coordinate_dict\n",
    "                        coordinate_dict[chain][atom_count_dict[chain]] = np.array([x,y,z])\n",
    "                    # if actual chain already in coordinate_dict\n",
    "                    else:\n",
    "                        # move index forward\n",
    "                        atom_count_dict[chain] += 1\n",
    "                        # add the atom coordinates\n",
    "                        coordinate_dict[chain][atom_count_dict[chain]] = np.array([x,y,z])\n",
    "\n",
    "    # if there is only one chain, flat the dict\n",
    "    if len(coordinate_dict) == 1:\n",
    "        coordinate_dict = coordinate_dict.get([k for k in coordinate_dict][0])\n",
    "\n",
    "    return coordinate_dict\n",
    "\n",
    "\n",
    "def get_coordinate_tensor_from_dict(coordinate_dict, device='cuda'):\n",
    "    '''\n",
    "        Convert a coordinate_dict to a torch.tensor, for parallel euclidean distance calculation.\n",
    "        Works on dict in the form {atom_key : [x, y, z]}\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    coordinate_dict : dict\n",
    "        Is the coordinate_dict in the form {key : [x, y, z]}.\n",
    "        It also works for N-dimensional points.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    zero : torch.tensor\n",
    "        Returns a torch.tensor of shape n x m\n",
    "        'n'  are the keys in coordinate_dict al len(coordinate_dict)\n",
    "        'm' is the number of dimensions of your data points\n",
    "        \n",
    "        It save on gpu if torch.cuda.is_available(), else on cpu\n",
    "        If you want to move your data on cpu, e.g. for visualization,\n",
    "        you need to output_tensor.cpu()\n",
    "    '''\n",
    "    \n",
    "\n",
    "    #variables with dict dimension\n",
    "    dim0 = len(coordinate_dict)\n",
    "    first_key = [k for k in coordinate_dict.keys()][0]\n",
    "    dim1 = len(coordinate_dict[first_key])\n",
    "\n",
    "    #initialize a 0s tensor\n",
    "    #device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    zero = torch.zeros([dim0,dim1], dtype=torch.float32, device=device)\n",
    "\n",
    "    for index, peptide in enumerate(coordinate_dict):\n",
    "            \n",
    "        zero[index] = torch.tensor(coordinate_dict[peptide], device=device)\n",
    "                \n",
    "    return zero\n",
    "\n",
    "\n",
    "def get_tensors_from_multichain_dict(coordinate_dict):\n",
    "    '''\n",
    "    Generate tensor from multichain coordinate dict.\n",
    "    Your coordinate_dict is in the form:\n",
    "        \n",
    "        {chain : {atom : [x, y, z] }}\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    coordinate_dict : dict\n",
    "        Your coordinate_dict.\n",
    "        It is in the form:\n",
    "        {chain : {atom : [x, y, z] }}.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tensor_dict : dict\n",
    "        It is a dict of tensor, one tensor per chain.\n",
    "\n",
    "    '''\n",
    "    tensor_dict = {}\n",
    "    for chain in coordinate_dict:\n",
    "        tensor_dict[chain] = get_coordinate_tensor_from_dict(coordinate_dict[chain])\n",
    "    return tensor_dict\n",
    "\n",
    "\n",
    "def distance_matrix_from_2d_tensor(peptide1_tensor, peptide2_tensor=None, device='cpu'):\n",
    "    '''\n",
    "    Minimal function to calculate euclidean distance between two set of points\n",
    "    using quadratic expansion. Thanks to:\n",
    "            https://discuss.pytorch.org/t/efficient-distance-matrix-computation/9065\n",
    "            https://github.com/pytorch/pytorch/pull/25799\n",
    "            https://github.com/pytorch/pytorch/issues/15253\n",
    "    \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    peptide1_tensor : torch.tensor\n",
    "        torch.tensor of shape n x d.\n",
    "        \n",
    "    peptide2_tensor : torch.tensor, optional\n",
    "        The default is None.\n",
    "        torch.tensor for which you want to calculate te distance from peptide1_tensor\n",
    "        shape m x p\n",
    "        \n",
    "    device : str, optional\n",
    "        Options: 'cpu', 'cuda'\n",
    "        The default is 'cpu'.\n",
    "        \n",
    "        Is the device on which to compute the calculation.\n",
    "        You can set it to 'cuda' if you have an Nvidia GPU and CUDA driver installed.\n",
    "        \n",
    "        'cuda' will move the data in the GPU memory, so you have to use data.cpu() to move\n",
    "        data back to system memory. data in system memory are needed to plot data\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    distance_map : torch.tensor\n",
    "        shape n x p\n",
    "        tensor with the distances data\n",
    "\n",
    "    '''\n",
    "    \n",
    "\n",
    "    if peptide2_tensor == None:\n",
    "        peptide2_tensor = peptide1_tensor\n",
    "\n",
    "    # calculate distance\n",
    "    x_norm = torch.pow(peptide1_tensor, 2).sum(1).view(-1,1)\n",
    "    y_t = torch.transpose(peptide2_tensor, 0, 1)\n",
    "    y_norm = torch.pow(peptide2_tensor, 2).sum(1).view(1,-1)\n",
    "    \n",
    "    distance_map = torch.sqrt(x_norm + y_norm - 2.0 * torch.mm(peptide1_tensor, y_t))\n",
    "    \n",
    "    # convert nan to 0  (using this instead of torch.clamp())       \n",
    "    distance_map[torch.isnan(distance_map)] = 0\n",
    "    \n",
    "    # if you are calculating pointwise distance a single tensor\n",
    "    # main diagonal is 0, to fix stability errors\n",
    "    if peptide1_tensor is peptide2_tensor:\n",
    "        distance_map = distance_map.fill_diagonal_(0)\n",
    "    \n",
    "    return distance_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This works if i multiply a tensor with a matrix\n",
    "def fast_cdist(x1, x2):\n",
    "    adjustment = x1.mean(-2, keepdim=True)\n",
    "    x1 = x1 - adjustment\n",
    "    x2 = x2 - adjustment  # x1 and x2 should be identical in all dims except -2 at this point\n",
    "\n",
    "    # Compute squared distance matrix using quadratic expansion\n",
    "    # But be clever and do it with a single matmul call\n",
    "    x1_norm = x1.pow(2).sum(dim=-1, keepdim=True)\n",
    "    x1_pad = torch.ones_like(x1_norm)\n",
    "    x2_norm = x2.pow(2).sum(dim=-1, keepdim=True)\n",
    "    x2_pad = torch.ones_like(x2_norm)\n",
    "    x1_ = torch.cat([-2. * x1, x1_norm, x1_pad], dim=-1)\n",
    "    x2_ = torch.cat([x2, x2_pad, x2_norm], dim=-1)\n",
    "    res = x1_.matmul(x2_.transpose(-2, -1))\n",
    "\n",
    "    # Zero out negative values\n",
    "    #res.clamp_min_(1e-30).sqrt_()\n",
    "    res = res.sqrt()\n",
    "    res[torch.isnan(res)]=0\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosa voglio?\n",
    "# voglio fare in modo di accellerare la computazione delle distanze anche tra peptidi di dimensione diversa\n",
    "# utilizzando operazioni tra tensori per parallelizzare i calcoli\n",
    "#\n",
    "# se ho un set di proteine di dimensione diversa,\n",
    "# come faccio il calcolo delle distanze utilizzando i tensori?\n",
    "# \n",
    "# opzione 1\n",
    "# faccio tensori che contengono peptidi della stessa dimensione\n",
    "# poi come metto i risultati in ordine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aminoacids_name = '/home/lillo/Documenti/Tesi_CNTE/Martini_ff/Martini_itp/from_fede_cluster/martini_v2.2_aminoacids.itp'\n",
    "solvents_name = '/home/lillo/Documenti/Tesi_CNTE/Martini_ff/Martini_itp/from_fede_cluster/martini_v2.0_solvents.itp'\n",
    "ions_name = '/home/lillo/Documenti/Tesi_CNTE/Martini_ff/Martini_itp/from_fede_cluster/martini_v2.0_ions.itp'\n",
    "water_name = '/home/lillo/Documenti/Tesi_CNTE/Martini_ff/Martini_itp/from_fede_cluster/martini_v2.2.itp'\n",
    "sugars_name = '/home/lillo/Documenti/Tesi_CNTE/Martini_ff/Martini_itp/05-2020/martini_v2.0_sugars.itp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_molnames(path):\n",
    "    name_list = []\n",
    "    flag = False\n",
    "    with open(path) as martini_amino:\n",
    "        for line in martini_amino:\n",
    "            if flag:\n",
    "                name_list.append(line.split()[0])\n",
    "                flag = False\n",
    "\n",
    "            if len(line.split()) > 1:\n",
    "                actual_line = line.split()\n",
    "\n",
    "                actual_line = [i.split(';') for i in actual_line]\n",
    "                if 'molname' in actual_line[1] or 'molname' in actual_line[0]:\n",
    "                    flag = True\n",
    "    return name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni = universe.select_atoms('not name W WF CL- NA+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ho un dict con dentro un dict per ogni peptide in cui key:val is res_number:[x,y,z].\n",
    "# faccio un dict dove {key:value} è {peptide_index:tensor of shape n x 3}, dove n è il numero di residui del peptide.\n",
    "# raggruppo in un dict per dimensione, dove {key:val} is {numero di residui : tensore of shape m x n x 3\n",
    "# dove 'm' è il numero di peptidi, 'n' è il numero di residui nei peptidi, 3 è [x,y,z].\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcola la distanza mediana tra c alfa per ogni peptide\n",
    "# poi prendi la mediana della mediana\n",
    "# che sarà il threshold di distanza che definisce il contatto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = trajectory(glac_3perc_1_gro, glac_3perc_1_trr, select=['aminoacids'])\n",
    "b = trajectory(glac_3perc_2_gro, glac_3perc_2_trr, select=['aminoacids'])\n",
    "c = trajectory(glac_3perc_3_gro, glac_3perc_3_trr, select=['aminoacids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.explore()\n",
    "b.explore()\n",
    "c.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.compose_database(100)\n",
    "b.compose_database(100)\n",
    "c.compose_database(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a.analyze_inLoop()\n",
    "b.analyze_inLoop()\n",
    "c.analyze_inLoop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.get_data()\n",
    "b.get_data()\n",
    "c.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.get_database()\n",
    "b.get_database()\n",
    "c.get_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a.database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a.plot_aggregates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.plot_contacts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.plot_peptides_in_beta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.plot3d_parallel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.plot_graph(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.plot_frame_aggregate(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.plot3d_antiparallel_negative()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.plot3d_antiparallel_positive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import morphoscanner\n",
    "from morphoscanner import backend, data_acquisition, trj_object\n",
    "from morphoscanner.backend import distance_tensor, pattern_recognition, graph, topology\n",
    "from morphoscanner.backend.check_val import isInt\n",
    "\n",
    "import tqdm\n",
    "from timeit import default_timer as timer\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from scipy.interpolate import make_interp_spline, BSpline, interp1d,interpolate\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "class trajectory:\n",
    "    '''Class to operate on trajectory files.\n",
    "    It makes an object that contain the trajectory of the simulation.\n",
    "    From this object is possible to conduct analysis'''\n",
    "\n",
    "    def __init__(self, trj_gro, trj_xtc, select = None):\n",
    "        \n",
    "        self.trj_gro = trj_gro\n",
    "        self.trj_xtc = trj_xtc\n",
    "        self.universe = backend.topology.make_universe(self.trj_gro, self.trj_xtc)\n",
    "        self.number_of_frames = len(self.universe.trajectory)\n",
    "        \n",
    "        if select == None:\n",
    "            select = ['aminoacids']\n",
    "            \n",
    "        self.select = select\n",
    "       \n",
    "        self.peptide_length_list = backend.topology.get_peptide_length_list(self.trj_gro, self.select)\n",
    "        \n",
    "        self.len_dict = backend.topology.get_peptide_length_dict(self.peptide_length_list)\n",
    "        \n",
    "        print('In your trajectory there are %d frames.\\n' % self.number_of_frames)\n",
    "\n",
    "        morphoscanner.backend.topology.print_peptides_length(self.len_dict)\n",
    "        \n",
    "        return            \n",
    "        \n",
    "    def split(self, to_split: list, split_size: list):\n",
    "        '''Manually split peptide_length_list in case of seeds.\n",
    "        \n",
    "        Input:\n",
    "            to_split: list\n",
    "                list of int or ints.\n",
    "                Each int refers to the length of a peptides seed\n",
    "                from self.len_dict.keys() that you want to split in single peptide.\n",
    "                For example if in len dict there are seeds of length 96 that you want to split,\n",
    "                to_split = [96]\n",
    "                \n",
    "            split_size: list\n",
    "                list of int or ints.\n",
    "                This is the size in which you want to split your to_split seeds.\n",
    "                For example if you want to split your seeds of length 96 in peptides of length 12,\n",
    "                split_size = [12]\n",
    "                \n",
    "        Output:\n",
    "            Change the original self.peptide_length_list with a new list of splitted peptides.\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        splitting_dict = data_acquisition.script_inputs.get_splitting_dict(to_split, split_size)\n",
    "        self.peptide_length_list = data_acquisition.script_inputs.get_new_peptides_length(self.peptide_length_list, splitting_dict)\n",
    "        print('Splitting done.\\n')\n",
    "        print('\"peptide_length_list\" attribute has been updated with the new length.')\n",
    "        \n",
    "        return    \n",
    "    \n",
    "    def explore(self):\n",
    "        frame = 0\n",
    "        self.frames = {}\n",
    "        self.frames[frame] = trj_object.trj_objects.frames(frame)\n",
    "        self.frames[frame].peptides = backend.topology.get_data_from_trajectory_frame_v2(universe=self.universe, frame=frame, select=self.select)\n",
    "        print('Exploration of frame %d done.\\n' % frame)\n",
    "\n",
    "        return    \n",
    "    \n",
    "    def compose_database(self, sampling_interval=1):\n",
    "        \n",
    "        steps = [s for s in range(self.number_of_frames) if (s % sampling_interval)==0 and (s != 0)]\n",
    "        for step in tqdm.tqdm(steps):\n",
    "            self.universe.trajectory[step]\n",
    "            self.frames[step] = trj_object.trj_objects.frames(step)\n",
    "            self.frames[step].peptides = {}\n",
    "            for pep in self.frames[0].peptides:\n",
    "                c_list = {}\n",
    "\n",
    "                for idx, i in enumerate(self.frames[0].peptides[pep].atom_numbers.values()):\n",
    "                    p = self.universe.atoms[i].position\n",
    "                    c_list[idx] = p\n",
    "\n",
    "                self.frames[step].peptides[pep] = trj_object.trj_objects.single_peptide(self.frames[0].peptides[pep].sequence,self.frames[0].peptides[pep].atom_numbers,c_list)\n",
    "\n",
    "        return\n",
    "        \n",
    "    def get_frame(self, frame):\n",
    "        \n",
    "        a_frame = {}\n",
    "\n",
    "        for pep in self.frames[frame].peptides:\n",
    "            a_frame[pep] = self.frames[frame].peptides[pep].coordinates\n",
    "\n",
    "        return a_frame\n",
    "    \n",
    "    def get_peptide(self, peptide):\n",
    "    \n",
    "        a_peptide = {}\n",
    "        for frame in self.frames:\n",
    "            \n",
    "            a_peptide[frame] = self.frames[frame].peptides[peptide].coordinates\n",
    "            \n",
    "        return a_peptide\n",
    "    \n",
    "    # add something to ask for threshold in main.py\n",
    "    def analysis(self, frame, threshold_multiplier=1.45):\n",
    "        # check if threshold is given\n",
    "        try:\n",
    "            threshold = self.contact_threshold\n",
    "        except:\n",
    "            dic_0 = self.get_frame(0)\n",
    "            frame_distance_0 = distance_tensor.compute_distance_and_contact_maps(dic_0, threshold=0, contacts_calculation=False)\n",
    "            threshold = distance_tensor.get_median_c_alpha_distance(frame_distance_0) * threshold_multiplier\n",
    "            self.contact_threshold = threshold\n",
    "            print(\"Two nearby atoms of different peptides are contacting if the distance is lower than: %s Angstrom\" % str(self.contact_threshold))\n",
    "    \n",
    "        #frame = frame\n",
    "        print('Analyzing frame n° ', frame)\n",
    "    \n",
    "        frame_dict = self.get_frame(frame)\n",
    "        \n",
    "        start_dist = timer()\n",
    "        frame_distance, frame_contact = distance_tensor.compute_distance_and_contact_maps(frame_dict, threshold=threshold)\n",
    "        end_dist = timer()\n",
    "        print('Time to compute distance is: ', (end_dist - start_dist))\n",
    "\n",
    "        start_den = timer()\n",
    "        frame_denoised, df = pattern_recognition.denoise_contact_maps_torch(frame_contact)\n",
    "        end_den = timer()\n",
    "        print('Time to denoise: ', (end_den-start_den))\n",
    "    \n",
    "        frame_graph_full = graph.graph_v1(frame_denoised, df)\n",
    "        \n",
    "        subgraphs = graph.find_subgraph(frame_graph_full)  \n",
    "        \n",
    "        self.frames[frame].results = trj_object.trj_objects.results()\n",
    "        self.frames[frame].results.distance_maps = frame_distance\n",
    "        self.frames[frame].results.contact_maps = frame_contact\n",
    "        self.frames[frame].results.cross_correlation = df\n",
    "        self.frames[frame].results.graph = frame_graph_full\n",
    "        self.frames[frame].results.subgraphs = subgraphs\n",
    "        print('Finished analysis of frame n° %d' % frame)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    \n",
    "    def analyze_inLoop(self, threshold=None, threshold_multiplier=1.45):\n",
    "        \n",
    "        if threshold != None:\n",
    "            self.contact_threshold=threshold\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        print('processing started...')\n",
    "        start = timer()\n",
    "        for frame in self.frames:\n",
    "            start_an = timer()\n",
    "            self.analysis(frame, threshold_multiplier=threshold_multiplier)\n",
    "            end_an = timer()\n",
    "            text = 'Time needed to analyze frame %d was %f seconds' % (frame, (end_an-start_an))\n",
    "            print(text)\n",
    "\n",
    "        end = timer()\n",
    "\n",
    "        print('Total time to analyze dataset was %f seconds' % (end -start))\n",
    "        return\n",
    "    \n",
    "    ###\n",
    "    ### THESE HAVE BEEN PORTED FROM OLD TRAJECTORY TO STREAMLINE ANALYSIS OF GLICOSILATED PEPTIDES!\n",
    "    ###\n",
    "    \n",
    "    \n",
    "    def get_sense(self):\n",
    "\n",
    "        ''' Analyze self.frames to retrieve the number of contact \n",
    "            per sense (\"parallel\" and \"antiparallel\")\n",
    "        '''\n",
    "        # instantiate main dict\n",
    "        sense_dict = {}\n",
    "        # loop trough frames\n",
    "        for frame in self.frames:\n",
    "            group = self.frames[frame].results.cross_correlation.groupby('sense').groups\n",
    "            # check for antiparallel key in the frame_data\n",
    "            if 'antiparallel' in group:\n",
    "                # get number of antiparallel contacts\n",
    "                antiparallel = len(group['antiparallel'])\n",
    "            else:\n",
    "                antiparallel = 0\n",
    "            # check for parallel key in the frame_data\n",
    "            if 'parallel' in group:\n",
    "                # get number of parallel contacts\n",
    "                parallel = len(group['parallel'])\n",
    "            else:\n",
    "                parallel = 0\n",
    "            # add frame data to main dict\n",
    "            sense_dict[frame] = {  'parallel' : parallel,\n",
    "                               'antiparallel' : antiparallel}\n",
    "        # at the end convert dict to pandas.DataFrame\n",
    "        self.sense_df = pd.DataFrame.from_dict(sense_dict, orient='index')\n",
    "\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def subgraph_length_peptide(self):\n",
    "        '''Get information about the size of the aggregates in the trajectory\n",
    "        Argument: aggregate\n",
    "        return: dict, keys = frame number,\n",
    "                      value = a sorted list (big to small) of the aggregate size in that frame\n",
    "        '''\n",
    "\n",
    "        if len(self.frames) > 0:\n",
    "\n",
    "            self.subgraph_size_peptide = {}\n",
    "\n",
    "            for key in self.frames.keys():\n",
    "\n",
    "                subgraph_dict = {}\n",
    "\n",
    "                subgraph_dict[key] = morphoscanner.backend.graph.find_subgraph(self.frames[key].results.graph)\n",
    "\n",
    "                len_list = []\n",
    "\n",
    "                for i in subgraph_dict[key]:\n",
    "\n",
    "                    len_list.append(len(i))\n",
    "\n",
    "                len_list.sort(reverse=True)\n",
    "\n",
    "                self.subgraph_size_peptide[key] = [len_list]\n",
    "\n",
    "        self.subgraph_len_pep_df = pd.DataFrame.from_dict(self.subgraph_size_peptide, orient='index', columns=['n° of peptides in macroaggregates'])\n",
    "\n",
    "        #else:\n",
    "         #   print('You have to analyze one or more frame before analyze the results.')\n",
    "         #   print('Use \"Analyze\" or \"AnalyzeInLoop\" on the dataset first!')\n",
    "\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def macroaggregate_sense_data(self):\n",
    "\n",
    "        macroaggregate_sense_dict = {}\n",
    "\n",
    "        for frame in self.frames:\n",
    "            graph = self.frames[frame].results.graph\n",
    "            subs = self.frames[frame].results.subgraphs\n",
    "            #senses = contact_sense_in_subgraph(graph, subs)\n",
    "            #sense_counter = count_sense_in_subgraph(senses)\n",
    "            sense_counter = morphoscanner.backend.graph.sense_in_subgraph(graph, subs)\n",
    "            macroaggregate_sense_dict[frame] = sense_counter\n",
    "\n",
    "        self.macroaggregate_df = pd.DataFrame.from_dict(macroaggregate_sense_dict, orient='index')\n",
    "\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def number_of_macroaggregate_per_frame(self):\n",
    "        number_of_peptide = {}\n",
    "        for i in self.subgraph_size_peptide:\n",
    "            number_of_peptide[i] = len(self.subgraph_size_peptide[i][0])\n",
    "\n",
    "        self.number_of_peptide_df = pd.DataFrame.from_dict(number_of_peptide, orient='index', columns=['n° of macroaggreates'])\n",
    "\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def shift_profile(self):\n",
    "        '''Calculate shift profile for the current trajectory.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Save data in self.frames[frame_number].results.shift....\n",
    "        '''\n",
    "        # instantiate main dict to store trajectory data\n",
    "        shift_profile = {}\n",
    "        # iterate through frames\n",
    "        for frame in self.frames:\n",
    "            # create a dict for each frame to store frame data\n",
    "            shift_profile[frame] = {} \n",
    "            # max shift possible is the max legth of the peptides in the trajectory\n",
    "            # (in number of residues)\n",
    "            max_shift = max(self.peptide_length_list)\n",
    "            # get cross_corr dataframe gruped by contact sense \n",
    "            a = self.frames[frame].results.cross_correlation.groupby('sense')\n",
    "            # for each contact sense\n",
    "            for group in a.groups:\n",
    "                # create a nested dict for the contact sense\n",
    "                shift_profile[frame][group] = {}\n",
    "                # if sense of the contact is parallel\n",
    "                # positive or negative shift is not important\n",
    "                if group == 'parallel':\n",
    "                    # for dataframe index (contact data)\n",
    "                    for index in a.groups[group]:\n",
    "                        #shift of the current contact\n",
    "                        shift = abs(self.frames[frame].results.cross_correlation.iloc[index]['shift'])\n",
    "                        # if is there, add 1 to current shift counter\n",
    "                        try:\n",
    "                            shift_profile[frame][group][shift] += 1\n",
    "                        # if is not there, just add the first contact to counter\n",
    "                        except:\n",
    "                            shift_profile[frame][group][shift] = 1\n",
    "                        # fill with 0 shift values not found (to plot)\n",
    "                        for i in range(max_shift):\n",
    "                            if i not in shift_profile[frame][group]:\n",
    "                                shift_profile[frame][group][i] = 0\n",
    "                        # order dict by ascending keys (to plot)\n",
    "                        shift_profile[frame][group] = {k[0]:k[1] for k in sorted(shift_profile[frame][group].items())}\n",
    "                        # add data to frame.results\n",
    "                        self.frames[frame].results.shift_profile_parallel = shift_profile[frame][group]\n",
    "                # if sense of the contact is antiparallel\n",
    "                # positive or negative shift is important\n",
    "                # because C and N terminal of respective peptides\n",
    "                # can interact differently\n",
    "                if group == 'antiparallel':\n",
    "                    for index in a.groups[group]:\n",
    "                        shift = self.frames[frame].results.cross_correlation.iloc[index]['shift']\n",
    "                        \n",
    "                        if shift > 0:\n",
    "                            shift_profile[frame][group]['negative'] = {}\n",
    "                            try:\n",
    "                                shift_profile[frame][group]['negative'][shift] += 1\n",
    "                            except:\n",
    "                                shift_profile[frame][group]['negative'][shift] = 1\n",
    "                            for i in range(max_shift):\n",
    "                                if i not in shift_profile[frame][group]['negative']:\n",
    "                                    shift_profile[frame][group]['negative'][i] = 0\n",
    "                            shift_profile[frame][group]['negative'] = {k[0]:k[1] for k in sorted(shift_profile[frame][group]['negative'].items())}\n",
    "                            self.frames[frame].results.shift_profile_antiparallel_negative = shift_profile[frame][group]['negative']\n",
    "    \n",
    "                        if shift <= 0:\n",
    "                            shift = abs(shift)\n",
    "                            shift_profile[frame][group]['positive'] = {}\n",
    "                            try:\n",
    "                                shift_profile[frame][group]['positive'][shift] += 1\n",
    "                            except:\n",
    "                                shift_profile[frame][group]['positive'][shift] = 1\n",
    "                            for i in range(max_shift):\n",
    "                                if i not in shift_profile[frame][group]['positive']:\n",
    "                                    shift_profile[frame][group]['positive'][i] = 0\n",
    "                            shift_profile[frame][group]['positive'] = {k[0]:k[1] for k in sorted(shift_profile[frame][group]['positive'].items())}\n",
    "                            self.frames[frame].results.shift_profile_antiparallel_positive = shift_profile[frame][group]['positive']\n",
    "        return\n",
    "\n",
    "\n",
    "    def get_data(self):\n",
    "        self.get_sense()\n",
    "        self.subgraph_length_peptide()\n",
    "        self.macroaggregate_sense_data()\n",
    "        self.number_of_macroaggregate_per_frame()\n",
    "        self.shift_profile()\n",
    "        return\n",
    "    \n",
    "        \n",
    "    def get_database(self):\n",
    "        \n",
    "        self.database = pd.concat((self.subgraph_len_pep_df, self.sense_df, self.number_of_peptide_df, self.macroaggregate_df), axis=1)\n",
    "\n",
    "        return\n",
    "    \n",
    "    \n",
    "    ######################\n",
    "    #############################\n",
    "    #####################\n",
    "    \n",
    "    \n",
    "    def plot_contacts(self):\n",
    "        index = self.database.index\n",
    "        contact = [i+e for i, e in zip(self.database['parallel'], self.database['antiparallel'])]\n",
    "        antiparallel = self.database['antiparallel']\n",
    "        antip_total_ratio = [anti/cont if cont != 0 else 0 for anti, cont in zip(antiparallel, contact)]\n",
    "        tss = [self.universe.trajectory[i].time/1000 for i in index]\n",
    "        tss_int = np.array(tss) \n",
    "        x = np.linspace(tss_int.min(),tss_int.max(),1000)\n",
    "        spl = interpolate.interp1d(tss, antip_total_ratio, kind = 'nearest')\n",
    "        antip_total_ratio_smooth = spl(x)\n",
    "\n",
    "        plt.plot(x, antip_total_ratio_smooth,'-')\n",
    "        plt.title('β-sheets alignment over time')\n",
    "        plt.xlabel('Time (ns)')\n",
    "        plt.ylabel('β-Sheet Organizational Index')\n",
    "\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def plot_peptides_in_beta(self):\n",
    "        index = self.database.index\n",
    "        tss = [self.universe.trajectory[i].time/1000 for i in index]\n",
    "        beta = [sum(i) for i in self.database['n° of peptides in macroaggregates']]\n",
    "        tss_int = np.array(tss)\n",
    "        number_of_peptides = len(self.frames[0].peptides)\n",
    "        x = np.linspace(tss_int.min(),tss_int.max(),100000)\n",
    "        spl = interpolate.interp1d(tss, beta, kind ='nearest')\n",
    "        beta_smooth  = spl(x)\n",
    "        \n",
    "        plt.plot(x,beta_smooth/number_of_peptides * 100,'-')\n",
    "        plt.title('% of peptides involved in β-sheets')\n",
    "        plt.ylim((0,100))\n",
    "        plt.xlabel('Time (ns)')\n",
    "        plt.ylabel('% of Peptides in β-sheet')\n",
    "    \n",
    "        return \n",
    "\n",
    "    def plot_aggregates(self):\n",
    "        index = self.database.index\n",
    "        tss = [self.universe.trajectory[i].time/1000 for i in index]\n",
    "        aggregates = self.database['n° of macroaggreates']\n",
    "        tss_int = np.array(tss)\n",
    "        x = np.linspace(tss_int.min(),tss_int.max(),1000)\n",
    "        spl = interpolate.interp1d(tss,aggregates,kind='nearest')\n",
    "        aggregates_smooth = spl(x)\n",
    "        \n",
    "        plt.plot(x, aggregates_smooth,'-')\n",
    "        plt.ylim((0,len(self.frames[0].peptides)/2))\n",
    "        plt.title('Aggregation Order')\n",
    "        plt.xlabel('Time (ns)')\n",
    "        plt.ylabel('N° of macroaggregates')\n",
    "\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def plot_shift_parallel(self, frame=None):\n",
    "        try:\n",
    "            f = self.frames[frame].results.shift_profile_parallel\n",
    "        \n",
    "        except:\n",
    "            max_shift = max(self.peptide_length_list)\n",
    "            f = {k:0 for k in range(max_shift)}\n",
    "\n",
    "        x = [val for val in f.keys()]\n",
    "        y = [k for k in f.values()]\n",
    "        plt.plot(x, y)\n",
    "        plt.xlabel('Parallel Shift')\n",
    "        plt.ylabel('Number of contacts')\n",
    "        plt.show()\n",
    "        return\n",
    "    \n",
    "    def plot_shift_antiparallel_positive(self, frame=None):\n",
    "        try:\n",
    "            f = self.frames[frame].results.shift_profile_antiparallel_positive\n",
    "        except:\n",
    "            max_shift = max(self.peptide_length_list)\n",
    "            f = {k:0 for k in range(max_shift)}    \n",
    "        x = [val for val in f.keys()]\n",
    "        y = [k for k in f.values()]\n",
    "        plt.plot(x, y)\n",
    "        plt.xlabel('Antiparallel + Shift')\n",
    "        plt.ylabel('Number of contacts')\n",
    "        plt.show() \n",
    "        return\n",
    "    \n",
    "    def plot_shift_antiparallel_negative(self, frame=None):\n",
    "        try:\n",
    "            f = self.frames[frame].results.shift_profile_antiparallel_negative\n",
    "        except:\n",
    "            max_shift = max(self.peptide_length_list)\n",
    "            f = {k:0 for k in range(max_shift)} \n",
    "            \n",
    "        x = [val for val in f.keys()]\n",
    "        y = [k for k in f.values()]\n",
    "        plt.plot(x, y)\n",
    "        plt.xlabel('Antiparallel - Shift')\n",
    "        plt.ylabel('Number of contacts')\n",
    "        plt.show() \n",
    "        return\n",
    "\n",
    "\n",
    "    def get_subgraphs_sense(self, frame):\n",
    "        '''Retrive information about contact sense of each aggregate\n",
    "        found in self.frames[frame]['subgraphs_full']\n",
    "        Parameters\n",
    "        ----------\n",
    "        frame : int\n",
    "            The frame of which you want to get contact sense informations.\n",
    "        Returns\n",
    "        -------\n",
    "        sense_dict : dict\n",
    "            A dict containing the informations about contacts, in the form:\n",
    "                {'parallel' : int,\n",
    "                 'antiparallel' : int,\n",
    "                 'value' : str}\n",
    "            The key 'value' contains the sense of the predominant contact sense,\n",
    "            'parallel' or 'antiparallale',\n",
    "            or the str 'equal' if both sense have the same number of contacts.\n",
    "        '''\n",
    "        \n",
    "        # check if requested frame have been parsed\n",
    "        if frame not in self.frames:\n",
    "            print('Frame %d is not in the sampled frames\\n' % frame)\n",
    "        else:\n",
    "            # check if in the frame there are aggregate\n",
    "            if len(self.frames[frame].results.subgraphs) < 1:\n",
    "                print('There are no aggregate in frame %d.\\n' % frame)\n",
    "            else:\n",
    "                # if checks are passed\n",
    "                # create empty dict\n",
    "                sense_dict = {}\n",
    "                \n",
    "                # iterate subgraphs\n",
    "                for index_sub, subgraph in enumerate(self.frames[frame].results.subgraphs):\n",
    "                    \n",
    "                    # create a new dict for each aggregate, to store contact sense information\n",
    "                    sense_dict[index_sub] = {'parallel' : 0,\n",
    "                                             'antiparallel' : 0,\n",
    "                                             'value' : 0   }\n",
    "                    # get information about contacts from database\n",
    "                    #  use only peptide1 column to gather contacts one time only \n",
    "                    for index_contact, contact in enumerate(self.frames[frame].results.cross_correlation.peptide1):\n",
    "                        if contact in subgraph:\n",
    "                            sense = (self.frames[frame].results.cross_correlation.iloc[index_contact].sense)\n",
    "                            # add 1 to the right sense counter in the sense_dict\n",
    "                            sense_dict[index_sub][sense] += 1\n",
    "                    # check if contacts number is equal in both senses\n",
    "                    if sense_dict[index_sub]['parallel'] == sense_dict[index_sub]['antiparallel']:\n",
    "                        sense_dict[index_sub]['value'] = 'equal'\n",
    "                    else:\n",
    "                        # if contacts are not equal, get the predominant contact sense\n",
    "                        sense_dict[index_sub]['value'] = max(sense_dict[index_sub], key=sense_dict[index_sub].get)\n",
    "    \n",
    "                return sense_dict\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    def plot_frame_aggregate(self, frame: int):\n",
    "        '''Plot the frame with color code that identify the\n",
    "        sense of the majority of contacts in an aggregate.\n",
    "        Grey: no contact,\n",
    "        Green: majority of parallel contacts,\n",
    "        Blue: majority of antparallel contacts,\n",
    "        Yellow: equal number of parallel and antiparallel contacts\n",
    "        \n",
    "        The plot can be made interactive using jupyter-notebook,\n",
    "        with:\n",
    "            %matplotlib notebook\n",
    "        Parameters\n",
    "        ----------\n",
    "        frame : int\n",
    "            The frame that you want to plot\n",
    "        Returns\n",
    "        -------\n",
    "        plot\n",
    "            Return a matplotlib.pyplot 3d scatter plot.\n",
    "        '''\n",
    "        \n",
    "        # get predominant contact sense for each aggregate\n",
    "        sense_dict = self.get_subgraphs_sense(frame)\n",
    "        # get subgraphs\n",
    "        subgraphs = self.frames[frame].results.subgraphs\n",
    "        # get coordinate dict\n",
    "        coordinate_dict = self.get_frame(frame)\n",
    "        # make a flat (1D) list of peptide in the aggregates\n",
    "        flat_subgraphs = [pep for group in subgraphs for pep in group]\n",
    "        # create a color dictionary with each sense corresponding to a color\n",
    "        colors = {'parallel' : 'limegreen',\n",
    "                  'antiparallel' : 'b',\n",
    "                  'equal' : 'y',\n",
    "                  'no' : 'gray'}    \n",
    "        \n",
    "        # instantiate empty dict to plot aggregates\n",
    "        x = {}\n",
    "        y = {}\n",
    "        z = {}\n",
    "        # iterate through aggregates\n",
    "        for index_sub, subgraph in enumerate(subgraphs):\n",
    "            # create a list to gather coordinate of each aggregate's atom\n",
    "            x[index_sub] = []\n",
    "            y[index_sub] = []\n",
    "            z[index_sub] = []\n",
    "            # for each peptide in the aggregate\n",
    "            for peptide in subgraph:\n",
    "                # for each atom of the peptide\n",
    "                for atom in coordinate_dict[peptide]:\n",
    "                    # get x, y and z coordinates and save it in the correct list\n",
    "                    x[index_sub].append(coordinate_dict[peptide][atom][0])\n",
    "                    y[index_sub].append(coordinate_dict[peptide][atom][1])\n",
    "                    z[index_sub].append(coordinate_dict[peptide][atom][2])\n",
    "        \n",
    "        # instantiate lists for non contacting peptides\n",
    "        x_not = []\n",
    "        y_not = []\n",
    "        z_not = []\n",
    "        # get coordinate of non contacting peptides\n",
    "        for pep in coordinate_dict:\n",
    "            if pep not in flat_subgraphs:\n",
    "                for atom in coordinate_dict[pep]:\n",
    "                    x_not.append(coordinate_dict[pep][atom][0])\n",
    "                    y_not.append(coordinate_dict[pep][atom][1])\n",
    "                    z_not.append(coordinate_dict[pep][atom][2])\n",
    "        \n",
    "        fig = plt.figure()\n",
    "    \n",
    "        ax = plt.axes(projection='3d')\n",
    "    \n",
    "        # scatter aggregates atoms\n",
    "        for group in x:\n",
    "    \n",
    "            ax.scatter3D(x[group],y[group],z[group], color=colors[sense_dict[group]['value']])\n",
    "        \n",
    "        # scatter non contacting peptides atoms\n",
    "        ax.scatter3D(x_not, y_not, z_not, color=colors['no'])\n",
    "        \n",
    "        return plt.show()\n",
    "    \n",
    "    \n",
    "    def plot_graph(self, frame: int):\n",
    "        '''Plot the frame graph, with visual information about\n",
    "            number of contacts between peptides and sense of the contacts.\n",
    "            \n",
    "            Edge thickness scale with the number of contacts between two\n",
    "            contacting peptides.\n",
    "            \n",
    "            Green edges are parallel contacts.\n",
    "            Blue edges are antiparallel contacts.\n",
    "        Parameters\n",
    "        ----------\n",
    "        frame : int\n",
    "            The frame of which you want to plot the graph.\n",
    "        Returns\n",
    "        -------\n",
    "        plot\n",
    "            matplotlib.pyplot 3d scatter5 plot.\n",
    "        '''\n",
    "    \n",
    "        graph = self.frames[frame].results.graph\n",
    "        \n",
    "        # Used to plot\n",
    "        edges = graph.edges()\n",
    "        colors = [graph[u][v][0]['color'] for u,v in edges]\n",
    "        weights = [graph[u][v][0]['weight'] for u,v in edges]\n",
    "        \n",
    "        # output a plot\n",
    "        return nx.draw_networkx(graph, edges=edges, edge_color=colors, width=weights)\n",
    "\n",
    "    \n",
    "# Use the .gro file but do not select by using the BB nomenclature\n",
    "# Use instead the aminoacids names and numbers on the first element\n",
    "# and compare it with the data inside molnames\n",
    "\n",
    "    ### Use this to plot 3d data from trajectory object\n",
    "\n",
    "    def plot3d_parallel(self):\n",
    "        # Read timestep from trajectory\n",
    "        index = self.database.index\n",
    "        # get timestep of each frame (in nanoseconds)\n",
    "        y = [self.universe.trajectory[i].time/1000 for i in index]\n",
    "        # get the shift range\n",
    "        x = [i for i in range(max(self.peptide_length_list))]\n",
    "        # calculate total contacts per frame\n",
    "        total_contact = [(self.database.iloc[i]['parallel'] + self.database.iloc[i]['antiparallel']) for i in range(len(self.database))]\n",
    "        z = []\n",
    "        for f_index, frame in enumerate(self.frames):\n",
    "\n",
    "            try:\n",
    "                # compute contact ratio\n",
    "                f = [i/total_contact[f_index] if i!=0 else 0 for i in self.frames[frame].results.shift_profile_parallel.values()]\n",
    "\n",
    "            except:\n",
    "                # if no contact, fill with 0\n",
    "                max_shift = max(self.peptide_length_list)\n",
    "                f = [0 for k in range(max_shift)]\n",
    "             # append frame data\n",
    "            z.append(f)\n",
    "        # cast to np.array\n",
    "        z = np.asarray(z)\n",
    "        fig = go.Figure(data=[go.Surface(z=z*100, x=x, y=y)])\n",
    "        fig.update_layout(autosize=True,\n",
    "                          scene = dict(\n",
    "                        xaxis_title='P Shift',\n",
    "                        yaxis_title='Time (ps)',\n",
    "                        zaxis_title='Contact %',\n",
    "                        zaxis = dict(nticks=20, range=[0,100])),\n",
    "                            title='Parallel Shift')\n",
    "        fig.show()\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "    def plot3d_antiparallel_negative(self):\n",
    "        # Read timestep from trajectory\n",
    "        index = self.database.index\n",
    "        # get timestep of each frame (in nanoseconds)\n",
    "        y = [self.universe.trajectory[i].time/1000 for i in index]\n",
    "        # get the shift range\n",
    "        x = [i for i in range(max(self.peptide_length_list))]\n",
    "        # calculate total contacts per frame\n",
    "        total_contact = [(self.database.iloc[i]['parallel'] + self.database.iloc[i]['antiparallel']) for i in range(len(self.database))]\n",
    "        z = []\n",
    "        for f_index, frame in enumerate(self.frames):\n",
    "\n",
    "            try:\n",
    "                # compute contact ratio\n",
    "                f = [i/total_contact[f_index] if i!=0 else 0 for i in self.frames[frame].results.shift_profile_antiparallel_negative.values()]\n",
    "\n",
    "            except:\n",
    "                # if no contact, fill with 0\n",
    "                max_shift = max(self.peptide_length_list)\n",
    "                f = [0 for k in range(max_shift)]\n",
    "             # append frame data\n",
    "            z.append(f)\n",
    "        # cast to np.array\n",
    "        z = np.asarray(z)\n",
    "        fig = go.Figure(data=[go.Surface(z=z*100, x=x, y=y)])\n",
    "        fig.update_layout(autosize=True,\n",
    "                          scene = dict(\n",
    "                        xaxis_title='AP- Shift',\n",
    "                        yaxis_title='Time (ps)',\n",
    "                        zaxis_title='Contact %',\n",
    "                        zaxis = dict(nticks=20, range=[0,100])),\n",
    "                            title='Antiparallel Negative Shift')\n",
    "        fig.show()\n",
    "\n",
    "        return\n",
    "\n",
    "    def plot3d_antiparallel_positive(self):\n",
    "        # Read timestep from trajectory\n",
    "        index = self.database.index\n",
    "        # get timestep of each frame (in nanoseconds)\n",
    "        y = [self.universe.trajectory[i].time/1000 for i in index]\n",
    "        # get the shift range\n",
    "        x = [i for i in range(max(self.peptide_length_list))]\n",
    "        # calculate total contacts per frame\n",
    "        total_contact = [(self.database.iloc[i]['parallel'] + self.database.iloc[i]['antiparallel']) for i in range(len(self.database))]\n",
    "        z = []\n",
    "        for f_index, frame in enumerate(self.frames):\n",
    "\n",
    "            try:\n",
    "                # compute contact ratio\n",
    "                f = [i/total_contact[f_index] if i!=0 else 0 for i in self.frames[frame].results.shift_profile_antiparallel_positive.values()]\n",
    "\n",
    "            except:\n",
    "                # if no contact, fill with 0\n",
    "                max_shift = max(self.peptide_length_list)\n",
    "                f = [0 for k in range(max_shift)]\n",
    "             # append frame data\n",
    "            z.append(f)\n",
    "        # cast to np.array\n",
    "        z = np.asarray(z)\n",
    "        fig = go.Figure(data=[go.Surface(z=z*100, x=x, y=y)])\n",
    "        fig.update_layout(autosize=True,\n",
    "                          scene = dict(\n",
    "                        xaxis_title='Ap + Shift',\n",
    "                        yaxis_title='Time (ps)',\n",
    "                        zaxis_title='Contact %',\n",
    "                        zaxis = dict(nticks=20, range=[0,100])),\n",
    "                            title='Antiparallel Positive Shift')\n",
    "        fig.show()\n",
    "    \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_contacts(self):\n",
    "    index = self.database.index\n",
    "    contact = [i+e for i, e in zip(self.database['parallel'], self.database['antiparallel'])]\n",
    "    antiparallel = self.database['antiparallel']\n",
    "    antip_total_ratio = [anti/cont if cont != 0 else 0 for anti, cont in zip(antiparallel, contact)]\n",
    "    tss = [self.universe.trajectory[i].time/1000 for i in index]\n",
    "    tss_int = np.array(tss) \n",
    "    x = np.linspace(tss_int.min(),tss_int.max(),1000)\n",
    "    spl = interpolate.interp1d(tss, antip_total_ratio, kind = 'nearest')\n",
    "    antip_total_ratio_smooth = spl(x)\n",
    "\n",
    "    plt.plot(x, antip_total_ratio_smooth,'-')\n",
    "    plt.title('β-sheets alignment over time')\n",
    "    plt.xlabel('Time (ns)')\n",
    "    plt.ylabel('β-Sheet Organizational Index')\n",
    "\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.plot3d_parallel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to use functions on multiple trajectory objects\n",
    "\n",
    "# WORKING\n",
    "def trajectory_antiparallel_positive(self):\n",
    "\n",
    "    # Read timestep from trajectory\n",
    "    index = self.database.index\n",
    "    # get timestep of each frame (in nanoseconds)\n",
    "    y = [self.universe.trajectory[i].time/1000 for i in index]\n",
    "    # get the shift range\n",
    "    x = [i for i in range(max(self.peptide_length_list))]\n",
    "    # calculate total contacts per frame\n",
    "    total_contact = [(self.database.iloc[i]['parallel'] + self.database.iloc[i]['antiparallel']) for i in range(len(self.database))]\n",
    "    z = []\n",
    "    for f_index, frame in enumerate(self.frames):\n",
    "\n",
    "        try:\n",
    "            # compute contact ratio\n",
    "            f = [i/total_contact[f_index] if i!=0 else 0 for i in self.frames[frame].results.shift_profile_antiparallel_positive.values()]\n",
    "        except:\n",
    "            # if no contact, fill with 0\n",
    "            max_shift = max(self.peptide_length_list)\n",
    "            f = [0 for k in range(max_shift)]\n",
    "        z.append(f)\n",
    "    z = np.asarray(z)\n",
    "    return x, y, z\n",
    "\n",
    "\n",
    "def trajectory_antiparallel_negative(self):\n",
    "\n",
    "    # Read timestep from trajectory\n",
    "    index = self.database.index\n",
    "    # get timestep of each frame (in nanoseconds)\n",
    "    y = [self.universe.trajectory[i].time/1000 for i in index]\n",
    "    # get the shift range\n",
    "    x = [i for i in range(max(self.peptide_length_list))]\n",
    "    # calculate total contacts per frame\n",
    "    total_contact = [(self.database.iloc[i]['parallel'] + self.database.iloc[i]['antiparallel']) for i in range(len(self.database))]\n",
    "    z = []\n",
    "    for f_index, frame in enumerate(self.frames):\n",
    "\n",
    "        try:\n",
    "            # compute contact ratio\n",
    "            f = [i/total_contact[f_index] if i!=0 else 0 for i in self.frames[frame].results.shift_profile_antiparallel_negative.values()]\n",
    "        except:\n",
    "            # if no contact, fill with 0\n",
    "            max_shift = max(self.peptide_length_list)\n",
    "            f = [0 for k in range(max_shift)]\n",
    "        z.append(f)\n",
    "    z = np.asarray(z)\n",
    "    return x, y, z\n",
    "\n",
    "def trajectory_parallel(self):\n",
    "\n",
    "    # Read timestep from trajectory\n",
    "    index = self.database.index\n",
    "    # get timestep of each frame (in nanoseconds)\n",
    "    y = [self.universe.trajectory[i].time/1000 for i in index]\n",
    "    # get the shift range\n",
    "    x = [i for i in range(max(self.peptide_length_list))]\n",
    "    # calculate total contacts per frame\n",
    "    total_contact = [(self.database.iloc[i]['parallel'] + self.database.iloc[i]['antiparallel']) for i in range(len(self.database))]\n",
    "    z = []\n",
    "    for f_index, frame in enumerate(self.frames):\n",
    "\n",
    "        try:\n",
    "            # compute contact ratio\n",
    "            f = [i/total_contact[f_index] if i!=0 else 0 for i in self.frames[frame].results.shift_profile_parallel.values()]\n",
    "        except:\n",
    "            # if no contact, fill with 0\n",
    "            max_shift = max(self.peptide_length_list)\n",
    "            f = [0 for k in range(max_shift)]\n",
    "        z.append(f)\n",
    "    z = np.asarray(z)\n",
    "    return x, y, z\n",
    "# Scrivere funzione che prende i dati in out dalla funzione sopra.\n",
    "# poi prendi max(x), max(y), mean(z, axis=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,z = trajectory_antiparallel_positive(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3d_antiparallel_positive_shift(x,y,z):\n",
    "    fig = go.Figure(data=[go.Surface(z=z*100, x=x, y=y)])\n",
    "    fig.update_layout(autosize=True,\n",
    "                          scene = dict(\n",
    "                        xaxis_title='AP+ Shift',\n",
    "                        yaxis_title='Time (ns)',\n",
    "                        zaxis_title='Contact %',\n",
    "                        zaxis = dict(nticks=20, range=[0,100])),\n",
    "                        title='Antiparallel Positive Shift')\n",
    "    fig.show()\n",
    "    return\n",
    "\n",
    "def plot_3d_antiparallel_negative_shift(x,y,z):\n",
    "    fig = go.Figure(data=[go.Surface(z=z*100, x=x, y=y)])\n",
    "    fig.update_layout(autosize=True,\n",
    "                          scene = dict(\n",
    "                        xaxis_title='AP- Shift',\n",
    "                        yaxis_title='Time (ns)',\n",
    "                        zaxis_title='Contact %',\n",
    "                        zaxis = dict(nticks=20, range=[0,100])),\n",
    "                        title='Antiparallel Negative Shift')\n",
    "    fig.show()\n",
    "    return\n",
    "\n",
    "def plot_3d_parallel_shift(x,y,z):\n",
    "    fig = go.Figure(data=[go.Surface(z=z*100, x=x, y=y)])\n",
    "    fig.update_layout(autosize=True,\n",
    "                          scene = dict(\n",
    "                        xaxis_title='P Shift',\n",
    "                        yaxis_title='Time (ns)',\n",
    "                        zaxis_title='Contact %',\n",
    "                        zaxis = dict(nticks=20, range=[0,100])),\n",
    "                        title='Parallel Shift')\n",
    "    fig.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_(x_av,y_av,z_av)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3d_antiparallel_positive_average(data: list):\n",
    "    \n",
    "    mp = [i for i in map(trajectory_antiparallel_positive, data)]\n",
    "    \n",
    "    x_av = max([i[0] for i in mp])\n",
    "    y_av = max([i[1] for i in mp])\n",
    "    z_av = np.mean(np.asarray([i[2] for i in mp]), axis=0)\n",
    "    \n",
    "    plot_3d_antiparallel_positive_shift(x_av, y_av, z_av)\n",
    "    \n",
    "    return\n",
    "    \n",
    "def plot_3d_antiparallel_negative_average(data: list):\n",
    "    \n",
    "    mp = [i for i in map(trajectory_antiparallel_negative, data)]\n",
    "    \n",
    "    x_av = max([i[0] for i in mp])\n",
    "    y_av = max([i[1] for i in mp])\n",
    "    z_av = np.mean(np.asarray([i[2] for i in mp]), axis=0)\n",
    "    \n",
    "    plot_3d_antiparallel_negative_shift(x_av, y_av, z_av)\n",
    "    \n",
    "    return\n",
    "    \n",
    "def plot_3d_parallel_average(data: list):\n",
    "    \n",
    "    mp = [i for i in map(trajectory_parallel, data)]\n",
    "    \n",
    "    x_av = max([i[0] for i in mp])\n",
    "    y_av = max([i[1] for i in mp])\n",
    "    z_av = np.mean(np.asarray([i[2] for i in mp]), axis=0)\n",
    "    \n",
    "    plot_3d_parallel_shift(x_av, y_av, z_av)\n",
    "    \n",
    "    return\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = [i for i in map(trajectory_antiparallel_positive, [a,b,c])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_av = np.mean(np.asarray([i[2] for i in mp]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_av = max([i[0] for i in mp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_av = max([i[1] for i in mp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(z_av)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_antiparallel_positive_average((a,b,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_antiparallel_negative_average((a,b,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_parallel_average((a,b,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_peptides_in_beta(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(self.universe.trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_beta_data(self):\n",
    "\n",
    "    index = self.database.index\n",
    "    beta = [sum(i) for i in self.database['n° of peptides in macroaggregates']]\n",
    "    tss_int = np.array([self.universe.trajectory[i].time/1000 for i in index]).astype(int)\n",
    "    number_of_peptides = len(self.frames[0].peptides)\n",
    "    x = np.linspace(tss_int.min(),tss_int.max(), tss_int.max())\n",
    "    spl = interpolate.interp1d(tss_int, beta, kind ='cubic')\n",
    "    beta_smooth = spl(x)\n",
    "    beta_smooth_norm = (beta_smooth/number_of_peptides) * 100\n",
    "\n",
    "    return x, beta_smooth_norm\n",
    "\n",
    "def plot_beta_average(data:list, label: str):\n",
    "\n",
    "    beta_data = np.array([i for i in map(get_beta_data, data)])\n",
    "    beta_average = np.mean(beta_data, axis=0)[1]\n",
    "    x = np.max(beta_data, axis=0)[0]\n",
    "\n",
    "    plt.plot(x, beta_average, '-',label=label)\n",
    "    plt.title('% of peptides involved in β-sheets')\n",
    "    plt.ylim((0,100))\n",
    "    plt.xlabel('Time (ns)')\n",
    "    plt.ylabel('% of Peptides in β-sheet')\n",
    "    plt.legend()\n",
    "    return\n",
    "\n",
    "\n",
    "def get_contacts_data(self):\n",
    "    index = self.database.index\n",
    "    contact = [i+e for i, e in zip(self.database['parallel'], self.database['antiparallel'])]\n",
    "    antiparallel = self.database['antiparallel']\n",
    "    antip_total_ratio = [anti/cont if cont != 0 else 0 for anti, cont in zip(antiparallel, contact)]\n",
    "    tss_int = np.array([self.universe.trajectory[i].time/1000 for i in index]).astype(int)\n",
    "    x = np.linspace(tss_int.min(),tss_int.max(), tss_int.max())\n",
    "    spl = interpolate.interp1d(tss_int, antip_total_ratio, kind = 'cubic') # kind='linear'\n",
    "    antip_total_ratio_smooth = spl(x)\n",
    "\n",
    "    return x, antip_total_ratio_smooth\n",
    "\n",
    "def plot_contacts_average(data: list, label: str):\n",
    "\n",
    "    contacts = np.array([i for i in map(get_contacts_data, data)])\n",
    "    x = np.max(contacts, axis=0)[0]\n",
    "    antiparallel_contacts_average_ratio = np.mean(contacts, axis=0)[1]\n",
    "\n",
    "    plt.plot(x, antiparallel_contacts_average_ratio,'-', label=label)\n",
    "    plt.title('β-sheets alignment over time')\n",
    "    plt.xlabel('Time (ns)')\n",
    "    plt.ylabel('β-Sheet Organizational Index')\n",
    "    plt.ylim(0,1)\n",
    "    plt.legend()\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def get_aggregates(self):\n",
    "    index = self.database.index\n",
    "    aggregates = self.database['n° of macroaggreates']\n",
    "    tss_int = np.array([self.universe.trajectory[i].time/1000 for i in index]).astype(int)\n",
    "    x = np.linspace(tss_int.min(),tss_int.max(),tss_int.max())\n",
    "    spl = interpolate.interp1d(tss_int, aggregates, kind='cubic')\n",
    "    aggregates_smooth = spl(x)\n",
    "\n",
    "    return x, aggregates_smooth\n",
    "\n",
    "def plot_aggregates_average(data: list, label: str):\n",
    "    \n",
    "    aggregates_data = np.array([i for i in map(get_aggregates, data)])\n",
    "    x = np.max(aggregates_data, axis=0)[0]\n",
    "    y = np.mean(aggregates_data, axis=0)[1]    \n",
    "\n",
    "    y_max = max([len(i.frames[0].peptides) for i in [a,b,c]])//2\n",
    "    \n",
    "    plt.plot(x, y,'-',label=label)\n",
    "    plt.title('Aggregation Order')\n",
    "    plt.xlabel('Time (ns)')\n",
    "    plt.ylabel('N° of macroaggregates')\n",
    "    plt.legend()\n",
    "    plt.yticks([i for i in range(0,y_max+2, 2)])\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_beta_average([a,b,c], label='all')\n",
    "plot_beta_average([a], label='a')\n",
    "plot_beta_average([b], label='b')\n",
    "plot_beta_average([c], label='c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contacts_data(self):\n",
    "    index = self.database.index\n",
    "    contact = [i+e for i, e in zip(self.database['parallel'], self.database['antiparallel'])]\n",
    "    antiparallel = self.database['antiparallel']\n",
    "    antip_total_ratio = [anti/cont if cont != 0 else 0 for anti, cont in zip(antiparallel, contact)]\n",
    "    tss_int = np.array([self.universe.trajectory[i].time/1000 for i in index]).astype(int)\n",
    "    x = np.linspace(tss_int.min(),tss_int.max(), tss_int.max())\n",
    "    spl = interpolate.interp1d(tss_int, antip_total_ratio, kind = 'cubic') # kind='linear'\n",
    "    antip_total_ratio_smooth = spl(x)\n",
    "\n",
    "    return x, antip_total_ratio_smooth\n",
    "    \n",
    "def plot_contacts_average(data: list, label: str):\n",
    "    \n",
    "    contacts = np.array([i for i in map(get_contacts_data, data)])\n",
    "    x = np.max(contacts, axis=0)[0]\n",
    "    antiparallel_contacts_average_ratio = np.mean(contacts, axis=0)[1]\n",
    "    \n",
    "    plt.plot(x, antiparallel_contacts_average_ratio,'-', label=label)\n",
    "    plt.title('β-sheets alignment over time')\n",
    "    plt.xlabel('Time (ns)')\n",
    "    plt.ylabel('β-Sheet Organizational Index')\n",
    "    plt.ylim(0,1)\n",
    "    plt.legend()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_contacts_average([a,b,c], label='all')\n",
    "plot_contacts_average([a], label='a')\n",
    "plot_contacts_average([b], label='b')\n",
    "plot_contacts_average([c], label='c')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_aggregates(self):\n",
    "    index = self.database.index\n",
    "    aggregates = self.database['n° of macroaggreates']\n",
    "    tss_int = np.array([self.universe.trajectory[i].time/1000 for i in index]).astype(int)\n",
    "    x = np.linspace(tss_int.min(),tss_int.max(),tss_int.max())\n",
    "    spl = interpolate.interp1d(tss_int, aggregates, kind='cubic')\n",
    "    aggregates_smooth = spl(x)\n",
    "\n",
    "    return x, aggregates_smooth\n",
    "\n",
    "def plot_aggregates_average(data: list, label: str):\n",
    "    \n",
    "    aggregates_data = np.array([i for i in map(get_aggregates, data)])\n",
    "    x = np.max(aggregates_data, axis=0)[0]\n",
    "    y = np.mean(aggregates_data, axis=0)[1]    \n",
    "\n",
    "    y_max = max([len(i.frames[0].peptides) for i in [a,b,c]])//2\n",
    "    \n",
    "    plt.plot(x, y,'-',label=label)\n",
    "    plt.title('Aggregation Order')\n",
    "    plt.xlabel('Time (ns)')\n",
    "    plt.ylabel('N° of macroaggregates')\n",
    "    plt.legend()\n",
    "    plt.yticks([i for i in range(0,y_max+2, 2)])\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_aggregates_average([a,b,c], label='all')\n",
    "plot_aggregates_average([a], label='a')\n",
    "plot_aggregates_average([b], label='b')\n",
    "plot_aggregates_average([c], label='c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_max = max([len(i.frames[0].peptides) for i in [a,b,c]])//2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_antiparallel_negative_average((a,b,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_antiparallel_positive_average((a,b,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_parallel_average((a,b,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_parallel_average([a,b,c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iimport numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import make_interp_spline, BSpline, interp1d,interpolate\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "# Run this cell to use functions on multiple trajectory objects\n",
    "\n",
    "# WORKING\n",
    "def trajectory_antiparallel_positive(self):\n",
    "\n",
    "    # Read timestep from trajectory\n",
    "    index = self.database.index\n",
    "    # get timestep of each frame (in nanoseconds)\n",
    "    y = [self.universe.trajectory[i].time/1000 for i in index]\n",
    "    # get the shift range\n",
    "    x = [i for i in range(max(self.peptide_length_list))]\n",
    "    # calculate total contacts per frame\n",
    "    total_contact = [(self.database.iloc[i]['parallel'] + self.database.iloc[i]['antiparallel']) for i in range(len(self.database))]\n",
    "    z = []\n",
    "    for f_index, frame in enumerate(self.frames):\n",
    "\n",
    "        try:\n",
    "            # compute contact ratio\n",
    "            f = [i/total_contact[f_index] if i!=0 else 0 for i in self.frames[frame].results.shift_profile_antiparallel_positive.values()]\n",
    "        except:\n",
    "            # if no contact, fill with 0\n",
    "            max_shift = max(self.peptide_length_list)\n",
    "            f = [0 for k in range(max_shift)]\n",
    "        z.append(f)\n",
    "    z = np.asarray(z)\n",
    "    return x, y, z\n",
    "\n",
    "\n",
    "def trajectory_antiparallel_negative(self):\n",
    "\n",
    "    # Read timestep from trajectory\n",
    "    index = self.database.index\n",
    "    # get timestep of each frame (in nanoseconds)\n",
    "    y = [self.universe.trajectory[i].time/1000 for i in index]\n",
    "    # get the shift range\n",
    "    x = [i for i in range(max(self.peptide_length_list))]\n",
    "    # calculate total contacts per frame\n",
    "    total_contact = [(self.database.iloc[i]['parallel'] + self.database.iloc[i]['antiparallel']) for i in range(len(self.database))]\n",
    "    z = []\n",
    "    for f_index, frame in enumerate(self.frames):\n",
    "\n",
    "        try:\n",
    "            # compute contact ratio\n",
    "            f = [i/total_contact[f_index] if i!=0 else 0 for i in self.frames[frame].results.shift_profile_antiparallel_negative.values()]\n",
    "        except:\n",
    "            # if no contact, fill with 0\n",
    "            max_shift = max(self.peptide_length_list)\n",
    "            f = [0 for k in range(max_shift)]\n",
    "        z.append(f)\n",
    "    z = np.asarray(z)\n",
    "    return x, y, z\n",
    "\n",
    "def trajectory_parallel(self):\n",
    "\n",
    "    # Read timestep from trajectory\n",
    "    index = self.database.index\n",
    "    # get timestep of each frame (in nanoseconds)\n",
    "    y = [self.universe.trajectory[i].time/1000 for i in index]\n",
    "    # get the shift range\n",
    "    x = [i for i in range(max(self.peptide_length_list))]\n",
    "    # calculate total contacts per frame\n",
    "    total_contact = [(self.database.iloc[i]['parallel'] + self.database.iloc[i]['antiparallel']) for i in range(len(self.database))]\n",
    "    z = []\n",
    "    for f_index, frame in enumerate(self.frames):\n",
    "\n",
    "        try:\n",
    "            # compute contact ratio\n",
    "            f = [i/total_contact[f_index] if i!=0 else 0 for i in self.frames[frame].results.shift_profile_parallel.values()]\n",
    "        except:\n",
    "            # if no contact, fill with 0\n",
    "            max_shift = max(self.peptide_length_list)\n",
    "            f = [0 for k in range(max_shift)]\n",
    "        z.append(f)\n",
    "    z = np.asarray(z)\n",
    "    return x, y, z\n",
    "\n",
    "def plot_3d_antiparallel_positive_shift(x,y,z):\n",
    "    fig = go.Figure(data=[go.Surface(z=z*100, x=x, y=y)])\n",
    "    fig.update_layout(autosize=True,\n",
    "                          scene = dict(\n",
    "                        xaxis_title='AP+ Shift',\n",
    "                        yaxis_title='Time (ns)',\n",
    "                        zaxis_title='Contact %',\n",
    "                        zaxis = dict(nticks=20, range=[0,100])),\n",
    "                        title='Antiparallel Positive Shift')\n",
    "    fig.show()\n",
    "    return\n",
    "\n",
    "def plot_3d_antiparallel_negative_shift(x,y,z):\n",
    "    fig = go.Figure(data=[go.Surface(z=z*100, x=x, y=y)])\n",
    "    fig.update_layout(autosize=True,\n",
    "                          scene = dict(\n",
    "                        xaxis_title='AP- Shift',\n",
    "                        yaxis_title='Time (ns)',\n",
    "                        zaxis_title='Contact %',\n",
    "                        zaxis = dict(nticks=20, range=[0,100])),\n",
    "                        title='Antiparallel Negative Shift')\n",
    "    fig.show()\n",
    "    return\n",
    "\n",
    "def plot_3d_parallel_shift(x,y,z):\n",
    "    fig = go.Figure(data=[go.Surface(z=z*100, x=x, y=y)])\n",
    "    fig.update_layout(autosize=True,\n",
    "                          scene = dict(\n",
    "                        xaxis_title='P Shift',\n",
    "                        yaxis_title='Time (ns)',\n",
    "                        zaxis_title='Contact %',\n",
    "                        zaxis = dict(nticks=20, range=[0,100])),\n",
    "                        title='Parallel Shift')\n",
    "    fig.show()\n",
    "    return\n",
    "\n",
    "\n",
    "def plot_3d_antiparallel_positive_average(data: list):\n",
    "    \n",
    "    mp = [i for i in map(trajectory_antiparallel_positive, data)]\n",
    "    \n",
    "    x_av = max([i[0] for i in mp])\n",
    "    y_av = max([i[1] for i in mp])\n",
    "    z_av = np.mean(np.asarray([i[2] for i in mp]), axis=0)\n",
    "    \n",
    "    plot_3d_antiparallel_positive_shift(x_av, y_av, z_av)\n",
    "    \n",
    "    return\n",
    "    \n",
    "def plot_3d_antiparallel_negative_average(data: list):\n",
    "    \n",
    "    mp = [i for i in map(trajectory_antiparallel_negative, data)]\n",
    "    \n",
    "    x_av = max([i[0] for i in mp])\n",
    "    y_av = max([i[1] for i in mp])\n",
    "    z_av = np.mean(np.asarray([i[2] for i in mp]), axis=0)\n",
    "    \n",
    "    plot_3d_antiparallel_negative_shift(x_av, y_av, z_av)\n",
    "    \n",
    "    return\n",
    "    \n",
    "def plot_3d_parallel_average(data: list):\n",
    "    \n",
    "    mp = [i for i in map(trajectory_parallel, data)]\n",
    "    \n",
    "    x_av = max([i[0] for i in mp])\n",
    "    y_av = max([i[1] for i in mp])\n",
    "    z_av = np.mean(np.asarray([i[2] for i in mp]), axis=0)\n",
    "    \n",
    "    plot_3d_parallel_shift(x_av, y_av, z_av)\n",
    "    \n",
    "    return\n",
    "    \n",
    "\n",
    "def get_beta_data(self):\n",
    "\n",
    "    index = self.database.index\n",
    "    beta = [sum(i) for i in self.database['n° of peptides in macroaggregates']]\n",
    "    tss_int = np.array([self.universe.trajectory[i].time/1000 for i in index]).astype(int)\n",
    "    number_of_peptides = len(self.frames[0].peptides)\n",
    "    x = np.linspace(tss_int.min(),tss_int.max(), tss_int.max())\n",
    "    spl = interpolate.interp1d(tss_int, beta, kind ='cubic')\n",
    "    beta_smooth = spl(x)\n",
    "    beta_smooth_norm = (beta_smooth/number_of_peptides) * 100\n",
    "\n",
    "    return x, beta_smooth_norm\n",
    "\n",
    "def plot_beta_average(data:list, label: str):\n",
    "\n",
    "    beta_data = np.array([i for i in map(get_beta_data, data)])\n",
    "    beta_average = np.mean(beta_data, axis=0)[1]\n",
    "    x = np.max(beta_data, axis=0)[0]\n",
    "\n",
    "    plt.plot(x, beta_average, '-',label=label)\n",
    "    plt.title('% of peptides involved in β-sheets')\n",
    "    plt.ylim((0,100))\n",
    "    plt.xlabel('Time (ns)')\n",
    "    plt.ylabel('% of Peptides in β-sheet')\n",
    "    plt.legend()\n",
    "    return\n",
    "\n",
    "\n",
    "def get_contacts_data(self):\n",
    "    index = self.database.index\n",
    "    contact = [i+e for i, e in zip(self.database['parallel'], self.database['antiparallel'])]\n",
    "    antiparallel = self.database['antiparallel']\n",
    "    antip_total_ratio = [anti/cont if cont != 0 else 0 for anti, cont in zip(antiparallel, contact)]\n",
    "    tss_int = np.array([self.universe.trajectory[i].time/1000 for i in index]).astype(int)\n",
    "    x = np.linspace(tss_int.min(),tss_int.max(), tss_int.max())\n",
    "    spl = interpolate.interp1d(tss_int, antip_total_ratio, kind = 'cubic') # kind='linear'\n",
    "    antip_total_ratio_smooth = spl(x)\n",
    "\n",
    "    return x, antip_total_ratio_smooth\n",
    "\n",
    "def plot_contacts_average(data: list, label: str):\n",
    "\n",
    "    contacts = np.array([i for i in map(get_contacts_data, data)])\n",
    "    x = np.max(contacts, axis=0)[0]\n",
    "    antiparallel_contacts_average_ratio = np.mean(contacts, axis=0)[1]\n",
    "\n",
    "    plt.plot(x, antiparallel_contacts_average_ratio,'-', label=label)\n",
    "    plt.title('β-sheets alignment over time')\n",
    "    plt.xlabel('Time (ns)')\n",
    "    plt.ylabel('β-Sheet Organizational Index')\n",
    "    plt.ylim(0,1)\n",
    "    plt.legend()\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def get_aggregates(self):\n",
    "    index = self.database.index\n",
    "    aggregates = self.database['n° of macroaggreates']\n",
    "    tss_int = np.array([self.universe.trajectory[i].time/1000 for i in index]).astype(int)\n",
    "    x = np.linspace(tss_int.min(),tss_int.max(),tss_int.max())\n",
    "    spl = interpolate.interp1d(tss_int, aggregates, kind='cubic')\n",
    "    aggregates_smooth = spl(x)\n",
    "\n",
    "    return x, aggregates_smooth\n",
    "\n",
    "def plot_aggregates_average(data: list, label: str):\n",
    "    \n",
    "    aggregates_data = np.array([i for i in map(get_aggregates, data)])\n",
    "    x = np.max(aggregates_data, axis=0)[0]\n",
    "    y = np.mean(aggregates_data, axis=0)[1]    \n",
    "\n",
    "    y_max = max([len(i.frames[0].peptides) for i in data])//2\n",
    "    \n",
    "    plt.plot(x, y,'-',label=label)\n",
    "    plt.title('Aggregation Order')\n",
    "    plt.xlabel('Time (ns)')\n",
    "    plt.ylabel('N° of macroaggregates')\n",
    "    plt.legend()\n",
    "    plt.yticks([i for i in range(0,y_max+2, 2)])\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = morphoscanner.trajectory.trajectory(glac_3perc_1_gro, glac_3perc_1_trr, select=['aminoacids'])\n",
    "b = morphoscanner.trajectory.trajectory(glac_3perc_2_gro, glac_3perc_2_trr, select=['aminoacids'])\n",
    "c = morphoscanner.trajectory.trajectory(glac_3perc_3_gro, glac_3perc_3_trr, select=['aminoacids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.explore()\n",
    "b.explore()\n",
    "c.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.compose_database(100)\n",
    "b.compose_database(100)\n",
    "c.compose_database(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a.analyze_inLoop(threshold=None, threshold_multiplier=1.45)\n",
    "b.analyze_inLoop(threshold=None, threshold_multiplier=1.45)\n",
    "c.analyze_inLoop(threshold=None, threshold_multiplier=1.45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.get_data()\n",
    "b.get_data()\n",
    "c.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.get_database()\n",
    "b.get_database()\n",
    "c.get_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.analysis.plot_3d_antiparallel_negative_average([a,b,c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.analysis.plot_3d_antiparallel_positive_average([a,b,c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.analysis.plot_3d_parallel_average([a,b,c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te = morphoscanner.analysis.trajectory_antiparallel_positive(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(te[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.frames[200].results.shift_profile_antiparallel_positive.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(te[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(te[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.plot_frame_aggregate(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(a.frames[100].results.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.plot_graph(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.frames[500].results.graph.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(self, frame: int):\n",
    "    '''\n",
    "    Plot the frame graph, with visual information about\n",
    "    number of contacts between peptides and sense of the contacts.\n",
    "\n",
    "    Edge thickness scale with the number of contacts between two\n",
    "    contacting peptides.\n",
    "\n",
    "    Green edges are parallel contacts.\n",
    "    Blue edges are antiparallel contacts.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    frame : int\n",
    "        The frame of which you want to plot the graph.\n",
    "    Returns\n",
    "    -------\n",
    "    plot\n",
    "        matplotlib.pyplot 3d scatter5 plot.\n",
    "    '''\n",
    "\n",
    "    graph = self.frames[frame].results.graph\n",
    "\n",
    "    # Used to plot\n",
    "    coord = {}\n",
    "    for node in a.frames[frame].results.graph.nodes:\n",
    "        a_tens = torch.tensor([a.frames[frame].peptides[node].coordinates[i] for i in a.frames[frame].peptides[node].coordinates])\n",
    "        a_tens = torch.median(a_tens, dim=0)\n",
    "        coord[node] = a_tens.values\n",
    "        \n",
    "    edges = graph.edges()\n",
    "    colors = [graph[u][v][0]['color'] for u,v in edges]\n",
    "    weights = [graph[u][v][0]['weight'] for u,v in edges]\n",
    "\n",
    "    # output a plot\n",
    "    return nx.draw_networkx(graph, edge_color=colors, width=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(self=a, frame=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.frames[500].results.graph.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = 500\n",
    "coord={}\n",
    "for node in a.frames[frame].results.graph.nodes:\n",
    "    a_tens = torch.tensor([a.frames[frame].peptides[node].coordinates[i] for i in a.frames[frame].peptides[node].coordinates])\n",
    "    a_tens = torch.median(a_tens, dim=0)\n",
    "    coord[node] = a_tens.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[a.frames[500].peptides[node].coordinates[i] for i in a.frames[500].peptides[node].coordinates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_tens = torch.tensor([a.frames[500].peptides[node].coordinates[i] for i in a.frames[500].peptides[node].coordinates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_tens = torch.median(a_tens, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_tens.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.plot_contacts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj_prod = morphoscanner.trajectory.trajectory(prod_gro, (prod_xtc, prod1_xtc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj_prod.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj_prod.compose_database(500) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj_prod.analyze_inLoop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj_prod.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj_prod.get_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj_prod.plot_frame_aggregate(2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj_prod.plot_graph(2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj_prod.plot3d_parallel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import morphoscanner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj_mix = morphoscanner.trajectory.trajectory(trj_gro, trj_xtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj_mix.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj_mix.compose_database(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj_mix.analyze_inLoop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj_mix.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj_mix.get_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj_mix.plot_frame_aggregate(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj_mix.plot3d_antiparallel_negative()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mda.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Morphoscanner: a Library for Self Assembling Peptide Analysis from Molecular Dynamics Simulation made with Gromacs\n",
    "\n",
    "**Morphoscanner** is a tool developed to analyze *Gromacs* MD simulations of *SAPs* and recognize specific topological patterns in the SAPs network, in simulation made with the **Martini CG Force Field**.\n",
    "\n",
    "The available version of Morphoscanner can recognize *Beta-sheet* topologies and retrieve quantitative and qualitative data on the SAP assembling process.\n",
    "\n",
    "Morphoscanner is written in Python 3 using an object oriented approach.\n",
    "\n",
    "Morphoscanner is developed to be versatile and easily accessible at the same time.\n",
    "\n",
    "The software  leverages ***parallel computing*** for some steps of the work-flow. It parallelize operations both on *CPU* and *GPU*, if an **Nvidia GPU** is found on the system and the correct version of *cudatoolkit* is installed. Parallelizzation of the full workflow is in development.\n",
    "\n",
    "The tool can be distributed using *pip* repository and used as a *python module*.\n",
    "\n",
    "The script gives ease of usage: it only needs the Gromacs output and some topology info as input, and gives *.xlsx* files (Microsoft Excel) as output.\n",
    "It can run using the *main.py* file of Morphoscanner.\n",
    "\n",
    "The python module can be imported in an IDE and used to write customized scripts and to do specific analysis. Morphoscanner can used to analyze MD trajectory data in a jupyter-notebook, and it integrates with the main packages used in the data-science workflow, as Numpy, Pandas, PyTorch, MDAnalysis, Matplotlib and NetworkX.\n",
    "\n",
    "\n",
    "## Prerequisites\n",
    "Is suggested to install the package in a ***conda environment*** using **Anaconda**, due to the *active development status* of *Morphoscanner*.\n",
    "\n",
    "**If you have an *Nvidia GPU* you can use** *PyTorch* **hardware acceleration by installing the package** *cudatoolkit*.\n",
    "\n",
    "The *Nvidia Driver*, *cudatoolkit* and *PyTorch* version have to be compatible. The compatibility can be checked in the respective websites:\n",
    "\n",
    "- [Nvidia Driver and cudatoolkit compatibility](https://docs.nvidia.com/deploy/cuda-compatibility/index.html).\n",
    "- [PyTorch and cudatoolkit compatibility](https://pytorch.org/).\n",
    "\n",
    "Tested drivers and packages version are in the following table.\n",
    "\n",
    " \n",
    " System | Nvidia Driver | cudatoolkit | PyTorch\n",
    "--------|---------------|-------------|--------\n",
    "Manjaro 20.1.2 | 440.100 | 10.2 | 1.6.0\n",
    "\n",
    "### Installing Anaconda\n",
    "The [Anaconda installer](https://www.anaconda.com/distribution/ \"Anaconda website\") can be downloaded and installed in the user system using [the instructions](https://docs.anaconda.com/anaconda/install/linux/ \"Installation Instructions\").\n",
    "\n",
    "### Conda env creation\n",
    "***Conda envs*** can be created following the [conda documentation](https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html \"conda envs management\").\n",
    "\n",
    "The channel *conda-forge* is needed to install MDAnalysis.\n",
    "[Here](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-channels.html) the official *conda* docs on how to manage channels.\n",
    "\n",
    "Add the conda-forge channel (*--append* will add the channel as the last of the channel list, *--add* will ad the channel as the first of the channels list).\n",
    "```bash\n",
    "conda config --append channels conda-forge\n",
    "```\n",
    "\n",
    "An *env* called *morphoscanner* can be created with: \n",
    "```bash\n",
    "conda create -n morphoscanner python=3.8 pip numpy pandas mdanalysis tqdm pytorch networkx cudatoolkit=10.2 matplotlib scipy plotly\n",
    "```\n",
    "\n",
    "The installed packages can be checked (in the active env) with:\n",
    "```bash\n",
    "conda list\n",
    "```\n",
    "\n",
    "You can activate the env with:\n",
    "```bash\n",
    "conda activate morphoscanner\n",
    "```\n",
    "\n",
    "## Morphoscanner installation\n",
    "\n",
    "### Morphoscanner Installation as Module\n",
    "\n",
    "Inside the env you have to install morphoscanner:\n",
    "```bash\n",
    "pip install git+https://github.com/lillux/morphoscanner.git#egg=morphoscanner\n",
    "```\n",
    "You need to be a collaborator of the project to download the package. The prompt will ask for *username* and *password*.\n",
    "\n",
    "Then it will be installed in your env. You can now use morphoscanner from your *IDE* or *Python Console*.\n",
    "\n",
    "Branches other than yhe *default branch* can be installed adding the name of the branch that you want to download, like *@branch_name*, after the repository url. For example, to download the v0.0.2 branch:\n",
    "\n",
    "```bash\n",
    "pip install git+https://github.com/lillux/morphoscanner.git@v0.0.2#egg=morphoscanner\n",
    "```\n",
    "\n",
    "\n",
    "### Morphoscanner as Script\n",
    "\n",
    "You can download morphoscanner from its [Github repository](https://github.com/lillux/morphoscanner \"Morphoscanner repository\").\n",
    "\n",
    "It will be downloaded as a compressed archive. Unpack it in a directory. Then move to the directory and run:\n",
    "```bash\n",
    "python main.py\n",
    "```\n",
    "\n",
    "The script will start and the input paths of the trajectory files will be requested.\n",
    "\n",
    "\n",
    "## Getting started\n",
    "\n",
    "Using ***Morphoscanner*** as a *Python module* is straightforward, leveraging MDAnalysis capability of I/O:\n",
    "``` python\n",
    "from morphoscanner.trajectory import trajectory\n",
    "```\n",
    "\n",
    "The .gro and .xtc or .trr files must be inserted as path:\n",
    "``` python\n",
    "_gro = '/path/to/your/gro'\n",
    "_xtc = '/path/to/your/xtc'\n",
    "```\n",
    "\n",
    "Create class instance:\n",
    "``` python\n",
    "trj = trajectory(_gro, _xtc)\n",
    "```\n",
    "\n",
    "Multiple consecutive trajectory can be merged and read as a single trajectory:\n",
    "``` python\n",
    "trj = trajectory(_gro, (_xtc1, _xtc2, _xtc3))\n",
    "```\n",
    "\n",
    "*Specify the number of grains composing the peptide backbone.*\\\n",
    "\n",
    "To compose the database the number of aminoacids and other backbone grains has to be known. This information can be obtained in two ways:\n",
    "\n",
    "- **Automatic Parsing**\\\n",
    "Automatic parsing can be used when the peptides have been inserted in the simulation as a separate entities. If this is the case, *Morphoscanner* will parse the .gro file and automatically parse backbone grains.\n",
    "To choose *Automatic parsing* just don't insert the *peptide_length* argument, or \n",
    "\n",
    "``` python\n",
    "peptide_length = None\n",
    "```\n",
    "# REMOVE!!!!\n",
    "\n",
    "- **Assisted Parsing**\n",
    "If in your simulation you inserted premade aggregate, or groups of peptides as a single entities, you have to specify the size of a single peptide of the group.\n",
    "To specify the number of grains composing the peptides backbone, just assign the number to the peptide_length argument as an *integer*:\n",
    "\n",
    "``` python\n",
    "peptide_length = int\n",
    "```\n",
    "\n",
    "*Specify the  frame sampling*.\\\n",
    "The frame in the trajectory can be sampled.\\\n",
    "To sample all frames just leave *interval* argument empty or choose 1 as argument. If you want to sample choose the sampling interval as an *integer*:\n",
    "\n",
    "``` python\n",
    "interval = int\n",
    "```\n",
    "\n",
    "After choosing the correct *peptide_length* and *interval* (or not, if you want to parse automatically), put them inside the *compose_database* function:\n",
    "``` python\n",
    "trj.compose_database(peptide_length = peptide_length, interval = interval)\n",
    "```\n",
    "\n",
    "Analyze the database (this can take some time):\n",
    "``` python\n",
    "trj.analyze_inLoop()\n",
    "```\n",
    "\n",
    "Get data:\n",
    "``` python\n",
    "trj.get_data()\n",
    "```\n",
    "\n",
    "Get database with results:\n",
    "``` python\n",
    "trj.get_database()\n",
    "```\n",
    "\n",
    "Show database:\n",
    "``` python\n",
    "trj.database\n",
    "```\n",
    "\n",
    "A *pandas.DataFrame* will be shown at the end of the analysis.\n",
    "\n",
    "The database can be saved as an *excel file* leveraging *pandas* capability:\n",
    "\n",
    "Set an output path:\n",
    "```python\n",
    "output_path = 'path/to/your/directory'\n",
    "```\n",
    "Set the name of the file:\n",
    "```python\n",
    "file_name = 'name_of_the_output_file'\n",
    "```\n",
    "\n",
    "Export the database with .xlsx file extension:\n",
    "```python\n",
    "trj.database.to_excel(output_path, sheet_name=file_name)\n",
    "```\n",
    "\n",
    "### Plotting results\n",
    "\n",
    "After the analysis the data can be visualized with plotting functions.\\\n",
    "Interactive visualization can be enabled in jupyter-notebook with:\n",
    "``` python\n",
    "%matplotlib notebook\n",
    "```\n",
    "\n",
    "To deactivate interactive visualization:\n",
    "``` python\n",
    "%matplotlib inline\n",
    "```\n",
    "\n",
    "- Plot the number of aggregate in the sampled timesteps:\n",
    "```python\n",
    "trj.plot_aggregates()\n",
    "```\n",
    "\n",
    "- Plot the ratio of contacts antiparallel/(parallel + antiparallel) in the sampled timesteps:\n",
    "``` python\n",
    "trj.plot_contacts()\n",
    "```\n",
    "\n",
    "- Plot one of the sampled frames, visualizing the aggregate with a color code that define the sense of the majority of the contacts in that aggregate.\\\n",
    "    Green: majority of parallel contacts.\\\n",
    "    Blue: majority of antiparallel contacs.\\\n",
    "    Yellow: equal number of parallel and antiparallel contacts.\\\n",
    "    Gray: no contacts.\n",
    "```python\n",
    "trj.plot_frame_aggregate(frame: int)\n",
    "```\n",
    "- Plot the graph of one of the sampled frames with qualitative visual indications.\\\n",
    "    Edge thickness: thickness proportional to the number of contacts between the two petides (nodes).\\\n",
    "    Edge green: parallel contact.\\\n",
    "    Edge blue: antiparallel contact.\n",
    "``` python\n",
    "trj.plot_graph(0)\n",
    "```\n",
    "\n",
    "### Additional data\n",
    "\n",
    "Additional data can be found in:\n",
    "``` python\n",
    "trj.frames[frame]\n",
    "```\n",
    "\n",
    "This is a dict that contains a dict for each sampled and analyzed frame, with the data computed during the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj_mix.universe.trajectory[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj_mix.universe.atoms[55].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import plotly\n",
    "#import plotly.express as px\n",
    "\n",
    "from mpl_toolkits import mplot3d\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "#from functools import lru_cache\n",
    "#import re\n",
    "import networkx as nx\n",
    "from networkx.algorithms import approximation\n",
    "\n",
    "import MDAnalysis as mda\n",
    "\n",
    "#import scipy\n",
    "#import sklearn\n",
    "#import skimage\n",
    "\n",
    "#import xml.etree.ElementTree as et\n",
    "#from Bio.PDB import *\n",
    "#import nglview as nv\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# http://nglviewer.org/nglview/latest/api.html\n",
    "# https://biopython.org/wiki/The_Biopython_Structural_Bioinformatics_FAQ\n",
    "# https://ambermd.org/tutorials/analysis/tutorial_notebooks/nglview_notebook/index.html\n",
    "# https://amber-md.github.io/pytraj/latest/_api/pytraj.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contact_matrix = np.loadtxt('/home/lillo/TesiCNTE/CNTE/dataset/contact_matrix.txt')   #laptop\n",
    "#contact_matrix = np.loadtxt('/home/lillo/Code/Tesi/dataset/contact_matrix.txt')        #fisso\n",
    "#contact_matrix_single = contact_matrix.reshape(100,100,12,12)\n",
    "\n",
    "#gromacs_output = open('/home/lillo/Code/Tesi/dataset/dm4500Compl_mix1_K2_1%4500ns.gro') #fisso\n",
    "#gromacs_output = open('/home/lillo/TesiCNTE/CNTE/dataset/dm4500Compl_mix1_K2_1%4500ns.gro') #laptop\n",
    "\n",
    "#path = '/home/lillo/Code/Tesi/dataset/dm4500Compl_mix1_K2_1%4500ns.gro' #fisso\n",
    "#path = '/home/lillo/TesiCNTE/CNTE/dataset/dm4500Compl_mix1_K2_1%4500ns.gro' #laptop\n",
    "\n",
    "# import 2mxu file (beta sheet)\n",
    "\n",
    "#path_to_mmCIF = open('/home/lillo/TesiCNTE/pdb/2mxu/2mxu.cif')  ## laptop\n",
    "#path_to_pdb = '/home/lillo/TesiCNTE/pdb/2mxu/2mxu.pdb'  ## laptop\n",
    "#pa_to_pdb = '/home/lillo/TesiCNTE/pdb/2mxu/2mxu.pdb'  ## laptop\n",
    "\n",
    "#path_to_mmCIF = open('/home/lillo/Code/Tesi/pdb/2mxu/2mxu.cif')  ## fisso\n",
    "#path_to_pdb = '/home/lillo/Code/Tesi/pdb/2mxu/2mxu.pdb'  ## fisso\n",
    "#pa_to_pdb = '/home/lillo/Code/Tesi/pdb/2mxu/2mxu.pdb'  ## fisso\n",
    "\n",
    "#seed_1_path = '/home/lillo/TesiCNTE/from_cluster/aggregate1.gro' # laptop\n",
    "#seed_1_path = '/home/lillo/Code/Tesi/dataset/aggregate1.gro'    # Fisso\n",
    "\n",
    "#prod_gro = '/home/lillo/TesiCNTE/from_cluster/prod/prod_part1/min.gro'            # laptop\n",
    "#prod_xtc = '/home/lillo/TesiCNTE/from_cluster/prod/prod_part1/prod.xtc'           # laptop\n",
    "#prod1_xtc = '/home/lillo/TesiCNTE/from_cluster/prod/prod_part2/prod-compl.xtc'    # laptop\n",
    "\n",
    "#prod_gro = '/home/lillo/Code/Tesi/dataset/prod/prod_part1/min.gro'           #fisso\n",
    "#prod_xtc = '/home/lillo/Code/Tesi/dataset/prod/prod_part1/prod.xtc'          #fisso\n",
    "#prod1_xtc = '/home/lillo/Code/Tesi/dataset/prod/prod_part2/prod-compl.xtc'   #fisso\n",
    "\n",
    "\n",
    "trj_xtc = '/home/lillo/TesiCNTE/CNTE/trajectory/prd-LDLK12-100mer-out-mol.xtc'  #laptop\n",
    "trj_gro = '/home/lillo/TesiCNTE/CNTE/trajectory/min-LDLK12-100mer-out-c.gro'    #laptop\n",
    "\n",
    "#trj_gro = '/home/lillo/Code/Tesi/dataset/trajectory_6_12_19/min-LDLK12-100mer-out-c.gro'     #fisso\n",
    "#trj_xtc = '/home/lillo/Code/Tesi/dataset/trajectory_6_12_19/prd-LDLK12-100mer-out-mol.xtc'   #fisso\n",
    "\n",
    "#lipase = '/home/lillo/Documenti/PDB/lipase/3d2c.pdb'\n",
    "#lipase1 = '/home/lillo/Documenti/PDB/lipase/1gpl.pdb'\n",
    "\n",
    "glico_6bis_gro = '/home/lillo/TesiCNTE/from_cluster/glicosilati_6bis/6bis-gluc/eq-2-out.gro'\n",
    "glico_6bis_trr = '/home/lillo/TesiCNTE/from_cluster/glicosilati_6bis/6bis-gluc/production/prd-6bis-GLUC-40mer-3per-out.trr'\n",
    "glico_6bis_tpr = '/home/lillo/TesiCNTE/from_cluster/glicosilati_6bis/6bis-gluc/production/prd-6bis-GLUC-40mer-3per.tpr'\n",
    "\n",
    "#glico_6bis_gro = '/home/lillo/Documenti/Tesi_CNTE/data/glicosilati_6bis/6bis-gluc/eq-2-out.gro'\n",
    "#glico_6bis_trr = '/home/lillo/Documenti/Tesi_CNTE/data/glicosilati_6bis/6bis-gluc/production/prd-6bis-GLUC-40mer-3per-out.trr'\n",
    "#glico_6bis_tpr = '/home/lillo/Documenti/Tesi_CNTE/data/glicosilati_6bis/6bis-gluc/production/prd-6bis-GLUC-40mer-3per.tpr'\n",
    "\n",
    "#p73_2per_wat_seed_1_gro = '/home/lillo/TesiCNTE/from_cluster/peptide_73/MARTINI/2%/WATER/2%/seed_1/prod/73prod.gro'     # laptop\n",
    "#p73_2per_wat_seed_1_xtc = '/home/lillo/TesiCNTE/from_cluster/peptide_73/MARTINI/2%/WATER/2%/seed_1/prod/73prod.xtc'     # laptop\n",
    "#p73_2per_wat_seed_1_trr = '/home/lillo/TesiCNTE/from_cluster/peptide_73/MARTINI/2%/WATER/2%/seed_1/prod/73prod.trr'     # laptop\n",
    "\n",
    "### LAPTOP GLICOSILATI\n",
    "glac_1perc_1_gro = '/home/lillo/TesiCNTE/from_cluster/glicosilati_6bis/6bis-GlAC/1perc/6bis-GLAC-1p/equilibration-2/eq-2-out.gro'\n",
    "glac_1perc_1_trr = '/home/lillo/TesiCNTE/from_cluster/glicosilati_6bis/6bis-GlAC/1perc/6bis-GLAC-1p/production/prd-6bis-GLAC-13mer-1per-out.trr'\n",
    "\n",
    "glac_1perc_2_gro = '/home/lillo/TesiCNTE/from_cluster/glicosilati_6bis/6bis-GlAC/1perc/6bis-GLAC-1p-2/equilibration-2/eq-2-out.gro'\n",
    "glac_1perc_2_trr = '/home/lillo/TesiCNTE/from_cluster/glicosilati_6bis/6bis-GlAC/1perc/6bis-GLAC-1p-2/production/prd-6bis-GLAC-13mer-1per-2-out.trr'\n",
    "\n",
    "glac_1perc_3_gro = '/home/lillo/TesiCNTE/from_cluster/glicosilati_6bis/6bis-GlAC/1perc/6bis-GLAC-1p-3/equilibration-2/eq-2-out.gro'\n",
    "glac_1perc_3_trr = '/home/lillo/TesiCNTE/from_cluster/glicosilati_6bis/6bis-GlAC/1perc/6bis-GLAC-1p-3/production/prd-6bis-GLAC-13mer-1per-3-out.trr'\n",
    "\n",
    "glac_3perc_1_gro = '/home/lillo/TesiCNTE/from_cluster/glicosilati_6bis/6bis-GlAC/3perc/6bis-GLAC/equilibration-2/eq-2-out.gro'\n",
    "glac_3perc_1_trr = '/home/lillo/TesiCNTE/from_cluster/glicosilati_6bis/6bis-GlAC/3perc/6bis-GLAC/production/prd-6bis-GLAC-40mer-3per-out.trr'\n",
    "\n",
    "glac_3perc_2_gro = '/home/lillo/TesiCNTE/from_cluster/glicosilati_6bis/6bis-GlAC/3perc/6bis-GLAC-2/equilibration-2/eq-2-out.gro'\n",
    "glac_3perc_2_trr = '/home/lillo/TesiCNTE/from_cluster/glicosilati_6bis/6bis-GlAC/3perc/6bis-GLAC-2/production/prd-6bis-40mer-3per-out.trr'\n",
    "\n",
    "glac_3perc_3_gro = '/home/lillo/TesiCNTE/from_cluster/glicosilati_6bis/6bis-GlAC/3perc/6bis-GLAC-3/equilibration-2/eq-2-out.gro'\n",
    "glac_3perc_3_trr = '/home/lillo/TesiCNTE/from_cluster/glicosilati_6bis/6bis-GlAC/3perc/6bis-GLAC-3/production/prd-6bis-GLAC-40mer-3per-out.trr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trj.number_of_BB_atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import morphoscanner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_gro = get_gro()\n",
    "_xtc = get_xtc()\n",
    "\n",
    "trj = trajectory(_gro, _xtc)\n",
    "\n",
    "print('Your trajectory has %d frames' % trj.number_of_frames)\n",
    "print('Your trajectory has %d BB atoms' % trj.number_of_BB_atoms)\n",
    "\n",
    "\n",
    "peptide_length = peptide_length(sentence='Set the number of aminoacids in one peptide (int): ')\n",
    "interval = get_interval(sentence='Set the interval between sampled frames (int): ')\n",
    "start_from = start_from(sentence='Set the index from which you want to start.\\n\\n0 if you have a single simulation.\\n0 if you are analyzing split1.\\nlen(split1) if you are analyzing split2.\\ninteger: ')\n",
    "\n",
    "output_path, file_name = get_destination_dir_and_name()\n",
    "\n",
    "\n",
    "trj.compose_database(peptide_length=peptide_length, interval=interval)\n",
    "trj.analyze_inLoop()\n",
    "trj.get_data()\n",
    "trj.get_database()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.stack([torch.from_numpy(zero[e]) for e in zero])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.backend.topology.get_peptide_length_list((trj_gro))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = morphoscanner.backend.readGro.clean_gro(trj_gro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dispatch_data(atom):\n",
    "    \n",
    "    if type(atom) != list:\n",
    "        \n",
    "        raise ValueError(\"%s is not a list, it is of type %s...\\n \" % (str(atom), type(atom)))\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        atom_number = check_int_and_return(atom[0])\n",
    "        \n",
    "        residue_number = check_int_and_return(atom[1])\n",
    "        \n",
    "        residue_name = atom[2]\n",
    "        \n",
    "        x = float(atom[3])\n",
    "        \n",
    "        y = float(atom[4])\n",
    "        \n",
    "        z = float(atom[5])\n",
    "        \n",
    "    \n",
    "    \n",
    "        return atom_number, residue_number, residue_name, x, y, z\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatch_data(cleaned[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(cleaned[0]) == list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "def isInt(s):\n",
    "    '''Check if s is type int and return bool.\n",
    "    \n",
    "    Input: object\n",
    "    \n",
    "    Output: bool'''\n",
    "    \n",
    "    try:\n",
    "        return float(str(s)).is_integer()\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "    \n",
    "    \n",
    "def check_int_and_return(value):\n",
    "    \n",
    "    '''Check int and return value, else raise ValueError and print object type\n",
    "    \n",
    "    Input = object\n",
    "    \n",
    "    Output = int'''\n",
    "\n",
    "    if isInt(value):\n",
    "\n",
    "        return int(value)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"%s is not an integer, it is of type %s...\\n \" % (str(value), type(value))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_list = morphoscanner.backend.topology.get_peptide_length_list (p73_2per_wat_seed_1_gro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "c_list = {}\n",
    "for idx, i in enumerate(peptides_dict[21].atom_numbers.values()):\n",
    "    p = universe.atoms[i].position\n",
    "    c_list[idx] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type(peptides_dict[0].frame_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Mi serve un oggetto peptide con sequenza ed atom_number.\n",
    "### La sequenza la prendo una volta sola e sarà sempre la stessa\n",
    "### L'atom_number mi serve perché così posso prendermi le coordinate\n",
    "### dai timestep quando voglio, anche per singolo peptide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_list\n",
    "first_key = [k for k in peptides_dict][0]\n",
    "if type(peptides_dict[first_key].frame_coordinates) is dict:\n",
    "    print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_peptide_list(coordinate_dict, peptide_list=None, centroid=False):\n",
    "    '''\n",
    "    Plot peptides from a trajectory frame.\n",
    "    Using jupyter-notebook, use '%matplotlib notebook' to\n",
    "    plot the points cloud in 3D.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    coordinate_dict : dict\n",
    "        Is the dict that contains all the coordinate\n",
    "        of the atoms of a single frame.\n",
    "        A single frame of the output of \n",
    "        backend.topology.get_coordinate_dict_from_trajectory \n",
    "        is a coordinate_dict.\n",
    "        \n",
    "    peptide_list : list, optional\n",
    "        The default is None. By default all the peptides\n",
    "        will be plotted.\n",
    "            Is a list of int. Put here the index of the peptide\n",
    "            or peptides that you want to plot.\n",
    "            For example [0,2,5,24,1,6] to plot\n",
    "            only these peptides.\n",
    "        \n",
    "    centroid : bool, optional\n",
    "        The default is False.\n",
    "            The centroid of a peptide can be plotted\n",
    "            in red together with the selected peptide.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    3D plot\n",
    "        Return a scattered 3D plot.\n",
    "\n",
    "    '''\n",
    "    \n",
    "      \n",
    "    # if no peptide specified, plot all\n",
    "    if peptide_list == None:\n",
    "        peptide_list = [p for p in coordinate_dict]\n",
    "\n",
    "\n",
    "    # if there is only a single peptide to show\n",
    "    # use the single peptide function to normalize axis        \n",
    "    if len(peptide_list) == 1:\n",
    "        \n",
    "        return plot_single_peptide(coordinate_dict[peptide_list[0]])\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        x = []\n",
    "        y = []\n",
    "        z = []\n",
    "        x_median = float\n",
    "        y_median = float\n",
    "        z_median = float\n",
    "\n",
    "\n",
    "        for peptide in range(len(peptide_list)):\n",
    "            x.append([peptide])\n",
    "            y.append([peptide])\n",
    "            z.append([peptide])\n",
    "            for aminoacid in coordinate_dict[peptide_list[peptide]]:\n",
    "\n",
    "                point = coordinate_dict[peptide_list[peptide]][aminoacid]\n",
    "                x[peptide].append(point[0])\n",
    "                y[peptide].append(point[1])\n",
    "                z[peptide].append(point[2])\n",
    "\n",
    "            del x[peptide][0]\n",
    "            del y[peptide][0]\n",
    "            del z[peptide][0]\n",
    "\n",
    "        if centroid == True:\n",
    "\n",
    "            def assemble_coordinate(axis_coordinate_list):\n",
    "                median_list = []\n",
    "                for coordinate_set in axis_coordinate_list:\n",
    "                    median = np.median(coordinate_set)\n",
    "                    median_list.append(median)\n",
    "                return median_list\n",
    "\n",
    "            x_median = assemble_coordinate(x)\n",
    "            y_median = assemble_coordinate(y)\n",
    "            z_median = assemble_coordinate(z)\n",
    "\n",
    "\n",
    "        #%matplotlib notebook\n",
    "\n",
    "        fig = plt.figure()\n",
    "\n",
    "        ax = plt.axes(projection='3d')\n",
    "\n",
    "\n",
    "        for pep in range(len(x)):\n",
    "\n",
    "            ax.scatter3D(x[pep],y[pep],z[pep])\n",
    "\n",
    "            if centroid == True:\n",
    "\n",
    "                ax.scatter3D(x_median[pep], y_median[pep], z_median[pep], c='red')\n",
    "\n",
    "\n",
    "        #return  plt.show(), [x,y,z], [x_median, y_median, z_median]         \n",
    "    return plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot.plot_single_peptide(c_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_protein(c_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot from trajectory positions  ### WORKING BUT YOU NEED TO:\n",
    "# make_universe\n",
    "# positions = universe.select_atoms('name BB').positions\n",
    "def plot_peptide_from_trajectory_frame(positions, peptide_list=None, centroid=False):\n",
    "    \n",
    "    '''\n",
    "    Plot atoms from universe.trajectory[frame]\n",
    "    '''\n",
    "       \n",
    "    if peptide_list == None:\n",
    "        \n",
    "        peptide_list = [e for e in range(len(positions))]\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "\n",
    "    for peptide in range(len(peptide_list)):\n",
    "        x.append([peptide])\n",
    "        y.append([peptide])\n",
    "        z.append([peptide])\n",
    "\n",
    "        point = positions[peptide_list[peptide]]\n",
    "        #print(peptide, point)\n",
    "        x[peptide].append(point[0])\n",
    "        y[peptide].append(point[1])\n",
    "        z[peptide].append(point[2])\n",
    "\n",
    "        del x[peptide][0]\n",
    "        del y[peptide][0]\n",
    "        del z[peptide][0]\n",
    "\n",
    "    fig = plt.figure()\n",
    "\n",
    "    ax = plt.axes(projection='3d')\n",
    "\n",
    "    for pep in range(len(x)):\n",
    "\n",
    "        # scatter points, making list from torch tensor item\n",
    "        ax.scatter3D([e.item() for e in x[pep]],[e.item() for e in y[pep]],[e.item() for e in z[pep]])\n",
    "\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from morphoscanner import backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe = mda.Universe(trj_gro, trj_xtc, in_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = universe.trajectory[150].positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = universe.trajectory[150].positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_peptide_list(coordinate_dict, peptide_list=None, centroid=False):\n",
    "    '''Plot peptides from a trajectory frame.\n",
    "        Using jupyter-notebook, use '%matplotlib notebook' to\n",
    "        plot the points cloud in 3D.\n",
    "    \n",
    "    Inputs:     coordinate_dict, dict   Is the dict that contains all the coordinate\n",
    "                                        of the atoms of a single frame.\n",
    "                                        A single frame of the output of \n",
    "                                        backend.topology.get_coordinate_dict_from_trajectory \n",
    "                                        is a coordinate_dict.\n",
    "    \n",
    "                peptide_list, list.     is a list of int. Put here the index of the peptide\n",
    "                                        or peptides that you want to plot\n",
    "                                \n",
    "                centroid,   bool.       default=False \n",
    "                                        The centroid of a peptide can be plotted\n",
    "                                        in red together with the selected peptide.\n",
    "                                           \n",
    "    Return:     show a 3D plot\n",
    "    '''\n",
    "    \n",
    "    # if there is only a single peptide to show\n",
    "    # use the single peptide function to normalize axis    \n",
    "    \n",
    "    if peptide_list == None:\n",
    "        peptide_list = [p for p in coordinate_dict]\n",
    "    \n",
    "    \n",
    "    if len(peptide_list) == 1:\n",
    "        \n",
    "        return plot_single_peptide(coordinate_dict[peptide_list[0]])\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        x = []\n",
    "        y = []\n",
    "        z = []\n",
    "        x_median = float\n",
    "        y_median = float\n",
    "        z_median = float\n",
    "\n",
    "\n",
    "        for peptide in range(len(peptide_list)):\n",
    "            x.append([peptide])\n",
    "            y.append([peptide])\n",
    "            z.append([peptide])\n",
    "            for aminoacid in coordinate_dict[peptide_list[peptide]]:\n",
    "\n",
    "                point = coordinate_dict[peptide_list[peptide]][aminoacid]\n",
    "                x[peptide].append(point[0])\n",
    "                y[peptide].append(point[1])\n",
    "                z[peptide].append(point[2])\n",
    "\n",
    "            del x[peptide][0]\n",
    "            del y[peptide][0]\n",
    "            del z[peptide][0]\n",
    "\n",
    "        if centroid == True:\n",
    "\n",
    "            def assemble_coordinate(axis_coordinate_list):\n",
    "                median_list = []\n",
    "                for coordinate_set in axis_coordinate_list:\n",
    "                    median = np.median(coordinate_set)\n",
    "                    median_list.append(median)\n",
    "                return median_list\n",
    "\n",
    "            x_median = assemble_coordinate(x)\n",
    "            y_median = assemble_coordinate(y)\n",
    "            z_median = assemble_coordinate(z)\n",
    "\n",
    "\n",
    "        #%matplotlib notebook\n",
    "\n",
    "        fig = plt.figure()\n",
    "\n",
    "        ax = plt.axes(projection='3d')\n",
    "\n",
    "\n",
    "        for pep in range(len(x)):\n",
    "\n",
    "            ax.scatter3D(x[pep],y[pep],z[pep])\n",
    "\n",
    "            if centroid == True:\n",
    "\n",
    "                ax.scatter3D(x_median[pep], y_median[pep], z_median[pep], c='red')\n",
    "\n",
    "\n",
    "        #return  plt.show(), [x,y,z], [x_median, y_median, z_median]         \n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = [i for i in range(100,1001,100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = [i for i in range(10,101,10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_for_compatibility(to_split,split_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from morphoscanner.backend.check_val import check_int_and_return, isInt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_dict = morphoscanner.backend.topology.get_peptide_length_dict(peptide_length_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_dict.get(96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_for_splitting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly as px \n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_protein(coordinate_dict):\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "\n",
    "    for residue in coordinate_dict:\n",
    "        point = coordinate_dict[residue]\n",
    "        x.append(point[0])\n",
    "        y.append(point[1])\n",
    "        z.append(point[2])\n",
    "\n",
    "\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    z = np.asarray(z)\n",
    "\n",
    "    fig = go.Figure(data = [go.Scatter3d (x = x, y = y, z= z)])\n",
    "    return fig.show()\n",
    "\n",
    "def heatmap2d(arr: np.ndarray):\n",
    "    plt.imshow(arr, cmap = 'viridis', interpolation = 'nearest')\n",
    "    plt.colorbar()\n",
    "    return plt.show()\n",
    "\n",
    "def get_euclidean_distance(point_1, point_2):\n",
    "\n",
    "    euclidean_distance = np.sqrt(np.sum([((point_1[0] - point_2[0])**2), ((point_1[1] - point_2[1])**2), ((point_1[2] - point_2[2])**2)]))\n",
    "\n",
    "    return euclidean_distance\n",
    "\n",
    "def compute_distance_map(coordinate_dict):\n",
    "    i = 0\n",
    "    distance_map = np.zeros((len(coordinate_dict),len(coordinate_dict)))\n",
    "    for  i  in range(i, len(coordinate_dict)-1):\n",
    "        coordinate_1 = coordinate_dict[i] \n",
    "        for j in range(0, len(coordinate_dict)-1):\n",
    "            coordinate_2 = coordinate_dict[j]\n",
    "            euclidean_distance = get_euclidean_distance(coordinate_1, coordinate_2)\n",
    "            distance_map[i][j] = euclidean_distance\n",
    "            distance_map[j][i] = euclidean_distance\n",
    "    return distance_map\n",
    "\n",
    "def contact_map_helix(distance_map):\n",
    "    contact_map = np.zeros((len(distance_map),len(distance_map)))\n",
    "    for i in range(1, len(distance_map)-1):\n",
    "        for j in range(1, len(distance_map)-1):\n",
    "            if 0.45 < distance_map[i][j] < 0.46:\n",
    "                contact_map[i][j] = 1\n",
    "            elif 0.52 < distance_map[i][j] < 0.56:\n",
    "                contact_map[i][j] = 2\n",
    "    return contact_map\n",
    "\n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_split = check_input_multiple_int_recursive_with_sentence('Write the length of the peptides that you want to split (as an integer): ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "def isInt(s):\n",
    "    '''Check if s is type int and return bool.\n",
    "    \n",
    "    Input: object\n",
    "    \n",
    "    Output: bool'''\n",
    "    \n",
    "    try:\n",
    "        return float(str(s)).is_integer()\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "    \n",
    "    \n",
    "def check_int_and_return(value):\n",
    "    \n",
    "    '''Check int and return value, else raise ValueError and print object type\n",
    "    \n",
    "    Input = object\n",
    "    \n",
    "    Output = int'''\n",
    "\n",
    "    if isInt(value):\n",
    "\n",
    "        return int(value)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"%s is not an integer, it is of type %s...\\n \" % (str(value), type(value))) \n",
    "\n",
    "\n",
    "        \n",
    "##############################\n",
    "#############################\n",
    "##############################\n",
    "\n",
    "\n",
    "def ask_for_splitting(limit=5):\n",
    "\n",
    "    answer = input(\"Do you want to split peptides? Write 'yes' or 'no': \")\n",
    "    \n",
    "    if answer not in {'n','no','y','yes'}:\n",
    "        print('This is not a valid answer, please write yes or no.\\n'\n",
    "            '%d trial left.' % limit)\n",
    "        limit -= 1\n",
    "        if limit == 0:\n",
    "            raise sys.exit('Too many wrong inputs. Closing...')\n",
    "        else:\n",
    "            return ask_for_splitting(limit=limit)\n",
    "\n",
    "    elif answer in {'n', 'no'}:\n",
    "        print('The .gro topology file is set as reference for the analysis')\n",
    "        return False\n",
    "\n",
    "    elif answer in {'y', 'yes'}:\n",
    "        return True\n",
    "\n",
    "\n",
    "\n",
    "def check_input_multiple_int_recursive_with_sentence(sentence, limit=5):\n",
    "    \n",
    "    value = input(sentence)\n",
    "    input_list = value.split()\n",
    "    \n",
    "    if len(input_list) == 0:\n",
    "        limit -= 1\n",
    "        \n",
    "        if limit == 0:\n",
    "            raise sys.exit(\"Too many empty inputs. Closing...\")\n",
    "        else:\n",
    "            print('%d trial left.\\n'\n",
    "                  'You forgot to insert a value...please retry.' % limit)\n",
    "            return check_input_multiple_int_recursive_with_sentence(sentence=sentence, limit=limit)\n",
    "    \n",
    "    else:\n",
    "        va_list = []\n",
    "        for val in input_list:\n",
    "            \n",
    "            if isInt(val):\n",
    "                va_list.append(int(val))\n",
    "        \n",
    "                \n",
    "            else:\n",
    "                limit -= 1\n",
    "                print('%d trial left.' % (limit))\n",
    "                if limit == 0:\n",
    "                    raise sys.exit(\"%s is not an integer, it is of type %s...\\nClosing... \" % (str(val), type(val))) \n",
    "                else:\n",
    "                    print(\"%s is not an integer, it is of type %s...\\n \" % (str(val), type(val)))\n",
    "                    return check_input_multiple_int_recursive_with_sentence(sentence=sentence, limit=limit)\n",
    "        \n",
    "        return va_list\n",
    "    \n",
    "    \n",
    "def check_for_compatibility(list1, list2):\n",
    "    if len(list1) == len(list2):\n",
    "        \n",
    "        for e1, e2 in zip(list1, list2):\n",
    "            if e1%e2 != 0:\n",
    "                print('%d is not multiple of %d' % (e1,e2))\n",
    "                return False\n",
    "            \n",
    "        \n",
    "        else:\n",
    "            return True\n",
    "    \n",
    "    else:\n",
    "        raise ValueError('Your lists are of different len! list1 len = %d, list2 len = %d.' % (len(list1), len(list2)))\n",
    "\n",
    "\n",
    "def get_splitting_dict(to_split, split_size):\n",
    "    \n",
    "    splitting_dict = {}\n",
    "    \n",
    "    for length, split_dim in zip(to_split, split_size):\n",
    "        #check for divisibility\n",
    "        if (length%split_dim) == 0:\n",
    "            splitting_dict[length] = split_dim\n",
    "    \n",
    "    return splitting_dict\n",
    "\n",
    "def get_new_peptides_length(peptide_length_list, splitting_dict):\n",
    "    new_peptide_list = []\n",
    "    for pep_length in peptide_length_list:\n",
    "        if pep_length in splitting_dict.keys():\n",
    "            new_size = splitting_dict[pep_length]\n",
    "            new_peptide_list.extend([splitting_dict[pep_length] for p in range((pep_length//new_size))])\n",
    "        else:\n",
    "            new_peptide_list.append(pep_length)\n",
    "    \n",
    "    return new_peptide_list\n",
    "\n",
    "\n",
    "#####################################\n",
    "####################################+\n",
    "#####################################\n",
    "\n",
    "#to complete\n",
    "# i want to get frame and the tensor inside frame object\n",
    "# then continue analysis\n",
    "\n",
    "class frames():\n",
    "    \n",
    "    def __init__(self, frame):\n",
    "        \n",
    "        self.frame = frame\n",
    "        \n",
    "        pass\n",
    "        \n",
    "        \n",
    "#        frame_dict = self.get_frame(frame)\n",
    "#        frame_tensor = distance_tensor.get_coordinate_tensor_from_dict_multi(frame_dict)\n",
    "#        frame_tensor = distance_tensor.cat_tensor_for_size(frame_tensor)\n",
    "     \n",
    "    def get_frame(self):\n",
    "\n",
    "        a_frame = {}\n",
    "        for pep in super().frames[self.frame].peptides:\n",
    "            a_frame[pep] = super().frames[self.frame].peptides[pep].coordinates\n",
    "        \n",
    "        \n",
    "  #  def get_tensor(self):\n",
    "   #     frame_dict = \n",
    "    #    frame_tensor = distance_tensor.get_coordinate_tensor_from_dict_multi(frame_dict)\n",
    "    #    frame_tensor = distance_tensor.cat_tensor_for_size(frame_tensor)\n",
    "\n",
    "#    return a_frame\n",
    "\n",
    "\n",
    "    #def frame_tensor()\n",
    "    \n",
    "    \n",
    "        pass\n",
    "    \n",
    "        \n",
    "\n",
    "# Classes in dev\n",
    "\n",
    "class single_peptide():\n",
    "    \n",
    "    ''' Class that define peptides\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, sequence, atom_n, coordinates):\n",
    "        \n",
    "        self.sequence = sequence\n",
    "        self.atom_numbers = atom_n\n",
    "        self.coordinates = coordinates\n",
    "        \n",
    "        return\n",
    "\n",
    "    def get_coordinate_from_frame(self, coordinates):\n",
    "        \n",
    "        self\n",
    "        \n",
    "    #do this for each peptide to gather distances\n",
    "    # this is not optimized but still faster than before\n",
    "    def distance(self):\n",
    "        \n",
    "\n",
    "        self.distances = {}\n",
    "        for tens in frame_tensor:\n",
    "\n",
    "            dists[tens] = fast_cdist(frame_tensor[tens], tt.unsqueeze(0))\n",
    "\n",
    "        return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old one\n",
    "def get_data_from_trajectory_frame_v1(universe, frame, peptide_length_list, atom_to_select='BB'):\n",
    "\n",
    "    # move universe frame to memory\n",
    "    universe.trajectory[frame]\n",
    "\n",
    "    coordinate_dict = {}\n",
    "    residues_dict = {}\n",
    "    atom_number_dict = {}\n",
    "    \n",
    "    res_counter = 0\n",
    "    object_dict = {} # new\n",
    "    #print(length_list)\n",
    "    for pep_index, peptide in enumerate(peptide_length_list):\n",
    "\n",
    "        coordinate_dict[pep_index] = {}\n",
    "        residues_dict[pep_index] = {}\n",
    "        atom_number_dict[pep_index] = {}\n",
    "        \n",
    "        for res in range(peptide):\n",
    "\n",
    "            actual_res = universe.residues[res_counter]\n",
    "            \n",
    "            for index, atom in enumerate(actual_res.atoms):\n",
    "\n",
    "                atom_type = str(atom).split()[2]\n",
    "\n",
    "                if atom_type == atom_to_select:\n",
    "                    \n",
    "                    atom_number = (int(str(atom).split()[1].split(':')[0]) - 1)\n",
    "\n",
    "                    residue_name = (str(atom).split()[8].split(',')[0])\n",
    "\n",
    "                    coordi = universe.atoms[atom_number].position\n",
    "\n",
    "                    coordinate_dict[pep_index][res] = coordi\n",
    "                    residues_dict[pep_index][res] = residue_name\n",
    "                    atom_number_dict[pep_index][res] = atom_number\n",
    "                    \n",
    "                    res_counter += 1\n",
    "        \n",
    "        object_dict[pep_index] = single_peptide(residues_dict[pep_index], atom_number_dict[pep_index], coordinate_dict[pep_index])\n",
    "        \n",
    "                    \n",
    "    return object_dict\n",
    "    #return residues_dict, atom_number_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(new_peptide_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(peptide_length_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe = morphoscanner.backend.topology.make_universe(trj_gro,trj_xtc)\n",
    "peptide_length_list = morphoscanner.backend.topology.get_peptide_length_list(trj_gro)\n",
    "len_dict = morphoscanner.backend.topology.get_peptide_length_dict(peptide_length_list)\n",
    "morphoscanner.backend.topology.print_peptides_length(len_dict)\n",
    "have_to_split = ask_for_splitting()\n",
    "if have_to_split:\n",
    "    to_split = check_input_multiple_int_recursive_with_sentence('Write the length of the peptides that you want to split (as integer or list of integer separated by a space): ')\n",
    "    split_size = check_input_multiple_int_recursive_with_sentence('\\nWrite the length in which you want to split your peptides (as integer or list of integer separated by a space).\\n'\n",
    "                                                                 'The list should be of the same length of the list above, \\nthe numbers have to be divisors of the numbers inserted above. ')\n",
    "    compatible = check_for_compatibility(to_split, split_size)\n",
    "    if compatible:\n",
    "        splitting_dict = get_splitting_dict(to_split, split_size)\n",
    "        new_peptides_length = get_new_peptides_length(peptide_length_list, splitting_dict)\n",
    "        print('Splitting done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "have_to_split = ask_for_splitting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class results():\n",
    "    \n",
    "    def __init__(self, frame):\n",
    "        self.frame = frame\n",
    "        pass\n",
    "\n",
    "    #def get_data(self, data_name, data):\n",
    "        \n",
    "    #    setattr(self, data_name, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class results():\n",
    "    def __init__(self, frame):\n",
    "    \n",
    "        frame = frame\n",
    "        print('Analyzing frame n° ', frame)\n",
    "    \n",
    "        frame_dict = self.get_frame(frame)\n",
    "    \n",
    "        frame_tensor = distance_tensor.get_coordinate_tensor_from_dict(frame_dict)\n",
    "    \n",
    "        start_dist = timer()\n",
    "        frame_distance_maps = distance_tensor.compute_euclidean_norm_torch(frame_tensor)\n",
    "        end_dist = timer()\n",
    "        print('Time to compute distance is: ', (end_dist - start_dist))\n",
    "    \n",
    "        start_contc = timer()\n",
    "        frame_contact = pattern_recognition.compute_contact_maps_as_array(frame_distance_maps)\n",
    "        end_contc = timer()\n",
    "        print('Time to compute contact is: ', (end_contc - start_contc))\n",
    "    \n",
    "        start_den = timer()\n",
    "        frame_denoised, df = pattern_recognition.denoise_contact_maps(frame_contact)\n",
    "        end_den = timer()\n",
    "        print('Time to denoise: ', (end_den-start_den))\n",
    "    \n",
    "        frame_graph_full = graph.graph_v1(frame_denoised, df)\n",
    "        setattr(self, 'graph', frame_graph_full)\n",
    "        \n",
    "        subgraphs = find_subgraph(frame_graph_full)        \n",
    "        setattr(self, 'subgraph', subgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from morphoscanner import backend, data_acquisition, trj_object\n",
    "from morphoscanner.backend import distance_tensor, pattern_recognition, graph\n",
    "\n",
    "from morphoscanner.backend.check_val import isInt\n",
    "import sys\n",
    "\n",
    "\n",
    "class trajectory:\n",
    "    '''Class to operate on trajectory files.\n",
    "\n",
    "    It makes an object that contain the trajectory of the simulation'''\n",
    "\n",
    "    def __init__(self, trj_gro, trj_xtc, select = None):\n",
    "        \n",
    "        self.trj_gro = trj_gro\n",
    "        self.trj_xtc = trj_xtc\n",
    "        self.universe = backend.topology.make_universe(self.trj_gro, self.trj_xtc)\n",
    "        self.number_of_frames = len(self.universe.trajectory)\n",
    "        #self.number_of_BB_atoms = len(self.universe.select_atoms('name BB'))\n",
    "        \n",
    "        if select == None:\n",
    "            select = ['peptide']\n",
    "            \n",
    "        self.select = select\n",
    "       \n",
    "        self.peptide_length_list = backend.topology.get_peptide_length_list(self.trj_gro, self.select)\n",
    "        \n",
    "        self.len_dict = backend.topology.get_peptide_length_dict(self.peptide_length_list)\n",
    "        \n",
    "        print('In your trajectory there are %d frames.\\n' % self.number_of_frames)\n",
    "        #print('In each frame there are %d BB atoms.\\n' % self.number_of_BB_atoms)\n",
    "        morphoscanner.backend.topology.print_peptides_length(self.len_dict)\n",
    "        \n",
    "        return\n",
    "        \n",
    "        \n",
    "    def split(self, to_split: list, split_size: list):\n",
    "        '''Manually split peptide_length_list in case of seeds.\n",
    "        \n",
    "        Input:\n",
    "            to_split: list\n",
    "                list of int or ints.\n",
    "                Each int refers to the length of a peptides seed\n",
    "                from self.len_dict.keys() that you want to split in single peptide.\n",
    "                For example if in len dict there are seeds of length 96 that you want to split,\n",
    "                to_split = [96]\n",
    "                \n",
    "            split_size: list\n",
    "                list of int or ints.\n",
    "                This is the size in which you want to split your to_split seeds.\n",
    "                For example if you want to split your seeds of length 96 in peptides of length 12,\n",
    "                split_size = [12]\n",
    "                \n",
    "        Output:\n",
    "            Change the original self.peptide_length_list with a new list of splitted peptides.\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        splitting_dict = data_acquisition.script_inputs.get_splitting_dict(to_split, split_size)\n",
    "        self.peptide_length_list = data_acquisition.script_inputs.get_new_peptides_length(self.peptide_length_list, splitting_dict)\n",
    "        print('Splitting done.\\n')\n",
    "        print('\"peptide_length_list\" attribute has been updated with the new length.')\n",
    "        \n",
    "        return    \n",
    "    \n",
    "    def explore(self):\n",
    "        # v1 with frame priority\n",
    "\n",
    "        frame = 0\n",
    "        self.frames = {}\n",
    "        self.frames[frame] = frames(frame)\n",
    "        self.frames[frame].peptides = morphoscanner.backend.topology.get_data_from_trajectory_frame_v2(universe=self.universe, frame=frame, peptide_length_list=self.peptide_length_list, select=self.select)\n",
    "        print('Exploration of frame %d done.\\n' % frame)\n",
    "\n",
    "        return    \n",
    "    \n",
    "    def compose_database(self, sampling_interval=1):\n",
    "        \n",
    "        steps = [s for s in range(self.number_of_frames) if s%sampling_interval==0 and s != 0]\n",
    "        for step in tqdm.tqdm(steps):\n",
    "            self.universe.trajectory[step]\n",
    "            self.frames[step] = frames(step)\n",
    "            self.frames[step].peptides = {}\n",
    "            for pep in self.frames[0].peptides:\n",
    "                c_list = {}\n",
    "\n",
    "                for idx, i in enumerate(self.frames[0].peptides[pep].atom_numbers.values()):\n",
    "                    p = self.universe.atoms[i].position\n",
    "                    c_list[idx] = p\n",
    "\n",
    "                self.frames[step].peptides[pep] = single_peptide(self.frames[0].peptides[pep].sequence,self.frames[0].peptides[pep].atom_numbers,c_list)\n",
    "\n",
    "        return\n",
    "        \n",
    "    def get_frame(self, frame):\n",
    "        \n",
    "        a_frame = {}\n",
    "\n",
    "        for pep in self.frames[frame].peptides:\n",
    "            a_frame[pep] = self.frames[frame].peptides[pep].coordinates\n",
    "\n",
    "        return a_frame\n",
    "    \n",
    "    def get_peptide(self, peptide):\n",
    "    \n",
    "        a_peptide = {}\n",
    "        for frame in self.frames:\n",
    "            \n",
    "            a_peptide[frame] = self.frames[frame].peptides[peptide].coordinates\n",
    "            \n",
    "        return a_peptide\n",
    "    \n",
    "    def analysis(self, frame):\n",
    "    \n",
    "        frame = frame\n",
    "        print('Analyzing frame n° ', frame)\n",
    "    \n",
    "        frame_dict = self.get_frame(frame)\n",
    "    \n",
    "        frame_tensor = distance_tensor.get_coordinate_tensor_from_dict(frame_dict)\n",
    "    \n",
    "        start_dist = timer()\n",
    "        frame_distance_maps = distance_tensor.compute_euclidean_norm_torch(frame_tensor)\n",
    "        end_dist = timer()\n",
    "        print('Time to compute distance is: ', (end_dist - start_dist))\n",
    "    \n",
    "        start_contc = timer()\n",
    "        frame_contact = pattern_recognition.compute_contact_maps_as_array(frame_distance_maps)\n",
    "        end_contc = timer()\n",
    "        print('Time to compute contact is: ', (end_contc - start_contc))\n",
    "    \n",
    "        start_den = timer()\n",
    "        frame_denoised, df = pattern_recognition.denoise_contact_maps(frame_contact)\n",
    "        end_den = timer()\n",
    "        print('Time to denoise: ', (end_den-start_den))\n",
    "    \n",
    "        frame_graph_full = graph.graph_v1(frame_denoised, df)\n",
    "        \n",
    "        subgraphs = graph.find_subgraph(frame_graph_full)        \n",
    "\n",
    "        \n",
    "        try:\n",
    "            self.results[frame] = results(frame)       \n",
    "\n",
    "        except:\n",
    "            self.results = {}\n",
    "            self.results[frame] = results(frame)       \n",
    "\n",
    "        self.results[frame].graph = frame_graph_full\n",
    "        self.results[frame].subgraphs = subgraphs\n",
    "        self.results[frame].cross_correlation = df\n",
    "        \n",
    "        print('Finished analysis of frame n° %d' % frame)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test = trajectory(trj_gro, trj_xtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t_test.split([96],[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test.compose_database(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test.analysis(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(t_test.results[150].graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot.plot_peptide_list(t_test.get_frame(150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assemble a coordinate dict for each frame for a peptide\n",
    "# assemble a coordinate dict for each peptide in a single frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_frame = {}\n",
    "\n",
    "for pep in t_test.frames[150].peptides:\n",
    "    a_frame[pep] = t_test.frames[150].peptides[pep].coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t_test.frames[0].peptides[15].coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot.plot_single_peptide(t_test.frames[0].peptides[16].coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Instantiate universe and peptide list\n",
    "universe = morphoscanner.backend.topology.make_universe(trj_gro,trj_xtc)\n",
    "peptide_length_list = morphoscanner.backend.topology.get_peptide_length_list(trj_gro)\n",
    "\n",
    "\n",
    "coordinate, sequence, atom_number = get_data_from_trajectory_frame(universe, 0, peptide_length_list)\n",
    "\n",
    "peptides_dict = {}\n",
    "for seq, coord, atm_n in zip(sequence, coordinate, atom_number):\n",
    "\n",
    "    peptides_dict[seq] = single_peptide(sequence.get(seq), atom_number.get(atm_n))\n",
    "    \n",
    "    actual_frame = universe.trajectory.trajectory.frame\n",
    "    \n",
    "    peptides_dict[seq].get_coordinate_from_frame(frame=actual_frame, coordinates=coordinate.get(coord))\n",
    "\n",
    "    \n",
    "start = timer()\n",
    "for step in steps:\n",
    "    universe.trajectory[step]\n",
    "    \n",
    "    for pep in peptides_dict:\n",
    "        c_list = {}\n",
    "        \n",
    "        for idx, i in enumerate(peptides_dict[pep].atom_numbers.values()):\n",
    "            p = universe.atoms[i].position\n",
    "            c_list[idx] = p\n",
    "            \n",
    "        peptides_dict[pep].get_coordinate_from_frame(step, c_list)\n",
    "        \n",
    "end = timer()\n",
    "print(end-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot.plot_peptide_list(t_test.get_peptide(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peptides_dict[0].frames.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#steps = [i for i in range(universe.trajectory.n_frames) if i%10 == 0]\n",
    "steps = [i for i in range(universe.trajectory.n_frames)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_process_dict = peptides_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "\n",
    "#multiprocessing.cpu_count()\n",
    "available_cpu = len(os.sched_getaffinity(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test.peptide[0].frames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis(frame):\n",
    "\n",
    "    # WHY len(frame_denoised) is len(frame_dict)-1 ???????\n",
    "    \n",
    "    frame = frame\n",
    "    print('Analyzing frame n° ', frame)\n",
    "\n",
    "    frame_dict = t_test.get_frame(frame)\n",
    "\n",
    "    frame_tensor = backend.distance_tensor.get_coordinate_tensor_from_dict(frame_dict)\n",
    "\n",
    "    start_dist = timer()\n",
    "    frame_distance_maps = backend.distance_tensor.compute_euclidean_norm_torch(frame_tensor)\n",
    "    end_dist = timer()\n",
    "    print('Time to compute distance is: ', (end_dist - start_dist))\n",
    "\n",
    "    start_contc = timer()\n",
    "    frame_contact = backend.pattern_recognition.compute_contact_maps_as_array(frame_distance_maps)\n",
    "    end_contc = timer()\n",
    "    print('Time to compute contact is: ', (end_contc - start_contc))\n",
    "\n",
    "    start_den = timer()\n",
    "    frame_denoised, df = backend.pattern_recognition.denoise_contact_maps(frame_contact)\n",
    "    end_den = timer()\n",
    "    print('Time to denoise: ', (end_den-start_den))\n",
    "\n",
    "    #frame_graph = backend.graph.nx_graph_search(self.frame_denoised)\n",
    "    \n",
    "    frame_graph_full = backend.graph.graph_v1(frame_denoised, df)\n",
    "\n",
    "    subgraphs = backend.graph.find_subgraph(frame_graph_full)\n",
    "\n",
    "    self.[frame] = results.get_data(self, 'graph', frame_graph_full)\n",
    "    self.results[frame].get_data(self, 'subgraph', subgraphs)\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a_dict.update({'a':1, 'b':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dict.update({'c':3, 'd':4, 'e': {'a':1, 'b':2, 'c':3}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class frames(object):\n",
    "    \n",
    "    pass\n",
    "    \n",
    "    \n",
    "    #def __init__(self, coordinates):\n",
    "        \n",
    "        #self.coordinates = coordinates\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "# Classes in dev\n",
    "\n",
    "class single_peptide():\n",
    "    \n",
    "    ''' Class that define peptides\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, seq, atom_n):\n",
    "        \n",
    "        self.sequence = seq\n",
    "        self.atom_numbers = atom_n\n",
    "        #self.frames_coordinates = frames()\n",
    "        \n",
    "        return\n",
    "    \n",
    "    \n",
    "#    def get_coordinate_from_frame(self, frame, coordinates):\n",
    "#        \n",
    "#        name = 'frame_' + str(frame)\n",
    "#\n",
    "#        setattr(self.frames_coordinates, name, coordinates)\n",
    "#        \n",
    "#        return\n",
    "    \n",
    "    def get_coordinate_from_frame(self, frame, coordinates):\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            self.frames[frame] = coordinates\n",
    "        except:\n",
    "            self.frames = {}\n",
    "            self.frames[frame] = coordinates\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@author: lillo\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def get_coordinate_from_pdb(file):\n",
    "    '''\n",
    "    Parse a pdb file. Support single chain and multiple chain\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file : str\n",
    "        The path of the .pdb file in your system.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    coordinate_dict : dict\n",
    "        A dict of dict with the coordinate of each atom of the pdb file.\n",
    "        \n",
    "        Depending on the input file it has different levels of nesting:\n",
    "            \n",
    "            for single chain:\n",
    "                atom_index : [x,y,z]\n",
    "                \n",
    "            for multiple chain:\n",
    "                \n",
    "                chain_index : {atom index : [x,y,z]}\n",
    "    '''\n",
    "    \n",
    "    with open(file) as pdbfile:\n",
    "\n",
    "        coordinate_dict = {}\n",
    "        atom_count_dict = {}\n",
    "        start = 0\n",
    "\n",
    "        for line in pdbfile:\n",
    "            \n",
    "            # split line\n",
    "            splitted_line = [line[:6], line[6:11], line[12:16], line[17:20], line[21], line[22:26], line[30:38], line[38:46], line[46:54]]\n",
    "            # get line header\n",
    "            line_id = splitted_line[0].split()[0]\n",
    "            \n",
    "            #check for atom and heteroatom\n",
    "            if line_id in {'ATOM', 'HETATM'}:\n",
    "                \n",
    "                # get CA atom only\n",
    "                if splitted_line[2].split()[0] in {'CA'}:\n",
    "                    \n",
    "                    # get atom num for indexing\n",
    "                    atom_num = int(splitted_line[5])\n",
    "                    # get protein chain for indexing\n",
    "                    chain = splitted_line[4]\n",
    "                    # get coordinates\n",
    "                    x, y, z = float(splitted_line[6]), float(splitted_line[7]), float(splitted_line[8])\n",
    "                    \n",
    "                    # check if actual chain already has an entry in coordinate_dict\n",
    "                    if chain not in coordinate_dict.keys():\n",
    "                        \n",
    "                        # index from 'start'\n",
    "                        atom_count_dict[chain] = start\n",
    "                        # create key for new chain\n",
    "                        coordinate_dict[chain] = {}\n",
    "                        # put actual atom coordinates in coordinate_dict\n",
    "                        coordinate_dict[chain][atom_count_dict[chain]] = np.array([x,y,z])\n",
    "                    # if actual chain already in coordinate_dict\n",
    "                    else:\n",
    "                        # move index forward\n",
    "                        atom_count_dict[chain] += 1\n",
    "                        # add the atom coordinates\n",
    "                        coordinate_dict[chain][atom_count_dict[chain]] = np.array([x,y,z])\n",
    "\n",
    "    # if there is only one chain, flat the dict\n",
    "    if len(coordinate_dict) == 1:\n",
    "        coordinate_dict = coordinate_dict.get([k for k in coordinate_dict][0])\n",
    "\n",
    "    return coordinate_dict\n",
    "\n",
    "\n",
    "def get_coordinate_tensor_from_dict(coordinate_dict, device='cuda'):\n",
    "    '''\n",
    "        Convert a coordinate_dict to a torch.tensor, for parallel euclidean distance calculation.\n",
    "        Works on dict in the form {atom_key : [x, y, z]}\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    coordinate_dict : dict\n",
    "        Is the coordinate_dict in the form {key : [x, y, z]}.\n",
    "        It also works for N-dimensional points.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    zero : torch.tensor\n",
    "        Returns a torch.tensor of shape n x m\n",
    "        'n'  are the keys in coordinate_dict al len(coordinate_dict)\n",
    "        'm' is the number of dimensions of your data points\n",
    "        \n",
    "        It save on gpu if torch.cuda.is_available(), else on cpu\n",
    "        If you want to move your data on cpu, e.g. for visualization,\n",
    "        you need to output_tensor.cpu()\n",
    "    '''\n",
    "    \n",
    "\n",
    "    #variables with dict dimension\n",
    "    dim0 = len(coordinate_dict)\n",
    "    first_key = [k for k in coordinate_dict.keys()][0]\n",
    "    dim1 = len(coordinate_dict[first_key])\n",
    "\n",
    "    #initialize a 0s tensor\n",
    "    #device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    zero = torch.zeros([dim0,dim1], dtype=torch.float32, device=device)\n",
    "\n",
    "    for index, peptide in enumerate(coordinate_dict):\n",
    "            \n",
    "        zero[index] = torch.tensor(coordinate_dict[peptide], device=device)\n",
    "                \n",
    "    return zero\n",
    "\n",
    "\n",
    "def get_tensors_from_multichain_dict(coordinate_dict):\n",
    "    '''\n",
    "    Generate tensor from multichain coordinate dict.\n",
    "    Your coordinate_dict is in the form:\n",
    "        \n",
    "        {chain : {atom : [x, y, z] }}\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    coordinate_dict : dict\n",
    "        Your coordinate_dict.\n",
    "        It is in the form:\n",
    "        {chain : {atom : [x, y, z] }}.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tensor_dict : dict\n",
    "        It is a dict of tensor, one tensor per chain.\n",
    "\n",
    "    '''\n",
    "    tensor_dict = {}\n",
    "    for chain in coordinate_dict:\n",
    "        tensor_dict[chain] = get_coordinate_tensor_from_dict(coordinate_dict[chain])\n",
    "    return tensor_dict\n",
    "\n",
    "\n",
    "def distance_matrix_from_2d_tensor(peptide1_tensor, peptide2_tensor=None, device='cpu'):\n",
    "    '''\n",
    "    Minimal function to calculate euclidean distance between two set of points\n",
    "    using quadratic expansion. Thanks to:\n",
    "            https://discuss.pytorch.org/t/efficient-distance-matrix-computation/9065\n",
    "            https://github.com/pytorch/pytorch/pull/25799\n",
    "            https://github.com/pytorch/pytorch/issues/15253\n",
    "    \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    peptide1_tensor : torch.tensor\n",
    "        torch.tensor of shape n x d.\n",
    "        \n",
    "    peptide2_tensor : torch.tensor, optional\n",
    "        The default is None.\n",
    "        torch.tensor for which you want to calculate te distance from peptide1_tensor\n",
    "        shape m x p\n",
    "        \n",
    "    device : str, optional\n",
    "        Options: 'cpu', 'cuda'\n",
    "        The default is 'cpu'.\n",
    "        \n",
    "        Is the device on which to compute the calculation.\n",
    "        You can set it to 'cuda' if you have an Nvidia GPU and CUDA driver installed.\n",
    "        \n",
    "        'cuda' will move the data in the GPU memory, so you have to use data.cpu() to move\n",
    "        data back to system memory. data in system memory are needed to plot data\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    distance_map : torch.tensor\n",
    "        shape n x p\n",
    "        tensor with the distances data\n",
    "\n",
    "    '''\n",
    "    \n",
    "\n",
    "    if peptide2_tensor == None:\n",
    "        peptide2_tensor = peptide1_tensor\n",
    "\n",
    "    # calculate distance\n",
    "    x_norm = torch.pow(peptide1_tensor, 2).sum(1).view(-1,1)\n",
    "    y_t = torch.transpose(peptide2_tensor, 0, 1)\n",
    "    y_norm = torch.pow(peptide2_tensor, 2).sum(1).view(1,-1)\n",
    "    \n",
    "    distance_map = torch.sqrt(x_norm + y_norm - 2.0 * torch.mm(peptide1_tensor, y_t))\n",
    "    \n",
    "    # convert nan to 0  (using this instead of torch.clamp())       \n",
    "    distance_map[torch.isnan(distance_map)] = 0\n",
    "    \n",
    "    # if you are calculating pointwise distance a single tensor\n",
    "    # main diagonal is 0, to fix stability errors\n",
    "    if peptide1_tensor is peptide2_tensor:\n",
    "        distance_map = distance_map.fill_diagonal_(0)\n",
    "    \n",
    "    return distance_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This works if i multiply a tensor with a matrix\n",
    "def fast_cdist(x1, x2):\n",
    "    adjustment = x1.mean(-2, keepdim=True)\n",
    "    x1 = x1 - adjustment\n",
    "    x2 = x2 - adjustment  # x1 and x2 should be identical in all dims except -2 at this point\n",
    "\n",
    "    # Compute squared distance matrix using quadratic expansion\n",
    "    # But be clever and do it with a single matmul call\n",
    "    x1_norm = x1.pow(2).sum(dim=-1, keepdim=True)\n",
    "    x1_pad = torch.ones_like(x1_norm)\n",
    "    x2_norm = x2.pow(2).sum(dim=-1, keepdim=True)\n",
    "    x2_pad = torch.ones_like(x2_norm)\n",
    "    x1_ = torch.cat([-2. * x1, x1_norm, x1_pad], dim=-1)\n",
    "    x2_ = torch.cat([x2, x2_pad, x2_norm], dim=-1)\n",
    "    res = x1_.matmul(x2_.transpose(-2, -1))\n",
    "\n",
    "    # Zero out negative values\n",
    "    #res.clamp_min_(1e-30).sqrt_()\n",
    "    res = res.sqrt()\n",
    "    res[torch.isnan(res)]=0\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#working\n",
    "def compute_distance_between_each_peptide(coordinate_dict):\n",
    "    # instantiate tensor\n",
    "    coordinate_tensor = morphoscanner.backend.distance_tensor.get_coordinate_tensor_from_dict_multi(coordinate_dict)\n",
    "    # group tensor for size\n",
    "    group_tensor, order_tensor = morphoscanner.backend.distance_tensor.cat_tensor_for_size(coordinate_tensor)\n",
    "    \n",
    "    #start = timer()\n",
    "    distance_maps_dict = {}\n",
    "    for tensor in coordinate_tensor:\n",
    "        distance_maps_dict[tensor] = {}\n",
    "        for tensor_group in group_tensor:\n",
    "            index_dict = order_tensor[tensor_group]\n",
    "            distance = fast_cdist(coordinate_tensor[tensor],group_tensor[tensor_group])\n",
    "                      \n",
    "            for map_index, m in enumerate(distance):\n",
    "                real_index = index_dict[map_index]\n",
    "                distance_maps_dict[tensor][real_index] = m\n",
    "\n",
    "    #end = timer()\n",
    "    #print(end-start)\n",
    "    return distance_maps_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_multi = compute_distance_between_each_peptide(multidim.get_frame(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d_multi[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(d_multi[20][20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosa voglio?\n",
    "# voglio fare in modo di accellerare la computazione delle distanze anche tra peptidi di dimensione diversa\n",
    "# utilizzando operazioni tra tensori per parallelizzare i calcoli\n",
    "#\n",
    "# se ho un set di proteine di dimensione diversa,\n",
    "# come faccio il calcolo delle distanze utilizzando i tensori?\n",
    "# \n",
    "# opzione 1\n",
    "# faccio tensori che contengono peptidi della stessa dimensione\n",
    "# poi come metto i risultati in ordine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group tensors of same size in a single tensor, and put them in a dict\n",
    "def cat_tensor_for_size(tensor_dict):\n",
    "    \n",
    "    container_tensor = {}\n",
    "    for i in tensor_dict:\n",
    "        actual_tensor_len = len(tensor_dict[i])\n",
    "\n",
    "        if actual_tensor_len in container_tensor.keys():\n",
    "            container_tensor[actual_tensor_len] = torch.cat((container_tensor[actual_tensor_len],tensor_dict[i].unsqueeze(0)))\n",
    "\n",
    "        else:\n",
    "            container_tensor[actual_tensor_len] = tensor_dict[i].unsqueeze(0)\n",
    "\n",
    "    return container_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_dict = t_test.get_frame(0)\n",
    "tensor = morphoscanner.backend.distance_tensor.get_coordinate_tensor_from_dict_multi(test_dict)\n",
    "tens_group = cat_tensor_for_size(tensor)\n",
    "tens_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "distance = {}\n",
    "for group1 in tens_group:\n",
    "    distance[group1] = {}\n",
    "    for index, tens in enumerate(tens_group[group1]):\n",
    "        distance[group1][index] = {}\n",
    "        for group2 in tens_group:\n",
    "\n",
    "            dist = fast_cdist(tens_group[group2], tens)\n",
    "            distance[group1][index][group2] = dist\n",
    "end = timer()\n",
    "print(end -start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#frame_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_tensor = distance_tensor.get_coordinate_tensor_from_dict_multi(frame_dict)\n",
    "frame_tensor = distance_tensor.cat_tensor_for_size(frame_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "distance = {}\n",
    "for group1 in frame_tensor:\n",
    "    distance[group1] = {}\n",
    "    for index, tens in enumerate(frame_tensor[group1]):\n",
    "        distance[group1][index] = {}\n",
    "        for group2 in frame_tensor:\n",
    "\n",
    "            dist = fast_cdist(frame_tensor[group2], tens)\n",
    "            distance[group1][index][group2] = dist\n",
    "end = timer()\n",
    "print(end -start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = distance_tensor.get_coordinate_tensor_from_dict_single(t_test.frames[0].peptides[0].coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do this for each peptide to gather distances\n",
    "# this is not optimized but still faster than before\n",
    "def distance():\n",
    "    \n",
    "    dists = {}\n",
    "    for tens in frame_tensor:\n",
    "    \n",
    "        dists[tens] = fast_cdist(frame_tensor[tens], tt.unsqueeze(0))\n",
    "    \n",
    "    return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right = morphoscanner.backend.distance.compute_distance_map(frame_dict, 0, 25)\n",
    "at = distance_tensor.get_coordinate_tensor_from_dict_single(t_test.frames[0].peptides[25].coordinates)\n",
    "bt = distance_tensor.get_coordinate_tensor_from_dict_single(t_test.frames[0].peptides[0].coordinates)\n",
    "abs_dist = abs(right.T - approx.numpy())\n",
    "approx = distance_tensor.fast_cdist(at, bt)\n",
    "np.mean(abs_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_trajectory_frame_v2(universe, frame, select=['aminoacids']):\n",
    "    # move to frame\n",
    "    universe.trajectory[frame]\n",
    "    \n",
    "    temporary_list = []\n",
    "    pep_index = 0\n",
    "\n",
    "    coordinate_dict = {}\n",
    "    residues_dict = {}\n",
    "    atom_number_dict = {}\n",
    "\n",
    "    object_dict = {} # new\n",
    "\n",
    "    #select = ['peptide']\n",
    "\n",
    "    accepted_costituents = []\n",
    "\n",
    "    for element in select:\n",
    "        if element in morphoscanner.molnames.costituents.keys():\n",
    "            try:\n",
    "                accepted_costituents.extend(morphoscanner.molnames.costituents.get(element))\n",
    "\n",
    "            except:\n",
    "                accepted_costituents.append(morphoscanner.molnames.costituents.get(element))\n",
    "        else:\n",
    "            raise ValueError('%s is not a valid key for morphoscanner.molnames.costituents.\\n' % str(select))\n",
    "\n",
    "\n",
    "    for res in universe.residues:\n",
    "        if res.resname in accepted_costituents:\n",
    "\n",
    "            res_num = res.resnum - 1 # -1 becaus id start from 1, but indexing start from 0\n",
    "\n",
    "            atom = res.atoms[0] # always take the first atom of the residues (backbone)\n",
    "\n",
    "            atom_index = atom.id - 1 # -1 becaus id start from 1, but indexing start from 0\n",
    "\n",
    "            atom_coordinate = atom.position\n",
    "\n",
    "            resname = atom.resname\n",
    "\n",
    "\n",
    "            if len(temporary_list) == 0:\n",
    "\n",
    "                temporary_list.append(res_num)\n",
    "\n",
    "                object_dict[pep_index] = {}\n",
    "\n",
    "                coordinate_dict[pep_index] = {}\n",
    "                residues_dict[pep_index] = {}\n",
    "                atom_number_dict[pep_index] = {}\n",
    "\n",
    "\n",
    "            else:\n",
    "                if temporary_list[-1] > res_num:\n",
    "\n",
    "                    object_dict[pep_index] = morphoscanner.trj_object.trj_objects.single_peptide(residues_dict[pep_index], atom_number_dict[pep_index], coordinate_dict[pep_index])\n",
    "\n",
    "                    pep_index += 1\n",
    "\n",
    "                    temporary_list = []\n",
    "                    temporary_list.append(res_num)\n",
    "\n",
    "                    object_dict[pep_index] = {}\n",
    "\n",
    "                    coordinate_dict[pep_index] = {}\n",
    "                    residues_dict[pep_index] = {}\n",
    "                    atom_number_dict[pep_index] = {}\n",
    "\n",
    "\n",
    "                else:\n",
    "                    temporary_list.append(res_num)\n",
    "\n",
    "            coordinate_dict[pep_index][res_num] = atom_coordinate\n",
    "            residues_dict[pep_index][res_num] = resname\n",
    "            atom_number_dict[pep_index][res_num] = atom_index\n",
    "\n",
    "    object_dict[pep_index] = morphoscanner.trj_object.trj_objects.single_peptide(residues_dict[pep_index], atom_number_dict[pep_index], coordinate_dict[pep_index])\n",
    "    \n",
    "    return object_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### USING THIS ONE\n",
    "# to complete\n",
    "# i want to get frame and the tensor inside frame object\n",
    "# then continue analysis\n",
    "\n",
    "class frames():\n",
    "    \n",
    "    def __init__(self, frame):\n",
    "        \n",
    "        self.frame = frame\n",
    "        \n",
    "        pass\n",
    "        \n",
    "\n",
    "    def get_frame(self):\n",
    "\n",
    "        a_frame = {}\n",
    "        for pep in super().frames[self.frame].peptides:\n",
    "            a_frame[pep] = super().frames[self.frame].peptides[pep].coordinates    \n",
    "    \n",
    "        pass\n",
    "    \n",
    "# save results in this\n",
    "\n",
    "class results():\n",
    "    \n",
    "    pass\n",
    "    \n",
    "        \n",
    "\n",
    "# Classes in dev\n",
    "\n",
    "class single_peptide():\n",
    "    \n",
    "    ''' Class that define peptides\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, sequence, atom_n, coordinates):\n",
    "        \n",
    "        self.sequence = sequence\n",
    "        self.atom_numbers = atom_n\n",
    "        self.coordinates = coordinates\n",
    "        \n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_dict = {}\n",
    "for index, i in enumerate(a):\n",
    "    #print(object_dict[i].coordinates)\n",
    "    c_dict[index] = a[i].coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot.plot_peptide_list(c_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return string in a string with numbers\n",
    "def return_if_string(string):\n",
    "    digits = []\n",
    "    for i in string:\n",
    "        if not i.isdigit():\n",
    "            digits.append(i)\n",
    "\n",
    "    string = ''.join(digits)\n",
    "\n",
    "    return string\n",
    "\n",
    "# return numbers in a string with numbers\n",
    "def return_if_digit(string):\n",
    "    digits = []\n",
    "    for i in string:\n",
    "        if i.isdigit():\n",
    "            digits.append(i)\n",
    "\n",
    "    string = ''.join(digits)\n",
    "\n",
    "    return string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dispatch_data(atom):\n",
    "    \n",
    "    if type(atom) != list:\n",
    "        \n",
    "        raise ValueError(\"%s is not a list, it is of type %s...\\n \" % (str(atom), type(atom)))\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        atom_number = check_int_and_return(atom[0])\n",
    "        \n",
    "        residue_number = check_int_and_return(atom[1])\n",
    "        \n",
    "        residue_name = atom[2]\n",
    "        \n",
    "        x = float(atom[3])\n",
    "        \n",
    "        y = float(atom[4])\n",
    "        \n",
    "        z = float(atom[5])\n",
    "        \n",
    "    \n",
    "    \n",
    "        return atom_number, residue_number, residue_name, x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from morphoscanner import backend, data_acquisition, trj_object\n",
    "from morphoscanner.backend import distance_tensor, pattern_recognition, graph\n",
    "\n",
    "from morphoscanner.backend.check_val import isInt\n",
    "import sys\n",
    "\n",
    "\n",
    "class trajectory:\n",
    "    '''Class to operate on trajectory files.\n",
    "    It makes an object that contain the trajectory of the simulation.\n",
    "    From this object is possible to conduct analysis'''\n",
    "\n",
    "    def __init__(self, trj_gro, trj_xtc, select = None):\n",
    "        \n",
    "        self.trj_gro = trj_gro\n",
    "        self.trj_xtc = trj_xtc\n",
    "        self.universe = backend.topology.make_universe(self.trj_gro, self.trj_xtc)\n",
    "        self.number_of_frames = len(self.universe.trajectory)\n",
    "        \n",
    "        if select == None:\n",
    "            select = ['aminoacids']\n",
    "            \n",
    "        self.select = select\n",
    "       \n",
    "        self.peptide_length_list = backend.topology.get_peptide_length_list(self.trj_gro, self.select)\n",
    "        \n",
    "        self.len_dict = backend.topology.get_peptide_length_dict(self.peptide_length_list)\n",
    "        \n",
    "        print('In your trajectory there are %d frames.\\n' % self.number_of_frames)\n",
    "\n",
    "        morphoscanner.backend.topology.print_peptides_length(self.len_dict)\n",
    "        \n",
    "        return            \n",
    "        \n",
    "    def split(self, to_split: list, split_size: list):\n",
    "        '''Manually split peptide_length_list in case of seeds.\n",
    "        \n",
    "        Input:\n",
    "            to_split: list\n",
    "                list of int or ints.\n",
    "                Each int refers to the length of a peptides seed\n",
    "                from self.len_dict.keys() that you want to split in single peptide.\n",
    "                For example if in len dict there are seeds of length 96 that you want to split,\n",
    "                to_split = [96]\n",
    "                \n",
    "            split_size: list\n",
    "                list of int or ints.\n",
    "                This is the size in which you want to split your to_split seeds.\n",
    "                For example if you want to split your seeds of length 96 in peptides of length 12,\n",
    "                split_size = [12]\n",
    "                \n",
    "        Output:\n",
    "            Change the original self.peptide_length_list with a new list of splitted peptides.\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        splitting_dict = data_acquisition.script_inputs.get_splitting_dict(to_split, split_size)\n",
    "        self.peptide_length_list = data_acquisition.script_inputs.get_new_peptides_length(self.peptide_length_list, splitting_dict)\n",
    "        print('Splitting done.\\n')\n",
    "        print('\"peptide_length_list\" attribute has been updated with the new length.')\n",
    "        \n",
    "        return    \n",
    "    \n",
    "    def explore(self, frame=0): # you can change the frame number if you want to manually explore other frames\n",
    "    \n",
    "        self.frames = {}\n",
    "        self.frames[frame] = frames(frame)\n",
    "        self.frames[frame].peptides = morphoscanner.backend.topology.get_data_from_trajectory_frame_v2(universe=self.universe, frame=frame, select=self.select)\n",
    "        print('Exploration of frame %d done.\\n' % frame)\n",
    "\n",
    "        return    \n",
    "    \n",
    "    def compose_database(self, sampling_interval=1):\n",
    "        \n",
    "        steps = [s for s in range(self.number_of_frames) if (s % sampling_interval)==0 and (s != 0)]\n",
    "        for step in tqdm.tqdm(steps):\n",
    "            self.universe.trajectory[step]\n",
    "            self.frames[step] = frames(step)\n",
    "            self.frames[step].peptides = {}\n",
    "            for pep in self.frames[0].peptides:\n",
    "                c_list = {}\n",
    "\n",
    "                for idx, i in enumerate(self.frames[0].peptides[pep].atom_numbers.values()):\n",
    "                    p = self.universe.atoms[i].position\n",
    "                    c_list[idx] = p\n",
    "\n",
    "                #self.frames[step].peptides[pep] = single_peptide(self.frames[0].peptides[pep].sequence,self.frames[0].peptides[pep].atom_numbers,c_list)\n",
    "                self.frames[step].peptides[pep] = single_peptide(self.frames[0].peptides[pep].sequence, self.frames[0].peptides[pep].atom_numbers,c_list)\n",
    "        return\n",
    "        \n",
    "    def get_frame(self, frame):\n",
    "        \n",
    "        a_frame = {}\n",
    "\n",
    "        for pep in self.frames[frame].peptides:\n",
    "            a_frame[pep] = self.frames[frame].peptides[pep].coordinates\n",
    "\n",
    "        return a_frame\n",
    "    \n",
    "    def get_peptide(self, peptide):\n",
    "    \n",
    "        a_peptide = {}\n",
    "        for frame in self.frames:\n",
    "            \n",
    "            a_peptide[frame] = self.frames[frame].peptides[peptide].coordinates\n",
    "            \n",
    "        return a_peptide\n",
    "    \n",
    "    \n",
    "    # add something to ask for threshold in main.py\n",
    "    def analysis(self, frame, threshold_multiplier=1.45):\n",
    "        # check if threshold is given\n",
    "        try:\n",
    "            threshold = self.contact_threshold\n",
    "        except:\n",
    "            dic_0 = self.get_frame(0)\n",
    "            frame_distance_0 = compute_distance_and_contact_maps(dic_0, threshold=0, contacts_calculation=False)\n",
    "            threshold = get_threshold_distance(frame_distance_0) * threshold_multiplier\n",
    "            self.contact_threshold = threshold\n",
    "            print(\"Two nearby atoms of different peptides are contacting if the distance is lower than: %s Angstrom\" % str(self.contact_threshold))\n",
    "    \n",
    "        #frame = frame\n",
    "        print('Analyzing frame n° ', frame)\n",
    "    \n",
    "        frame_dict = self.get_frame(frame)\n",
    "    \n",
    "        #frame_tensor = distance_tensor.get_coordinate_tensor_from_dict(frame_dict)\n",
    "    \n",
    "        start_dist = timer()\n",
    "        #frame_distance_maps = distance_tensor.compute_euclidean_norm_torch(frame_tensor)\n",
    "        frame_distance, frame_contact = compute_distance_and_contact_maps(frame_dict, threshold=threshold)\n",
    "        end_dist = timer()\n",
    "        print('Time to compute distance is: ', (end_dist - start_dist))\n",
    "    \n",
    "        #start_contc = timer()\n",
    "        #frame_contact = pattern_recognition.compute_contact_maps_as_array(frame_distance_maps)\n",
    "        #end_contc = timer()\n",
    "        #print('Time to compute contact is: ', (end_contc - start_contc))\n",
    "    \n",
    "        start_den = timer()\n",
    "        #frame_denoised, df = pattern_recognition.denoise_contact_maps(frame_contact)\n",
    "        frame_denoised, df = denoise_contact_maps_torch(frame_contact)\n",
    "\n",
    "        end_den = timer()\n",
    "        print('Time to denoise: ', (end_den-start_den))\n",
    "    \n",
    "        frame_graph_full = graph.graph_v1(frame_denoised, df)\n",
    "        \n",
    "        subgraphs = graph.find_subgraph(frame_graph_full)  \n",
    "        \n",
    "        self.frames[frame].results = results()\n",
    "        self.frames[frame].results.distance_maps = frame_distance\n",
    "        self.frames[frame].results.contact_maps = frame_contact\n",
    "        self.frames[frame].results.cross_correlation = df\n",
    "        self.frames[frame].results.graph = frame_graph_full\n",
    "        self.frames[frame].results.subgraphs = subgraphs\n",
    "        print('Finished analysis of frame n° %d' % frame)\n",
    "        \n",
    "        return\n",
    "    \n",
    "        \n",
    "    def analyze_inLoop(self, threshold=None, threshold_multiplier=1.45):\n",
    "        \n",
    "        if threshold != None:\n",
    "            self.contact_threshold=threshold\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        print('processing started...')\n",
    "        start = timer()\n",
    "        for frame in self.frames:\n",
    "            start_an = timer()\n",
    "            self.analysis(frame, threshold_multiplier=threshold_multiplier)\n",
    "            end_an = timer()\n",
    "            text = 'Time needed to analyze frame %d was %f seconds' % (frame, (end_an-start_an))\n",
    "            print(text)\n",
    "\n",
    "        end = timer()\n",
    "\n",
    "\n",
    "        print('Total time to analyze dataset was %f seconds' % (end -start))\n",
    "        return\n",
    "    \n",
    "    \n",
    "    ### THESE HAVE BEEN PORTED FROM OLD TRAJECTORY TO STREAMLINE ANALYSIS OF GLICOSILATED PEPTIDES!\n",
    "    ###\n",
    "    \n",
    "    \n",
    "    def get_sense(self):\n",
    "\n",
    "        ''' Analyze self.frames to retrieve the number of contact \n",
    "            per sense (\"parallel\" and \"antiparallel\")\n",
    "        '''\n",
    "\n",
    "        # instantiate main dict\n",
    "        sense_dict = {}\n",
    "\n",
    "        # loop trough frames\n",
    "        for frame in self.frames:\n",
    "\n",
    "            group = self.frames[frame].results.cross_correlation.groupby('sense').groups\n",
    "\n",
    "            # check for antiparallel key in the frame_data\n",
    "            if 'antiparallel' in group:\n",
    "\n",
    "                # get number of antiparallel contacts\n",
    "                antiparallel = len(group['antiparallel'])\n",
    "\n",
    "            else:\n",
    "                antiparallel = 0\n",
    "\n",
    "            # check for parallel key in the frame_data\n",
    "            if 'parallel' in group:\n",
    "\n",
    "                # get number of parallel contacts\n",
    "                parallel = len(group['parallel'])\n",
    "\n",
    "            else:\n",
    "                parallel = 0\n",
    "\n",
    "            # add frame data to main dict\n",
    "            sense_dict[frame] = {  'parallel' : parallel,\n",
    "                               'antiparallel' : antiparallel}\n",
    "\n",
    "        # at the end convert dict to pandas.DataFrame\n",
    "        self.sense_df = pd.DataFrame.from_dict(sense_dict, orient='index')\n",
    "\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def subgraph_length_peptide(self):\n",
    "        '''Get information about the size of the aggregates in the trajectory\n",
    "        Argument: aggregate\n",
    "        return: dict, keys = frame number,\n",
    "                      value = a sorted list (big to small) of the aggregate size in that frame\n",
    "        '''\n",
    "\n",
    "        if len(self.frames) > 0:\n",
    "\n",
    "            self.subgraph_size_peptide = {}\n",
    "\n",
    "            for key in self.frames.keys():\n",
    "\n",
    "                subgraph_dict = {}\n",
    "\n",
    "                subgraph_dict[key] = morphoscanner.backend.graph.find_subgraph(self.frames[key].results.graph)\n",
    "\n",
    "                len_list = []\n",
    "\n",
    "                for i in subgraph_dict[key]:\n",
    "\n",
    "                    len_list.append(len(i))\n",
    "\n",
    "                len_list.sort(reverse=True)\n",
    "\n",
    "                self.subgraph_size_peptide[key] = [len_list]\n",
    "\n",
    "        self.subgraph_len_pep_df = pd.DataFrame.from_dict(self.subgraph_size_peptide, orient='index', columns=['n° of peptides in macroaggregates'])\n",
    "\n",
    "        #else:\n",
    "         #   print('You have to analyze one or more frame before analyze the results.')\n",
    "         #   print('Use \"Analyze\" or \"AnalyzeInLoop\" on the dataset first!')\n",
    "\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def macroaggregate_sense_data(self):\n",
    "\n",
    "        macroaggregate_sense_dict = {}\n",
    "\n",
    "        for frame in self.frames:\n",
    "            graph = self.frames[frame].results.graph\n",
    "            subs = self.frames[frame].results.subgraphs\n",
    "            #senses = contact_sense_in_subgraph(graph, subs)\n",
    "            #sense_counter = count_sense_in_subgraph(senses)\n",
    "            sense_counter = morphoscanner.backend.graph.sense_in_subgraph(graph, subs)\n",
    "            macroaggregate_sense_dict[frame] = sense_counter\n",
    "\n",
    "        self.macroaggregate_df = pd.DataFrame.from_dict(macroaggregate_sense_dict, orient='index')\n",
    "\n",
    "        return\n",
    "    \n",
    "    \n",
    "    \n",
    "    def number_of_macroaggregate_per_frame(self):\n",
    "        number_of_peptide = {}\n",
    "        for i in self.subgraph_size_peptide:\n",
    "            number_of_peptide[i] = len(self.subgraph_size_peptide[i][0])\n",
    "\n",
    "        self.number_of_peptide_df = pd.DataFrame.from_dict(number_of_peptide, orient='index', columns=['n° of macroaggreates'])\n",
    "\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def shift_profile(self):\n",
    "    \n",
    "        shift_profile = {}\n",
    "        for frame in self.frames:\n",
    "            shift_profile[frame] = {} \n",
    "            for shift_value in self.frames[frame].results.cross_correlation['shift']:\n",
    "                try:\n",
    "                    shift_profile[frame][shift_value] += 1\n",
    "                except:\n",
    "                    shift_profile[frame][shift_value] = 1\n",
    "\n",
    "            f = {k[0]:k[1] for k in sorted(shift_profile[frame].items())}\n",
    "            self.frames[frame].results.shift_profile = f\n",
    "        return\n",
    "\n",
    "\n",
    "    def get_data(self):\n",
    "        self.get_sense()\n",
    "        self.subgraph_length_peptide()\n",
    "        self.macroaggregate_sense_data()\n",
    "        self.number_of_macroaggregate_per_frame()\n",
    "        self.shift_profile()\n",
    "        return\n",
    "    \n",
    "        \n",
    "    def get_database(self):\n",
    "        \n",
    "        self.database = pd.concat((self.subgraph_len_pep_df, self.sense_df, self.number_of_peptide_df, self.macroaggregate_df), axis=1)\n",
    "\n",
    "        return\n",
    "    \n",
    "    \n",
    "    ######################\n",
    "    #############################\n",
    "    #####################\n",
    "    \n",
    "    \n",
    "    def plot_contacts(self):\n",
    "        index = self.database.index\n",
    "        contact = [i+e for i, e in zip(self.database['parallel'], self.database['antiparallel'])]\n",
    "        antiparallel = self.database['antiparallel']\n",
    "    \n",
    "        antip_total_ratio = [anti/cont if cont != 0 else 0 for anti, cont in zip(antiparallel, contact)]\n",
    "        tss = [self.universe.trajectory[i].time for ts in self.universe.trajectory for i in index]\n",
    "        \n",
    "        plt.plot(tss, antip_total_ratio, 'bo')\n",
    "        #plt.xticks([0,250000,500000,750000,1000000],[0,250,500,750,1000])\n",
    "        #plt.xlabel('Time (ps)')\n",
    "        #plt.ylabel('Antiparallel / Total contacts')\n",
    "        plt.xlabel('Time (ns)')\n",
    "        plt.ylabel('β-Sheet Organizational Index')\n",
    "    \n",
    "        return\n",
    "    \n",
    "    \n",
    "    def plot_peptides_in_beta(self):\n",
    "        index = self.database.index\n",
    "        tss = [self.universe.trajectory[i].time for ts in self.universe.trajectory for i in index]\n",
    "        beta = [sum(i) for i in self.database['n° of peptides in macroaggregates']]\n",
    "        plt.plot(tss,beta,'bo')\n",
    "        #plt.xticks([0,250000,500000,750000,1000000],[0,250,500,750,1000])\n",
    "        plt.xlabel('Time (ns)')\n",
    "        plt.ylabel('Peptides in β-sheet')\n",
    "    \n",
    "        return \n",
    "\n",
    "    \n",
    "    def plot_aggregates(self):\n",
    "        index = self.database.index\n",
    "        tss = [self.universe.trajectory[i].time for ts in self.universe.trajectory for i in index]\n",
    "        aggregates = self.database['n° of macroaggreates']\n",
    "        plt.plot(tss, aggregates,'bo')\n",
    "        #plt.xlabel('Time (ps')\n",
    "        #plt.xticks([0,250000,500000,750000,1000000],[0,250,500,750,1000])\n",
    "        plt.xlabel('Time (ns)')\n",
    "        plt.ylabel('N° of macroaggregates')\n",
    "\n",
    "        return\n",
    "    \n",
    "    def plot_shift(self, frame=None):\n",
    "        f = self.frames[frame].results.shift_profile\n",
    "        x = [val for val in f.keys()]\n",
    "        y = [k for k in f.values()]\n",
    "        plt.plot(x, y)\n",
    "        plt.xlabel('Shift value')\n",
    "        plt.ylabel('Number of contacts')\n",
    "        plt.show() \n",
    "        return\n",
    "\n",
    "\n",
    "    def get_subgraphs_sense(self, frame):\n",
    "        '''Retrive information about contact sense of each aggregate\n",
    "        found in self.frames[frame]['subgraphs_full']\n",
    "        Parameters\n",
    "        ----------\n",
    "        frame : int\n",
    "            The frame of which you want to get contact sense informations.\n",
    "        Returns\n",
    "        -------\n",
    "        sense_dict : dict\n",
    "            A dict containing the informations about contacts, in the form:\n",
    "                {'parallel' : int,\n",
    "                 'antiparallel' : int,\n",
    "                 'value' : str}\n",
    "            The key 'value' contains the sense of the predominant contact sense,\n",
    "            'parallel' or 'antiparallale',\n",
    "            or the str 'equal' if both sense have the same number of contacts.\n",
    "        '''\n",
    "        \n",
    "        # check if requested frame have been parsed\n",
    "        if frame not in self.frames:\n",
    "            print('Frame %d is not in the sampled frames\\n' % frame)\n",
    "        else:\n",
    "            # check if in the frame there are aggregate\n",
    "            if len(self.frames[frame].results.subgraphs) < 1:\n",
    "                print('There are no aggregate in frame %d.\\n' % frame)\n",
    "            else:\n",
    "                # if checks are passed\n",
    "                # create empty dict\n",
    "                sense_dict = {}\n",
    "                \n",
    "                # iterate subgraphs\n",
    "                for index_sub, subgraph in enumerate(self.frames[frame].results.subgraphs):\n",
    "                    \n",
    "                    # create a new dict for each aggregate, to store contact sense information\n",
    "                    sense_dict[index_sub] = {'parallel' : 0,\n",
    "                                             'antiparallel' : 0,\n",
    "                                             'value' : 0   }\n",
    "                    # get information about contacts from database\n",
    "                    #  use only peptide1 column to gather contacts one time only \n",
    "                    for index_contact, contact in enumerate(self.frames[frame].results.cross_correlation.peptide1):\n",
    "                        if contact in subgraph:\n",
    "                            sense = (self.frames[frame].results.cross_correlation.iloc[index_contact].sense)\n",
    "                            # add 1 to the right sense counter in the sense_dict\n",
    "                            sense_dict[index_sub][sense] += 1\n",
    "                    # check if contacts number is equal in both senses\n",
    "                    if sense_dict[index_sub]['parallel'] == sense_dict[index_sub]['antiparallel']:\n",
    "                        sense_dict[index_sub]['value'] = 'equal'\n",
    "                    else:\n",
    "                        # if contacts are not equal, get the predominant contact sense\n",
    "                        sense_dict[index_sub]['value'] = max(sense_dict[index_sub], key=sense_dict[index_sub].get)\n",
    "    \n",
    "                return sense_dict\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    def plot_frame_aggregate(self, frame: int):\n",
    "        '''Plot the frame with color code that identify the\n",
    "        sense of the majority of contacts in an aggregate.\n",
    "        Grey: no contact,\n",
    "        Green: majority of parallel contacts,\n",
    "        Blue: majority of antparallel contacts,\n",
    "        Yellow: equal number of parallel and antiparallel contacts\n",
    "        \n",
    "        The plot can be made interactive using jupyter-notebook,\n",
    "        with:\n",
    "            %matplotlib notebook\n",
    "        Parameters\n",
    "        ----------\n",
    "        frame : int\n",
    "            The frame that you want to plot\n",
    "        Returns\n",
    "        -------\n",
    "        plot\n",
    "            Return a matplotlib.pyplot 3d scatter plot.\n",
    "        '''\n",
    "        \n",
    "        # get predominant contact sense for each aggregate\n",
    "        sense_dict = self.get_subgraphs_sense(frame)\n",
    "        # get subgraphs\n",
    "        subgraphs = self.frames[frame].results.subgraphs\n",
    "        # get coordinate dict\n",
    "        coordinate_dict = self.get_frame(frame)\n",
    "        # make a flat (1D) list of peptide in the aggregates\n",
    "        flat_subgraphs = [pep for group in subgraphs for pep in group]\n",
    "        # create a color dictionary with each sense corresponding to a color\n",
    "        colors = {'parallel' : 'limegreen',\n",
    "                  'antiparallel' : 'b',\n",
    "                  'equal' : 'y',\n",
    "                  'no' : 'gray'}    \n",
    "        \n",
    "        # instantiate empty dict to plot aggregates\n",
    "        x = {}\n",
    "        y = {}\n",
    "        z = {}\n",
    "        # iterate through aggregates\n",
    "        for index_sub, subgraph in enumerate(subgraphs):\n",
    "            # create a list to gather coordinate of each aggregate's atom\n",
    "            x[index_sub] = []\n",
    "            y[index_sub] = []\n",
    "            z[index_sub] = []\n",
    "            # for each peptide in the aggregate\n",
    "            for peptide in subgraph:\n",
    "                # for each atom of the peptide\n",
    "                for atom in coordinate_dict[peptide]:\n",
    "                    # get x, y and z coordinates and save it in the correct list\n",
    "                    x[index_sub].append(coordinate_dict[peptide][atom][0])\n",
    "                    y[index_sub].append(coordinate_dict[peptide][atom][1])\n",
    "                    z[index_sub].append(coordinate_dict[peptide][atom][2])\n",
    "        \n",
    "        # instantiate lists for non contacting peptides\n",
    "        x_not = []\n",
    "        y_not = []\n",
    "        z_not = []\n",
    "        # get coordinate of non contacting peptides\n",
    "        for pep in coordinate_dict:\n",
    "            if pep not in flat_subgraphs:\n",
    "                for atom in coordinate_dict[pep]:\n",
    "                    x_not.append(coordinate_dict[pep][atom][0])\n",
    "                    y_not.append(coordinate_dict[pep][atom][1])\n",
    "                    z_not.append(coordinate_dict[pep][atom][2])\n",
    "        \n",
    "        fig = plt.figure()\n",
    "    \n",
    "        ax = plt.axes(projection='3d')\n",
    "    \n",
    "        # scatter aggregates atoms\n",
    "        for group in x:\n",
    "    \n",
    "            ax.scatter3D(x[group],y[group],z[group], color=colors[sense_dict[group]['value']])\n",
    "        \n",
    "        # scatter non contacting peptides atoms\n",
    "        ax.scatter3D(x_not, y_not, z_not, color=colors['no'])\n",
    "        \n",
    "        return plt.show()\n",
    "    \n",
    "    \n",
    "    def plot_graph(self, frame: int):\n",
    "        '''Plot the frame graph, with visual information about\n",
    "            number of contacts between peptides and sense of the contacts.\n",
    "            \n",
    "            Edge thickness scale with the number of contacts between two\n",
    "            contacting peptides.\n",
    "            \n",
    "            Green edges are parallel contacts.\n",
    "            Blue edges are antiparallel contacts.\n",
    "        Parameters\n",
    "        ----------\n",
    "        frame : int\n",
    "            The frame of which you want to plot the graph.\n",
    "        Returns\n",
    "        -------\n",
    "        plot\n",
    "            matplotlib.pyplot 3d scatter5 plot.\n",
    "        '''\n",
    "    \n",
    "        graph = self.frames[frame].results.graph\n",
    "        \n",
    "        # Used to plot\n",
    "        edges = graph.edges()\n",
    "        colors = [graph[u][v][0]['color'] for u,v in edges]\n",
    "        weights = [graph[u][v][0]['weight'] for u,v in edges]\n",
    "        \n",
    "        # output a plot\n",
    "        return nx.draw_networkx(graph, edges=edges, edge_color=colors, width=weights)\n",
    "\n",
    "    \n",
    "# Use the .gro file but do not select by using the BB nomenclature\n",
    "# Use instead the aminoacids names and numbers on the first element\n",
    "# and compare it with the data inside molnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from morphoscanner import backend\n",
    "universe_glico = trajectory(glico_6bis_gro, glico_6bis_trr, select=['aminoacids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe_glico.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe_glico.compose_database(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe_glico.analyze_inLoop(threshold_multiplier=1.45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe_glico.get_sense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe_glico.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe_glico.get_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe_glico.database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe_glico.plot_peptides_in_beta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "universe_glico.plot_aggregates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe_glico.plot_contacts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe_glico.plot_frame_aggregate(250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe_glico.plot_graph(250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = universe_glico "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe_glico.frames[250].results.cross_correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe_glico.plot_shift(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe_glico.frames[250].results.shift_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aminoacids_name = '/home/lillo/Documenti/Tesi_CNTE/Martini_ff/Martini_itp/from_fede_cluster/martini_v2.2_aminoacids.itp'\n",
    "solvents_name = '/home/lillo/Documenti/Tesi_CNTE/Martini_ff/Martini_itp/from_fede_cluster/martini_v2.0_solvents.itp'\n",
    "ions_name = '/home/lillo/Documenti/Tesi_CNTE/Martini_ff/Martini_itp/from_fede_cluster/martini_v2.0_ions.itp'\n",
    "water_name = '/home/lillo/Documenti/Tesi_CNTE/Martini_ff/Martini_itp/from_fede_cluster/martini_v2.2.itp'\n",
    "sugars_name = '/home/lillo/Documenti/Tesi_CNTE/Martini_ff/Martini_itp/05-2020/martini_v2.0_sugars.itp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_molnames(path):\n",
    "    name_list = []\n",
    "    flag = False\n",
    "    with open(path) as martini_amino:\n",
    "        for line in martini_amino:\n",
    "            if flag:\n",
    "                name_list.append(line.split()[0])\n",
    "                flag = False\n",
    "\n",
    "            if len(line.split()) > 1:\n",
    "                actual_line = line.split()\n",
    "\n",
    "                actual_line = [i.split(';') for i in actual_line]\n",
    "                if 'molname' in actual_line[1] or 'molname' in actual_line[0]:\n",
    "                    flag = True\n",
    "    return name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni = universe.select_atoms('not name W WF CL- NA+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = 250\n",
    "\n",
    "frame_dict = universe_glico.get_frame(frame)\n",
    "\n",
    "frame_tensor = distance_tensor.get_coordinate_tensor_from_dict(frame_dict)\n",
    "\n",
    "start_dist = timer()\n",
    "frame_distance_maps = distance_tensor.compute_euclidean_norm_torch(frame_tensor)\n",
    "end_dist = timer()\n",
    "print('Time to compute distance is: ', (end_dist - start_dist))\n",
    "\n",
    "start_contc = timer()\n",
    "frame_contact = pattern_recognition.compute_contact_maps_as_array(frame_distance_maps)\n",
    "end_contc = timer()\n",
    "print('Time to compute contact is: ', (end_contc - start_contc))\n",
    "\n",
    "start_den = timer()\n",
    "frame_denoised, df = pattern_recognition.denoise_contact_maps(frame_contact)\n",
    "end_den = timer()\n",
    "print('Time to denoise: ', (end_den-start_den))\n",
    "\n",
    "frame_graph_full = graph.graph_v1(frame_denoised, df)\n",
    "\n",
    "subgraphs = graph.find_subgraph(frame_graph_full)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frame_distance_maps[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot.plot_peptide_list(universe_glico.get_frame(250), [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frame_contact[0][25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frame_denoised[0][25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "universe_glico.frames[250].results.cross_correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multidim = trajectory(trj_gro, trj_xtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multidim.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_dict = multidim.get_frame(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_tens = morphoscanner.backend.distance_tensor.get_coordinate_tensor_from_dict_multi(m_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_tensor, peptide_order = morphoscanner.backend.distance_tensor.cat_tensor_for_size(m_tens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_tens = morphoscanner.backend.distance_tensor.cat_tensor_for_size(m_tens)\n",
    "for tensor in m_tens:\n",
    "    for tensor_group in group_tens:\n",
    "        distance = morphoscanner.backend.distance_tensor.fast_cdist(group_tens[tensor_group], m_tens[tensor])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot.plot_peptide_list(m_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(distance_0_all[0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ho un dict con dentro un dict per ogni peptide in cui key:val is res_number:[x,y,z].\n",
    "# faccio un dict dove {key:value} è {peptide_index:tensor of shape n x 3}, dove n è il numero di residui del peptide.\n",
    "# raggruppo in un dict per dimensione, dove {key:val} is {numero di residui : tensore of shape m x n x 3\n",
    "# dove 'm' è il numero di peptidi, 'n' è il numero di residui nei peptidi, 3 è [x,y,z].\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group tensors of same size in a single tensor, and put them in a dict\n",
    "def cat_tensor_for_size(tensor_dict):\n",
    "    '''Group 2D tensors of same shape in a 3D tensor,\n",
    "        and then put in a dict.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tensor_dict : dict\n",
    "        output of get_coordinate_tensor_from_dict_multi\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    container_tensor : dict\n",
    "        a dict for a key for each tensor size, of which value is a 3D tensor\n",
    "        that contains all the 2D tensor of same shape.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    container_tensor = {}\n",
    "    peptide_index_in_tensor = {}\n",
    "    \n",
    "    for i in tensor_dict:\n",
    "        actual_tensor_len = len(tensor_dict[i])\n",
    "\n",
    "\n",
    "        if actual_tensor_len in container_tensor.keys():\n",
    "            container_tensor[actual_tensor_len] = torch.cat((container_tensor[actual_tensor_len],tensor_dict[i].unsqueeze(0)))\n",
    "            peptide_index_in_tensor[actual_tensor_len][len(peptide_index_in_tensor[actual_tensor_len])] = i\n",
    "        else:\n",
    "            container_tensor[actual_tensor_len] = tensor_dict[i].unsqueeze(0)\n",
    "            peptide_index_in_tensor[actual_tensor_len] = {}\n",
    "            peptide_index_in_tensor[actual_tensor_len][len(peptide_index_in_tensor[actual_tensor_len])] = i\n",
    "\n",
    "\n",
    "    return container_tensor, peptide_index_in_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_tens, tens_ord = cat_tensor_for_size(m_tens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#working\n",
    "def compute_distance_between_each_peptide(coordinate_dict):\n",
    "    # instantiate tensor\n",
    "    coordinate_tensor = morphoscanner.backend.distance_tensor.get_coordinate_tensor_from_dict_multi(coordinate_dict)\n",
    "    # group tensor for size\n",
    "    group_tensor, order_tensor = morphoscanner.backend.distance_tensor.cat_tensor_for_size(coordinate_tensor)\n",
    "    \n",
    "    #start = timer()\n",
    "    distance_maps_dict = {}\n",
    "    for tensor in coordinate_tensor:\n",
    "        distance_maps_dict[tensor] = {}\n",
    "        for tensor_group in group_tensor:\n",
    "            index_dict = order_tensor[tensor_group]\n",
    "            distance = morphoscanner.backend.distance_tensor.fast_cdist(coordinate_tensor[tensor],group_tensor[tensor_group])\n",
    "                      \n",
    "            for map_index, m in enumerate(distance):\n",
    "                real_index = index_dict[map_index]\n",
    "                distance_maps_dict[tensor][real_index] = m\n",
    "\n",
    "    #end = timer()\n",
    "    #print(end-start)\n",
    "    return distance_maps_dict\n",
    "\n",
    "d_multi = compute_distance_between_each_peptide(multidim.get_frame(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_multi = compute_distance_between_each_peptide(multidim.get_frame(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_multi[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact = morphoscanner.backend.distance.compute_distance_maps_from_coordinate_dict(multidim.get_frame(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = compute_distance_between_each_peptide(multidim.get_frame(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate error between exact and approximation\n",
    "mean_d = []\n",
    "for idx_first, exact_first in enumerate(exact):\n",
    "    for idx_second, exact_second in enumerate(exact_first):\n",
    "        difference = np.mean(abs(exact_second - t[idx_first][idx_second].numpy()))\n",
    "        mean_d.append(difference)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(mean_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPUTE CONTACT MAPS\n",
    "# TO DO: parametrize the threshold distance in a better way (e.g. )\n",
    "# DISTANCE MAP ARRAY WILL NOT EXIST IN DISTINCT PEPTIDE SIZE SIMULATION\n",
    "def compute_contact_maps_as_array(distance_maps_array, radius_multiplier=1.5):      ## TAKE INPUT FOR RADIUS MULTIPLIER\n",
    "\n",
    "    # median consecutive residues distance from first peptide\n",
    "    distances_pep_1 = []\n",
    "    for i in range(distance_maps_array[0][0].shape[0] - 1): # there was a -1, and len(denoised_dict) was len(coordinate_dict)-1\n",
    "        distances_pep_1.append(distance_maps_array[0][0][i][i+1])\n",
    "\n",
    "    intrapeptide_minimum_distance = np.median(distances_pep_1)\n",
    "\n",
    "    #temporary list\n",
    "    contact_map_list = []\n",
    "\n",
    "    # contact is in a distance up to 150% of the intrapeptide_minimum_distance [TO IMPROVE!!!]\n",
    "    threshold_distance = (intrapeptide_minimum_distance * radius_multiplier)\n",
    "\n",
    "    for model_1 in range(distance_maps_array.shape[0]):\n",
    "        contact_map_list.append([])\n",
    "        for model_2 in range(distance_maps_array[model_1].shape[0]):\n",
    "\n",
    "            contact_map_list[model_1].append([])\n",
    "\n",
    "            if model_1 == model_2:\n",
    "\n",
    "                contact_map_list[model_1][model_2].extend(np.zeros((distance_maps_array.shape[2], distance_maps_array.shape[3])))\n",
    "\n",
    "            else:\n",
    "\n",
    "                contact_map = np.zeros((distance_maps_array.shape[2], distance_maps_array.shape[3]))\n",
    "\n",
    "                for chain_1 in range(distance_maps_array[model_1][model_2].shape[0]):\n",
    "\n",
    "                    for chain_2 in range(distance_maps_array[model_1][model_2][chain_1].shape[0]):\n",
    "\n",
    "                        distance = distance_maps_array[model_1][model_2][chain_1][chain_2]\n",
    "\n",
    "                        if distance < threshold_distance:\n",
    "                            contact_map[chain_1][chain_2] = 1 #True\n",
    "                        else:\n",
    "                            pass\n",
    "\n",
    "                contact_map_list[model_1][model_2].extend(contact_map)\n",
    "\n",
    "    contact_array = np.asarray(contact_map_list)\n",
    "\n",
    "    return contact_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usa matrix multiplication to compute contact maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in t:\n",
    "    for e in t[i]:\n",
    "        print(t[i][e].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test = morphoscanner.trajectory_new.trajectory(trj_gro, trj_xtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test.compose_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_test = compute_distance_between_each_peptide(t_test.get_frame(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_maps_array = d_test\n",
    "radius_multiplier = 1.5\n",
    "\n",
    "# median consecutive residues distance from first peptide\n",
    "distances_pep_1 = []\n",
    "for i in range(distance_maps_array[0][0].shape[0] - 1): # there was a -1, and len(denoised_dict) was len(coordinate_dict)-1\n",
    "    distances_pep_1.append(distance_maps_array[0][0][i][i+1])\n",
    "\n",
    "intrapeptide_minimum_distance = np.median(distances_pep_1)\n",
    "\n",
    "#temporary list\n",
    "contact_map_list = []\n",
    "\n",
    "# contact is in a distance up to 150% of the intrapeptide_minimum_distance [TO IMPROVE!!!]\n",
    "threshold_distance = (intrapeptide_minimum_distance * radius_multiplier)\n",
    "\n",
    "for model_1 in range(distance_maps_array.shape[0]):\n",
    "    contact_map_list.append([])\n",
    "    for model_2 in range(distance_maps_array[model_1].shape[0]):\n",
    "\n",
    "        contact_map_list[model_1].append([])\n",
    "\n",
    "        if model_1 == model_2:\n",
    "\n",
    "            contact_map_list[model_1][model_2].extend(np.zeros((distance_maps_array.shape[2], distance_maps_array.shape[3])))\n",
    "\n",
    "        else:\n",
    "\n",
    "            contact_map = np.zeros((distance_maps_array.shape[2], distance_maps_array.shape[3]))\n",
    "\n",
    "            for chain_1 in range(distance_maps_array[model_1][model_2].shape[0]):\n",
    "\n",
    "                for chain_2 in range(distance_maps_array[model_1][model_2][chain_1].shape[0]):\n",
    "\n",
    "                    distance = distance_maps_array[model_1][model_2][chain_1][chain_2]\n",
    "\n",
    "                    if distance < threshold_distance:\n",
    "                        contact_map[chain_1][chain_2] = 1 #True\n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "            contact_map_list[model_1][model_2].extend(contact_map)\n",
    "\n",
    "contact_array = np.asarray(contact_map_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_pep_1 = []\n",
    "for i in range(distance_maps_array[0][0].shape[0] - 1): # there was a -1, and len(denoised_dict) was len(coordinate_dict)-1\n",
    "    distances_pep_1.append(distance_maps_array[0][0][i][i+1])\n",
    "\n",
    "intrapeptide_minimum_distance = np.median(distances_pep_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intrapeptide_minimum_distance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinate_dict = t_test.get_frame(0)\n",
    "coordinate_tensor = morphoscanner.backend.distance_tensor.get_coordinate_tensor_from_dict_multi(coordinate_dict)\n",
    "    # group tensor for size\n",
    "group_tensor, order_tensor = morphoscanner.backend.distance_tensor.cat_tensor_for_size(coordinate_tensor)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = morphoscanner.backend.distance_tensor.fast_cdist(coordinate_tensor[0],group_tensor[96])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "distances_pep_1 = []\n",
    "for i in range(distance[0].shape[0] - 1):\n",
    "    distances_pep_1.append(distance[0][i][i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = np.median(distances_pep_1)*radius_multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contact_mask = distance.new_full(distance.shape,fill_value=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contact = distance - contact_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contact[contact > 0] = 0\n",
    "contact[contact < 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinate_tensor = morphoscanner.backend.distance_tensor.get_coordinate_tensor_from_dict_multi(multidim.get_frame(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_tensor, order_tensor = morphoscanner.backend.distance_tensor.cat_tensor_for_size(coordinate_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in group_tensor:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experimental distance and contact together\n",
    "def compute_distance_and_contacts_between_each_peptide(coordinate_dict, radius_multiplier=1.5):\n",
    "    # instantiate tensor\n",
    "    coordinate_tensor = morphoscanner.backend.distance_tensor.get_coordinate_tensor_from_dict_multi(coordinate_dict)\n",
    "    # group tensor for size\n",
    "    group_tensor, order_tensor = morphoscanner.backend.distance_tensor.cat_tensor_for_size(coordinate_tensor)\n",
    "    \n",
    "    #start = timer()\n",
    "    distance_maps_dict = {}\n",
    "    contact_maps_dict = {}\n",
    "    for tensor in coordinate_tensor:\n",
    "        distance_maps_dict[tensor] = {}\n",
    "        contact_maps_dict[tensor] = {}\n",
    "        for tensor_group in group_tensor:\n",
    "            index_dict = order_tensor[tensor_group]\n",
    "            #calculate distance\n",
    "            distance = morphoscanner.backend.distance_tensor.fast_cdist(coordinate_tensor[tensor],group_tensor[tensor_group])\n",
    "            \n",
    "            #calculate mean intrapeptide distance\n",
    "            # THIS IS IN THE WRONG PLACE\n",
    "            distances_pep_1 = []\n",
    "            for i in range(distance[0].shape[0] - 1):\n",
    "                #print(distance)\n",
    "                #print(distance[tensor_group].shape[0] - 1)\n",
    "                distances_pep_1.append(distance[0][i][i+1])\n",
    "                threshold = np.median(distances_pep_1)*radius_multiplier\n",
    "                \n",
    "            contact_mask = distance.new_full(distance.shape,fill_value=threshold)\n",
    "            contact = distance - contact_mask\n",
    "            contact[contact > 0] = 0\n",
    "            contact[contact < 0] = 1\n",
    "                \n",
    "                \n",
    "            for map_index, m in enumerate(distance):\n",
    "                real_index = index_dict[map_index]\n",
    "                distance_maps_dict[tensor][real_index] = m\n",
    "                contact_maps_dict[tensor][real_index] = contact\n",
    "\n",
    "    #end = timer()\n",
    "    #print(end-start)\n",
    "    return distance_maps_dict, contact_maps_dict, distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dist, cont, d = compute_distance_and_contacts_between_each_peptide(t_test.get_frame(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.backend.topology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t_test.frames[0].peptides[0].coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### WORKING 25/08/2020\n",
    "def compute_distance_and_contact_maps(coordinate_dict, threshold = 5, contacts_calculation=True):\n",
    "\n",
    "    # instantiate tensor\n",
    "    coordinate_tensor = morphoscanner.backend.distance_tensor.get_coordinate_tensor_from_dict_multi(coordinate_dict)\n",
    "    # group tensor for size\n",
    "    group_tensor, order_tensor = morphoscanner.backend.distance_tensor.cat_tensor_for_size(coordinate_tensor)\n",
    "\n",
    "    distance_maps_dict = {}\n",
    "    contact_maps_dict = {}\n",
    "\n",
    "    # move through tensor\n",
    "    for tensor in coordinate_tensor:\n",
    "        distance_maps_dict[tensor] = {}\n",
    "        contact_maps_dict[tensor] = {}\n",
    "        # move through tensor size\n",
    "        for tensor_group in group_tensor:\n",
    "            index_dict = order_tensor[tensor_group]\n",
    "\n",
    "            #calculate distance\n",
    "            distance = morphoscanner.backend.distance_tensor.fast_cdist(coordinate_tensor[tensor],group_tensor[tensor_group])\n",
    "\n",
    "            #save data maps in dictionary\n",
    "            for map_index, m in enumerate(distance):\n",
    "                real_index = index_dict[map_index]\n",
    "                distance_maps_dict[tensor][real_index] = m\n",
    "            \n",
    "            if contacts_calculation == True:\n",
    "                \n",
    "                #crate mask for contact threshold\n",
    "                contact_mask = distance.new_full(distance.shape, fill_value=threshold)\n",
    "                #calculate contacts\n",
    "                contact = distance - contact_mask\n",
    "                #clean masks\n",
    "                contact[contact > 0] = 0\n",
    "                contact[contact < 0] = 1\n",
    "                \n",
    "                #save contact maps in dict \n",
    "                for cont_index, c in enumerate(contact):\n",
    "                    real_index = index_dict[cont_index]\n",
    "                    contact_maps_dict[tensor][real_index] = c\n",
    "    \n",
    "    if contacts_calculation == True:\n",
    "        return distance_maps_dict, contact_maps_dict\n",
    "    else:\n",
    "        return distance_maps_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(contact_maps_dict[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#continua qua\n",
    "threshold_list = []\n",
    "for idx, i in enumerate(distance):\n",
    "    for e in range(distance[idx].shape[1] - 1):\n",
    "        #print(distance[idx][e][e+1])\n",
    "        threshold_list.append(distance[idx][e][e+1])\n",
    "threshold = np.median(threshold_list)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contact_maps_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_pep_1 = []\n",
    "for i in range(distance[0].shape[0] - 1):\n",
    "    print(distance)\n",
    "    print(distance[tensor_group].shape[0] - 1)\n",
    "    distances_pep_1.append(distance[0][i][i+1])\n",
    "    threshold = np.median(distances_pep_1)*radius_multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(contact_maps_dict[0][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#glico_1p_1.peptide_length_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make it work, partially copied new data retrieval in topology.py\n",
    "# fix also new trajectory in new_trajectory.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glico_1p_1 = trajectory(trj_gro,trj_xtc,select=['aminoacids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glico_1p_1.split(to_split=[96], split_size=[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glico_1p_1.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glico_1p_1.compose_database(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glico_1p_1.analyze_inLoop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glico_1p_1.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glico_1p_1.get_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "glico_1p_1.database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glico_1p_1.plot_aggregates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glico_1p_1.plot_contacts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glico_1p_1.plot_frame_aggregate(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glico_1p_1.plot_graph(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = glico_1p_1\n",
    "\n",
    "frame = 1000\n",
    "frame_dict = self.get_frame(frame)\n",
    "\n",
    "self.frames[frame].results = results()\n",
    "\n",
    "\n",
    "\n",
    "#frame_tensor = distance_tensor.get_coordinate_tensor_from_dict(frame_dict)\n",
    "\n",
    "start_dist = timer()\n",
    "#frame_distance_maps = distance_tensor.compute_euclidean_norm_torch(frame_tensor)\n",
    "frame_distance, frame_contact = compute_distance_and_contact_maps(frame_dict)\n",
    "end_dist = timer()\n",
    "print('Time to compute distance is: ', (end_dist - start_dist))\n",
    "self.frames[frame].results.distance_maps = frame_distance\n",
    "self.frames[frame].results.contact_maps = frame_contact\n",
    "\n",
    "#start_contc = timer()\n",
    "#frame_contact = pattern_recognition.compute_contact_maps_as_array(frame_distance_maps)\n",
    "#end_contc = timer()\n",
    "#print('Time to compute contact is: ', (end_contc - start_contc))\n",
    "\n",
    "start_den = timer()\n",
    "frame_denoised, df = denoise_contact_maps(frame_contact)\n",
    "end_den = timer()\n",
    "print('Time to denoise: ', (end_den-start_den))\n",
    "\n",
    "frame_graph_full = graph.graph_v1(frame_denoised, df)\n",
    "\n",
    "subgraphs = graph.find_subgraph(frame_graph_full)  \n",
    "\n",
    "#self.frames[frame].results = results()\n",
    "self.frames[frame].results.cross_correlation = df\n",
    "self.frames[frame].results.graph = frame_graph_full\n",
    "self.frames[frame].results.subgraphs = subgraphs\n",
    "print('Finished analysis of frame n° %d' % frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contact_array = frame_contact\n",
    "def cross_correlation_function_for_dataset_with_dataframe_torch(contact_array):\n",
    "    '''Perform Normalized Cross Correlation function on the dataset\n",
    "        to check for contact. Get a dict for processing and a pandas.DataFrame\n",
    "        for data analysis\n",
    "\n",
    "        Input: contact maps\n",
    "\n",
    "        Output: contact_dict,         for further processing\n",
    "                pandas.DataFrame,     for data analysis\n",
    "\n",
    "\n",
    "    '''\n",
    "    contact_dict = {}\n",
    "\n",
    "    for row in range(len(contact_array)):\n",
    "\n",
    "        for col in range((row+1), len(contact_array[row])):\n",
    "            best_match = []\n",
    "            #print('row is %d and col is %d' % (row, col))\n",
    "            #print(type(contact_array[row][col]))\n",
    "            #print(contact_array[row][col])\n",
    "            best_match = normalized_cross_correlation_function_torch(contact_array[row][col])\n",
    "\n",
    "            if len(best_match) == 0:\n",
    "                pass\n",
    "\n",
    "            else:\n",
    "                if row in contact_dict:\n",
    "                    contact_dict[row].append([row, col, best_match])\n",
    "\n",
    "                else:\n",
    "                    contact_dict[row] = [[row, col, best_match]]\n",
    "\n",
    "    contact_list = morphoscanner.backend.utilities.contact_list_from_dict(contact_dict)\n",
    "    #contact_list = contact_list_from_dict(contact_dict)\n",
    "\n",
    "\n",
    "    columns_names = ['peptide1', 'peptide2', 'NCC Value', 'shift index', 'contacts', 'sense', 'shift']\n",
    "\n",
    "    df = pd.DataFrame(contact_list, columns=columns_names)\n",
    "\n",
    "    return contact_dict, df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise_contact_maps_torch(contact_maps):\n",
    "    \n",
    "    '''Denoise the contact_maps dataset using the shift_matrix\n",
    "    \n",
    "    Arguments : contact_maps, normalized_cross_correlation_result\n",
    "    \n",
    "    return : a dict with key:value = row : row, col, denoised_map\n",
    "    \n",
    "    '''\n",
    "\n",
    "    normalized_cross_correlation_results, df = cross_correlation_function_for_dataset_with_dataframe_torch(contact_maps)\n",
    "\n",
    "\n",
    "    denoised_dict = {}\n",
    "\n",
    "    for peptide_1 in normalized_cross_correlation_results:\n",
    "        denoised_dict[peptide_1] = {}\n",
    "        for index, peptide_2 in enumerate(normalized_cross_correlation_results[peptide_1]):\n",
    "\n",
    "            row = peptide_2[0]\n",
    "            col = peptide_2[1]\n",
    "\n",
    "\n",
    "\n",
    "            contact_map = contact_maps[row][col]\n",
    "            sense = peptide_2[2][3]\n",
    "            shift_matrix_index = normalized_cross_correlation_results[peptide_1][index][2][1]\n",
    "\n",
    "            shift_matrix = shift_library_maker_torch(contact_map)\n",
    "            shift_matrix = shift_matrix[sense][shift_matrix_index]\n",
    "            denoised_map = contact_map.double() * shift_matrix\n",
    "\n",
    "            denoised_dict[row][col] = denoised_map\n",
    "            \n",
    "            \n",
    "    full_denoised_dict = {}\n",
    "    for peptide_1 in tqdm.tqdm(denoised_dict):\n",
    "        for peptide_2 in denoised_dict[peptide_1]:\n",
    "            contact_map = denoised_dict[peptide_1][peptide_2]\n",
    "\n",
    "            if peptide_1 in full_denoised_dict:\n",
    "                full_denoised_dict[peptide_1][peptide_2] = contact_map\n",
    "\n",
    "            if peptide_1 not in full_denoised_dict:\n",
    "                full_denoised_dict[peptide_1] = {peptide_2:contact_map}\n",
    "\n",
    "            if peptide_2 in full_denoised_dict:\n",
    "                #full_denoised_dict[peptide_2][peptide_1] = contact_map.T #this is for numpy\n",
    "                full_denoised_dict[peptide_2][peptide_1] = contact_map.transpose(1,0) # this is for pytorch\n",
    "\n",
    "\n",
    "            if peptide_2 not in full_denoised_dict:\n",
    "                #full_denoised_dict[peptide_2] = {peptide_1:contact_map.T} #this is for numpy\n",
    "                full_denoised_dict[peptide_2] = {peptide_1:contact_map.transpose(1,0)} # this is for pytorch\n",
    "    \n",
    "    return full_denoised_dict, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_cross_correlation_function_torch(contact_map, minimum_contact=2):\n",
    "    '''\n",
    "    Calculate normalized cross correlation function between a contact map and an ideal map.\n",
    "\n",
    "    Arguments : contact map, as output from get_contact_maps function\n",
    "                shift_matrix_stack, as output from shift_matrix_maker function\n",
    "\n",
    "    Return : a list [ncc_value, index (in the shift_matrix_stack) of the shift matrix\n",
    "                that is matching the contact map\n",
    "\n",
    "            '''\n",
    "    contact_map = contact_map.double()\n",
    "    shift_matrix_library = shift_library_maker_torch(contact_map)\n",
    "\n",
    "    cross_correlation_values = []\n",
    "    max_val = []\n",
    "    sum_contact_map = torch.sum(contact_map)\n",
    "    #print(\"sum_contact_map dtype is: %s \" % str(type(sum_contact_map)))\n",
    "\n",
    "    if sum_contact_map < minimum_contact:\n",
    "        pass\n",
    "\n",
    "    else:\n",
    "        for sense in shift_matrix_library:\n",
    "            for index, z in enumerate(shift_matrix_library[sense]):\n",
    "\n",
    "                shift_matrix = shift_matrix_library[sense][index]\n",
    "                sum_shift_matrix = torch.sum(shift_matrix)\n",
    "                #print(\"contact_map type is: %s\" % str(contact_map.dtype))\n",
    "                ncc_value = (torch.sum((contact_map * shift_matrix))/((torch.sqrt(sum_contact_map))*(torch.sqrt(sum_shift_matrix))))  # normalized cross correlation function of contact matrix and shift matrix\n",
    "                cross_correlation_values.append([ncc_value, index, sum_contact_map, sense])\n",
    "\n",
    "        max_val = max(cross_correlation_values) # get only the best match (highest value of ncc)\n",
    "\n",
    "    return max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(self.frames[150].results.contact_maps[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_library_maker_torch(contact_map_to_analyze):\n",
    "\n",
    "    ''' Create shift matrix library to perform pattern recognition on a contact map.\n",
    "    \n",
    "    Inputs: numpy.array, a single contact map\n",
    "    \n",
    "    returns: dict of shift matrix to analyze the given contact map\n",
    "\n",
    "            shift matrix are diagonal matrix spanning all the given contact map\n",
    "            \n",
    "    '''\n",
    "    \n",
    "    row = contact_map_to_analyze.shape[0]\n",
    "    col = contact_map_to_analyze.shape[1]\n",
    "\n",
    "    kron_dict = {}\n",
    "    kron_list_parallel = []\n",
    "    kron_list_antiparallel = []\n",
    "\n",
    "    for e in range(-row+1, col):\n",
    "        array = np.eye(row, col, e)\n",
    "        kron_list_parallel.append(array)\n",
    "        kron_list_antiparallel.append(np.fliplr(array))\n",
    "\n",
    "    kron_array_parallel = torch.from_numpy(np.asarray(kron_list_parallel))\n",
    "    kron_array_antiparallel = torch.from_numpy(np.asarray(kron_list_antiparallel))\n",
    "    kron_dict['parallel'] = kron_array_parallel\n",
    "    kron_dict['antiparallel'] = kron_array_antiparallel\n",
    "    \n",
    "    #print((kron_array_parallel.dtype))\n",
    "    #print(type(kron_array_antiparallel.dtype))\n",
    "\n",
    "    return kron_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = glico_1p_1.frames[150].results.contact_maps[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_library_maker(mp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.plot_graph(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.plot_frame_aggregate(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcola la distanza mediana tra c alfa per ogni peptide\n",
    "# poi prendi la mediana della mediana\n",
    "# che sarà il threshold di distanza che definisce il contatto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe_glico.frames[0].results.distance_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_threshold_distance(distance_maps):\n",
    "    median_list = []\n",
    "    for row in distance_maps:\n",
    "        self_distance_map = distance_maps[row][row]\n",
    "        intrapep_distance_median = torch.median(torch.diag(self_distance_map,1))\n",
    "        median_list.append(intrapep_distance_median)\n",
    "\n",
    "    threshold = torch.median(torch.tensor(median_list))\n",
    "    return threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold*1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_m = universe_glico.frames[0].results.distance_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_threshold_distance(distance_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct_dict = {}\n",
    "for frame in self.frames:\n",
    "    len_count = 0\n",
    "    for subgraph in self.frames[frame].results.subgraphs:\n",
    "        len_count += len(subgraph)\n",
    "    struct_dict[frame] = len_count\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_structuration(self):\n",
    "    index = self.database.index\n",
    "    tss = [self.universe.trajectory[i].time for ts in self.universe.trajectory for i in index]\n",
    "\n",
    "    structuration = [sum(i) for i in self.database['n° of peptides in macroaggregates']]\n",
    "    plt.plot(tss, structuration,'bo')\n",
    "    plt.xlabel('Time (ps')\n",
    "    plt.ylabel('N° of structured peptides')\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.database.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[sum(i) for i in self.database['n° of peptides in macroaggregates']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [7, 4, 3, 3, 3, 3, 2, 2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_structuration(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(self.frames[0].peptides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.frames[150].results.cross_correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contact_map = self.frames[150].results.contact_maps[19][35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_cross_correlation_function_torch(contact_map, minimum_contact=2):\n",
    "    '''\n",
    "    Calculate normalized cross correlation function between a contact map and an ideal map.\n",
    "\n",
    "    Arguments : contact map, as output from get_contact_maps function\n",
    "                shift_matrix_stack, as output from shift_matrix_maker function\n",
    "\n",
    "    Return : a list [ncc_value, index (in the shift_matrix_stack) of the shift matrix\n",
    "                that is matching the contact map\n",
    "\n",
    "            '''\n",
    "    minimum_contact=2\n",
    "    contact_map = contact_map.double()\n",
    "    shift_matrix_library = shift_library_maker_torch(contact_map)\n",
    "\n",
    "    cross_correlation_values = []\n",
    "    max_val = []\n",
    "    sum_contact_map = torch.sum(contact_map)\n",
    "    shift_matrix_center_index = ((contact_map.shape[0] + contact_map.shape[1]) -1)//2\n",
    "    #print(\"sum_contact_map dtype is: %s \" % str(type(sum_contact_map)))\n",
    "\n",
    "    if sum_contact_map < minimum_contact:\n",
    "        pass\n",
    "\n",
    "    else:\n",
    "        for sense in shift_matrix_library:\n",
    "            for index, z in enumerate(shift_matrix_library[sense]):\n",
    "\n",
    "                shift_matrix = shift_matrix_library[sense][index]\n",
    "                sum_shift_matrix = torch.sum(shift_matrix)\n",
    "                #print(\"contact_map type is: %s\" % str(contact_map.dtype))\n",
    "                ncc_value = (torch.sum((contact_map * shift_matrix))/((torch.sqrt(sum_contact_map))*(torch.sqrt(sum_shift_matrix))))  # normalized cross correlation function of contact matrix and shift matrix\n",
    "                cross_correlation_values.append([ncc_value, index, sum_contact_map, sense])\n",
    "\n",
    "        max_val = max(cross_correlation_values) # get only the best match (highest value of ncc)\n",
    "\n",
    "        shift = abs(shift_matrix_center_index - max_val[1])\n",
    "        max_val.append(shift)\n",
    "\n",
    "    \n",
    "    return max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contact_list_from_dict(contact_dict):\n",
    "    \n",
    "    contact_list = []\n",
    "    for peptide in contact_dict:\n",
    "\n",
    "        for contact in contact_dict[peptide]:\n",
    "\n",
    "            new_data = [contact[0], contact[1], contact[2][0], contact[2][1], contact[2][2], contact[2][3], contact[2][4]]\n",
    "            contact_list.append(new_data)\n",
    "    return contact_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(shift_matrix_library['antiparallel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(shift_matrix_library['antiparallel'][20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(self.frames[150].results.contact_maps[2][18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "self.frames[150].results.cross_correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "self.frames[150].results.cross_correlation.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for contacting in self.frames[150].results.cross_correlation.iloc:\n",
    "    if contacting['sense'] == 'antiparallel':\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj = trajectory(glac_3perc_1_gro, glac_3perc_1_trr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj.compose_database(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj.analyze_inLoop(threshold_multiplier=1.45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj.get_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj.database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj.plot_aggregates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj.plot_contacts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj.plot_structuration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj.plot_graph(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj.plot_frame_aggregate(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "self.frames.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_profile(self):\n",
    "    \n",
    "    shift_profile = {}\n",
    "    for frame in self.frames:\n",
    "        shift_profile[frame] = {} \n",
    "        for shift_value in self.frames[frame].results.cross_correlation['shift']:\n",
    "            try:\n",
    "                shift_profile[frame][shift_value] += 1\n",
    "            except:\n",
    "                shift_profile[frame][shift_value] = 1\n",
    "        \n",
    "        f = {k[0]:k[1] for k in sorted(shift_profile[frame].items())}\n",
    "        self.frames[frame].results.shift_profile = f\n",
    "    return\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = shift_profile[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.frames[50].results.cross_correlation['shift']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_shift(self, frame=None):\n",
    "    f = self.frames[frame].results.shift_profile\n",
    "    x = [val for val in f.keys()]\n",
    "    y = [k for k in f.values()]\n",
    "    plt.plot(x, y)\n",
    "    plt.xlabel('Shift value')\n",
    "    plt.ylabel('Number of contacts')\n",
    "    plt.show() \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In your trajectory there are 1001 frames.\n",
      "\n",
      "Length: 21, Peptides: 40\n"
     ]
    }
   ],
   "source": [
    "trj = morphoscanner.trajectory_new.trajectory(glac_3perc_1_gro, glac_3perc_1_trr, select=['aminoacids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploration of frame 0 done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trj.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 64.15it/s]\n"
     ]
    }
   ],
   "source": [
    "trj.compose_database(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing started...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'morphoscanner.backend.distance_tensor' has no attribute 'get_threshold_distance'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/git_repo/sap_analysis/morphoscanner/trajectory_new.py\u001b[0m in \u001b[0;36manalysis\u001b[0;34m(self, frame, threshold_multiplier)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontact_threshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'trajectory' object has no attribute 'contact_threshold'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f5c15d52bf34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze_inLoop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/git_repo/sap_analysis/morphoscanner/trajectory_new.py\u001b[0m in \u001b[0;36manalyze_inLoop\u001b[0;34m(self, threshold, threshold_multiplier)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mstart_an\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold_multiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthreshold_multiplier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mend_an\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Time needed to analyze frame %d was %f seconds'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mend_an\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart_an\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git_repo/sap_analysis/morphoscanner/trajectory_new.py\u001b[0m in \u001b[0;36manalysis\u001b[0;34m(self, frame, threshold_multiplier)\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mdic_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0mframe_distance_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistance_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_distance_and_contact_maps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdic_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontacts_calculation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistance_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_threshold_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_distance_0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mthreshold_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontact_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Two nearby atoms of different peptides are contacting if the distance is lower than: %s Angstrom\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontact_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'morphoscanner.backend.distance_tensor' has no attribute 'get_threshold_distance'"
     ]
    }
   ],
   "source": [
    "trj.analyze_inLoop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

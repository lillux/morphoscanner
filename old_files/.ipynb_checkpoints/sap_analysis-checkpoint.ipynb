{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "\n",
    "from mpl_toolkits import mplot3d\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "#from functools import lru_cache\n",
    "#import re\n",
    "import networkx as nx\n",
    "from networkx.algorithms import approximation\n",
    "\n",
    "\n",
    "import MDAnalysis as mda\n",
    "\n",
    "#import scipy\n",
    "#import sklearn\n",
    "#import skimage\n",
    "\n",
    "#import xml.etree.ElementTree as et\n",
    "#from Bio.PDB import *\n",
    "#import nglview as nv\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "# http://nglviewer.org/nglview/latest/api.html\n",
    "# https://biopython.org/wiki/The_Biopython_Structural_Bioinformatics_FAQ\n",
    "# https://ambermd.org/tutorials/analysis/tutorial_notebooks/nglview_notebook/index.html\n",
    "# https://amber-md.github.io/pytraj/latest/_api/pytraj.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contact_matrix = np.loadtxt('/home/lillo/TesiCNTE/CNTE/dataset/contact_matrix.txt')   #laptop\n",
    "#contact_matrix = np.loadtxt('/home/lillo/Code/Tesi/dataset/contact_matrix.txt')        #fisso\n",
    "#contact_matrix_single = contact_matrix.reshape(100,100,12,12)\n",
    "\n",
    "#gromacs_output = open('/home/lillo/Code/Tesi/dataset/dm4500Compl_mix1_K2_1%4500ns.gro') #fisso\n",
    "#gromacs_output = open('/home/lillo/TesiCNTE/CNTE/dataset/dm4500Compl_mix1_K2_1%4500ns.gro') #laptop\n",
    "\n",
    "#path = '/home/lillo/Code/Tesi/dataset/dm4500Compl_mix1_K2_1%4500ns.gro' #fisso\n",
    "path = '/home/lillo/TesiCNTE/CNTE/dataset/dm4500Compl_mix1_K2_1%4500ns.gro' #laptop\n",
    "\n",
    "# import 2mxu file (beta sheet)\n",
    "\n",
    "#path_to_mmCIF = open('/home/lillo/TesiCNTE/pdb/2mxu/2mxu.cif')  ## laptop\n",
    "#path_to_pdb = '/home/lillo/TesiCNTE/pdb/2mxu/2mxu.pdb'  ## laptop\n",
    "#pa_to_pdb = '/home/lillo/TesiCNTE/pdb/2mxu/2mxu.pdb'  ## laptop\n",
    "\n",
    "#path_to_mmCIF = open('/home/lillo/Code/Tesi/pdb/2mxu/2mxu.cif')  ## fisso\n",
    "#path_to_pdb = '/home/lillo/Code/Tesi/pdb/2mxu/2mxu.pdb'  ## fisso\n",
    "#pa_to_pdb = '/home/lillo/Code/Tesi/pdb/2mxu/2mxu.pdb'  ## fisso\n",
    "\n",
    "# aggregate blob\n",
    "\n",
    "seed_1_path = '/home/lillo/TesiCNTE/from_cluster/aggregate1.gro' # laptop\n",
    "#seed_1_path = '/home/lillo/Code/Tesi/dataset/aggregate1.gro' # Fisso\n",
    "\n",
    "# Trajectory with aggregate seed\n",
    "trj_xtc = '/home/lillo/TesiCNTE/CNTE/trajectory/prd-LDLK12-100mer-out-mol.xtc'  #laptop\n",
    "trj_gro = '/home/lillo/TesiCNTE/CNTE/trajectory/min-LDLK12-100mer-out-c.gro'  #laptop\n",
    "\n",
    "#trj_xtc = '/home/lillo/Code/Tesi/dataset/trajectory_6_12_19/prd-LDLK12-100mer-out-mol.xtc'  #fisso\n",
    "#trj_gro = '/home/lillo/Code/Tesi/dataset/trajectory_6_12_19/min-LDLK12-100mer-out-c.gro'  #fisso\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ .gro FILE AND PREPROCESSING\n",
    "\n",
    "def clean_gro(path):\n",
    "    \n",
    "    \n",
    "        # open file .gro and return a list with one element per line of the .gro file\n",
    "    def read_gro(path):\n",
    "        gromacs_output = open(path)\n",
    "\n",
    "        gro_file = []\n",
    "        for line in tqdm.tqdm(gromacs_output):\n",
    "            gro_file.append(line)\n",
    "\n",
    "\n",
    "\n",
    "        gromacs_output.close()        \n",
    "\n",
    "        return gro_file\n",
    "\n",
    "\n",
    "\n",
    "    # return string in a string with numbers\n",
    "    def return_if_string(string):\n",
    "        digits = []\n",
    "        for i in string:\n",
    "            if not i.isdigit():\n",
    "                digits.append(i)\n",
    "\n",
    "        string = ''.join(digits)\n",
    "\n",
    "        return string\n",
    "\n",
    "\n",
    "    # return numbers in a string with numbers\n",
    "    def return_if_digit(string):\n",
    "        digits = []\n",
    "        for i in string:\n",
    "            if i.isdigit():\n",
    "                digits.append(i)\n",
    "\n",
    "        string = ''.join(digits)\n",
    "\n",
    "        return string\n",
    "\n",
    "\n",
    "    # remove first, second and last lines from gro_file and reorder information\n",
    "    # FIX OPTION TO GET ENTRY RELATED TO A LABEL (as 'bb' or 'ca')\n",
    "    def clean_gro_file(gro_file):\n",
    "        cleaned_gro_file = []\n",
    "        for aminoacid in tqdm.tqdm(gro_file[2:-1]):\n",
    "            splitted = aminoacid.split()\n",
    "            if splitted[1] == 'BB':\n",
    "                position_in_peptide = return_if_digit(splitted[0])\n",
    "                residue = return_if_string(splitted[0])\n",
    "                index = splitted[2]\n",
    "                x = splitted[3]\n",
    "                y = splitted[4]\n",
    "                z = splitted[5]\n",
    "                cleaned_gro_file.append([index, position_in_peptide, residue, x, y, z])\n",
    "        return cleaned_gro_file\n",
    "    \n",
    "    \n",
    "    gro_file = read_gro(path)\n",
    "    cleaned_gro_file = clean_gro_file(gro_file)\n",
    "\n",
    "    return cleaned_gro_file\n",
    "\n",
    "\n",
    "# create coordinate dict from cleaned_gro_file\n",
    "def get_coordinate_dict_from_cleaned_gro(cleaned_gro_file):\n",
    "    \n",
    "    peptide_lenght_list = []\n",
    "\n",
    "    temporary_list = []\n",
    "\n",
    "    # iterate trough cleaned_gro_file\n",
    "    for residue in cleaned_gro_file:\n",
    "\n",
    "        # if temporary list just started, add aminoacid position in chain\n",
    "        if len(temporary_list) == 0:\n",
    "            temporary_list.append(int(residue[1]))\n",
    "\n",
    "        else:\n",
    "            # if position of actual residue is less than last residue\n",
    "            if temporary_list[-1] > int(residue[1]):\n",
    "\n",
    "                # append lenght of last peptide to peptide lenght list\n",
    "                peptide_lenght_list.append(len(temporary_list))\n",
    "\n",
    "                # empty temporary list\n",
    "                temporary_list = []\n",
    "\n",
    "                # append actual residue position\n",
    "                temporary_list.append(int(residue[1]))\n",
    "\n",
    "            # if position of actual residue is higher than last residue, ad current residue position\n",
    "            else:\n",
    "                temporary_list.append(int(residue[1]))\n",
    "\n",
    "    # append last peptide lenght to lenght stack\n",
    "    peptide_lenght_list.append(len(temporary_list))\n",
    "\n",
    "    # create empty dict for coordinate\n",
    "    peptide_coordinate_dict = {}\n",
    "\n",
    "    # create an entry in dict for every peptide in the file\n",
    "    for peptide in range(len(peptide_lenght_list)):\n",
    "        peptide_coordinate_dict[peptide] = {}\n",
    "\n",
    "        # for every residue in lenght peptide, add coordinate x, y, z\n",
    "        for residue in range(peptide_lenght_list[peptide]):\n",
    "            peptide_coordinate_dict[peptide][residue] = [float(coordinate) for coordinate in cleaned_gro_file[(peptide * peptide_lenght_list[peptide])+residue][3:]]\n",
    "\n",
    "    return peptide_coordinate_dict\n",
    "\n",
    "\n",
    "# compute euclidean distance\n",
    "def get_euclidean_distance(point_1, point_2):\n",
    "    \n",
    "    euclidean_distance = np.sqrt(np.sum([((point_1[0] - point_2[0])**2), ((point_1[1] - point_2[1])**2), ((point_1[2] - point_2[2])**2)]))\n",
    "\n",
    "    return euclidean_distance\n",
    "\n",
    "# compute distance map between two peptides\n",
    "def compute_distance_map(coordinate_dict, peptide_1, peptide_2):\n",
    "\n",
    "    distance_map = []\n",
    "    for amino_1 in coordinate_dict[peptide_1]:\n",
    "        coordinate_1 = coordinate_dict[peptide_1][amino_1]\n",
    "        \n",
    "        distance_map.append([amino_1])\n",
    "        \n",
    "        for amino_2 in coordinate_dict[peptide_2]:\n",
    "            coordinate_2 = coordinate_dict[peptide_2][amino_2]\n",
    "            \n",
    "            euclidean_distance = get_euclidean_distance(coordinate_1, coordinate_2)\n",
    "            distance_map[amino_1].append(euclidean_distance)\n",
    "        \n",
    "        del distance_map[amino_1][0]\n",
    "\n",
    "    distance_map = np.asarray(distance_map)\n",
    "    \n",
    "    return distance_map\n",
    "\n",
    "# compute distance map and return a n_peptide x n_peptide x n_res x n_res array\n",
    "def compute_distance_maps_from_coordinate_dict(coordinate_dict):\n",
    "    \n",
    "    aggregate_distance_map = []\n",
    "\n",
    "    #for peptide_1 in tqdm.tqdm(coordinate_dict):\n",
    "    for peptide_1 in coordinate_dict:\n",
    "        aggregate_distance_map.append([peptide_1])\n",
    "        \n",
    "        #for peptide_2 in tqdm.tqdm(coordinate_dict):\n",
    "        for peptide_2 in coordinate_dict:\n",
    "            distance_map = compute_distance_map(coordinate_dict, peptide_1, peptide_2)\n",
    "            \n",
    "            aggregate_distance_map[peptide_1].append(distance_map)\n",
    "\n",
    "        del aggregate_distance_map[peptide_1][0]\n",
    "\n",
    "    aggregate_distance_array = np.asarray(aggregate_distance_map)\n",
    "    \n",
    "    return aggregate_distance_array\n",
    "\n",
    "\n",
    "# COMPUTE CONTACT MAPS\n",
    "# TO DO: parametrize the threshold distance in a better way (e.g. )\n",
    "def compute_contact_maps_as_array(distance_maps_array):\n",
    "    \n",
    "    # distance between the first and the second aminoacid of the first chain\n",
    "    intrapeptide_minimum_distance = distance_maps_array[0][0][0][1] \n",
    "\n",
    "    contact_map_list = []\n",
    "\n",
    "    # contact is in a distance up to 150% of the intrapeptide_minimum_distance [TO IMPROVE!!!]\n",
    "    threshold_distance = (intrapeptide_minimum_distance * 1.5)\n",
    "\n",
    "    for model_1 in range(distance_maps_array.shape[0]):\n",
    "        contact_map_list.append([])\n",
    "        for model_2 in range(distance_maps_array[model_1].shape[0]):\n",
    "\n",
    "            contact_map_list[model_1].append([])\n",
    "\n",
    "            if model_1 == model_2:\n",
    "\n",
    "                contact_map_list[model_1][model_2].extend(np.zeros((distance_maps_array.shape[2], distance_maps_array.shape[3])))\n",
    "\n",
    "            else:\n",
    "\n",
    "                contact_map = np.zeros((distance_maps_array.shape[2], distance_maps_array.shape[3]))\n",
    "\n",
    "                for chain_1 in range(distance_maps_array[model_1][model_2].shape[0]):\n",
    "\n",
    "                    for chain_2 in range(distance_maps_array[model_1][model_2][chain_1].shape[0]):\n",
    "\n",
    "                        distance = distance_maps_array[model_1][model_2][chain_1][chain_2]\n",
    "\n",
    "                        if distance < threshold_distance:\n",
    "                            contact_map[chain_1][chain_2] = 1 #True\n",
    "                        else:\n",
    "                            pass\n",
    "\n",
    "                contact_map_list[model_1][model_2].extend(contact_map)\n",
    "    \n",
    "    contact_array = np.asarray(contact_map_list)\n",
    "            \n",
    "    return contact_array\n",
    "\n",
    "\n",
    "#### ANALYSIS\n",
    "\n",
    "def shift_library_maker(contact_map_to_analyze):\n",
    "    \n",
    "    ''' riceve numero di righe e di colonne\n",
    "    restituisce un array shape((((row + col)*2)-2),row,col).\n",
    "    ogni slice Ã¨ una diagonale. Lo stack copre le diagonali su tutta la matrice'''\n",
    "    \n",
    "    row = contact_map_to_analyze.shape[0]\n",
    "    col = contact_map_to_analyze.shape[1]\n",
    "    \n",
    "    kron_dict = {}\n",
    "    kron_list_parallel = []\n",
    "    kron_list_antiparallel = []\n",
    "    \n",
    "    for e in range(-row+1, col):\n",
    "        array = np.eye(row, col, e)\n",
    "        kron_list_parallel.append(array)\n",
    "        kron_list_antiparallel.append(np.fliplr(array))\n",
    "        \n",
    "    kron_array_parallel = np.asarray(kron_list_parallel)\n",
    "    kron_array_antiparallel = np.asarray(kron_list_antiparallel)\n",
    "    \n",
    "    kron_dict['parallel'] = kron_array_parallel\n",
    "    kron_dict['antiparallel'] = kron_array_antiparallel\n",
    "    \n",
    "    return kron_dict\n",
    "\n",
    "\n",
    "def normalized_cross_correlation_function(contact_map):\n",
    "    '''\n",
    "    Calculate normalized cross correlation function between a contact map and an ideal map.\n",
    "    \n",
    "    Arguments : contact map, as output from get_contact_maps function\n",
    "                shift_matrix_stack, as output from shift_matrix_maker function\n",
    "                \n",
    "    Return : a list [ncc_value, index (in the shift_matrix_stack) of the shift matrix\n",
    "                that is matching the contact map\n",
    "            \n",
    "            '''\n",
    "    shift_matrix_library = shift_library_maker(contact_map)\n",
    "    \n",
    "    cross_correlation_values = []\n",
    "    max_val = []\n",
    "    sum_contact_map = np.sum(contact_map)\n",
    "    \n",
    "    if sum_contact_map < 2:\n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "        for sense in shift_matrix_library:\n",
    "            for index, z in enumerate(shift_matrix_library[sense]):\n",
    "\n",
    "                shift_matrix = shift_matrix_library[sense][index]\n",
    "                sum_shift_matrix = np.sum(shift_matrix)\n",
    "                ncc_value = (np.sum((contact_map * shift_matrix))/((np.sqrt(sum_contact_map))*(np.sqrt(sum_shift_matrix))))  # normalized cross correlation function of contact matrix and shift matrix\n",
    "                cross_correlation_values.append([ncc_value, index, sum_contact_map, sense])\n",
    "\n",
    "            max_val = max(cross_correlation_values) # get only the best match (highest value of ncc)\n",
    "\n",
    "    return max_val\n",
    "\n",
    "\n",
    "\n",
    "def normalized_cross_correlation_for_dataset(contact_array):\n",
    "    '''Calculate normalized cross correlation function between the full contacts map and and the .\n",
    "    \n",
    "    Arguments : contact map, as output from get_contact_maps function\n",
    "                shift_matrix_stack, as output from shift_matrix_maker function\n",
    "                \n",
    "    Return : a list [ncc_value, index (in the shift_matrix_stack) of the shift matrix that is matching the contact map'''\n",
    "    \n",
    "    contact_dict = {}\n",
    "    \n",
    "    #for row in tqdm.tqdm(range(contact_array.shape[0])):\n",
    "    for row in range(contact_array.shape[0]):\n",
    "    \n",
    "        for col in range((row+1), contact_array.shape[1]):\n",
    "        #for col in range(contact_array.shape[1]):\n",
    "\n",
    "            best_match = []\n",
    "            best_match = normalized_cross_correlation_function(contact_array[row][col])\n",
    "            \n",
    "            if len(best_match) == 0:\n",
    "                pass\n",
    "            \n",
    "            else:\n",
    "                if row in contact_dict:\n",
    "                    contact_dict[row].append([row, col, best_match])\n",
    "                \n",
    "                else:\n",
    "                    contact_dict[row] = [[row, col, best_match]]\n",
    "    \n",
    "    return contact_dict\n",
    "\n",
    "\n",
    "#denoise dataset\n",
    "def denoise_full_dataset(contact_maps, normalized_cross_correlation_results):\n",
    "    \n",
    "    '''Denoise the contact_maps dataset using the shift_matrix\n",
    "    \n",
    "    Arguments : contact_maps, normalized_cross_correlation_result\n",
    "    \n",
    "    return : a dict with key:value = row : row, col, denoised_map\n",
    "    \n",
    "    '''\n",
    "\n",
    "    denoised_dict = {}\n",
    "\n",
    "    for peptide_1 in normalized_cross_correlation_results:\n",
    "        denoised_dict[peptide_1] = {}\n",
    "        for index, peptide_2 in enumerate(normalized_cross_correlation_results[peptide_1]):\n",
    "\n",
    "            row = peptide_2[0]\n",
    "            col = peptide_2[1]\n",
    "\n",
    "\n",
    "\n",
    "            contact_map = contact_maps[row][col]\n",
    "            sense = peptide_2[2][3]\n",
    "            shift_matrix_index = normalized_cross_correlation_results[peptide_1][index][2][1]\n",
    "\n",
    "            shift_matrix = shift_library_maker(contact_map)\n",
    "            shift_matrix = shift_matrix[sense][shift_matrix_index]\n",
    "            denoised_map = contact_map * shift_matrix\n",
    "\n",
    "            denoised_dict[row][col] = denoised_map\n",
    "            \n",
    "    return denoised_dict\n",
    "\n",
    "\n",
    "#create a dict that contains the peptide couples contact and the specular peptide couples contact\n",
    "def reconstruct_full_matrix(denoised_dict):\n",
    "    full_denoised_dict = {}\n",
    "    for peptide_1 in tqdm.tqdm(denoised_dict):\n",
    "        for peptide_2 in denoised_dict[peptide_1]:\n",
    "            contact_map = denoised_dict[peptide_1][peptide_2]\n",
    "\n",
    "            if peptide_1 in full_denoised_dict:\n",
    "                full_denoised_dict[peptide_1][peptide_2] = contact_map\n",
    "\n",
    "            if peptide_1 not in full_denoised_dict:\n",
    "                full_denoised_dict[peptide_1] = {peptide_2:contact_map}\n",
    "\n",
    "            if peptide_2 in full_denoised_dict:\n",
    "                full_denoised_dict[peptide_2][peptide_1] = contact_map.T\n",
    "\n",
    "            if peptide_2 not in full_denoised_dict:\n",
    "                full_denoised_dict[peptide_2] = {peptide_1:contact_map.T}\n",
    "    \n",
    "    return full_denoised_dict\n",
    "\n",
    "\n",
    "# take array, return vector with sum along columns\n",
    "def get_row_vector(array):\n",
    "    row_vector = np.sum(array, axis=0)\n",
    "    return row_vector\n",
    "\n",
    "# take array, return vector with sum along row\n",
    "def get_col_vector(array):\n",
    "    col_vector = np.sum(array, axis=1)\n",
    "    return col_vector\n",
    "\n",
    "# graph clustering\n",
    "def nx_graph_search(denoised_dict):\n",
    "    \n",
    "    graph = nx.MultiGraph()\n",
    "    \n",
    "    for peptide_1 in denoised_dict:\n",
    "        for peptide_2 in denoised_dict[peptide_1]:\n",
    "            array_1 = denoised_dict[peptide_1][peptide_2]\n",
    "            for peptide_3 in denoised_dict[peptide_2]:\n",
    "                if peptide_3 != peptide_1:\n",
    "                    array_2 = denoised_dict[peptide_2][peptide_3]\n",
    "\n",
    "                    vect_1 = get_row_vector(array_1)\n",
    "                    vect_2 = get_col_vector(array_2)\n",
    "\n",
    "                    contacts = np.dot(vect_1, vect_2)\n",
    "                    \n",
    "                    if contacts >= 3:\n",
    "\n",
    "                        graph.add_edge(peptide_1, peptide_2)\n",
    "                     \n",
    "                        graph.add_edge(peptide_2, peptide_3)\n",
    "\n",
    "    return graph\n",
    "\n",
    "#A novel graph clustering algorithm based on discrete-time quantum random walk\n",
    "#S.G. Roya, A. Chakrabarti\n",
    "\n",
    "\n",
    "# working with networkX\n",
    "# if contacts >= target\n",
    "\n",
    "# when you add_edge, nodes are created if they are not there\n",
    "# you can put info in edge (as distance, n of contacts, contact map)\n",
    "# you HAVE TO (but you can not also) put key to index multiple nodes that are joined with a single node\n",
    "# \n",
    "# add edge from pep1 to pep2 (you HAVE TO (###to explore utility of key) put key to index multiple nodes that are joined with a single node)\n",
    "# add edge from pep3 to pep3 ( same as before with key)\n",
    "\n",
    "\n",
    "#FIND SUBGRAPH\n",
    "def find_subgraph(graph):\n",
    "    '''\n",
    "    Find subgraph that have no node in common.\n",
    "    \n",
    "    Argument: NetworkX MultiGraph\n",
    "    \n",
    "    Return: list of subgraph ordered from one end to the other\n",
    "    \n",
    "    '''\n",
    "\n",
    "    subgraph_list = []\n",
    "    \n",
    "    for node in graph:\n",
    "        \n",
    "        # don't explore node that are already in subgraph_list\n",
    "        if node not in set(nod for nod_list in subgraph_list for nod in nod_list):\n",
    "            \n",
    "            # tree is the list of nodes joined to node, starting from node\n",
    "            # using depht first search\n",
    "            tree = [e for e in nx.algorithms.traversal.depth_first_search.dfs_tree(graph, node)]\n",
    "            \n",
    "            # check if the first node of the tree has adjiacency == 1\n",
    "            # so it checks if it is the first or last node of the subgraph\n",
    "            if len(graph[tree[0]]) == 1:\n",
    "                \n",
    "                if len(subgraph_list) == 0:\n",
    "                    subgraph_list.append(tree)\n",
    "                    \n",
    "                else:\n",
    "                    # use generator to check if the tree is already in the subgraph\n",
    "                    if set(tree) not in (set(i) for i in subgraph_list):\n",
    "                        subgraph_list.append(tree)\n",
    "                        \n",
    "    return subgraph_list\n",
    "\n",
    "\n",
    "########## PLOT PEPTIDE LIST\n",
    "# plot a list of peptide point cloud in 3d space.\n",
    "# The box axis have arbitrary scale dependent on the aminoacids distance\n",
    "# you can select to show the centroid\n",
    "def plot_peptide_list(coordinate_dict, peptide_list, centroid=False):\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "    x_median = float\n",
    "    y_median = float\n",
    "    z_median = float\n",
    "    \n",
    "\n",
    "    for peptide in range(len(peptide_list)):\n",
    "        x.append([peptide])\n",
    "        y.append([peptide])\n",
    "        z.append([peptide])\n",
    "        for aminoacid in coordinate_dict[peptide_list[peptide]]:\n",
    "\n",
    "            point = coordinate_dict[peptide_list[peptide]][aminoacid]\n",
    "            x[peptide].append(point[0])\n",
    "            y[peptide].append(point[1])\n",
    "            z[peptide].append(point[2])\n",
    "\n",
    "        del x[peptide][0]\n",
    "        del y[peptide][0]\n",
    "        del z[peptide][0]\n",
    "        \n",
    "    if centroid == True:\n",
    "        \n",
    "        def assemble_coordinate(axis_coordinate_list):\n",
    "            median_list = []\n",
    "            for coordinate_set in axis_coordinate_list:\n",
    "                median = np.median(coordinate_set)\n",
    "                median_list.append(median)\n",
    "            return median_list\n",
    "        \n",
    "        x_median = assemble_coordinate(x)\n",
    "        y_median = assemble_coordinate(y)\n",
    "        z_median = assemble_coordinate(z)\n",
    "        \n",
    "\n",
    "    #%matplotlib notebook\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes(projection='3d')\n",
    "    \n",
    "    for pep in range(len(x)):\n",
    "       \n",
    "        ax.scatter3D(x[pep],y[pep],z[pep])\n",
    "        \n",
    "        if centroid == True:\n",
    "            \n",
    "            ax.scatter3D(x_median[pep], y_median[pep], z_median[pep], c='red')\n",
    "            \n",
    "        \n",
    "    #return  plt.show(), [x,y,z], [x_median, y_median, z_median]\n",
    "    return  plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# get average distance map from distance maps set\n",
    "def get_mean_distance_map(distance_maps):\n",
    "    '''\n",
    "    Calculate mean distance map from distance maps set\n",
    "    \n",
    "    Argument: distance maps set\n",
    "    \n",
    "    return: np.array with average intrapeptide distance\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # create array of zeros of shape number_of_residues * number_of_residues\n",
    "    # depending on peptide residue number ### TO FIX FOR MULTIMONOMERIC ASSEMBLY\n",
    "    base = np.zeros((distance_maps[0][0].shape[0], distance_maps[0][0].shape[1]))\n",
    "    \n",
    "    # initialize counter\n",
    "    counter = 0\n",
    "    \n",
    "    # iterate throught peptides in the aggregate\n",
    "    for peptide_1 in range(distance_maps.shape[0]):\n",
    "        for peptide_2 in range(distance_maps.shape[1]):\n",
    "             \n",
    "            # if peptide index are the same (intrapeptide distance map)\n",
    "            if peptide_1 == peptide_2:\n",
    "                \n",
    "                # intrapeptide distance map\n",
    "                actual_distance_map = distance_maps[peptide_1][peptide_2]\n",
    "                \n",
    "                # sum base and current distance map\n",
    "                base = base + actual_distance_map\n",
    "                \n",
    "                #update counter\n",
    "                counter += 1\n",
    "\n",
    "    #for element in base (every element is the sum of distance_map(i,j) for every distance map)\n",
    "    for row in range(len(base)):\n",
    "        for col in range(len(base)):\n",
    "            \n",
    "            # find the mean for every element of the cumulative distance map\n",
    "            base[row][col] = (base[row][col])/counter\n",
    "            \n",
    "    return base\n",
    "\n",
    "\n",
    "def decompose_distance_map(distance_map):\n",
    "    '''Use Singular value decomposition to get\n",
    "    \n",
    "    distance_map.shape[1] dimensional coordinate\n",
    "    (same n of dimension as the peptide n of residue)\n",
    "    \n",
    "    As described in:\n",
    "    Mathematical Modeling of Protein Structure Using Distance Geometry\n",
    "    Jeong-Mi Yoon, Yash Gad, Zhijun Wu\n",
    "    \n",
    "    Argument: distance map (numpy.array 2D)\n",
    "    return: X : actual decomposition\n",
    "            \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # initialize a zeros matrix of same shape as the input map\n",
    "    D = np.zeros(distance_map.shape)\n",
    "    \n",
    "    #iterate trought row\n",
    "    for i in range(distance_map.shape[0]):\n",
    "        \n",
    "        # iterate trought cols\n",
    "        for j in range(distance_map.shape[1]):\n",
    "            \n",
    "            # distance between point point i and point j \n",
    "            dij = distance_map[i][j]\n",
    "            \n",
    "            # distance between point 0 and point j\n",
    "            d0j = distance_map[0][j]\n",
    "            \n",
    "            #distance between point i and point 0\n",
    "            di0 = distance_map[i][0]\n",
    "\n",
    "            #fill the zeros matrix with the value obtained with this formula\n",
    "            D[i][j] = (d0j**2 + di0**2 - dij**2)/2\n",
    "            \n",
    "    # check rank of matrix (should be of rank 3, but it is of rank distance_map.shape[1])\n",
    "    rank = np.linalg.matrix_rank(D)\n",
    "    \n",
    "    # Singular value decomposition on the D matrix\n",
    "    #svd = np.linalg.svd(D)\n",
    "    \n",
    "    svd = np.linalg.svd(D, full_matrices=False)\n",
    "    \n",
    "    # Calculate distance_map.shape[1] dimensional coordinate, but you need 3\n",
    "    # the non necessary dimension can give data to better reconstruct the peptide structure\n",
    "    X = svd[0]*np.sqrt(svd[1])\n",
    "\n",
    "    \n",
    "    #return X, svd, D, rank\n",
    "    return X\n",
    "\n",
    "def get_coordinate_from_decomposition(decomposition):\n",
    "    '''Take decomposition result and convert it into a coordinate vectors dict\n",
    "    \n",
    "    Argument: decomposition results\n",
    "    \n",
    "    return: dict with reconstructed 3d coordinate vector\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # take only the first three value to compose a 3D coordinate vector\n",
    "    coordinate = [e[:3] for e in decomposition]\n",
    "    \n",
    "    # initialize empty dict\n",
    "    reconstructed_coordinate_dict = {}\n",
    "    \n",
    "    # fill the dict with the ccordinate vectors\n",
    "    for index,coordinate_vector in enumerate(coordinate):\n",
    "        reconstructed_coordinate_dict[index] = coordinate_vector\n",
    "    \n",
    "    return reconstructed_coordinate_dict\n",
    "\n",
    "\n",
    "# \n",
    "def get_coordinate_from_distance_map(distance_map):\n",
    "    ''' compute 3d coordinate from distance map\n",
    "    \n",
    "    Argument: distance_map (numpy.array)\n",
    "    \n",
    "    return: dict with 3d coordinate for every alpha-carbon of a peptide\n",
    "    \n",
    "    '''\n",
    "    # perform singular value decomposition on distance_map (preprocessed)\n",
    "    decomposed_mean_distance_map = decompose_distance_map(distance_map)\n",
    "    \n",
    "    \n",
    "    # get 3D coordinate\n",
    "    reconstructed_coordinate_dict = get_coordinate_from_decomposition(decomposed_mean_distance_map)\n",
    "    \n",
    "    return reconstructed_coordinate_dict\n",
    "\n",
    "    \n",
    "    \n",
    "def plot_single_peptide(peptide_coordinate_dict, centroid=False):\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "    \n",
    "    for residue in peptide_coordinate_dict:\n",
    "        point = peptide_coordinate_dict[residue]\n",
    "        x.append(point[0])\n",
    "        y.append(point[1])\n",
    "        z.append(point[2])\n",
    "\n",
    "\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    z = np.asarray(z)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes(projection='3d')\n",
    "    ax.scatter3D(x,y,z, c='b')\n",
    "    \n",
    "    if centroid == True:\n",
    "            median_centroid = [np.median(x), np.median(y), np.median(z)]\n",
    "            ax.scatter3D(median_centroid[0], median_centroid[1], median_centroid[2], c='r')\n",
    "            \n",
    "    return plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open and clean .gro file\n",
    "# return list with an entry for every residue plus info\n",
    "start = timer()\n",
    "cleaned_gro_seed_1 = clean_gro(seed_1_path)\n",
    "end = timer()\n",
    "print(end - start)\n",
    "\n",
    "# return a dict with residue coordinate\n",
    "start = timer()\n",
    "coordinate_dict_seed_1 = get_coordinate_dict_from_cleaned_gro(cleaned_gro_seed_1)\n",
    "end = timer()\n",
    "print(end - start)\n",
    "\n",
    "# compute distance maps and return a n_peptide x n_peptide x n_res x n_res array ## from .gro coordinate dict\n",
    "start = timer()\n",
    "distance_maps_seed_1 = compute_distance_maps_from_coordinate_dict(coordinate_dict_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "# compute contact maps from distance maps\n",
    "start = timer()\n",
    "contact_maps_seed_1 = compute_contact_maps_as_array(distance_maps_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "# compute cross correlation and get values\n",
    "start = timer()\n",
    "normalized_cross_correlation_results_seed_1 = normalized_cross_correlation_for_dataset(contact_maps_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "# denoise dataset\n",
    "start = timer()\n",
    "denoised_dict_seed_1 = denoise_full_dataset(contact_maps_seed_1, normalized_cross_correlation_results_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "# recreate full contact map dataset mirrroring the upper triangle\n",
    "# return dict\n",
    "start = timer()\n",
    "full_denoised_dict_seed_1 = reconstruct_full_matrix(denoised_dict_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "#create graph\n",
    "start = timer()\n",
    "graph_seed_1 = nx_graph_search(full_denoised_dict_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "#search subgraph\n",
    "start = timer()\n",
    "subgrap_list_seed_1 = find_subgraph(graph_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "#find mean distance map\n",
    "start = timer()\n",
    "mean_distance_map_seed_1 = get_mean_distance_map(distance_maps_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "# decompose mean distance matrix\n",
    "start = timer()\n",
    "decomposed_mean_distance_map = decompose_distance_map(mean_distance_map_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "      \n",
    "# get coordinate from distance map      \n",
    "start = timer()\n",
    "reconstructed_coordinate_dict = get_coordinate_from_decomposition(decomposed_mean_distance_map)\n",
    "end = timer()\n",
    "print(end-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS FOR 3D VIEW OF PLOT\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS TO CLOSE ALL PLOT (run multiple time this cell if it does not work)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the reconstructed average peptide \n",
    "plot_single_peptide(reconstructed_coordinate_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot full coordinate from dict\n",
    "plot_peptide_list(coordinate_dict_seed_1, [e for e in coordinate_dict_seed_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRAJECTORY\n",
    "\n",
    "# using mdanalysis module\n",
    "\n",
    "\n",
    "#create Universe from a .gro with coordinates and an .xtc with the trajectory data\n",
    "u = mda.Universe(trj_gro,trj_xtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dict from a Universe in which each entry is a timestep of the MD simulation\n",
    "def create_trajectory_dict(u):\n",
    "    bb = u.select_atoms('name BB')\n",
    "    trajectory_dict = {}\n",
    "    for index, time_steps in enumerate(u.trajectory):\n",
    "        trajectory_dict[index] = bb.positions\n",
    "    return trajectory_dict\n",
    "\n",
    "# make trajectory dict\n",
    "trajectory_dict = create_trajectory_dict(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you change the number in the first parentesis, you change timestep\n",
    "#second parentesis are the bb grains\n",
    "pep = trajectory_dict[0][:1200] # this are all the coordinate of bb grains of timestep 0, as an array\n",
    "\n",
    "#cast coordinate from array to dict\n",
    "zero_c = get_coordinate_from_decomposition(pep)\n",
    "\n",
    "#plot dict as a single object\n",
    "plot_single_peptide(zero_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see the trajectory you need to install ngl-view\n",
    "# https://github.com/arose/nglview\n",
    "#\n",
    "# pay attention to this:\n",
    "#   pip install nglview\n",
    "#\n",
    "# in a terminal, in the env where ngl-view is installed, send this:\n",
    "# jupyter-nbextension enable nglview --py --sys-prefix\n",
    "#\n",
    "\n",
    "\n",
    "view = nv.show_mdanalysis(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class morphoscanner():\n",
    "    \n",
    "    \n",
    "    \n",
    "    class math_utility():\n",
    "\n",
    "        # take array, return vector with sum along columns\n",
    "        def get_row_vector(array):\n",
    "            row_vector = np.sum(array, axis=0)\n",
    "            return row_vector\n",
    "\n",
    "        # take array, return vector with sum along row\n",
    "        def get_col_vector(array):\n",
    "            col_vector = np.sum(array, axis=1)\n",
    "            return col_vector\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    class read():\n",
    "        \n",
    "        # READ .gro FILE AND PREPROCESSING\n",
    "\n",
    "        def clean_gro(path):\n",
    "\n",
    "\n",
    "                # open file .gro and return a list with one element per line of the .gro file\n",
    "            def read_gro(path):\n",
    "                gromacs_output = open(path)\n",
    "\n",
    "                gro_file = []\n",
    "                for line in tqdm.tqdm(gromacs_output):\n",
    "                    gro_file.append(line)\n",
    "\n",
    "\n",
    "\n",
    "                gromacs_output.close()        \n",
    "\n",
    "                return gro_file\n",
    "\n",
    "\n",
    "\n",
    "            # return string in a string with numbers\n",
    "            def return_if_string(string):\n",
    "                digits = []\n",
    "                for i in string:\n",
    "                    if not i.isdigit():\n",
    "                        digits.append(i)\n",
    "\n",
    "                string = ''.join(digits)\n",
    "\n",
    "                return string\n",
    "\n",
    "\n",
    "            # return numbers in a string with numbers\n",
    "            def return_if_digit(string):\n",
    "                digits = []\n",
    "                for i in string:\n",
    "                    if i.isdigit():\n",
    "                        digits.append(i)\n",
    "\n",
    "                string = ''.join(digits)\n",
    "\n",
    "                return string\n",
    "\n",
    "\n",
    "            # remove first, second and last lines from gro_file and reorder information\n",
    "            # FIX OPTION TO GET ENTRY RELATED TO A LABEL (as 'bb' or 'ca')\n",
    "            def clean_gro_file(gro_file):\n",
    "                cleaned_gro_file = []\n",
    "                for aminoacid in tqdm.tqdm(gro_file[2:-1]):\n",
    "                    splitted = aminoacid.split()\n",
    "                    if splitted[1] == 'BB':\n",
    "                        position_in_peptide = return_if_digit(splitted[0])\n",
    "                        residue = return_if_string(splitted[0])\n",
    "                        index = splitted[2]\n",
    "                        x = splitted[3]\n",
    "                        y = splitted[4]\n",
    "                        z = splitted[5]\n",
    "                        cleaned_gro_file.append([index, position_in_peptide, residue, x, y, z])\n",
    "                return cleaned_gro_file\n",
    "\n",
    "\n",
    "            gro_file = read_gro(path)\n",
    "            cleaned_gro_file = clean_gro_file(gro_file)\n",
    "\n",
    "            return cleaned_gro_file\n",
    "        \n",
    "        # create coordinate dict from cleaned_gro_file\n",
    "        def get_coordinate_dict_from_cleaned_gro(cleaned_gro_file):\n",
    "\n",
    "            peptide_lenght_list = []\n",
    "\n",
    "            temporary_list = []\n",
    "\n",
    "            # iterate trough cleaned_gro_file\n",
    "            for residue in cleaned_gro_file:\n",
    "\n",
    "                # if temporary list just started, add aminoacid position in chain\n",
    "                if len(temporary_list) == 0:\n",
    "                    temporary_list.append(int(residue[1]))\n",
    "\n",
    "                else:\n",
    "                    # if position of actual residue is less than last residue\n",
    "                    if temporary_list[-1] > int(residue[1]):\n",
    "\n",
    "                        # append lenght of last peptide to peptide lenght list\n",
    "                        peptide_lenght_list.append(len(temporary_list))\n",
    "\n",
    "                        # empty temporary list\n",
    "                        temporary_list = []\n",
    "\n",
    "                        # append actual residue position\n",
    "                        temporary_list.append(int(residue[1]))\n",
    "\n",
    "                    # if position of actual residue is higher than last residue, ad current residue position\n",
    "                    else:\n",
    "                        temporary_list.append(int(residue[1]))\n",
    "\n",
    "            # append last peptide lenght to lenght stack\n",
    "            peptide_lenght_list.append(len(temporary_list))\n",
    "\n",
    "            # create empty dict for coordinate\n",
    "            peptide_coordinate_dict = {}\n",
    "\n",
    "            # create an entry in dict for every peptide in the file\n",
    "            for peptide in range(len(peptide_lenght_list)):\n",
    "                peptide_coordinate_dict[peptide] = {}\n",
    "\n",
    "                # for every residue in lenght peptide, add coordinate x, y, z\n",
    "                for residue in range(peptide_lenght_list[peptide]):\n",
    "                    peptide_coordinate_dict[peptide][residue] = [float(coordinate) for coordinate in cleaned_gro_file[(peptide * peptide_lenght_list[peptide])+residue][3:]]\n",
    "\n",
    "            return peptide_coordinate_dict\n",
    "        \n",
    "        \n",
    "        def get_coordinate_dict_from_cleaned_gro_for_fixed_lenght_peptides(cleaned_gro_file, peptide_lenght):\n",
    "            '''Works only with system made of peptide of equal peptide length\n",
    "                (the peptide in the trajectory have all the same number of aminoacids).\n",
    "\n",
    "            Usefull to disassemble premade aggregate in a system of omogenous peptide lenght'''\n",
    "\n",
    "            peptide_coordinate_dict = {}\n",
    "\n",
    "            for peptide in range(len(cleaned_gro_file)//peptide_lenght):\n",
    "\n",
    "                peptide_coordinate_dict[peptide] = {}\n",
    "\n",
    "                peptide_data = cleaned_gro_file[(peptide*peptide_lenght):((peptide*peptide_lenght)+peptide_lenght)]\n",
    "\n",
    "                for index, amino in enumerate(peptide_data):\n",
    "\n",
    "                    peptide_coordinate_dict[peptide][index] = [float(amino[3]), float(amino[4]), float(amino[5])] ## can you generalize this 3? Maybe with re or isdigit function??\n",
    "\n",
    "            return peptide_coordinate_dict\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    class distance():\n",
    "        \n",
    "        # compute euclidean distance\n",
    "        def get_euclidean_distance(point_1, point_2):\n",
    "\n",
    "            euclidean_distance = np.sqrt(np.sum([((point_1[0] - point_2[0])**2), ((point_1[1] - point_2[1])**2), ((point_1[2] - point_2[2])**2)]))\n",
    "\n",
    "            return euclidean_distance\n",
    "\n",
    "        # compute distance map between two peptides\n",
    "        def compute_distance_map(coordinate_dict, peptide_1, peptide_2):\n",
    "\n",
    "            distance_map = []\n",
    "            for amino_1 in coordinate_dict[peptide_1]:\n",
    "                coordinate_1 = coordinate_dict[peptide_1][amino_1]\n",
    "\n",
    "                distance_map.append([amino_1])\n",
    "\n",
    "                for amino_2 in coordinate_dict[peptide_2]:\n",
    "                    coordinate_2 = coordinate_dict[peptide_2][amino_2]\n",
    "\n",
    "                    euclidean_distance = morphoscanner.distance.get_euclidean_distance(coordinate_1, coordinate_2)\n",
    "                    distance_map[amino_1].append(euclidean_distance)\n",
    "\n",
    "                del distance_map[amino_1][0]\n",
    "\n",
    "            distance_map = np.asarray(distance_map)\n",
    "\n",
    "            return distance_map\n",
    "\n",
    "        # compute distance map and return a n_peptide x n_peptide x n_res x n_res array\n",
    "        def compute_distance_maps_from_coordinate_dict(coordinate_dict):\n",
    "\n",
    "            aggregate_distance_map = []\n",
    "\n",
    "            for peptide_1 in tqdm.tqdm(coordinate_dict):\n",
    "            #for peptide_1 in coordinate_dict:\n",
    "                aggregate_distance_map.append([peptide_1])\n",
    "\n",
    "                #for peptide_2 in tqdm.tqdm(coordinate_dict):\n",
    "                for peptide_2 in coordinate_dict:\n",
    "                    distance_map = morphoscanner.distance.compute_distance_map(coordinate_dict, peptide_1, peptide_2)\n",
    "\n",
    "                    aggregate_distance_map[peptide_1].append(distance_map)\n",
    "\n",
    "                del aggregate_distance_map[peptide_1][0]\n",
    "\n",
    "            aggregate_distance_array = np.asarray(aggregate_distance_map)\n",
    "\n",
    "            return aggregate_distance_array\n",
    "\n",
    "\n",
    "        # COMPUTE CONTACT MAPS\n",
    "        # TO DO: parametrize the threshold distance in a better way (e.g. )\n",
    "        def compute_contact_maps_as_array(distance_maps_array):\n",
    "\n",
    "            # distance between the first and the second aminoacid of the first chain\n",
    "            intrapeptide_minimum_distance = distance_maps_array[0][0][0][1] \n",
    "\n",
    "            contact_map_list = []\n",
    "\n",
    "            # contact is in a distance up to 150% of the intrapeptide_minimum_distance [TO IMPROVE!!!]\n",
    "            threshold_distance = (intrapeptide_minimum_distance * 1.5)\n",
    "\n",
    "            for model_1 in range(distance_maps_array.shape[0]):\n",
    "                contact_map_list.append([])\n",
    "                for model_2 in range(distance_maps_array[model_1].shape[0]):\n",
    "\n",
    "                    contact_map_list[model_1].append([])\n",
    "\n",
    "                    if model_1 == model_2:\n",
    "\n",
    "                        contact_map_list[model_1][model_2].extend(np.zeros((distance_maps_array.shape[2], distance_maps_array.shape[3])))\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        contact_map = np.zeros((distance_maps_array.shape[2], distance_maps_array.shape[3]))\n",
    "\n",
    "                        for chain_1 in range(distance_maps_array[model_1][model_2].shape[0]):\n",
    "\n",
    "                            for chain_2 in range(distance_maps_array[model_1][model_2][chain_1].shape[0]):\n",
    "\n",
    "                                distance = distance_maps_array[model_1][model_2][chain_1][chain_2]\n",
    "\n",
    "                                if distance < threshold_distance:\n",
    "                                    contact_map[chain_1][chain_2] = 1 #True\n",
    "                                else:\n",
    "                                    pass\n",
    "\n",
    "                        contact_map_list[model_1][model_2].extend(contact_map)\n",
    "\n",
    "            contact_array = np.asarray(contact_map_list)\n",
    "\n",
    "            return contact_array\n",
    "        \n",
    "        \n",
    "        \n",
    "        # get average distance map from distance maps set\n",
    "        def get_mean_distance_map(distance_maps):\n",
    "            '''\n",
    "            Calculate mean distance map from distance maps set\n",
    "\n",
    "            Argument: distance maps set\n",
    "\n",
    "            return: np.array with average intrapeptide distance\n",
    "\n",
    "            '''\n",
    "\n",
    "            # create array of zeros of shape number_of_residues * number_of_residues\n",
    "            # depending on peptide residue number ### TO FIX FOR MULTIMONOMERIC ASSEMBLY\n",
    "            base = np.zeros((distance_maps[0][0].shape[0], distance_maps[0][0].shape[1]))\n",
    "\n",
    "            # initialize counter\n",
    "            counter = 0\n",
    "\n",
    "            # iterate throught peptides in the aggregate\n",
    "            for peptide_1 in range(distance_maps.shape[0]):\n",
    "                for peptide_2 in range(distance_maps.shape[1]):\n",
    "\n",
    "                    # if peptide index are the same (intrapeptide distance map)\n",
    "                    if peptide_1 == peptide_2:\n",
    "\n",
    "                        # intrapeptide distance map\n",
    "                        actual_distance_map = distance_maps[peptide_1][peptide_2]\n",
    "\n",
    "                        # sum base and current distance map\n",
    "                        base = base + actual_distance_map\n",
    "\n",
    "                        #update counter\n",
    "                        counter += 1\n",
    "\n",
    "            #for element in base (every element is the sum of distance_map(i,j) for every distance map)\n",
    "            for row in range(len(base)):\n",
    "                for col in range(len(base)):\n",
    "\n",
    "                    # find the mean for every element of the cumulative distance map\n",
    "                    base[row][col] = (base[row][col])/counter\n",
    "\n",
    "            return base\n",
    "\n",
    "        # Singolar Value Decomposition of distance_map\n",
    "        def decompose_distance_map(distance_map):\n",
    "            '''Use Singular value decomposition to get\n",
    "\n",
    "            distance_map.shape[1] dimensional coordinate\n",
    "            (same n of dimension as the peptide n of residue)\n",
    "\n",
    "            As described in:\n",
    "            Mathematical Modeling of Protein Structure Using Distance Geometry\n",
    "            Jeong-Mi Yoon, Yash Gad, Zhijun Wu\n",
    "\n",
    "            Argument: distance map (numpy.array 2D)\n",
    "            return: X : actual decomposition\n",
    "\n",
    "\n",
    "            '''\n",
    "\n",
    "            # initialize a zeros matrix of same shape as the input map\n",
    "            D = np.zeros(distance_map.shape)\n",
    "\n",
    "            #iterate trought row\n",
    "            for i in range(distance_map.shape[0]):\n",
    "\n",
    "                # iterate trought cols\n",
    "                for j in range(distance_map.shape[1]):\n",
    "\n",
    "                    # distance between point point i and point j \n",
    "                    dij = distance_map[i][j]\n",
    "\n",
    "                    # distance between point 0 and point j\n",
    "                    d0j = distance_map[0][j]\n",
    "\n",
    "                    #distance between point i and point 0\n",
    "                    di0 = distance_map[i][0]\n",
    "\n",
    "                    #fill the zeros matrix with the value obtained with this formula\n",
    "                    D[i][j] = (d0j**2 + di0**2 - dij**2)/2\n",
    "\n",
    "            # check rank of matrix (should be of rank 3, but it is of rank distance_map.shape[1])\n",
    "            #rank = np.linalg.matrix_rank(D)\n",
    "\n",
    "            # Singular value decomposition on the D matrix\n",
    "            #svd = np.linalg.svd(D)\n",
    "\n",
    "            svd = np.linalg.svd(D, full_matrices=False)\n",
    "\n",
    "            # Calculate distance_map.shape[1] dimensional coordinate, but you need 3\n",
    "            # the non necessary dimension can give data to better reconstruct the peptide structure\n",
    "            X = svd[0]*np.sqrt(svd[1])\n",
    "\n",
    "\n",
    "            #return X, svd, D, rank\n",
    "            return X\n",
    "\n",
    "        def get_coordinate_from_decomposition(decomposition):\n",
    "            '''Take decomposition result and convert it into a coordinate vectors dict\n",
    "\n",
    "            Argument: decomposition results\n",
    "\n",
    "            return: dict with reconstructed 3d coordinate vector\n",
    "\n",
    "            '''\n",
    "\n",
    "            # take only the first three value to compose a 3D coordinate vector\n",
    "            coordinate = [e[:3] for e in decomposition]\n",
    "\n",
    "            # initialize empty dict\n",
    "            reconstructed_coordinate_dict = {}\n",
    "\n",
    "            # fill the dict with the ccordinate vectors\n",
    "            for index,coordinate_vector in enumerate(coordinate):\n",
    "                reconstructed_coordinate_dict[index] = coordinate_vector\n",
    "\n",
    "            return reconstructed_coordinate_dict\n",
    "\n",
    "\n",
    "        # reconstruct 3d coordinate from a distance map\n",
    "        def get_coordinate_from_distance_map(distance_map):\n",
    "            ''' compute 3d coordinate from distance map\n",
    "\n",
    "            Argument: distance_map (numpy.array)\n",
    "\n",
    "            return: dict with 3d coordinate for every alpha-carbon of a peptide\n",
    "\n",
    "            '''\n",
    "            # perform singular value decomposition on distance_map (preprocessed)\n",
    "            decomposed_mean_distance_map = decompose_distance_map(distance_map)\n",
    "\n",
    "\n",
    "            # get 3D coordinate\n",
    "            reconstructed_coordinate_dict = get_coordinate_from_decomposition(decomposed_mean_distance_map)\n",
    "\n",
    "            return reconstructed_coordinate_dict\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    class cross_correlation():\n",
    "        \n",
    "        #### ANALYSIS\n",
    "\n",
    "        def shift_library_maker(contact_map_to_analyze):\n",
    "\n",
    "            ''' riceve numero di righe e di colonne\n",
    "            restituisce un array shape((((row + col)*2)-2),row,col).\n",
    "            ogni slice Ã¨ una diagonale. Lo stack copre le diagonali su tutta la matrice'''\n",
    "\n",
    "            row = contact_map_to_analyze.shape[0]\n",
    "            col = contact_map_to_analyze.shape[1]\n",
    "\n",
    "            kron_dict = {}\n",
    "            kron_list_parallel = []\n",
    "            kron_list_antiparallel = []\n",
    "\n",
    "            for e in range(-row+1, col):\n",
    "                array = np.eye(row, col, e)\n",
    "                kron_list_parallel.append(array)\n",
    "                kron_list_antiparallel.append(np.fliplr(array))\n",
    "\n",
    "            kron_array_parallel = np.asarray(kron_list_parallel)\n",
    "            kron_array_antiparallel = np.asarray(kron_list_antiparallel)\n",
    "\n",
    "            kron_dict['parallel'] = kron_array_parallel\n",
    "            kron_dict['antiparallel'] = kron_array_antiparallel\n",
    "\n",
    "            return kron_dict\n",
    "\n",
    "\n",
    "        def normalized_cross_correlation_function(contact_map):\n",
    "            '''\n",
    "            Calculate normalized cross correlation function between a contact map and an ideal map.\n",
    "\n",
    "            Arguments : contact map, as output from get_contact_maps function\n",
    "                        shift_matrix_stack, as output from shift_matrix_maker function\n",
    "\n",
    "            Return : a list [ncc_value, index (in the shift_matrix_stack) of the shift matrix\n",
    "                        that is matching the contact map\n",
    "\n",
    "                    '''\n",
    "            shift_matrix_library = morphoscanner.cross_correlation.shift_library_maker(contact_map)\n",
    "\n",
    "            cross_correlation_values = []\n",
    "            max_val = []\n",
    "            sum_contact_map = np.sum(contact_map)\n",
    "\n",
    "            if sum_contact_map < 2:\n",
    "                pass\n",
    "\n",
    "            else:\n",
    "                for sense in shift_matrix_library:\n",
    "                    for index, z in enumerate(shift_matrix_library[sense]):\n",
    "\n",
    "                        shift_matrix = shift_matrix_library[sense][index]\n",
    "                        sum_shift_matrix = np.sum(shift_matrix)\n",
    "                        ncc_value = (np.sum((contact_map * shift_matrix))/((np.sqrt(sum_contact_map))*(np.sqrt(sum_shift_matrix))))  # normalized cross correlation function of contact matrix and shift matrix\n",
    "                        cross_correlation_values.append([ncc_value, index, sum_contact_map, sense])\n",
    "\n",
    "                    max_val = max(cross_correlation_values) # get only the best match (highest value of ncc)\n",
    "\n",
    "            return max_val\n",
    "\n",
    "\n",
    "\n",
    "        def normalized_cross_correlation_for_dataset(contact_array):\n",
    "            '''Calculate normalized cross correlation function between the full contacts map and and the .\n",
    "\n",
    "            Arguments : contact map, as output from get_contact_maps function\n",
    "                        shift_matrix_stack, as output from shift_matrix_maker function\n",
    "\n",
    "            Return : a list [ncc_value, index (in the shift_matrix_stack) of the shift matrix that is matching the contact map'''\n",
    "\n",
    "            contact_dict = {}\n",
    "\n",
    "            #for row in tqdm.tqdm(range(contact_array.shape[0])):\n",
    "            for row in range(contact_array.shape[0]):\n",
    "\n",
    "                for col in range((row+1), contact_array.shape[1]):\n",
    "                #for col in range(contact_array.shape[1]):\n",
    "\n",
    "                    best_match = []\n",
    "                    best_match = morphoscanner.cross_correlation.normalized_cross_correlation_function(contact_array[row][col])\n",
    "\n",
    "                    if len(best_match) == 0:\n",
    "                        pass\n",
    "\n",
    "                    else:\n",
    "                        if row in contact_dict:\n",
    "                            contact_dict[row].append([row, col, best_match])\n",
    "\n",
    "                        else:\n",
    "                            contact_dict[row] = [[row, col, best_match]]\n",
    "\n",
    "            return contact_dict\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    class denoise():\n",
    "        \n",
    "        \n",
    "        #denoise dataset\n",
    "        def denoise_contact_maps(contact_maps):\n",
    "            \n",
    "            '''Denoise the contact_maps dataset using the shift_matrix\n",
    "            \n",
    "            Arguments : contact_maps, normalized_cross_correlation_result\n",
    "            \n",
    "            return : a dict with key:value = row : row, col, denoised_map\n",
    "            \n",
    "            '''\n",
    "        \n",
    "            normalized_cross_correlation_results = morphoscanner.cross_correlation.normalized_cross_correlation_for_dataset(contact_maps)\n",
    "        \n",
    "        \n",
    "            denoised_dict = {}\n",
    "        \n",
    "            for peptide_1 in normalized_cross_correlation_results:\n",
    "                denoised_dict[peptide_1] = {}\n",
    "                for index, peptide_2 in enumerate(normalized_cross_correlation_results[peptide_1]):\n",
    "        \n",
    "                    row = peptide_2[0]\n",
    "                    col = peptide_2[1]\n",
    "        \n",
    "        \n",
    "        \n",
    "                    contact_map = contact_maps[row][col]\n",
    "                    sense = peptide_2[2][3]\n",
    "                    shift_matrix_index = normalized_cross_correlation_results[peptide_1][index][2][1]\n",
    "        \n",
    "                    shift_matrix = morphoscanner.cross_correlation.shift_library_maker(contact_map)\n",
    "                    shift_matrix = shift_matrix[sense][shift_matrix_index]\n",
    "                    denoised_map = contact_map * shift_matrix\n",
    "        \n",
    "                    denoised_dict[row][col] = denoised_map\n",
    "                    \n",
    "                    \n",
    "            full_denoised_dict = {}\n",
    "            for peptide_1 in tqdm.tqdm(denoised_dict):\n",
    "                for peptide_2 in denoised_dict[peptide_1]:\n",
    "                    contact_map = denoised_dict[peptide_1][peptide_2]\n",
    "        \n",
    "                    if peptide_1 in full_denoised_dict:\n",
    "                        full_denoised_dict[peptide_1][peptide_2] = contact_map\n",
    "        \n",
    "                    if peptide_1 not in full_denoised_dict:\n",
    "                        full_denoised_dict[peptide_1] = {peptide_2:contact_map}\n",
    "        \n",
    "                    if peptide_2 in full_denoised_dict:\n",
    "                        full_denoised_dict[peptide_2][peptide_1] = contact_map.T\n",
    "        \n",
    "                    if peptide_2 not in full_denoised_dict:\n",
    "                        full_denoised_dict[peptide_2] = {peptide_1:contact_map.T}\n",
    "            \n",
    "            return full_denoised_dict\n",
    "         \n",
    "        \n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    class graph():\n",
    "        \n",
    "        # graph clustering\n",
    "        def nx_graph_search(denoised_dict):\n",
    "\n",
    "            graph = nx.MultiGraph()\n",
    "\n",
    "            for peptide_1 in denoised_dict:\n",
    "                for peptide_2 in denoised_dict[peptide_1]:\n",
    "                    array_1 = denoised_dict[peptide_1][peptide_2]\n",
    "                    for peptide_3 in denoised_dict[peptide_2]:\n",
    "                        if peptide_3 != peptide_1:\n",
    "                            array_2 = denoised_dict[peptide_2][peptide_3]\n",
    "\n",
    "                            vect_1 = morphoscanner.math_utility.get_row_vector(array_1)\n",
    "                            vect_2 = morphoscanner.math_utility.get_col_vector(array_2)\n",
    "\n",
    "                            contacts = np.dot(vect_1, vect_2)\n",
    "\n",
    "                            if contacts >= 3:\n",
    "\n",
    "                                graph.add_edge(peptide_1, peptide_2)\n",
    "\n",
    "                                graph.add_edge(peptide_2, peptide_3)\n",
    "\n",
    "            return graph\n",
    "\n",
    "        #A novel graph clustering algorithm based on discrete-time quantum random walk\n",
    "        #S.G. Roya, A. Chakrabarti\n",
    "\n",
    "\n",
    "        # working with networkX\n",
    "        # if contacts >= target\n",
    "\n",
    "        # when you add_edge, nodes are created if they are not there\n",
    "        # you can put info in edge (as distance, n of contacts, contact map)\n",
    "        # you  can   put key to index multiple nodes that are joined with a single node\n",
    "        # \n",
    "        # add edge from pep1 to pep2 (you HAVE TO (###to explore utility of key) put key to index multiple nodes that are joined with a single node)\n",
    "        # add edge from pep3 to pep3 ( same as before with key)\n",
    "\n",
    "\n",
    "        #FIND SUBGRAPH\n",
    "        def find_subgraph(graph):\n",
    "            '''\n",
    "            Find subgraph that have no node in common.\n",
    "\n",
    "            Argument: NetworkX MultiGraph\n",
    "\n",
    "            Return: list of subgraph ordered from one end to the other\n",
    "\n",
    "            '''\n",
    "\n",
    "            subgraph_list = []\n",
    "\n",
    "            for node in graph:\n",
    "\n",
    "                # don't explore node that are already in subgraph_list\n",
    "                if node not in set(nod for nod_list in subgraph_list for nod in nod_list):\n",
    "\n",
    "                    # tree is the list of nodes joined to node, starting from node\n",
    "                    # using depht first search\n",
    "                    tree = [e for e in nx.algorithms.traversal.depth_first_search.dfs_tree(graph, node)]\n",
    "\n",
    "                    # check if the first node of the tree has adjiacency == 1\n",
    "                    # so it checks if it is the first or last node of the subgraph\n",
    "                    if len(graph[tree[0]]) == 1:\n",
    "\n",
    "                        if len(subgraph_list) == 0:\n",
    "                            subgraph_list.append(tree)\n",
    "\n",
    "                        else:\n",
    "                            # use generator to check if the tree is already in the subgraph\n",
    "                            if set(tree) not in (set(i) for i in subgraph_list):\n",
    "                                subgraph_list.append(tree)\n",
    "\n",
    "            return subgraph_list\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "              \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    class plot():\n",
    "        ########## PLOT PEPTIDE LIST\n",
    "        # plot a list of peptide point cloud in 3d space.\n",
    "        # The box axis have arbitrary scale dependent on the aminoacids distance\n",
    "        # you can select to show the centroid\n",
    "        def plot_peptide_list(coordinate_dict, peptide_list, centroid=False):\n",
    "            x = []\n",
    "            y = []\n",
    "            z = []\n",
    "            x_median = float\n",
    "            y_median = float\n",
    "            z_median = float\n",
    "\n",
    "\n",
    "            for peptide in range(len(peptide_list)):\n",
    "                x.append([peptide])\n",
    "                y.append([peptide])\n",
    "                z.append([peptide])\n",
    "                for aminoacid in coordinate_dict[peptide_list[peptide]]:\n",
    "\n",
    "                    point = coordinate_dict[peptide_list[peptide]][aminoacid]\n",
    "                    x[peptide].append(point[0])\n",
    "                    y[peptide].append(point[1])\n",
    "                    z[peptide].append(point[2])\n",
    "\n",
    "                del x[peptide][0]\n",
    "                del y[peptide][0]\n",
    "                del z[peptide][0]\n",
    "\n",
    "            if centroid == True:\n",
    "\n",
    "                def assemble_coordinate(axis_coordinate_list):\n",
    "                    median_list = []\n",
    "                    for coordinate_set in axis_coordinate_list:\n",
    "                        median = np.median(coordinate_set)\n",
    "                        median_list.append(median)\n",
    "                    return median_list\n",
    "\n",
    "                x_median = assemble_coordinate(x)\n",
    "                y_median = assemble_coordinate(y)\n",
    "                z_median = assemble_coordinate(z)\n",
    "\n",
    "\n",
    "            #%matplotlib notebook\n",
    "\n",
    "            fig = plt.figure()\n",
    "            \n",
    "            ax = plt.axes(projection='3d')\n",
    "            \n",
    "\n",
    "            for pep in range(len(x)):\n",
    "\n",
    "                ax.scatter3D(x[pep],y[pep],z[pep])\n",
    "\n",
    "                if centroid == True:\n",
    "\n",
    "                    ax.scatter3D(x_median[pep], y_median[pep], z_median[pep], c='red')\n",
    "\n",
    "\n",
    "            #return  plt.show(), [x,y,z], [x_median, y_median, z_median]         \n",
    "            return plt.show()\n",
    "        \n",
    "        \n",
    "        # plot single peptide (with autoscaling of axes)\n",
    "        def plot_single_peptide(peptide_coordinate_dict, centroid=False):\n",
    "            x = []\n",
    "            y = []\n",
    "            z = []\n",
    "\n",
    "            for residue in peptide_coordinate_dict:\n",
    "                point = peptide_coordinate_dict[residue]\n",
    "                x.append(point[0])\n",
    "                y.append(point[1])\n",
    "                z.append(point[2])\n",
    "\n",
    "\n",
    "            x = np.asarray(x)\n",
    "            y = np.asarray(y)\n",
    "            z = np.asarray(z)\n",
    "\n",
    "            fig = plt.figure()\n",
    "            ax = plt.axes(projection='3d')\n",
    "            ax.scatter3D(x,y,z, c='b')\n",
    "\n",
    "\n",
    "            if centroid == True:\n",
    "                median_centroid = [np.median(x), np.median(y), np.median(z)]\n",
    "                ax.scatter3D(median_centroid[0], median_centroid[1], median_centroid[2], c='r')\n",
    "\n",
    "            # Create cubic bounding box to simulate equal aspect ratio\n",
    "            max_range = np.array([x.max()-x.min(), y.max()-y.min(), z.max()-z.min()]).max()\n",
    "            Xb = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][0].flatten() + 0.5*(x.max()+x.min())\n",
    "            Yb = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][1].flatten() + 0.5*(y.max()+y.min())\n",
    "            Zb = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][2].flatten() + 0.5*(z.max()+z.min())\n",
    "            # Comment or uncomment following both lines to test the fake bounding box:\n",
    "            for xb, yb, zb in zip(Xb, Yb, Zb):\n",
    "                ax.plot([xb], [yb], [zb], 'w')\n",
    "\n",
    "            return plt.show()\n",
    "        \n",
    "    \n",
    "    # class for high level functionality, premade workflow...\n",
    "    class high_level():\n",
    "        \n",
    "        # automatically infer peptide lenght\n",
    "        def coordinate_dict_from_gro(gro_file):\n",
    "            \n",
    "            cleaned = morphoscanner.read.clean_gro(gro_file)\n",
    "            \n",
    "            coordinate = morphoscanner.read.get_coordinate_dict_from_cleaned_gro(cleaned)\n",
    "            \n",
    "            return coordinate\n",
    "        \n",
    "        \n",
    "        #specify peptide lenght\n",
    "        def coordinate_dict_from_gro_fix_len_peptide(gro_file, peptide_lenght):\n",
    "            \n",
    "            cleaned = morphoscanner.read.clean_gro(gro_file)\n",
    "            \n",
    "            coordinate = morphoscanner.read.get_coordinate_dict_from_cleaned_gro_for_fixed_lenght_peptides(cleaned, peptide_lenght)\n",
    "            \n",
    "            return coordinate\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with class library\n",
    "cleaned = morphoscanner.read.clean_gro(trj_gro)\n",
    "coordinate_dict = morphoscanner.read.get_coordinate_dict_from_cleaned_gro(cleaned)\n",
    "trj0_coordinate = morphoscanner.read.get_coordinate_dict_from_cleaned_gro_for_fixed_lenght_peptides(cleaned, 12)\n",
    "trj0_distance_maps = morphoscanner.distance.compute_distance_maps_from_coordinate_dict(trj0_coordinate)\n",
    "trj0_contact_maps = morphoscanner.distance.compute_contact_maps_as_array(trj0_distance_maps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj0_denoised_dict = morphoscanner.denoise.denoise_contact_maps(trj0_contact_maps)\n",
    "trj0_graph = morphoscanner.graph.nx_graph_search(trj0_denoised_dict)\n",
    "trj0_subgraph = morphoscanner.graph.find_subgraph(trj0_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot_peptide_list(trj0_coordinate, [e for e in trj0_coordinate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute distance maps and return a n_peptide x n_peptide x n_res x n_res array ## from .gro coordinate dict\n",
    "start = timer()\n",
    "distance_maps_seed_1 = compute_distance_maps_from_coordinate_dict(coordinate_dict_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "# compute contact maps from distance maps\n",
    "start = timer()\n",
    "contact_maps_seed_1 = compute_contact_maps_as_array(distance_maps_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "# compute cross correlation and get values\n",
    "start = timer()\n",
    "normalized_cross_correlation_results_seed_1 = normalized_cross_correlation_for_dataset(contact_maps_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "# denoise dataset\n",
    "start = timer()\n",
    "denoised_dict_seed_1 = denoise_full_dataset(contact_maps_seed_1, normalized_cross_correlation_results_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "# recreate full contact map dataset mirroring the upper triangle\n",
    "# return dict\n",
    "start = timer()\n",
    "full_denoised_dict_seed_1 = reconstruct_full_matrix(denoised_dict_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "#create graph\n",
    "start = timer()\n",
    "graph_seed_1 = nx_graph_search(full_denoised_dict_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "#search subgraph\n",
    "start = timer()\n",
    "subgrap_list_seed_1 = find_subgraph(graph_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "#find mean distance map\n",
    "start = timer()\n",
    "mean_distance_map_seed_1 = get_mean_distance_map(distance_maps_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "# decompose mean distance matrix\n",
    "start = timer()\n",
    "decomposed_mean_distance_map = decompose_distance_map(mean_distance_map_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "      \n",
    "# get coordinate from distance map      \n",
    "start = timer()\n",
    "reconstructed_coordinate_dict = get_coordinate_from_decomposition(decomposed_mean_distance_map)\n",
    "end = timer()\n",
    "print(end-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj0_mean_distance = morphoscanner.distance.get_mean_distance_map(trj0_distance_maps)\n",
    "\n",
    "plt.imshow(trj0_mean_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = u.select_atoms('name BB')\n",
    "    #trajectory_dict = {}\n",
    "    #for index, time_steps in enumerate(u.trajectory):\n",
    "     #   trajectory_dict[index] = bb.positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nx.draw_networkx(trj0_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj0_subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with class library\n",
    "\n",
    "cleaned = morphoscanner.read.clean_gro(trj_gro)\n",
    "coordinate_dict = morphoscanner.read.get_coordinate_dict_from_cleaned_gro(cleaned)\n",
    "trj0_coordinate = morphoscanner.read.get_coordinate_dict_from_cleaned_gro_for_fixed_lenght_peptides(cleaned, 12)\n",
    "trj0_distance_maps = morphoscanner.distance.compute_distance_maps_from_coordinate_dict(trj0_coordinate)\n",
    "trj0_contact_maps = morphoscanner.distance.compute_contact_maps_as_array(trj0_distance_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinate_dict_from_cleaned_gro_for_fixed_lenght_peptides(cleaned_gro_file, peptide_lenght):\n",
    "    '''Works only with system made of peptide of equal peptide length\n",
    "    (the peptide in the trajectory have all the same number of aminoacids).\n",
    "    \n",
    "    Usefull to disassemble premade aggregate in a system of omogenous peptide lenght'''\n",
    "    \n",
    "    peptide_coordinate_dict = {}\n",
    "\n",
    "    for peptide in range(len(cleaned_gro_file)//peptide_lenght):\n",
    "\n",
    "        peptide_coordinate_dict[peptide] = {}\n",
    "\n",
    "        peptide_data = cleaned_gro_file[(peptide*peptide_lenght):((peptide*peptide_lenght)+peptide_lenght)]\n",
    "\n",
    "        for index, amino in enumerate(peptide_data):\n",
    "\n",
    "            peptide_coordinate_dict[peptide][index] = [float(amino[3]), float(amino[4]), float(amino[5])] ## can you generalize this 3? Maybe with re or isdigit function??\n",
    "    \n",
    "    return peptide_coordinate_dict\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj0_coordinate = morphoscanner.read.get_coordinate_dict_from_cleaned_gro_for_fixed_lenght_peptides(cleaned, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peptide_lenght=12\n",
    "for peptide in range(len(cleaned)//peptide_lenght):\n",
    "\n",
    "        peptide_coordinate_dict[peptide] = {}\n",
    "\n",
    "        peptide_data = cleaned[(peptide*peptide_lenght):((peptide*peptide_lenght)+peptide_lenght)]\n",
    "\n",
    "        for index, amino in enumerate(peptide_data):\n",
    "\n",
    "            peptide_coordinate_dict[peptide][index] = [float(amino[3]), float(amino[4]), float(amino[5])] ## can you generalize this 3? May"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192300it [00:00, 2114021.30it/s]\n",
      "100%|ââââââââââ| 192297/192297 [00:00<00:00, 1653621.18it/s]\n",
      "100%|ââââââââââ| 100/100 [00:13<00:00,  7.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# Example with class library\n",
    "cleaned = morphoscanner.read.clean_gro(trj_gro)\n",
    "coordinate_dict = morphoscanner.read.get_coordinate_dict_from_cleaned_gro(cleaned)\n",
    "trj0_coordinate = morphoscanner.read.get_coordinate_dict_from_cleaned_gro_for_fixed_lenght_peptides(cleaned, 12)\n",
    "trj0_distance_maps = morphoscanner.distance.compute_distance_maps_from_coordinate_dict(trj0_coordinate)\n",
    "trj0_contact_maps = morphoscanner.distance.compute_contact_maps_as_array(trj0_distance_maps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj0_denoised_dict = morphoscanner.denoise.denoise_contact_maps(trj0_contact_maps)\n",
    "trj0_graph = morphoscanner.graph.nx_graph_search(trj0_denoised_dict)\n",
    "trj0_subgraph = morphoscanner.graph.find_subgraph(trj0_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj0_mean_distance = morphoscanner.distance.get_mean_distance_map(trj0_distance_maps)\n",
    "trj0_decomposition = morphoscanner.distance.decompose_distance_map(trj0_mean_distance)\n",
    "trj0_mean_coordinate = morphoscanner.distance.get_coordinate_from_decomposition(trj0_decomposition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot_peptide_list(trj0_coordinate,[0,1,2,3,4,5,6,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#morphoscanner.plot.plot_single_peptide(trj0_mean_coordinate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1203it [00:00, 1582235.09it/s]\n",
      "100%|ââââââââââ| 1200/1200 [00:00<00:00, 346779.99it/s]\n"
     ]
    }
   ],
   "source": [
    "t = morphoscanner.high_level.coordinate_dict_from_gro(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot_peptide_list(t, [e for e in t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coordinate_tensor(coordinate_dict):\n",
    "    \n",
    "    dim0 = len(coordinate_dict)\n",
    "    dim1 = len(coordinate_dict[0])\n",
    "    dim2 = len(coordinate_dict[0][0])\n",
    "\n",
    "    zero = torch.zeros([dim0,dim1,dim2], dtype=torch.float32, device='cuda')\n",
    "    \n",
    "    for peptide in coordinate_dict:\n",
    "        \n",
    "        for aminoacid in coordinate_dict[peptide]:\n",
    "\n",
    "            zero[peptide][aminoacid] = torch.cuda.FloatTensor(coordinate_dict[peptide][aminoacid])\n",
    "            \n",
    "    return zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinate_tens = coordinate_tensor(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinate_tens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_tras = coordinate_tens[0].t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero = torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_tras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(9, dtype= torch.float) - 4\n",
    "b = a.reshape((3, 3))\n",
    "torch.norm(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = b[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.norm(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.distance.get_euclidean_distance(b[0], b[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_distances(x, y=None):\n",
    "    '''\n",
    "    Input: x is a Nxd matrix\n",
    "           y is an optional Mxd matirx\n",
    "    Output: dist is a NxM matrix where dist[i,j] is the square norm \n",
    "    between x[i,:] and y[j,:]\n",
    "            if y is not given then use 'y=x'.\n",
    "    i.e. dist[i,j] = ||x[i,:]-y[j,:]||^2\n",
    "    '''\n",
    "    x_norm = (x**2).sum(1).view(-1, 1)\n",
    "    if y is not None:\n",
    "        y_t = torch.transpose(y, 0, 1)\n",
    "        y_norm = (y**2).sum(1).view(1, -1)\n",
    "    else:\n",
    "        y_t = torch.transpose(x, 0, 1)\n",
    "        y_norm = x_norm.view(1, -1)\n",
    "    \n",
    "    dist = x_norm + y_norm - 2.0 * torch.mm(x, y_t)\n",
    "    # Ensure diagonal is zero if x=y\n",
    "    # if y is None:\n",
    "    #     dist = dist - torch.diag(dist.diag)\n",
    "    return torch.clamp(dist, 0.0, np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = coordinate_tens[0]\n",
    "y = coordinate_tens[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_euclidean_norm_torc(nd_tensor, tensor1, tensor2)\n",
    "    \n",
    "    \n",
    "    x_norm = (x**2).sum(1).view(-1, 1)\n",
    "\n",
    "    y_t = torch.transpose(y, 0, 1)\n",
    "    y_norm = (y**2).sum(1).view(1, -1)\n",
    "\n",
    "    dist = torch.sqrt(x_norm + y_norm - 2.0 * torch.mm(x, y_t))\n",
    "\n",
    "        # Ensure diagonal is zero if x=y\n",
    "        # if y is None:\n",
    "        #     dist = dist - torch.diag(dist.diag)\n",
    "    fine = torch.clamp(dist, 0.0, np.inf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_euclidean_norm_torch(coordinate_tensor):\n",
    "    \n",
    "    zero = torch.zeros((coordinate_tensor.shape[0], coordinate_tensor.shape[0], coordinate_tensor.shape[1], coordinate_tensor.shape[1]), dtype=torch.float32, device='cuda')\n",
    "    \n",
    "    for index1, peptide1 in tqdm.tqdm(enumerate(coordinate_tens)):\n",
    "\n",
    "        for index2 in range(index1, coordinate_tens.shape[0]):\n",
    "            peptide2 = coordinate_tens[index2]\n",
    "\n",
    "            x_norm = torch.pow(peptide1, 2).sum(1).view(-1,1)\n",
    "            y_t = torch.transpose(peptide2, 0, 1)\n",
    "            y_norm = torch.pow(peptide2, 2).sum(1).view(-1,1)\n",
    "\n",
    "            #dist = torch.sqrt(x_norm + y_norm - 2.0 * torch.mm(peptide1, y_t))\n",
    "            dist = torch.sqrt(x_norm + y_norm - 2.0 * torch.mm(peptide1, y_t))\n",
    "\n",
    "            #fine = torch.clamp(dist, 0.0, np.inf)\n",
    "            \n",
    "            zero[index1][index2] = dist\n",
    "            \n",
    "            \n",
    "    \n",
    "    return zero\n",
    "#https://discuss.pytorch.org/t/efficient-distance-matrix-computation/9065\n",
    "#https://www.dropbox.com/h?preview=Parallel+Euclidean+distance+matrix+computation+on+big+datasets.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:00, 111.27it/s]\n"
     ]
    }
   ],
   "source": [
    "a = compute_euclidean_norm_torch(coordinate_tens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc204224450>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(a[0][0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc2047504d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(trj0_distance_maps[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eucli_dist = morphoscanner.distance.compute_distance_map(t,0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = zip(di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55f38079a21645b7b3f7c9f3dd6c53ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_ColormakerRegistry()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import math\n",
    "#import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import plotly\n",
    "#import plotly.express as px\n",
    "\n",
    "from mpl_toolkits import mplot3d\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "#from functools import lru_cache\n",
    "#import re\n",
    "import networkx as nx\n",
    "#from networkx.algorithms import approximation\n",
    "\n",
    "\n",
    "import MDAnalysis as mda\n",
    "\n",
    "#import scipy\n",
    "#import sklearn\n",
    "#import skimage\n",
    "\n",
    "#import xml.etree.ElementTree as et\n",
    "#from Bio.PDB import *\n",
    "import nglview as nv\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "import dask\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# database to handle data\n",
    "\n",
    "# in function, use dataframe and then pick right data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# http://nglviewer.org/nglview/latest/api.html\n",
    "# https://biopython.org/wiki/The_Biopython_Structural_Bioinformatics_FAQ\n",
    "# https://ambermd.org/tutorials/analysis/tutorial_notebooks/nglview_notebook/index.html\n",
    "# https://amber-md.github.io/pytraj/latest/_api/pytraj.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contact_matrix = np.loadtxt('/home/lillo/TesiCNTE/CNTE/dataset/contact_matrix.txt')   #laptop\n",
    "#contact_matrix = np.loadtxt('/home/lillo/Code/Tesi/dataset/contact_matrix.txt')        #fisso\n",
    "#contact_matrix_single = contact_matrix.reshape(100,100,12,12)\n",
    "\n",
    "#gromacs_output = open('/home/lillo/Code/Tesi/dataset/dm4500Compl_mix1_K2_1%4500ns.gro') #fisso\n",
    "#gromacs_output = open('/home/lillo/TesiCNTE/CNTE/dataset/dm4500Compl_mix1_K2_1%4500ns.gro') #laptop\n",
    "\n",
    "#path = '/home/lillo/Code/Tesi/dataset/dm4500Compl_mix1_K2_1%4500ns.gro' #fisso\n",
    "#path = '/home/lillo/TesiCNTE/CNTE/dataset/dm4500Compl_mix1_K2_1%4500ns.gro' #laptop\n",
    "\n",
    "# import 2mxu file (beta sheet)\n",
    "\n",
    "#path_to_mmCIF = open('/home/lillo/TesiCNTE/pdb/2mxu/2mxu.cif')  ## laptop\n",
    "#path_to_pdb = '/home/lillo/TesiCNTE/pdb/2mxu/2mxu.pdb'  ## laptop\n",
    "#pa_to_pdb = '/home/lillo/TesiCNTE/pdb/2mxu/2mxu.pdb'  ## laptop\n",
    "\n",
    "#path_to_mmCIF = open('/home/lillo/Code/Tesi/pdb/2mxu/2mxu.cif')  ## fisso\n",
    "#path_to_pdb = '/home/lillo/Code/Tesi/pdb/2mxu/2mxu.pdb'  ## fisso\n",
    "#pa_to_pdb = '/home/lillo/Code/Tesi/pdb/2mxu/2mxu.pdb'  ## fisso\n",
    "\n",
    "# aggregate blob\n",
    "\n",
    "#seed_1_path = '/home/lillo/TesiCNTE/from_cluster/aggregate1.gro' # laptop\n",
    "#seed_1_path = '/home/lillo/Code/Tesi/dataset/aggregate1.gro' # Fisso\n",
    "\n",
    "# Trajectory with aggregate seed\n",
    "trj_xtc = '/home/lillo/TesiCNTE/CNTE/trajectory/prd-LDLK12-100mer-out-mol.xtc'  #laptop\n",
    "trj_gro = '/home/lillo/TesiCNTE/CNTE/trajectory/min-LDLK12-100mer-out-c.gro'  #laptop\n",
    "\n",
    "#n_trj_xtc = '/home/lillo/Code/Tesi/dataset/trajectory_6_12_19/prd-LDLK12-100mer-out-mol.xtc'  #fisso\n",
    "#n_trj_gro = '/home/lillo/Code/Tesi/dataset/trajectory_6_12_19/min-LDLK12-100mer-out-c.gro'  #fisso\n",
    "\n",
    "\n",
    "#prod_trr = '/home/lillo/TesiCNTE/from_cluster/prod/prod.trr'   # laptop\n",
    "#prod_tpr = '/home/lillo/TesiCNTE/from_cluster/prod/prod.tpr'   # laptop\n",
    "\n",
    "# part 1\n",
    "prod_xtc = '/home/lillo/TesiCNTE/from_cluster/prod/prod_part1/prod.xtc'   # laptop\n",
    "prod_gro = '/home/lillo/TesiCNTE/from_cluster/prod/prod_part1/min.gro'    # laptop\n",
    "\n",
    "# part 2\n",
    "prod1_xtc = '/home/lillo/TesiCNTE/from_cluster/prod/prod_part2/prod-compl.xtc' #laptop\n",
    "prod1_gro = '/home/lillo/TesiCNTE/from_cluster/prod/prod_part2/prod-compl.gro' #laptop\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ .gro FILE AND PREPROCESSING\n",
    "\n",
    "def clean_gro(path):\n",
    "    \n",
    "    \n",
    "        # open file .gro and return a list with one element per line of the .gro file\n",
    "    def read_gro(path):\n",
    "        gromacs_output = open(path)\n",
    "\n",
    "        gro_file = []\n",
    "        for line in tqdm.tqdm(gromacs_output):\n",
    "            gro_file.append(line)\n",
    "\n",
    "\n",
    "\n",
    "        gromacs_output.close()        \n",
    "\n",
    "        return gro_file\n",
    "\n",
    "\n",
    "\n",
    "    # return string in a string with numbers\n",
    "    def return_if_string(string):\n",
    "        digits = []\n",
    "        for i in string:\n",
    "            if not i.isdigit():\n",
    "                digits.append(i)\n",
    "\n",
    "        string = ''.join(digits)\n",
    "\n",
    "        return string\n",
    "\n",
    "\n",
    "    # return numbers in a string with numbers\n",
    "    def return_if_digit(string):\n",
    "        digits = []\n",
    "        for i in string:\n",
    "            if i.isdigit():\n",
    "                digits.append(i)\n",
    "\n",
    "        string = ''.join(digits)\n",
    "\n",
    "        return string\n",
    "\n",
    "\n",
    "    # remove first, second and last lines from gro_file and reorder information\n",
    "    # FIX OPTION TO GET ENTRY RELATED TO A LABEL (as 'bb' or 'ca')\n",
    "    def clean_gro_file(gro_file):\n",
    "        cleaned_gro_file = []\n",
    "        for aminoacid in tqdm.tqdm(gro_file[2:-1]):\n",
    "            splitted = aminoacid.split()\n",
    "            if splitted[1] == 'BB':\n",
    "                position_in_peptide = return_if_digit(splitted[0])\n",
    "                residue = return_if_string(splitted[0])\n",
    "                index = splitted[2]\n",
    "                x = splitted[3]\n",
    "                y = splitted[4]\n",
    "                z = splitted[5]\n",
    "                cleaned_gro_file.append([index, position_in_peptide, residue, x, y, z])\n",
    "        return cleaned_gro_file\n",
    "    \n",
    "    \n",
    "    gro_file = read_gro(path)\n",
    "    cleaned_gro_file = clean_gro_file(gro_file)\n",
    "\n",
    "    return cleaned_gro_file\n",
    "\n",
    "\n",
    "# create coordinate dict from cleaned_gro_file\n",
    "def get_coordinate_dict_from_cleaned_gro(cleaned_gro_file):\n",
    "    \n",
    "    peptide_lenght_list = []\n",
    "\n",
    "    temporary_list = []\n",
    "\n",
    "    # iterate trough cleaned_gro_file\n",
    "    for residue in cleaned_gro_file:\n",
    "\n",
    "        # if temporary list just started, add aminoacid position in chain\n",
    "        if len(temporary_list) == 0:\n",
    "            temporary_list.append(int(residue[1]))\n",
    "\n",
    "        else:\n",
    "            # if position of actual residue is less than last residue\n",
    "            if temporary_list[-1] > int(residue[1]):\n",
    "\n",
    "                # append lenght of last peptide to peptide lenght list\n",
    "                peptide_lenght_list.append(len(temporary_list))\n",
    "\n",
    "                # empty temporary list\n",
    "                temporary_list = []\n",
    "\n",
    "                # append actual residue position\n",
    "                temporary_list.append(int(residue[1]))\n",
    "\n",
    "            # if position of actual residue is higher than last residue, ad current residue position\n",
    "            else:\n",
    "                temporary_list.append(int(residue[1]))\n",
    "\n",
    "    # append last peptide lenght to lenght stack\n",
    "    peptide_lenght_list.append(len(temporary_list))\n",
    "\n",
    "    # create empty dict for coordinate\n",
    "    peptide_coordinate_dict = {}\n",
    "\n",
    "    # create an entry in dict for every peptide in the file\n",
    "    for peptide in range(len(peptide_lenght_list)):\n",
    "        peptide_coordinate_dict[peptide] = {}\n",
    "\n",
    "        # for every residue in lenght peptide, add coordinate x, y, z\n",
    "        for residue in range(peptide_lenght_list[peptide]):\n",
    "            peptide_coordinate_dict[peptide][residue] = [float(coordinate) for coordinate in cleaned_gro_file[(peptide * peptide_lenght_list[peptide])+residue][3:]]\n",
    "\n",
    "    return peptide_coordinate_dict\n",
    "\n",
    "\n",
    "# compute euclidean distance\n",
    "def get_euclidean_distance(point_1, point_2):\n",
    "    \n",
    "    euclidean_distance = np.sqrt(np.sum([((point_1[0] - point_2[0])**2), ((point_1[1] - point_2[1])**2), ((point_1[2] - point_2[2])**2)]))\n",
    "\n",
    "    return euclidean_distance\n",
    "\n",
    "# compute distance map between two peptides\n",
    "def compute_distance_map(coordinate_dict, peptide_1, peptide_2):\n",
    "\n",
    "    distance_map = []\n",
    "    for amino_1 in coordinate_dict[peptide_1]:\n",
    "        coordinate_1 = coordinate_dict[peptide_1][amino_1]\n",
    "        \n",
    "        distance_map.append([amino_1])\n",
    "        \n",
    "        for amino_2 in coordinate_dict[peptide_2]:\n",
    "            coordinate_2 = coordinate_dict[peptide_2][amino_2]\n",
    "            \n",
    "            euclidean_distance = get_euclidean_distance(coordinate_1, coordinate_2)\n",
    "            distance_map[amino_1].append(euclidean_distance)\n",
    "        \n",
    "        del distance_map[amino_1][0]\n",
    "\n",
    "    distance_map = np.asarray(distance_map)\n",
    "    \n",
    "    return distance_map\n",
    "\n",
    "# compute distance map and return a n_peptide x n_peptide x n_res x n_res array\n",
    "def compute_distance_maps_from_coordinate_dict(coordinate_dict):\n",
    "    \n",
    "    aggregate_distance_map = []\n",
    "\n",
    "    #for peptide_1 in tqdm.tqdm(coordinate_dict):\n",
    "    for peptide_1 in coordinate_dict:\n",
    "        aggregate_distance_map.append([peptide_1])\n",
    "        \n",
    "        #for peptide_2 in tqdm.tqdm(coordinate_dict):\n",
    "        for peptide_2 in coordinate_dict:\n",
    "            distance_map = compute_distance_map(coordinate_dict, peptide_1, peptide_2)\n",
    "            \n",
    "            aggregate_distance_map[peptide_1].append(distance_map)\n",
    "\n",
    "        del aggregate_distance_map[peptide_1][0]\n",
    "\n",
    "    aggregate_distance_array = np.asarray(aggregate_distance_map)\n",
    "    \n",
    "    return aggregate_distance_array\n",
    "\n",
    "\n",
    "# COMPUTE CONTACT MAPS\n",
    "# TO DO: parametrize the threshold distance in a better way (e.g. )\n",
    "def compute_contact_maps_as_array(distance_maps_array):\n",
    "    \n",
    "    # distance between the first and the second aminoacid of the first chain\n",
    "    intrapeptide_minimum_distance = distance_maps_array[0][0][0][1] \n",
    "\n",
    "    contact_map_list = []\n",
    "\n",
    "    # contact is in a distance up to 150% of the intrapeptide_minimum_distance [TO IMPROVE!!!]\n",
    "    threshold_distance = (intrapeptide_minimum_distance * 1.5)\n",
    "\n",
    "    for model_1 in range(distance_maps_array.shape[0]):\n",
    "        contact_map_list.append([])\n",
    "        for model_2 in range(distance_maps_array[model_1].shape[0]):\n",
    "\n",
    "            contact_map_list[model_1].append([])\n",
    "\n",
    "            if model_1 == model_2:\n",
    "\n",
    "                contact_map_list[model_1][model_2].extend(np.zeros((distance_maps_array.shape[2], distance_maps_array.shape[3])))\n",
    "\n",
    "            else:\n",
    "\n",
    "                contact_map = np.zeros((distance_maps_array.shape[2], distance_maps_array.shape[3]))\n",
    "\n",
    "                for chain_1 in range(distance_maps_array[model_1][model_2].shape[0]):\n",
    "\n",
    "                    for chain_2 in range(distance_maps_array[model_1][model_2][chain_1].shape[0]):\n",
    "\n",
    "                        distance = distance_maps_array[model_1][model_2][chain_1][chain_2]\n",
    "\n",
    "                        if distance < threshold_distance:\n",
    "                            contact_map[chain_1][chain_2] = 1 #True\n",
    "                        else:\n",
    "                            pass\n",
    "\n",
    "                contact_map_list[model_1][model_2].extend(contact_map)\n",
    "    \n",
    "    contact_array = np.asarray(contact_map_list)\n",
    "            \n",
    "    return contact_array\n",
    "\n",
    "\n",
    "#### ANALYSIS\n",
    "\n",
    "def shift_library_maker(contact_map_to_analyze):\n",
    "    \n",
    "    ''' riceve numero di righe e di colonne\n",
    "    restituisce un array shape((((row + col)*2)-2),row,col).\n",
    "    ogni slice Ã¨ una diagonale. Lo stack copre le diagonali su tutta la matrice'''\n",
    "    \n",
    "    row = contact_map_to_analyze.shape[0]\n",
    "    col = contact_map_to_analyze.shape[1]\n",
    "    \n",
    "    kron_dict = {}\n",
    "    kron_list_parallel = []\n",
    "    kron_list_antiparallel = []\n",
    "    \n",
    "    for e in range(-row+1, col):\n",
    "        array = np.eye(row, col, e)\n",
    "        kron_list_parallel.append(array)\n",
    "        kron_list_antiparallel.append(np.fliplr(array))\n",
    "        \n",
    "    kron_array_parallel = np.asarray(kron_list_parallel)\n",
    "    kron_array_antiparallel = np.asarray(kron_list_antiparallel)\n",
    "    \n",
    "    kron_dict['parallel'] = kron_array_parallel\n",
    "    kron_dict['antiparallel'] = kron_array_antiparallel\n",
    "    \n",
    "    return kron_dict\n",
    "\n",
    "\n",
    "def normalized_cross_correlation_function(contact_map):\n",
    "    '''\n",
    "    Calculate normalized cross correlation function between a contact map and an ideal map.\n",
    "    \n",
    "    Arguments : contact map, as output from get_contact_maps function\n",
    "                shift_matrix_stack, as output from shift_matrix_maker function\n",
    "                \n",
    "    Return : a list [ncc_value, index (in the shift_matrix_stack) of the shift matrix\n",
    "                that is matching the contact map\n",
    "            \n",
    "            '''\n",
    "    shift_matrix_library = shift_library_maker(contact_map)\n",
    "    \n",
    "    cross_correlation_values = []\n",
    "    max_val = []\n",
    "    sum_contact_map = np.sum(contact_map)\n",
    "    \n",
    "    if sum_contact_map < 2:\n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "        for sense in shift_matrix_library:\n",
    "            for index, z in enumerate(shift_matrix_library[sense]):\n",
    "\n",
    "                shift_matrix = shift_matrix_library[sense][index]\n",
    "                sum_shift_matrix = np.sum(shift_matrix)\n",
    "                ncc_value = (np.sum((contact_map * shift_matrix))/((np.sqrt(sum_contact_map))*(np.sqrt(sum_shift_matrix))))  # normalized cross correlation function of contact matrix and shift matrix\n",
    "                cross_correlation_values.append([ncc_value, index, sum_contact_map, sense])\n",
    "\n",
    "            max_val = max(cross_correlation_values) # get only the best match (highest value of ncc)\n",
    "\n",
    "    return max_val\n",
    "\n",
    "\n",
    "\n",
    "def normalized_cross_correlation_for_dataset(contact_array):\n",
    "    '''Calculate normalized cross correlation function between the full contacts map and and the .\n",
    "    \n",
    "    Arguments : contact map, as output from get_contact_maps function\n",
    "                shift_matrix_stack, as output from shift_matrix_maker function\n",
    "                \n",
    "    Return : a list [ncc_value, index (in the shift_matrix_stack) of the shift matrix that is matching the contact map'''\n",
    "    \n",
    "    contact_dict = {}\n",
    "    \n",
    "    #for row in tqdm.tqdm(range(contact_array.shape[0])):\n",
    "    for row in range(contact_array.shape[0]):\n",
    "    \n",
    "        for col in range((row+1), contact_array.shape[1]):\n",
    "        #for col in range(contact_array.shape[1]):\n",
    "\n",
    "            best_match = []\n",
    "            best_match = normalized_cross_correlation_function(contact_array[row][col])\n",
    "            \n",
    "            if len(best_match) == 0:\n",
    "                pass\n",
    "            \n",
    "            else:\n",
    "                if row in contact_dict:\n",
    "                    contact_dict[row].append([row, col, best_match])\n",
    "                \n",
    "                else:\n",
    "                    contact_dict[row] = [[row, col, best_match]]\n",
    "    \n",
    "    return contact_dict\n",
    "\n",
    "\n",
    "#denoise dataset\n",
    "def denoise_full_dataset(contact_maps, normalized_cross_correlation_results):\n",
    "    \n",
    "    '''Denoise the contact_maps dataset using the shift_matrix\n",
    "    \n",
    "    Arguments : contact_maps, normalized_cross_correlation_result\n",
    "    \n",
    "    return : a dict with key:value = row : row, col, denoised_map\n",
    "    \n",
    "    '''\n",
    "\n",
    "    denoised_dict = {}\n",
    "\n",
    "    for peptide_1 in normalized_cross_correlation_results:\n",
    "        denoised_dict[peptide_1] = {}\n",
    "        for index, peptide_2 in enumerate(normalized_cross_correlation_results[peptide_1]):\n",
    "\n",
    "            row = peptide_2[0]\n",
    "            col = peptide_2[1]\n",
    "\n",
    "\n",
    "\n",
    "            contact_map = contact_maps[row][col]\n",
    "            sense = peptide_2[2][3]\n",
    "            shift_matrix_index = normalized_cross_correlation_results[peptide_1][index][2][1]\n",
    "\n",
    "            shift_matrix = shift_library_maker(contact_map)\n",
    "            shift_matrix = shift_matrix[sense][shift_matrix_index]\n",
    "            denoised_map = contact_map * shift_matrix\n",
    "\n",
    "            denoised_dict[row][col] = denoised_map\n",
    "            \n",
    "    return denoised_dict\n",
    "\n",
    "\n",
    "#create a dict that contains the peptide couples contact and the specular peptide couples contact\n",
    "def reconstruct_full_matrix(denoised_dict):\n",
    "    full_denoised_dict = {}\n",
    "    for peptide_1 in tqdm.tqdm(denoised_dict):\n",
    "        for peptide_2 in denoised_dict[peptide_1]:\n",
    "            contact_map = denoised_dict[peptide_1][peptide_2]\n",
    "\n",
    "            if peptide_1 in full_denoised_dict:\n",
    "                full_denoised_dict[peptide_1][peptide_2] = contact_map\n",
    "\n",
    "            if peptide_1 not in full_denoised_dict:\n",
    "                full_denoised_dict[peptide_1] = {peptide_2:contact_map}\n",
    "\n",
    "            if peptide_2 in full_denoised_dict:\n",
    "                full_denoised_dict[peptide_2][peptide_1] = contact_map.T\n",
    "\n",
    "            if peptide_2 not in full_denoised_dict:\n",
    "                full_denoised_dict[peptide_2] = {peptide_1:contact_map.T}\n",
    "    \n",
    "    return full_denoised_dict\n",
    "\n",
    "\n",
    "# take array, return vector with sum along columns\n",
    "def get_row_vector(array):\n",
    "    row_vector = np.sum(array, axis=0)\n",
    "    return row_vector\n",
    "\n",
    "# take array, return vector with sum along row\n",
    "def get_col_vector(array):\n",
    "    col_vector = np.sum(array, axis=1)\n",
    "    return col_vector\n",
    "\n",
    "# graph clustering\n",
    "def nx_graph_search(denoised_dict):\n",
    "    \n",
    "    graph = nx.MultiGraph()\n",
    "    \n",
    "    for peptide_1 in denoised_dict:\n",
    "        for peptide_2 in denoised_dict[peptide_1]:\n",
    "            array_1 = denoised_dict[peptide_1][peptide_2]\n",
    "            for peptide_3 in denoised_dict[peptide_2]:\n",
    "                if peptide_3 != peptide_1:\n",
    "                    array_2 = denoised_dict[peptide_2][peptide_3]\n",
    "\n",
    "                    vect_1 = get_row_vector(array_1)\n",
    "                    vect_2 = get_col_vector(array_2)\n",
    "\n",
    "                    contacts = np.dot(vect_1, vect_2)\n",
    "                    \n",
    "                    if contacts >= 3:\n",
    "\n",
    "                        graph.add_edge(peptide_1, peptide_2)\n",
    "                     \n",
    "                        graph.add_edge(peptide_2, peptide_3)\n",
    "\n",
    "    return graph\n",
    "\n",
    "#A novel graph clustering algorithm based on discrete-time quantum random walk\n",
    "#S.G. Roya, A. Chakrabarti\n",
    "\n",
    "\n",
    "# working with networkX\n",
    "# if contacts >= target\n",
    "\n",
    "# when you add_edge, nodes are created if they are not there\n",
    "# you can put info in edge (as distance, n of contacts, contact map)\n",
    "# you HAVE TO (but you can not also) put key to index multiple nodes that are joined with a single node\n",
    "# \n",
    "# add edge from pep1 to pep2 (you HAVE TO (###to explore utility of key) put key to index multiple nodes that are joined with a single node)\n",
    "# add edge from pep3 to pep3 ( same as before with key)\n",
    "\n",
    "\n",
    "#FIND SUBGRAPH\n",
    "def find_subgraph(graph):\n",
    "    '''\n",
    "    Find subgraph that have no node in common.\n",
    "    \n",
    "    Argument: NetworkX MultiGraph\n",
    "    \n",
    "    Return: list of subgraph ordered from one end to the other\n",
    "    \n",
    "    '''\n",
    "\n",
    "    subgraph_list = []\n",
    "    \n",
    "    for node in graph:\n",
    "        \n",
    "        # don't explore node that are already in subgraph_list\n",
    "        if node not in set(nod for nod_list in subgraph_list for nod in nod_list):\n",
    "            \n",
    "            # tree is the list of nodes joined to node, starting from node\n",
    "            # using depht first search\n",
    "            tree = [e for e in nx.algorithms.traversal.depth_first_search.dfs_tree(graph, node)]\n",
    "            \n",
    "            # check if the first node of the tree has adjiacency == 1\n",
    "            # so it checks if it is the first or last node of the subgraph\n",
    "            if len(graph[tree[0]]) == 1:\n",
    "                \n",
    "                if len(subgraph_list) == 0:\n",
    "                    subgraph_list.append(tree)\n",
    "                    \n",
    "                else:\n",
    "                    # use generator to check if the tree is already in the subgraph\n",
    "                    if set(tree) not in (set(i) for i in subgraph_list):\n",
    "                        subgraph_list.append(tree)\n",
    "                        \n",
    "    return subgraph_list\n",
    "\n",
    "\n",
    "########## PLOT PEPTIDE LIST\n",
    "# plot a list of peptide point cloud in 3d space.\n",
    "# The box axis have arbitrary scale dependent on the aminoacids distance\n",
    "# you can select to show the centroid\n",
    "def plot_peptide_list(coordinate_dict, peptide_list, centroid=False):\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "    x_median = float\n",
    "    y_median = float\n",
    "    z_median = float\n",
    "    \n",
    "\n",
    "    for peptide in range(len(peptide_list)):\n",
    "        x.append([peptide])\n",
    "        y.append([peptide])\n",
    "        z.append([peptide])\n",
    "        for aminoacid in coordinate_dict[peptide_list[peptide]]:\n",
    "\n",
    "            point = coordinate_dict[peptide_list[peptide]][aminoacid]\n",
    "            x[peptide].append(point[0])\n",
    "            y[peptide].append(point[1])\n",
    "            z[peptide].append(point[2])\n",
    "\n",
    "        del x[peptide][0]\n",
    "        del y[peptide][0]\n",
    "        del z[peptide][0]\n",
    "        \n",
    "    if centroid == True:\n",
    "        \n",
    "        def assemble_coordinate(axis_coordinate_list):\n",
    "            median_list = []\n",
    "            for coordinate_set in axis_coordinate_list:\n",
    "                median = np.median(coordinate_set)\n",
    "                median_list.append(median)\n",
    "            return median_list\n",
    "        \n",
    "        x_median = assemble_coordinate(x)\n",
    "        y_median = assemble_coordinate(y)\n",
    "        z_median = assemble_coordinate(z)\n",
    "        \n",
    "\n",
    "    #%matplotlib notebook\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes(projection='3d')\n",
    "    \n",
    "    for pep in range(len(x)):\n",
    "       \n",
    "        ax.scatter3D(x[pep],y[pep],z[pep])\n",
    "        \n",
    "        if centroid == True:\n",
    "            \n",
    "            ax.scatter3D(x_median[pep], y_median[pep], z_median[pep], c='red')\n",
    "            \n",
    "        \n",
    "    #return  plt.show(), [x,y,z], [x_median, y_median, z_median]\n",
    "    return  plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# get average distance map from distance maps set\n",
    "def get_mean_distance_map(distance_maps):\n",
    "    '''\n",
    "    Calculate mean distance map from distance maps set\n",
    "    \n",
    "    Argument: distance maps set\n",
    "    \n",
    "    return: np.array with average intrapeptide distance\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # create array of zeros of shape number_of_residues * number_of_residues\n",
    "    # depending on peptide residue number ### TO FIX FOR MULTIMONOMERIC ASSEMBLY\n",
    "    base = np.zeros((distance_maps[0][0].shape[0], distance_maps[0][0].shape[1]))\n",
    "    \n",
    "    # initialize counter\n",
    "    counter = 0\n",
    "    \n",
    "    # iterate throught peptides in the aggregate\n",
    "    for peptide_1 in range(distance_maps.shape[0]):\n",
    "        for peptide_2 in range(distance_maps.shape[1]):\n",
    "             \n",
    "            # if peptide index are the same (intrapeptide distance map)\n",
    "            if peptide_1 == peptide_2:\n",
    "                \n",
    "                # intrapeptide distance map\n",
    "                actual_distance_map = distance_maps[peptide_1][peptide_2]\n",
    "                \n",
    "                # sum base and current distance map\n",
    "                base = base + actual_distance_map\n",
    "                \n",
    "                #update counter\n",
    "                counter += 1\n",
    "\n",
    "    #for element in base (every element is the sum of distance_map(i,j) for every distance map)\n",
    "    for row in range(len(base)):\n",
    "        for col in range(len(base)):\n",
    "            \n",
    "            # find the mean for every element of the cumulative distance map\n",
    "            base[row][col] = (base[row][col])/counter\n",
    "            \n",
    "    return base\n",
    "\n",
    "\n",
    "def decompose_distance_map(distance_map):\n",
    "    '''Use Singular value decomposition to get\n",
    "    \n",
    "    distance_map.shape[1] dimensional coordinate\n",
    "    (same n of dimension as the peptide n of residue)\n",
    "    \n",
    "    As described in:\n",
    "    Mathematical Modeling of Protein Structure Using Distance Geometry\n",
    "    Jeong-Mi Yoon, Yash Gad, Zhijun Wu\n",
    "    \n",
    "    Argument: distance map (numpy.array 2D)\n",
    "    return: X : actual decomposition\n",
    "            \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # initialize a zeros matrix of same shape as the input map\n",
    "    D = np.zeros(distance_map.shape)\n",
    "    \n",
    "    #iterate trought row\n",
    "    for i in range(distance_map.shape[0]):\n",
    "        \n",
    "        # iterate trought cols\n",
    "        for j in range(distance_map.shape[1]):\n",
    "            \n",
    "            # distance between point point i and point j \n",
    "            dij = distance_map[i][j]\n",
    "            \n",
    "            # distance between point 0 and point j\n",
    "            d0j = distance_map[0][j]\n",
    "            \n",
    "            #distance between point i and point 0\n",
    "            di0 = distance_map[i][0]\n",
    "\n",
    "            #fill the zeros matrix with the value obtained with this formula\n",
    "            D[i][j] = (d0j**2 + di0**2 - dij**2)/2\n",
    "            \n",
    "    # check rank of matrix (should be of rank 3, but it is of rank distance_map.shape[1])\n",
    "    rank = np.linalg.matrix_rank(D)\n",
    "    \n",
    "    # Singular value decomposition on the D matrix\n",
    "    #svd = np.linalg.svd(D)\n",
    "    \n",
    "    svd = np.linalg.svd(D, full_matrices=False)\n",
    "    \n",
    "    # Calculate distance_map.shape[1] dimensional coordinate, but you need 3\n",
    "    # the non necessary dimension can give data to better reconstruct the peptide structure\n",
    "    X = svd[0]*np.sqrt(svd[1])\n",
    "\n",
    "    \n",
    "    #return X, svd, D, rank\n",
    "    return X\n",
    "\n",
    "def get_coordinate_from_decomposition(decomposition):\n",
    "    '''Take decomposition result and convert it into a coordinate vectors dict\n",
    "    \n",
    "    Argument: decomposition results\n",
    "    \n",
    "    return: dict with reconstructed 3d coordinate vector\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # take only the first three value to compose a 3D coordinate vector\n",
    "    coordinate = [e[:3] for e in decomposition]\n",
    "    \n",
    "    # initialize empty dict\n",
    "    reconstructed_coordinate_dict = {}\n",
    "    \n",
    "    # fill the dict with the ccordinate vectors\n",
    "    for index,coordinate_vector in enumerate(coordinate):\n",
    "        reconstructed_coordinate_dict[index] = coordinate_vector\n",
    "    \n",
    "    return reconstructed_coordinate_dict\n",
    "\n",
    "\n",
    "# \n",
    "def get_coordinate_from_distance_map(distance_map):\n",
    "    ''' compute 3d coordinate from distance map\n",
    "    \n",
    "    Argument: distance_map (numpy.array)\n",
    "    \n",
    "    return: dict with 3d coordinate for every alpha-carbon of a peptide\n",
    "    \n",
    "    '''\n",
    "    # perform singular value decomposition on distance_map (preprocessed)\n",
    "    decomposed_mean_distance_map = decompose_distance_map(distance_map)\n",
    "    \n",
    "    \n",
    "    # get 3D coordinate\n",
    "    reconstructed_coordinate_dict = get_coordinate_from_decomposition(decomposed_mean_distance_map)\n",
    "    \n",
    "    return reconstructed_coordinate_dict\n",
    "\n",
    "    \n",
    "    \n",
    "def plot_single_peptide(peptide_coordinate_dict, centroid=False):\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "    \n",
    "    for residue in peptide_coordinate_dict:\n",
    "        point = peptide_coordinate_dict[residue]\n",
    "        x.append(point[0])\n",
    "        y.append(point[1])\n",
    "        z.append(point[2])\n",
    "\n",
    "\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    z = np.asarray(z)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes(projection='3d')\n",
    "    ax.scatter3D(x,y,z, c='b')\n",
    "    \n",
    "    if centroid == True:\n",
    "            median_centroid = [np.median(x), np.median(y), np.median(z)]\n",
    "            ax.scatter3D(median_centroid[0], median_centroid[1], median_centroid[2], c='r')\n",
    "            \n",
    "    return plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open and clean .gro file\n",
    "# return list with an entry for every residue plus info\n",
    "start = timer()\n",
    "cleaned_gro_seed_1 = clean_gro(seed_1_path)\n",
    "end = timer()\n",
    "print(end - start)\n",
    "\n",
    "# return a dict with residue coordinate\n",
    "start = timer()\n",
    "coordinate_dict_seed_1 = get_coordinate_dict_from_cleaned_gro(cleaned_gro_seed_1)\n",
    "end = timer()\n",
    "print(end - start)\n",
    "\n",
    "# compute distance maps and return a n_peptide x n_peptide x n_res x n_res array ## from .gro coordinate dict\n",
    "start = timer()\n",
    "distance_maps_seed_1 = compute_distance_maps_from_coordinate_dict(coordinate_dict_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "# compute contact maps from distance maps\n",
    "start = timer()\n",
    "contact_maps_seed_1 = compute_contact_maps_as_array(distance_maps_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "# compute cross correlation and get values\n",
    "start = timer()\n",
    "normalized_cross_correlation_results_seed_1 = normalized_cross_correlation_for_dataset(contact_maps_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "# denoise dataset\n",
    "start = timer()\n",
    "denoised_dict_seed_1 = denoise_full_dataset(contact_maps_seed_1, normalized_cross_correlation_results_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "# recreate full contact map dataset mirrroring the upper triangle\n",
    "# return dict\n",
    "start = timer()\n",
    "full_denoised_dict_seed_1 = reconstruct_full_matrix(denoised_dict_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "#create graph\n",
    "start = timer()\n",
    "graph_seed_1 = nx_graph_search(full_denoised_dict_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "#search subgraph\n",
    "start = timer()\n",
    "subgrap_list_seed_1 = find_subgraph(graph_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "#find mean distance map\n",
    "start = timer()\n",
    "mean_distance_map_seed_1 = get_mean_distance_map(distance_maps_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "# decompose mean distance matrix\n",
    "start = timer()\n",
    "decomposed_mean_distance_map = decompose_distance_map(mean_distance_map_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "      \n",
    "# get coordinate from distance map      \n",
    "start = timer()\n",
    "reconstructed_coordinate_dict = get_coordinate_from_decomposition(decomposed_mean_distance_map)\n",
    "end = timer()\n",
    "print(end-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS FOR 3D VIEW OF PLOT\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS TO CLOSE ALL PLOT (run multiple time this cell if it does not work)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the reconstructed average peptide \n",
    "plot_single_peptide(reconstructed_coordinate_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot full coordinate from dict\n",
    "plot_peptide_list(coordinate_dict_seed_1, [e for e in coordinate_dict_seed_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRAJECTORY\n",
    "\n",
    "# using mdanalysis module\n",
    "\n",
    "\n",
    "#create Universe from a .gro with coordinates and an .xtc with the trajectory data\n",
    "u = mda.Universe(trj_gro,trj_xtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dict from a Universe in which each entry is a timestep of the MD simulation\n",
    "def create_trajectory_dict(u):\n",
    "    bb = u.select_atoms('name BB')\n",
    "    trajectory_dict = {}\n",
    "    for index, time_steps in enumerate(u.trajectory):\n",
    "        trajectory_dict[index] = bb.positions\n",
    "    return trajectory_dict\n",
    "\n",
    "# make trajectory dict\n",
    "trajectory_dict = create_trajectory_dict(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you change the number in the first parentesis, you change timestep\n",
    "#second parentesis are the bb grains\n",
    "pep = trajectory_dict[0][:1200] # this are all the coordinate of bb grains of timestep 0, as an array\n",
    "\n",
    "#cast coordinate from array to dict\n",
    "zero_c = get_coordinate_from_decomposition(pep)\n",
    "\n",
    "#plot dict as a single object\n",
    "plot_single_peptide(zero_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see the trajectory you need to install ngl-view\n",
    "# https://github.com/arose/nglview\n",
    "#\n",
    "# pay attention to this:\n",
    "#   pip install nglview\n",
    "#\n",
    "# in a terminal, in the env where ngl-view is installed, send this:\n",
    "# jupyter-nbextension enable nglview --py --sys-prefix\n",
    "#\n",
    "\n",
    "\n",
    "view = nv.show_mdanalysis(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class morphoscanner():\n",
    "    \n",
    "    \n",
    "    \n",
    "    class math_utility():\n",
    "\n",
    "        # take array, return vector with sum along columns\n",
    "        def get_row_vector(array):\n",
    "            row_vector = np.sum(array, axis=0)\n",
    "            return row_vector\n",
    "\n",
    "        # take array, return vector with sum along row\n",
    "        def get_col_vector(array):\n",
    "            col_vector = np.sum(array, axis=1)\n",
    "            return col_vector\n",
    "        \n",
    "        \n",
    "    class utility():\n",
    "        \n",
    "        def get_coordinate_dict_from_array(array):\n",
    "            '''Take decomposition result and convert it into a coordinate vectors dict\n",
    "\n",
    "            Argument: decomposition results\n",
    "\n",
    "            return: dict with reconstructed 3d coordinate vector\n",
    "\n",
    "            '''\n",
    "\n",
    "            # make list with n == array.shape[0]\n",
    "            coordinate = [e for e in array]\n",
    "\n",
    "            # initialize empty dict\n",
    "            reconstructed_coordinate_dict = {}\n",
    "\n",
    "            # fill the dict with the ccordinate vectors\n",
    "            for index,coordinate_vector in enumerate(coordinate):\n",
    "                reconstructed_coordinate_dict[index] = coordinate_vector\n",
    "\n",
    "            return reconstructed_coordinate_dict\n",
    "        \n",
    "        \n",
    "        \n",
    "        def contact_list_from_dict(contact_dict):\n",
    "            \n",
    "            contact_list = []\n",
    "            for peptide in contact_dict:\n",
    "\n",
    "                for contact in contact_dict[peptide]:\n",
    "\n",
    "                    new_data = [contact[0], contact[1], contact[2][0], contact[2][1], contact[2][2], contact[2][3]]\n",
    "                    contact_list.append(new_data)\n",
    "            return contact_list\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    class read():\n",
    "        \n",
    "        # READ .gro FILE AND PREPROCESSING\n",
    "\n",
    "        def clean_gro(path):\n",
    "\n",
    "\n",
    "                # open file .gro and return a list with one element per line of the .gro file\n",
    "            def read_gro(path):\n",
    "                gromacs_output = open(path)\n",
    "\n",
    "                gro_file = []\n",
    "                for line in gromacs_output:\n",
    "                    gro_file.append(line)\n",
    "\n",
    "\n",
    "\n",
    "                gromacs_output.close()        \n",
    "\n",
    "                return gro_file\n",
    "\n",
    "\n",
    "\n",
    "            # return string in a string with numbers\n",
    "            def return_if_string(string):\n",
    "                digits = []\n",
    "                for i in string:\n",
    "                    if not i.isdigit():\n",
    "                        digits.append(i)\n",
    "\n",
    "                string = ''.join(digits)\n",
    "\n",
    "                return string\n",
    "\n",
    "\n",
    "            # return numbers in a string with numbers\n",
    "            def return_if_digit(string):\n",
    "                digits = []\n",
    "                for i in string:\n",
    "                    if i.isdigit():\n",
    "                        digits.append(i)\n",
    "\n",
    "                string = ''.join(digits)\n",
    "\n",
    "                return string\n",
    "\n",
    "\n",
    "            # remove first, second and last lines from gro_file and reorder information\n",
    "            # FIX OPTION TO GET ENTRY RELATED TO A LABEL (as 'bb' or 'ca')\n",
    "            def clean_gro_file(gro_file):\n",
    "                cleaned_gro_file = []\n",
    "                for aminoacid in gro_file[2:-1]:\n",
    "                    splitted = aminoacid.split()\n",
    "                    if splitted[1] == 'BB':\n",
    "                        position_in_peptide = return_if_digit(splitted[0])\n",
    "                        residue = return_if_string(splitted[0])\n",
    "                        index = splitted[2]\n",
    "                        x = splitted[3]\n",
    "                        y = splitted[4]\n",
    "                        z = splitted[5]\n",
    "                        cleaned_gro_file.append([index, position_in_peptide, residue, x, y, z])\n",
    "                return cleaned_gro_file\n",
    "\n",
    "\n",
    "            gro_file = read_gro(path)\n",
    "            cleaned_gro_file = clean_gro_file(gro_file)\n",
    "\n",
    "            return cleaned_gro_file\n",
    "        \n",
    "        # create coordinate dict from cleaned_gro_file\n",
    "        def get_coordinate_dict_from_cleaned_gro(cleaned_gro_file):\n",
    "\n",
    "            peptide_lenght_list = []\n",
    "\n",
    "            temporary_list = []\n",
    "\n",
    "            # iterate trough cleaned_gro_file\n",
    "            for residue in cleaned_gro_file:\n",
    "\n",
    "                # if temporary list just started, add aminoacid position in chain\n",
    "                if len(temporary_list) == 0:\n",
    "                    temporary_list.append(int(residue[1]))\n",
    "\n",
    "                else:\n",
    "                    # if position of actual residue is less than last residue\n",
    "                    if temporary_list[-1] > int(residue[1]):\n",
    "\n",
    "                        # append lenght of last peptide to peptide lenght list\n",
    "                        peptide_lenght_list.append(len(temporary_list))\n",
    "\n",
    "                        # empty temporary list\n",
    "                        temporary_list = []\n",
    "\n",
    "                        # append actual residue position\n",
    "                        temporary_list.append(int(residue[1]))\n",
    "\n",
    "                    # if position of actual residue is higher than last residue, ad current residue position\n",
    "                    else:\n",
    "                        temporary_list.append(int(residue[1]))\n",
    "\n",
    "            # append last peptide lenght to lenght stack\n",
    "            peptide_lenght_list.append(len(temporary_list))\n",
    "\n",
    "            # create empty dict for coordinate\n",
    "            peptide_coordinate_dict = {}\n",
    "\n",
    "            # create an entry in dict for every peptide in the file\n",
    "            for peptide in range(len(peptide_lenght_list)):\n",
    "                peptide_coordinate_dict[peptide] = {}\n",
    "\n",
    "                # for every residue in lenght peptide, add coordinate x, y, z\n",
    "                for residue in range(peptide_lenght_list[peptide]):\n",
    "                    peptide_coordinate_dict[peptide][residue] = [float(coordinate) for coordinate in cleaned_gro_file[(peptide * peptide_lenght_list[peptide])+residue][3:]]\n",
    "\n",
    "            return peptide_coordinate_dict #, peptide_lenght_list\n",
    "        \n",
    "        \n",
    "        def get_coordinate_dict_from_cleaned_gro_for_fixed_lenght_peptides(cleaned_gro_file, peptide_lenght):\n",
    "            '''Works only with system made of peptide of equal peptide length\n",
    "                (the peptide in the trajectory have all the same number of aminoacids).\n",
    "\n",
    "            Usefull to disassemble premade aggregate in a system of omogenous peptide lenght'''\n",
    "\n",
    "            peptide_coordinate_dict = {}\n",
    "\n",
    "            for peptide in range(len(cleaned_gro_file)//peptide_lenght):\n",
    "\n",
    "                peptide_coordinate_dict[peptide] = {}\n",
    "\n",
    "                peptide_data = cleaned_gro_file[(peptide*peptide_lenght):((peptide*peptide_lenght)+peptide_lenght)]\n",
    "\n",
    "                for index, amino in enumerate(peptide_data):\n",
    "\n",
    "                    peptide_coordinate_dict[peptide][index] = [float(amino[3]), float(amino[4]), float(amino[5])] ## can you generalize this 3? Maybe with re or isdigit function??\n",
    "\n",
    "            return peptide_coordinate_dict\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    class dataframe():\n",
    "        \n",
    "        \n",
    "        def get_dataframe_from_trajectory(trj_gro, trj_xtc, peptide_length = None):\n",
    "            \n",
    "            '''Create pandas.DataFrame from trajectory files\n",
    "            \n",
    "            Arguments: str(.gro topology path),\n",
    "                       str(.xtc trajectory path),\n",
    "                       int (optional)\n",
    "                       \n",
    "            output: pandas.DataFrame\n",
    "            \n",
    "            The 3rd argument (peptide_length) is optional. If you leave it empty the\n",
    "            function will use the topology file to dynamically group residues into peptides,\n",
    "            strictly following the topology. It adapt to different peptide lengths (aminoacids number in the peptide)\n",
    "            \n",
    "            \n",
    "            If you do molecular dynamics simulation with peptide of fixed residues number,\n",
    "            you can insert the residues number and the function will parse the residues to\n",
    "            compose the peptides unsing that number.\n",
    "            \n",
    "            for example, you use peptides with 12 aminoacids each, but you start your simulation\n",
    "            using a premade seed of 4 peptides forming a beta-sheet. The gromacs topology file will\n",
    "            consider this as a 64 residues peptide. But it is actually made of 4 peptides of 12 aminoacid each.\n",
    "            If you set the peptide_length to 12, it will parse the premade beta sheet \n",
    "            as 4 peptides of 12 aminoacids each.\n",
    "            \n",
    "            '''\n",
    "\n",
    "            universe = morphoscanner.topology.make_universe(trj_gro, trj_xtc)\n",
    "\n",
    "            topology = trj_gro\n",
    "\n",
    "            peptides_list = morphoscanner.topology.get_peptide_length_list(trj_gro)\n",
    "\n",
    "\n",
    "            if peptide_length == None:\n",
    "\n",
    "\n",
    "                n_pep = len(peptides_list)\n",
    "\n",
    "\n",
    "            else:\n",
    "\n",
    "                n_pep = sum([(e//peptide_length) for e in peptides_list])\n",
    "\n",
    "            #columns_name = ['atom_number','peptide_number', 'residue_name', 'residue_position', 'coordinates']\n",
    "            columns_name = ['time_step','peptide_number', 'residue_position', 'residue_name', 'atom_position', 'atom_type', 'coordinates']\n",
    "\n",
    "            # create list for a pd.DataFrame\n",
    "            # as suggested in https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.append.html\n",
    "            for_pandas = []\n",
    "\n",
    "            trj_dict = {}\n",
    "\n",
    "            for index_ts, ts in enumerate(universe.trajectory):\n",
    "\n",
    "                trj_dict[index_ts] = {}\n",
    "\n",
    "                for peptide in range(n_pep):\n",
    "\n",
    "                    trj_dict[index_ts][peptide] = {}\n",
    "\n",
    "                    if peptide != 0:\n",
    "\n",
    "                        # if to check peptide_length\n",
    "\n",
    "                        if peptide_length == None:\n",
    "\n",
    "                            counter += peptides_list[peptide - 1]\n",
    "\n",
    "                        else:\n",
    "                            counter += peptide_length\n",
    "\n",
    "\n",
    "                    else:\n",
    "                        counter = 0\n",
    "\n",
    "\n",
    "                    if peptide_length == None:\n",
    "\n",
    "                        for res in range(peptides_list[peptide]):\n",
    "\n",
    "                            res_name = (str(universe.residues[res + counter]).split()[1].split(',')[0])#.split(',')[0])\n",
    "                            res_position = int(str(universe.residues[res + counter]).split()[2].split('>')[0])#.split(',')[0])\n",
    "                            res_id = str(res_position) + '_' + res_name\n",
    "\n",
    "                            #print(str(universe.residues[res + counter]))\n",
    "\n",
    "                            for index, atom in enumerate(universe.residues[res + (counter)].atoms):\n",
    "\n",
    "                                #print(atom)\n",
    "\n",
    "                                atom_number = (int(str(atom).split()[1].split(':')[0]) - 1)\n",
    "\n",
    "                                atom_type = str(atom).split()[2]\n",
    "\n",
    "                                coordinate = universe.atoms[atom_number].position\n",
    "\n",
    "                                position = len(trj_dict[index_ts][peptide])\n",
    "\n",
    "                                trj_dict[index_ts][peptide][position] = coordinate\n",
    "\n",
    "                                #features = [atom_number,peptide, res_name, position, coordinate]\n",
    "                                features = [index_ts, peptide, res_position, res_name, position, atom_type, coordinate]\n",
    "\n",
    "                                for_pandas.append(features)\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        for res in range(peptide_length):\n",
    "\n",
    "                            res_name = (str(universe.residues[res + counter]).split()[1].split(',')[0])#.split(',')[0])\n",
    "                            res_position = int(str(universe.residues[res + counter]).split()[2].split('>')[0]) - 1 # -1 to start index from 0\n",
    "                            res_id = str(res_position) + '_' + res_name\n",
    "\n",
    "                            #print(str(universe.residues[res + counter]))\n",
    "\n",
    "                            for index, atom in enumerate(universe.residues[res + (counter)].atoms):\n",
    "\n",
    "                                #print(atom)\n",
    "\n",
    "                                atom_number = (int(str(atom).split()[1].split(':')[0]) - 1)\n",
    "\n",
    "                                atom_type = str(atom).split()[2]\n",
    "\n",
    "                                coordinate = universe.atoms[atom_number].position\n",
    "\n",
    "                                position = len(trj_dict[index_ts][peptide])\n",
    "\n",
    "                                trj_dict[index_ts][peptide][position] = coordinate\n",
    "\n",
    "                                #features = [atom_number,peptide, res_name, position, coordinate]\n",
    "                                features = [index_ts, peptide, res_position, res_name, position, atom_type, coordinate]\n",
    "\n",
    "                                for_pandas.append(features)\n",
    "\n",
    "\n",
    "\n",
    "            #start = timer()\n",
    "            df = pd.DataFrame(for_pandas, columns=columns_name)\n",
    "            #end = timer()\n",
    "            #print(end-start)\n",
    "            return df\n",
    "\n",
    "    \n",
    "    \n",
    "        # get dataframe of bb grains for a frame ()\n",
    "        def get_bb(dataframe, frame):\n",
    "    \n",
    "            bb_dataframe = dataframe.groupby('time_step').get_group(frame).groupby('atom_type').get_group('BB')\n",
    "\n",
    "            return bb_dataframe\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        def get_peptide_tensor_from_dataframe(dataframe, step, peptide):\n",
    "            \n",
    "            '''Get 2d tensor with the coordinate of every atom (or grain) of a peptide, from a dataframe\n",
    "            \n",
    "            \n",
    "            Input:  dataframe, (the dataframe where your data are).\n",
    "            \n",
    "                    step, (frame of the trajectory from which you want to take the coordinate)\n",
    "                    \n",
    "                    peptide, (the peptide of which you want the coordinate)\n",
    "                    \n",
    "            Output: torch.tensor, of shape(n,3), where n is the number of atoms in the peptide\n",
    "            that you are considering. And 3 are the coordinate x, y, z of the atom.\n",
    "            '''\n",
    "        \n",
    "            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "            peptide_data = dataframe.groupby('time_step').get_group(step).groupby('peptide_number').get_group(peptide)\n",
    "\n",
    "            peptide_tensor = torch.tensor([vector for vector in peptide_data.coordinates.values], device=device)\n",
    "\n",
    "            return peptide_tensor\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        def distance_maps_from_dataframe(dataframe, time_step):\n",
    "            \n",
    "            '''Calculate distance maps for all the peptides in a step of the md simulation.\n",
    "            \n",
    "            Input:  pandas.DataFrame. Made with morphoscanner.dataframe.get_dataframe_from_trajectory()\n",
    "                    \n",
    "                    int. Timestep of the simulation\n",
    "                    \n",
    "                    \n",
    "            Output: dict of tensor. len(dict)==number of peptide in the simulation\n",
    "                                    len(dict[i])== number of peptide in the simulation\n",
    "                                    tensor.shape == (number of residue in peptide1, number of residue in peptide2)\n",
    "                                    \n",
    "            '''\n",
    "            \n",
    "            \n",
    "    \n",
    "            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "            number_of_peptides = len(dataframe.groupby('time_step').get_group(time_step).groupby('peptide_number'))\n",
    "            #number_of_peptides = 5\n",
    "\n",
    "            distance_dict = {}\n",
    "            # iterate trought all peptides in a frame\n",
    "            for peptide1 in range(number_of_peptides):\n",
    "\n",
    "                if peptide1 not in distance_dict.keys():\n",
    "\n",
    "                    distance_dict[peptide1] = {}\n",
    "\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "                number_of_atoms_in_peptide1 = len(dataframe.groupby('time_step').get_group(time_step).groupby('peptide_number').get_group(peptide1))\n",
    "\n",
    "\n",
    "\n",
    "                peptide1_tensor = morphoscanner.dataframe.get_peptide_tensor_from_dataframe(dataframe, time_step, peptide1)\n",
    "\n",
    "                # iterate trought peptide in the upper triangle only\n",
    "                for peptide2 in range(peptide1, number_of_peptides):\n",
    "\n",
    "\n",
    "                    number_of_atoms_in_peptide2 = len(dataframe.groupby('time_step').get_group(time_step).groupby('peptide_number').get_group(peptide2))\n",
    "\n",
    "\n",
    "                    peptide2_tensor = morphoscanner.dataframe.get_peptide_tensor_from_dataframe(dataframe, time_step, peptide2)\n",
    "\n",
    "\n",
    "                    distance_map = morphoscanner.distance_tensor.distance_matrix_from_2d_tensor(peptide1_tensor, peptide2_tensor)\n",
    "                    distance_dict[peptide1][peptide2] = distance_map\n",
    "\n",
    "                    if peptide2 in distance_dict.keys():\n",
    "\n",
    "                        #distance_dict[peptide2] = {}\n",
    "                        distance_dict[peptide2][peptide1] = distance_map.transpose(1,0)\n",
    "\n",
    "                    else:\n",
    "                        distance_dict[peptide2] = {}\n",
    "                        distance_dict[peptide2][peptide1] = distance_map.transpose(1,0)\n",
    "\n",
    "            return distance_dict\n",
    "        \n",
    "        # SO YOU CAN CALCULATE DISTANCE MAPS\n",
    "        # NOW YOU HAVE TO PUT THOSE IN A DATAFRAME\n",
    "\n",
    "    #return dist\n",
    "\n",
    "#https://discuss.pytorch.org/t/efficient-distance-matrix-computation/9065\n",
    "#https://www.dropbox.com/h?preview=Parallel+Euclidean+distance+matrix+computation+on+big+datasets.pdf  \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    class topology():\n",
    "    \n",
    "        \n",
    "        #get a list of the number of residues of every peptide in the topology\n",
    "        def get_peptide_length_list(topology):\n",
    "            \n",
    "            topology = morphoscanner.read.clean_gro(topology)\n",
    "    \n",
    "            peptide_lenght_list = []\n",
    "\n",
    "            temporary_list = []\n",
    "\n",
    "            # iterate trough topology\n",
    "            for residue in topology:\n",
    "\n",
    "                # if temporary list just started, add aminoacid position in chain\n",
    "                if len(temporary_list) == 0:\n",
    "                    temporary_list.append(int(residue[1]))\n",
    "\n",
    "                else:\n",
    "                    # if position of actual residue is less than last residue\n",
    "                    if temporary_list[-1] > int(residue[1]):\n",
    "\n",
    "                        # append lenght of last peptide to peptide lenght list\n",
    "                        peptide_lenght_list.append(len(temporary_list))\n",
    "\n",
    "                        # empty temporary list\n",
    "                        temporary_list = []\n",
    "\n",
    "                        # append actual residue position\n",
    "                        temporary_list.append(int(residue[1]))\n",
    "\n",
    "                    # if position of actual residue is higher than last residue, ad current residue position\n",
    "                    else:\n",
    "                        temporary_list.append(int(residue[1]))\n",
    "\n",
    "            # append last peptide lenght to lenght stack\n",
    "            peptide_lenght_list.append(len(temporary_list))\n",
    "\n",
    "            return peptide_lenght_list\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        def make_universe(trj_gro, trj_xtc):\n",
    "            ''' Leverage MDAnalysis.Universe() to parse trajectory file from gromacs output.\n",
    "\n",
    "            Intput: string: system path of gro file (topology) and\n",
    "                            system path of xtc file (trajectory)\n",
    "                            of the file to analyze\n",
    "\n",
    "            return: MDAnalysis.Universe()'''\n",
    "\n",
    "            universe = mda.Universe(trj_gro,trj_xtc)\n",
    "\n",
    "            return universe\n",
    "        \n",
    "          \n",
    "        \n",
    "        \n",
    "        \n",
    "        # create a dict from a Universe in which each entry is a timestep of the MD simulation\n",
    "        def create_trajectory_dict(universe):\n",
    "            bb = universe.select_atoms('name BB')\n",
    "            trajectory_dict = {}\n",
    "            \n",
    "            for index, time_steps in enumerate(universe.trajectory):\n",
    "                trajectory_dict[index] = bb.positions\n",
    "            \n",
    "            return trajectory_dict\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        # make trajectory dict\n",
    "        \n",
    "        def get_coordinate_dict_from_trajectory(trj_gro, trj_xtc, peptide_length=None, start_from=0, interval=0):\n",
    "            '''Parse coordinate from a .gro topology and a .xtc trajectory.\n",
    "            \n",
    "            Arguments:  .gro topology file path,\n",
    "                    \n",
    "                        .xtc trajectory file path,\n",
    "                        \n",
    "                        \n",
    "                        optional:\n",
    "                            \n",
    "                            peptide_length, default=None.   You can set the length of the peptide\n",
    "                                                            Usefull if you hae to analyze simulation in which\n",
    "                                                            there are premade aggregate\n",
    "                                            \n",
    "                            start_from, default=0.    You can chose from which frame start the counter.\n",
    "                                                        Usefull if you are working with a simulation\n",
    "                                                        made of different part. Eg. If part 1 end at\n",
    "                                                        frame 500, you can set start_from=500 and analyze\n",
    "                                                        part 2 of the simulation. Use it expecially\n",
    "                                                        if you are sampling (interval != 1)\n",
    "                                                        \n",
    "                            interval, default=0     Interval between sample. If you want all the frame,\n",
    "                                                    interval=1.\n",
    "                                                    If you want to skip sample, this parameter let you\n",
    "                                                    choose the interval between 2 sample frame.\n",
    "            \n",
    "            \n",
    "            '''\n",
    "\n",
    "            peptides_list = morphoscanner.topology.get_peptide_length_list(trj_gro)\n",
    "\n",
    "            universe = morphoscanner.topology.make_universe(trj_gro, trj_xtc)\n",
    "\n",
    "\n",
    "            if peptide_length == None:\n",
    "\n",
    "\n",
    "                n_pep = len(peptides_list)\n",
    "\n",
    "\n",
    "            else:\n",
    "\n",
    "                n_pep = sum([(e//peptide_length) for e in peptides_list])\n",
    "\n",
    "\n",
    "            trj_dict = {}\n",
    "\n",
    "            for index_ts, ts in tqdm.tqdm(enumerate(universe.trajectory)):\n",
    "            #for index_ts, ts in enumerate(universe.trajectory):\n",
    "\n",
    "                updated_index = (index_ts + start_from)\n",
    "\n",
    "                if (updated_index % interval) == 0:\n",
    "\n",
    "                    trj_dict[updated_index] = {}\n",
    "\n",
    "                    for peptide in range(n_pep):\n",
    "\n",
    "                        trj_dict[updated_index][peptide] = {}\n",
    "\n",
    "\n",
    "                        if peptide != 0:\n",
    "\n",
    "                            # if to check peptide_length\n",
    "                            if peptide_length == None:\n",
    "\n",
    "                                counter += peptides_list[peptide - 1]\n",
    "\n",
    "                            else:\n",
    "                                counter += peptide_length\n",
    "\n",
    "\n",
    "                        else:\n",
    "                            counter = 0\n",
    "\n",
    "\n",
    "\n",
    "                        if peptide_length == None:\n",
    "\n",
    "                            for res in range(peptides_list[peptide]):\n",
    "\n",
    "                                for index, atom in enumerate(universe.residues[res + (counter)].atoms):\n",
    "\n",
    "\n",
    "                                    atom_type = str(atom).split()[2]\n",
    "\n",
    "                                    if atom_type == 'BB':\n",
    "\n",
    "                                        atom_number = (int(str(atom).split()[1].split(':')[0]) - 1)\n",
    "\n",
    "                                        coordinate = universe.atoms[atom_number].position\n",
    "\n",
    "                                        position = len(trj_dict[updated_index][peptide])\n",
    "\n",
    "\n",
    "                                        trj_dict[updated_index][peptide][position] = coordinate\n",
    "\n",
    "\n",
    "                        else:\n",
    "\n",
    "                            for res in range(peptide_length):\n",
    "\n",
    "                                for index, atom in enumerate(universe.residues[res + (counter)].atoms):\n",
    "\n",
    "\n",
    "                                    atom_type = str(atom).split()[2]\n",
    "\n",
    "\n",
    "                                    if atom_type == 'BB':\n",
    "\n",
    "                                        atom_number = (int(str(atom).split()[1].split(':')[0]) - 1)\n",
    "\n",
    "                                        coordinate = universe.atoms[atom_number].position\n",
    "\n",
    "                                        position = len(trj_dict[updated_index][peptide])\n",
    "\n",
    "\n",
    "                                        trj_dict[updated_index][peptide][position] = coordinate\n",
    "\n",
    "                                    else:\n",
    "                                        pass\n",
    "\n",
    "\n",
    "            return trj_dict\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    class distance():\n",
    "        \n",
    "        \n",
    "        # compute euclidean distance\n",
    "        def get_euclidean_distance(point_1, point_2):\n",
    "\n",
    "            euclidean_distance = np.sqrt(np.sum([((point_1[0] - point_2[0])**2), ((point_1[1] - point_2[1])**2), ((point_1[2] - point_2[2])**2)]))\n",
    "\n",
    "            return euclidean_distance\n",
    "        \n",
    "        \n",
    "\n",
    "        # compute distance map between two peptides\n",
    "        def compute_distance_map(coordinate_dict, peptide_1, peptide_2):\n",
    "\n",
    "            distance_map = []\n",
    "            for amino_1 in coordinate_dict[peptide_1]:\n",
    "                coordinate_1 = coordinate_dict[peptide_1][amino_1]\n",
    "\n",
    "                distance_map.append([amino_1])\n",
    "\n",
    "                for amino_2 in coordinate_dict[peptide_2]:\n",
    "                    coordinate_2 = coordinate_dict[peptide_2][amino_2]\n",
    "\n",
    "                    euclidean_distance = morphoscanner.distance.get_euclidean_distance(coordinate_1, coordinate_2)\n",
    "                    distance_map[amino_1].append(euclidean_distance)\n",
    "\n",
    "                del distance_map[amino_1][0]\n",
    "\n",
    "            distance_map = np.asarray(distance_map)\n",
    "\n",
    "            return distance_map\n",
    "\n",
    "        \n",
    "        \n",
    "        # compute distance map and return a n_peptide x n_peptide x n_res x n_res array\n",
    "        def compute_distance_maps_from_coordinate_dict(coordinate_dict):\n",
    "\n",
    "            aggregate_distance_map = []\n",
    "\n",
    "            for peptide_1 in tqdm.tqdm(coordinate_dict):\n",
    "            #for peptide_1 in coordinate_dict:\n",
    "                aggregate_distance_map.append([peptide_1])\n",
    "\n",
    "                #for peptide_2 in tqdm.tqdm(coordinate_dict):\n",
    "                for peptide_2 in coordinate_dict:\n",
    "                    distance_map = morphoscanner.distance.compute_distance_map(coordinate_dict, peptide_1, peptide_2)\n",
    "\n",
    "                    aggregate_distance_map[peptide_1].append(distance_map)\n",
    "\n",
    "                del aggregate_distance_map[peptide_1][0]\n",
    "\n",
    "            aggregate_distance_array = np.asarray(aggregate_distance_map)\n",
    "\n",
    "            return aggregate_distance_array\n",
    "\n",
    "\n",
    "        # COMPUTE CONTACT MAPS\n",
    "        # TO DO: parametrize the threshold distance in a better way (e.g. )\n",
    "        def compute_contact_maps_as_array(distance_maps_array):\n",
    "\n",
    "            # distance between the first and the second aminoacid of the first chain\n",
    "            intrapeptide_minimum_distance = distance_maps_array[0][0][0][1] \n",
    "\n",
    "            contact_map_list = []\n",
    "\n",
    "            # contact is in a distance up to 150% of the intrapeptide_minimum_distance [TO IMPROVE!!!]\n",
    "            threshold_distance = (intrapeptide_minimum_distance * 1.5)\n",
    "\n",
    "            for model_1 in range(distance_maps_array.shape[0]):\n",
    "                contact_map_list.append([])\n",
    "                for model_2 in range(distance_maps_array[model_1].shape[0]):\n",
    "\n",
    "                    contact_map_list[model_1].append([])\n",
    "\n",
    "                    if model_1 == model_2:\n",
    "\n",
    "                        contact_map_list[model_1][model_2].extend(np.zeros((distance_maps_array.shape[2], distance_maps_array.shape[3])))\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        contact_map = np.zeros((distance_maps_array.shape[2], distance_maps_array.shape[3]))\n",
    "\n",
    "                        for chain_1 in range(distance_maps_array[model_1][model_2].shape[0]):\n",
    "\n",
    "                            for chain_2 in range(distance_maps_array[model_1][model_2][chain_1].shape[0]):\n",
    "\n",
    "                                distance = distance_maps_array[model_1][model_2][chain_1][chain_2]\n",
    "\n",
    "                                if distance < threshold_distance:\n",
    "                                    contact_map[chain_1][chain_2] = 1 #True\n",
    "                                else:\n",
    "                                    pass\n",
    "\n",
    "                        contact_map_list[model_1][model_2].extend(contact_map)\n",
    "\n",
    "            contact_array = np.asarray(contact_map_list)\n",
    "\n",
    "            return contact_array\n",
    "        \n",
    "        \n",
    "        \n",
    "        # get average distance map from distance maps set\n",
    "        def get_mean_distance_map(distance_maps):\n",
    "            '''\n",
    "            Calculate mean distance map from distance maps set\n",
    "\n",
    "            Argument: distance maps set\n",
    "\n",
    "            return: np.array with average intrapeptide distance\n",
    "\n",
    "            '''\n",
    "\n",
    "            # create array of zeros of shape number_of_residues * number_of_residues\n",
    "            # depending on peptide residue number ### TO FIX FOR MULTIMONOMERIC ASSEMBLY\n",
    "            base = np.zeros((distance_maps[0][0].shape[0], distance_maps[0][0].shape[1]))\n",
    "\n",
    "            # initialize counter\n",
    "            counter = 0\n",
    "\n",
    "            # iterate throught peptides in the aggregate\n",
    "            for peptide_1 in range(distance_maps.shape[0]):\n",
    "                for peptide_2 in range(distance_maps.shape[1]):\n",
    "\n",
    "                    # if peptide index are the same (intrapeptide distance map)\n",
    "                    if peptide_1 == peptide_2:\n",
    "\n",
    "                        # intrapeptide distance map\n",
    "                        actual_distance_map = distance_maps[peptide_1][peptide_2]\n",
    "\n",
    "                        # sum base and current distance map\n",
    "                        base = base + actual_distance_map\n",
    "\n",
    "                        #update counter\n",
    "                        counter += 1\n",
    "\n",
    "            #for element in base (every element is the sum of distance_map(i,j) for every distance map)\n",
    "            for row in range(len(base)):\n",
    "                for col in range(len(base)):\n",
    "\n",
    "                    # find the mean for every element of the cumulative distance map\n",
    "                    base[row][col] = (base[row][col])/counter\n",
    "\n",
    "            return base\n",
    "\n",
    "        # Singolar Value Decomposition of distance_map\n",
    "        def decompose_distance_map(distance_map):\n",
    "            '''Use Singular value decomposition to get\n",
    "\n",
    "            distance_map.shape[1] dimensional coordinate\n",
    "            (same n of dimension as the peptide n of residue)\n",
    "\n",
    "            As described in:\n",
    "            Mathematical Modeling of Protein Structure Using Distance Geometry\n",
    "            Jeong-Mi Yoon, Yash Gad, Zhijun Wu\n",
    "\n",
    "            Argument: distance map (numpy.array 2D)\n",
    "            return: X : actual decomposition\n",
    "\n",
    "\n",
    "            '''\n",
    "\n",
    "            # initialize a zeros matrix of same shape as the input map\n",
    "            D = np.zeros(distance_map.shape)\n",
    "\n",
    "            #iterate trought row\n",
    "            for i in range(distance_map.shape[0]):\n",
    "\n",
    "                # iterate trought cols\n",
    "                for j in range(distance_map.shape[1]):\n",
    "\n",
    "                    # distance between point point i and point j \n",
    "                    dij = distance_map[i][j]\n",
    "\n",
    "                    # distance between point 0 and point j\n",
    "                    d0j = distance_map[0][j]\n",
    "\n",
    "                    #distance between point i and point 0\n",
    "                    di0 = distance_map[i][0]\n",
    "\n",
    "                    #fill the zeros matrix with the value obtained with this formula\n",
    "                    D[i][j] = (d0j**2 + di0**2 - dij**2)/2\n",
    "\n",
    "            # check rank of matrix (should be of rank 3, but it is of rank distance_map.shape[1])\n",
    "            #rank = np.linalg.matrix_rank(D)\n",
    "\n",
    "            # Singular value decomposition on the D matrix\n",
    "            #svd = np.linalg.svd(D)\n",
    "\n",
    "            svd = np.linalg.svd(D, full_matrices=False)\n",
    "\n",
    "            # Calculate distance_map.shape[1] dimensional coordinate, but you need 3\n",
    "            # the non necessary dimension can give data to better reconstruct the peptide structure\n",
    "            X = svd[0]*np.sqrt(svd[1])\n",
    "\n",
    "\n",
    "            #return X, svd, D, rank\n",
    "            return X\n",
    "\n",
    "        def get_coordinate_from_decomposition(decomposition):\n",
    "            '''Take decomposition result and convert it into a coordinate vectors dict\n",
    "\n",
    "            Argument: decomposition results\n",
    "\n",
    "            return: dict with reconstructed 3d coordinate vector\n",
    "\n",
    "            '''\n",
    "\n",
    "            # take only the first three value to compose a 3D coordinate vector\n",
    "            coordinate = [e[:3] for e in decomposition]\n",
    "\n",
    "            # initialize empty dict\n",
    "            reconstructed_coordinate_dict = {}\n",
    "\n",
    "            # fill the dict with the ccordinate vectors\n",
    "            for index,coordinate_vector in enumerate(coordinate):\n",
    "                reconstructed_coordinate_dict[index] = coordinate_vector\n",
    "\n",
    "            return reconstructed_coordinate_dict\n",
    "\n",
    "\n",
    "        # reconstruct 3d coordinate from a distance map\n",
    "        def get_coordinate_from_distance_map(distance_map):\n",
    "            ''' compute 3d coordinate from distance map\n",
    "\n",
    "            Argument: distance_map (numpy.array)\n",
    "\n",
    "            return: dict with 3d coordinate for every alpha-carbon of a peptide\n",
    "\n",
    "            '''\n",
    "            # perform singular value decomposition on distance_map (preprocessed)\n",
    "            decomposed_mean_distance_map = decompose_distance_map(distance_map)\n",
    "\n",
    "\n",
    "            # get 3D coordinate\n",
    "            reconstructed_coordinate_dict = get_coordinate_from_decomposition(decomposed_mean_distance_map)\n",
    "\n",
    "            return reconstructed_coordinate_dict\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    class distance_tensor():\n",
    "        \n",
    "        # instantiate 3d tensor with shape n_peptides * n_residues * n_dimension\n",
    "        def get_coordinate_tensor_from_dict(coordinate_dict):\n",
    "    \n",
    "            #variables wit dict dimension\n",
    "            dim0 = len(coordinate_dict)\n",
    "            dim1 = len(coordinate_dict[0])\n",
    "            dim2 = len(coordinate_dict[0][0])\n",
    "\n",
    "            #initialize a 0s tensor\n",
    "            if torch.cuda.is_available() == True:\n",
    "                \n",
    "                zero = torch.zeros([dim0,dim1,dim2], dtype=torch.float32, device='cuda')\n",
    "\n",
    "            else:\n",
    "                zero = torch.zeros([dim0,dim1,dim2], dtype=torch.float32)\n",
    "\n",
    "\n",
    "            for peptide in coordinate_dict:\n",
    "\n",
    "                for aminoacid in coordinate_dict[peptide]:\n",
    "                    \n",
    "                    \n",
    "                    if torch.cuda.is_available() == True:\n",
    "                        # create torch tensor on cuda device with cordinate [x,y,z...]\n",
    "                        zero[peptide][aminoacid] = torch.cuda.FloatTensor(coordinate_dict[peptide][aminoacid])\n",
    "\n",
    "                    else:\n",
    "                        zero[peptide][aminoacid] = torch.FloatTensor(coordinate_dict[peptide][aminoacid])\n",
    "\n",
    "                        \n",
    "                        \n",
    "            return zero\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        #compute euclidean norm, fast\n",
    "        def compute_euclidean_norm_torch(coordinate_tensor):\n",
    "            '''Use matrix to compute euclidean distance dataset wise\n",
    "                and return a set of distance matrix for everi couple of peptides\n",
    "\n",
    "            ****Runs in parallel on CUDA devices.\n",
    "\n",
    "            Argument: tensor of shape n_peptide * n_residue * number of dimension (3 for 3d)\n",
    "\n",
    "            return: tensor of shape n_peptide * n_peptide * n_residue * n_peptide\n",
    "\n",
    "            '''\n",
    "\n",
    "            #create tensor of 0s with shape n_pep x n_pep * n_res + n_res\n",
    "            if torch.cuda.is_available() == True:\n",
    "                zero = torch.zeros((coordinate_tensor.shape[0], coordinate_tensor.shape[0], coordinate_tensor.shape[1], coordinate_tensor.shape[1]), dtype=torch.float32, device='cuda')\n",
    "            else:\n",
    "                zero = torch.zeros((coordinate_tensor.shape[0], coordinate_tensor.shape[0], coordinate_tensor.shape[1], coordinate_tensor.shape[1]), dtype=torch.float32)\n",
    "            \n",
    "            #cicle on peptide\n",
    "            for index1, peptide1 in tqdm.tqdm(enumerate(coordinate_tensor)):\n",
    "\n",
    "                #cicle on peptide (upper triangle + diagonal)\n",
    "                for index2 in range(index1, coordinate_tensor.shape[0]):\n",
    "                #for index2 in range(coordinate_tens.shape[0]):\n",
    "\n",
    "                    #coordinate vector\n",
    "                    peptide2 = coordinate_tensor[index2]\n",
    "\n",
    "                    x_norm = torch.pow(peptide1, 2).sum(1).view(-1,1)\n",
    "                    y_t = torch.transpose(peptide2, 0, 1)\n",
    "                    y_norm = torch.pow(peptide2, 2).sum(1).view(1,-1)\n",
    "\n",
    "                    dist = torch.sqrt(x_norm + y_norm - 2.0 * torch.mm(peptide1, y_t))\n",
    "\n",
    "                    #dist = x_norm + y_norm - 2.0 * torch.mm(peptide1, y_t)\n",
    "                    #fine = torch.clamp(dist, 0.0, np.inf) #should be there, but is not working somehow\n",
    "\n",
    "                    # add distance map in the right position of the 0s tensor\n",
    "                    zero[index1][index2] = dist\n",
    "\n",
    "                    # if mesuring between different peptides\n",
    "                    if index1 != index2:\n",
    "                        # put transpose of distance map in lower triangle\n",
    "                        zero[index2][index1] = dist.transpose(1,0)\n",
    "\n",
    "            #convert nan to 0  (using this instead of torch.clamp())       \n",
    "            zero[torch.isnan(zero)] = 0\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                # move to system memory and cast to numpy array\n",
    "                zero = zero.cpu().numpy()\n",
    "    \n",
    "            return zero\n",
    "    \n",
    "        #https://discuss.pytorch.org/t/efficient-distance-matrix-computation/9065\n",
    "        #https://www.dropbox.com/h?preview=Parallel+Euclidean+distance+matrix+computation+on+big+datasets.pdf      \n",
    "        \n",
    "        \n",
    "        \n",
    "        def distance_matrix_from_2d_tensor(peptide1_tensor, peptide2_tensor):\n",
    "            '''Minimal function to calculate euclidean distance between two set of points\n",
    "            using quadratic expansion. Thanks to:\n",
    "            https://discuss.pytorch.org/t/efficient-distance-matrix-computation/9065\n",
    "            \n",
    "            Input: 2d tensor of shape (n,3), 2d tensor of shape (m,3)\n",
    "            \n",
    "            Output: 2d tensor of shape (n,m)\n",
    "                    \n",
    "             '''\n",
    "\n",
    "            # calculate distance\n",
    "            x_norm = torch.pow(peptide1_tensor, 2).sum(1).view(-1,1)\n",
    "            y_t = torch.transpose(peptide2_tensor, 0, 1)\n",
    "            y_norm = torch.pow(peptide2_tensor, 2).sum(1).view(1,-1)\n",
    "\n",
    "            distance_map = torch.sqrt(x_norm + y_norm - 2.0 * torch.mm(peptide1_tensor, y_t))\n",
    "\n",
    "            # put transpose of distance map in lower triangle   \n",
    "            #convert nan to 0  (using this instead of torch.clamp())       \n",
    "            distance_map[torch.isnan(distance_map)] = 0\n",
    "\n",
    "            return distance_map\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    class cross_correlation():\n",
    "        \n",
    "        #### ANALYSIS\n",
    "\n",
    "        def shift_library_maker(contact_map_to_analyze):\n",
    "\n",
    "            ''' riceve numero di righe e di colonne\n",
    "            restituisce un array shape((((row + col)*2)-2),row,col).\n",
    "            ogni slice Ã¨ una diagonale. Lo stack copre le diagonali su tutta la matrice'''\n",
    "\n",
    "            row = contact_map_to_analyze.shape[0]\n",
    "            col = contact_map_to_analyze.shape[1]\n",
    "\n",
    "            kron_dict = {}\n",
    "            kron_list_parallel = []\n",
    "            kron_list_antiparallel = []\n",
    "\n",
    "            for e in range(-row+1, col):\n",
    "                array = np.eye(row, col, e)\n",
    "                kron_list_parallel.append(array)\n",
    "                kron_list_antiparallel.append(np.fliplr(array))\n",
    "\n",
    "            kron_array_parallel = np.asarray(kron_list_parallel)\n",
    "            kron_array_antiparallel = np.asarray(kron_list_antiparallel)\n",
    "\n",
    "            kron_dict['parallel'] = kron_array_parallel\n",
    "            kron_dict['antiparallel'] = kron_array_antiparallel\n",
    "\n",
    "            return kron_dict\n",
    "\n",
    "\n",
    "        def normalized_cross_correlation_function(contact_map, minimum_contact=2):\n",
    "            '''\n",
    "            Calculate normalized cross correlation function between a contact map and an ideal map.\n",
    "\n",
    "            Arguments : contact map, as output from get_contact_maps function\n",
    "                        shift_matrix_stack, as output from shift_matrix_maker function\n",
    "\n",
    "            Return : a list [ncc_value, index (in the shift_matrix_stack) of the shift matrix\n",
    "                        that is matching the contact map\n",
    "\n",
    "                    '''\n",
    "            shift_matrix_library = morphoscanner.cross_correlation.shift_library_maker(contact_map)\n",
    "\n",
    "            cross_correlation_values = []\n",
    "            max_val = []\n",
    "            sum_contact_map = np.sum(contact_map)\n",
    "\n",
    "            if sum_contact_map < minimum_contact:\n",
    "                pass\n",
    "\n",
    "            else:\n",
    "                for sense in shift_matrix_library:\n",
    "                    for index, z in enumerate(shift_matrix_library[sense]):\n",
    "\n",
    "                        shift_matrix = shift_matrix_library[sense][index]\n",
    "                        sum_shift_matrix = np.sum(shift_matrix)\n",
    "                        ncc_value = (np.sum((contact_map * shift_matrix))/((np.sqrt(sum_contact_map))*(np.sqrt(sum_shift_matrix))))  # normalized cross correlation function of contact matrix and shift matrix\n",
    "                        cross_correlation_values.append([ncc_value, index, sum_contact_map, sense])\n",
    "\n",
    "                    max_val = max(cross_correlation_values) # get only the best match (highest value of ncc)\n",
    "\n",
    "            return max_val\n",
    "\n",
    "\n",
    "\n",
    "        def normalized_cross_correlation_for_dataset(contact_array):\n",
    "            '''Calculate normalized cross correlation function between the full contacts map and and the .\n",
    "\n",
    "            Arguments : contact map, as output from get_contact_maps function\n",
    "                        shift_matrix_stack, as output from shift_matrix_maker function\n",
    "\n",
    "            Return : a list [ncc_value, index (in the shift_matrix_stack) of the shift matrix that is matching the contact map'''\n",
    "\n",
    "            contact_dict = {}\n",
    "\n",
    "            #for row in tqdm.tqdm(range(contact_array.shape[0])):\n",
    "            for row in range(contact_array.shape[0]):\n",
    "\n",
    "                for col in range((row+1), contact_array.shape[1]):\n",
    "                #for col in range(contact_array.shape[1]):\n",
    "\n",
    "                    best_match = []\n",
    "                    best_match = morphoscanner.cross_correlation.normalized_cross_correlation_function(contact_array[row][col])\n",
    "\n",
    "                    if len(best_match) == 0:\n",
    "                        pass\n",
    "\n",
    "                    else:\n",
    "                        if row in contact_dict:\n",
    "                            contact_dict[row].append([row, col, best_match])\n",
    "\n",
    "                        else:\n",
    "                            contact_dict[row] = [[row, col, best_match]]\n",
    "\n",
    "            return contact_dict\n",
    "        \n",
    "        \n",
    "        \n",
    "        #contact_array = frame_contact\n",
    "        def cross_correlation_function_for_dataset_with_dataframe(contact_array):\n",
    "            '''Perform Normalized Cross Correlation function on the dataset\n",
    "                to check for contact. Get a dict for processing and a pandas.DataFrame\n",
    "                for data analysis\n",
    "\n",
    "                Input: contact maps\n",
    "\n",
    "                Output: contact_dict,         for further processing\n",
    "                        pandas.DataFrame,     for data analysis\n",
    "\n",
    "\n",
    "            '''\n",
    "            contact_dict = {}\n",
    "\n",
    "            for row in range(contact_array.shape[0]):\n",
    "\n",
    "                for col in range((row+1), contact_array.shape[1]):\n",
    "                    best_match = []\n",
    "                    best_match = morphoscanner.cross_correlation.normalized_cross_correlation_function(contact_array[row][col])\n",
    "\n",
    "                    if len(best_match) == 0:\n",
    "                        pass\n",
    "\n",
    "                    else:\n",
    "                        if row in contact_dict:\n",
    "                            contact_dict[row].append([row, col, best_match])\n",
    "\n",
    "                        else:\n",
    "                            contact_dict[row] = [[row, col, best_match]]\n",
    "\n",
    "            contact_list = morphoscanner.utility.contact_list_from_dict(contact_dict)\n",
    "\n",
    "            columns_names = ['peptide1', 'peptide2', 'NCC Value', 'shift index', 'contacts', 'sense']\n",
    "\n",
    "            df = pd.DataFrame(contact_list, columns=columns_names)\n",
    "\n",
    "            return contact_dict, df\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    class denoise():\n",
    "        \n",
    "        \n",
    "        #denoise dataset. GET SENSE 'PARALLEL' OR 'ANTIPARALLEL'....'NEED TO KNOW AMINOACID OF PEPTIDES'\n",
    "        def denoise_contact_maps(contact_maps):\n",
    "            \n",
    "            '''Denoise the contact_maps dataset using the shift_matrix\n",
    "            \n",
    "            Arguments : contact_maps, normalized_cross_correlation_result\n",
    "            \n",
    "            return : a dict with key:value = row : row, col, denoised_map\n",
    "            \n",
    "            '''\n",
    "        \n",
    "            normalized_cross_correlation_results, df = morphoscanner.cross_correlation.cross_correlation_function_for_dataset_with_dataframe(contact_maps)\n",
    "        \n",
    "        \n",
    "            denoised_dict = {}\n",
    "        \n",
    "            for peptide_1 in normalized_cross_correlation_results:\n",
    "                denoised_dict[peptide_1] = {}\n",
    "                for index, peptide_2 in enumerate(normalized_cross_correlation_results[peptide_1]):\n",
    "        \n",
    "                    row = peptide_2[0]\n",
    "                    col = peptide_2[1]\n",
    "        \n",
    "        \n",
    "        \n",
    "                    contact_map = contact_maps[row][col]\n",
    "                    sense = peptide_2[2][3]\n",
    "                    shift_matrix_index = normalized_cross_correlation_results[peptide_1][index][2][1]\n",
    "        \n",
    "                    shift_matrix = morphoscanner.cross_correlation.shift_library_maker(contact_map)\n",
    "                    shift_matrix = shift_matrix[sense][shift_matrix_index]\n",
    "                    denoised_map = contact_map * shift_matrix\n",
    "        \n",
    "                    denoised_dict[row][col] = denoised_map\n",
    "                    \n",
    "                    \n",
    "            full_denoised_dict = {}\n",
    "            for peptide_1 in tqdm.tqdm(denoised_dict):\n",
    "                for peptide_2 in denoised_dict[peptide_1]:\n",
    "                    contact_map = denoised_dict[peptide_1][peptide_2]\n",
    "        \n",
    "                    if peptide_1 in full_denoised_dict:\n",
    "                        full_denoised_dict[peptide_1][peptide_2] = contact_map\n",
    "        \n",
    "                    if peptide_1 not in full_denoised_dict:\n",
    "                        full_denoised_dict[peptide_1] = {peptide_2:contact_map}\n",
    "        \n",
    "                    if peptide_2 in full_denoised_dict:\n",
    "                        full_denoised_dict[peptide_2][peptide_1] = contact_map.T\n",
    "        \n",
    "                    if peptide_2 not in full_denoised_dict:\n",
    "                        full_denoised_dict[peptide_2] = {peptide_1:contact_map.T}\n",
    "            \n",
    "            return full_denoised_dict, df\n",
    "         \n",
    "        \n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    class graph():\n",
    "        \n",
    "        # graph clustering\n",
    "        def nx_graph_search(denoised_dict, minimum_contacts = 3):\n",
    "            \n",
    "            ''' Graph clustering of peptides in the aggregate.\n",
    "            \n",
    "            Input: denoised contact maps dict\n",
    "            \n",
    "            return: networkx.MultiGraph\n",
    "            \n",
    "            #######\n",
    "            \n",
    "            Search for group of minimum 3 peptides (beta_sheet),\n",
    "            joined at least with 'minimum_contacts'. default = 3\n",
    "            \n",
    "            '''\n",
    "            # Instantiate graph\n",
    "            graph = nx.MultiGraph()\n",
    "            \n",
    "            #iter on peptide\n",
    "            for peptide_1 in denoised_dict:\n",
    "                \n",
    "                #iter on peptide joined to peptide1\n",
    "                for peptide_2 in denoised_dict[peptide_1]:\n",
    "                    #retrieve contact_map of peptide1 and peptide2\n",
    "                    array_1 = denoised_dict[peptide_1][peptide_2]\n",
    "                    \n",
    "                    #iter on peptide joined to peptide2\n",
    "                    for peptide_3 in denoised_dict[peptide_2]:\n",
    "                        if peptide_3 != peptide_1:\n",
    "                            #retrieve contact_map of peptide1 and peptide2\n",
    "                            array_2 = denoised_dict[peptide_2][peptide_3]\n",
    "                            \n",
    "                            # create row and column vector from contact maps\n",
    "                            vect_1 = morphoscanner.math_utility.get_row_vector(array_1)\n",
    "                            vect_2 = morphoscanner.math_utility.get_col_vector(array_2)\n",
    "                            \n",
    "                            #check for contact\n",
    "                            contacts = np.dot(vect_1, vect_2)\n",
    "                            \n",
    "                            #add edge only if there are enough contacts\n",
    "                            if contacts >= minimum_contacts:\n",
    "\n",
    "                                graph.add_edge(peptide_1, peptide_2)\n",
    "\n",
    "                                graph.add_edge(peptide_2, peptide_3)\n",
    "\n",
    "            return graph\n",
    "\n",
    "        #A novel graph clustering algorithm based on discrete-time quantum random walk\n",
    "        #S.G. Roya, A. Chakrabarti\n",
    "\n",
    "        # working with networkX\n",
    " \n",
    "        # when you add_edge, nodes are created if they are not there\n",
    "        # you can put info in edge (as distance, n of contacts, contact map)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        # create a full graph\n",
    "        def full_graph(denoised_dict):\n",
    "            ''' Create a full graph of all the peptides in the frame.\n",
    "\n",
    "            Every peptide is a node in the graph.\n",
    "            Edges join contacting peptides.\n",
    "            Edges have attribute 'length' that gives you the number of contact between the peptides\n",
    "\n",
    "            Useful for peptides behaviour analysis during molecular dynamics\n",
    "\n",
    "            Arguments: denoised contact maps dict\n",
    "            return: networkx.MultiGraph\n",
    "\n",
    "            '''\n",
    "            graph = nx.MultiGraph()\n",
    "\n",
    "            for peptide_1 in denoised_dict:\n",
    "                for peptide_2 in denoised_dict[peptide_1]:\n",
    "\n",
    "                    array_1 = denoised_dict[peptide_1][peptide_2]\n",
    "\n",
    "                    graph.add_node(peptide_1)\n",
    "                    graph.add_node(peptide_2)\n",
    "\n",
    "                    number_of_contacts = array_1.sum()\n",
    "\n",
    "                    if number_of_contacts >= 1:\n",
    "\n",
    "                        graph.add_edge(peptide_1, peptide_2, length = number_of_contacts)\n",
    "\n",
    "            return graph\n",
    "\n",
    "\n",
    "        #FIND SUBGRAPH\n",
    "        def find_subgraph_in_order(graph):\n",
    "            '''\n",
    "            Find subgraph of joined peptides that have no node in common,\n",
    "            starting from a node (peptide) with degree==1 (first or last node of the subgraph).\n",
    "            The node are in order from start to end of the beta-sheet.\n",
    "            \n",
    "            DOES NOT WORK IF EACH PEPTIDE IS TOUCHING MORE THAN ONE OTHER PEPTIDE\n",
    "            \n",
    "            so if adjacency > 1, or degree > 1 for each node in the graph, it does not work.\n",
    "            \n",
    "            Argument: NetworkX MultiGraph\n",
    "\n",
    "            Return: list of subgraph ordered from one end to the other\n",
    "\n",
    "            '''\n",
    "\n",
    "            subgraph_list = []\n",
    "\n",
    "            for node in graph:\n",
    "\n",
    "                # don't explore node that are already in subgraph_list\n",
    "                if node not in set(nod for nod_list in subgraph_list for nod in nod_list):\n",
    "\n",
    "                    # tree is the list of nodes joined to node, starting from node\n",
    "                    # using depht first search\n",
    "                    tree = [e for e in nx.algorithms.traversal.depth_first_search.dfs_tree(graph, node)]\n",
    "\n",
    "                    # check if the first node of the tree has adjiacency == 1\n",
    "                    # so it checks if it is the first or last node of the subgraph\n",
    "                    if len(graph[tree[0]]) == 1:\n",
    "\n",
    "                        if len(subgraph_list) == 0:\n",
    "                            subgraph_list.append(tree)\n",
    "\n",
    "                        else:\n",
    "                            # use generator to check if the tree is already in the subgraph\n",
    "                            if set(tree) not in (set(i) for i in subgraph_list):\n",
    "                                subgraph_list.append(tree)\n",
    "\n",
    "            return subgraph_list\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        def find_subgraph(graph):\n",
    "            '''\n",
    "            Find subgraph of joined peptides that have no node in common.\n",
    "            It start to search from always from peptide 0, and from that does depth first search.\n",
    "            The peptide of the subgraph that are touching are in consequential order in the sublist\n",
    "\n",
    "            Argument: NetworkX MultiGraph\n",
    "\n",
    "            Return: list of subgraph\n",
    "\n",
    "            '''\n",
    "\n",
    "            subgraph_list = []\n",
    "\n",
    "            for node in graph:\n",
    "\n",
    "                # don't explore node that are already in subgraph_list\n",
    "                if node not in set(nod for nod_list in subgraph_list for nod in nod_list):\n",
    "\n",
    "                    # tree is the list of nodes joined to node, starting from node\n",
    "                    # using depht first search\n",
    "                    tree = [e for e in nx.algorithms.traversal.depth_first_search.dfs_tree(graph, node)]\n",
    "\n",
    "                    # check if the first node of the tree has adjiacency == 1\n",
    "                    # so it checks if it is the first or last node of the subgraph\n",
    "                    #if len(graph[tree[0]]) == 1:\n",
    "\n",
    "                    if len(subgraph_list) == 0:\n",
    "                        subgraph_list.append(tree)\n",
    "\n",
    "                    else:\n",
    "                        # use generator to check if the tree is already in the subgraph\n",
    "                        if set(tree) not in (set(i) for i in subgraph_list):\n",
    "                            subgraph_list.append(tree)\n",
    "\n",
    "            return subgraph_list\n",
    "        \n",
    "      \n",
    "        \n",
    "        \n",
    "        \n",
    "        def get_not_in_subgraph(coordinate_dict, subgraph):\n",
    "            '''Get peptide alone or in cluster of 2 in a frame.\n",
    "            \n",
    "            Input: coordinate_dict, output of 'find_subgraph' function            \n",
    "            \n",
    "            Output: list\n",
    "            \n",
    "            #####\n",
    "            \n",
    "            Basically this function gives you all the node left out\n",
    "            from the 'find_subgraph' function. That are all the node\n",
    "            with 0 or 1 neighbour if you leave the 'minimum_contact' parameter\n",
    "            of the nx_graph_search funtion to the default value of 3.\n",
    "            \n",
    "            '''\n",
    "            # one line function # don't use clever shit my friend\n",
    "            #out = [e for e in coordinate_dict if e not in [a for i in subgraph for a in i]]\n",
    "\n",
    "            out = []\n",
    "            \n",
    "            # get a list with all the node in subgraph\n",
    "            subgraph = [a for i in subgraph for a in i]\n",
    "\n",
    "            # iter on all element and get the one that are not in subgraph\n",
    "            for e in coordinate_dict:\n",
    "\n",
    "                if e not in subgraph:\n",
    "\n",
    "                    out.append(e)\n",
    "\n",
    "            return out\n",
    "        \n",
    "        \n",
    "        \n",
    "        def subgraph_length(aggregate):\n",
    "            '''Get information about the size of the aggregates in the trajectory\n",
    "\n",
    "            Argument: aggregate\n",
    "\n",
    "            return: dict, keys = frame number,\n",
    "                          value = a sorted list (big to small) of the aggregate size in that frame\n",
    "\n",
    "\n",
    "            '''\n",
    "\n",
    "            subgraph_len_dict = {}\n",
    "\n",
    "            for key in aggregate.frames.keys():\n",
    "\n",
    "                subgraph_dict[key] = morphoscanner.graph.find_subgraph(aggregate.frames[key]['frame_graph_full'])\n",
    "\n",
    "                len_list = []\n",
    "\n",
    "                for i in subgraph_dict[key]:\n",
    "\n",
    "                    len_list.append(len(i))\n",
    "\n",
    "                len_list.sort(reverse=True)\n",
    "\n",
    "                subgraph_len_dict[key] = len_list\n",
    "\n",
    "                return subgraph_len_dict\n",
    "            \n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "  \n",
    "        \n",
    "        \n",
    "        \n",
    "    class plot():\n",
    "        \n",
    "        \n",
    "        ########## PLOT PEPTIDE LIST\n",
    "        # plot a list of peptide point cloud in 3d space.\n",
    "        # The box axis have arbitrary scale dependent on the aminoacids distance\n",
    "        # you can select to show the centroid\n",
    "        def plot_peptide_list(coordinate_dict, peptide_list, centroid=False):\n",
    "            \n",
    "            \n",
    "            if len(peptide_list) == 1:\n",
    "                \n",
    "                return morphoscanner.plot.plot_single_peptide(coordinate_dict[peptide_list[0]])\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                x = []\n",
    "                y = []\n",
    "                z = []\n",
    "                x_median = float\n",
    "                y_median = float\n",
    "                z_median = float\n",
    "\n",
    "\n",
    "                for peptide in range(len(peptide_list)):\n",
    "                    x.append([peptide])\n",
    "                    y.append([peptide])\n",
    "                    z.append([peptide])\n",
    "                    for aminoacid in coordinate_dict[peptide_list[peptide]]:\n",
    "\n",
    "                        point = coordinate_dict[peptide_list[peptide]][aminoacid]\n",
    "                        x[peptide].append(point[0])\n",
    "                        y[peptide].append(point[1])\n",
    "                        z[peptide].append(point[2])\n",
    "\n",
    "                    del x[peptide][0]\n",
    "                    del y[peptide][0]\n",
    "                    del z[peptide][0]\n",
    "\n",
    "                if centroid == True:\n",
    "\n",
    "                    def assemble_coordinate(axis_coordinate_list):\n",
    "                        median_list = []\n",
    "                        for coordinate_set in axis_coordinate_list:\n",
    "                            median = np.median(coordinate_set)\n",
    "                            median_list.append(median)\n",
    "                        return median_list\n",
    "\n",
    "                    x_median = assemble_coordinate(x)\n",
    "                    y_median = assemble_coordinate(y)\n",
    "                    z_median = assemble_coordinate(z)\n",
    "\n",
    "\n",
    "                #%matplotlib notebook\n",
    "\n",
    "                fig = plt.figure()\n",
    "\n",
    "                ax = plt.axes(projection='3d')\n",
    "\n",
    "\n",
    "                for pep in range(len(x)):\n",
    "\n",
    "                    ax.scatter3D(x[pep],y[pep],z[pep])\n",
    "\n",
    "                    if centroid == True:\n",
    "\n",
    "                        ax.scatter3D(x_median[pep], y_median[pep], z_median[pep], c='red')\n",
    "\n",
    "\n",
    "                #return  plt.show(), [x,y,z], [x_median, y_median, z_median]         \n",
    "            return plt.show()\n",
    "        \n",
    "        \n",
    "        \n",
    "        #plot from tensor\n",
    "        def plot_peptide_from_tensor(coordinate_dict, peptide_list, centroid=False):\n",
    "\n",
    "            x = []\n",
    "            y = []\n",
    "            z = []\n",
    "            x_median = float\n",
    "            y_median = float\n",
    "            z_median = float\n",
    "\n",
    "\n",
    "            for peptide in range(len(peptide_list)):\n",
    "                x.append([peptide])\n",
    "                y.append([peptide])\n",
    "                z.append([peptide])\n",
    "                for index, aminoacid in enumerate(coordinate_dict[peptide_list[peptide]]):\n",
    "\n",
    "                    point = coordinate_dict[peptide_list[peptide]][index]\n",
    "                    x[peptide].append(point[0])\n",
    "                    y[peptide].append(point[1])\n",
    "                    z[peptide].append(point[2])\n",
    "\n",
    "                del x[peptide][0]\n",
    "                del y[peptide][0]\n",
    "                del z[peptide][0]\n",
    "\n",
    "            x = torch.FloatTensor(x)\n",
    "            y = torch.FloatTensor(y)\n",
    "            z = torch.FloatTensor(z)\n",
    "\n",
    "            if centroid == True:\n",
    "\n",
    "                def assemble_coordinate(axis_coordinate_list):\n",
    "                    median_list = []\n",
    "                    for coordinate_set in axis_coordinate_list:\n",
    "                        median = torch.median(torch.FloatTensor(coordinate_set))\n",
    "                        print(median)\n",
    "                        median_list.append(median)\n",
    "                    return median_list\n",
    "\n",
    "                x_median = assemble_coordinate(x)\n",
    "                y_median = assemble_coordinate(y)\n",
    "                z_median = assemble_coordinate(z)\n",
    "\n",
    "            #%matplotlib notebook\n",
    "\n",
    "            fig = plt.figure()\n",
    "\n",
    "            ax = plt.axes(projection='3d')\n",
    "\n",
    "\n",
    "            for pep in range(len(x)):\n",
    "\n",
    "                # scatter points, making list from torch tensor item\n",
    "                ax.scatter3D([e.item() for e in x[pep]],[e.item() for e in y[pep]],[e.item() for e in z[pep]])\n",
    "\n",
    "                if centroid == True:\n",
    "\n",
    "                    ax.scatter3D(x_median[pep].item(), y_median[pep].item(), z_median[pep].item(), c='red')\n",
    "\n",
    "\n",
    "            #return  plt.show(), [x,y,z], [x_median, y_median, z_median]         \n",
    "            return plt.show()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # plot single peptide (with autoscaling of axes)\n",
    "        def plot_single_peptide(peptide_coordinate_dict, centroid=False):\n",
    "            x = []\n",
    "            y = []\n",
    "            z = []\n",
    "\n",
    "            for residue in peptide_coordinate_dict:\n",
    "                point = peptide_coordinate_dict[residue]\n",
    "                x.append(point[0])\n",
    "                y.append(point[1])\n",
    "                z.append(point[2])\n",
    "\n",
    "\n",
    "            x = np.asarray(x)\n",
    "            y = np.asarray(y)\n",
    "            z = np.asarray(z)\n",
    "\n",
    "            fig = plt.figure()\n",
    "            ax = plt.axes(projection='3d')\n",
    "            ax.scatter3D(x,y,z, c='b')\n",
    "\n",
    "\n",
    "            if centroid == True:\n",
    "                median_centroid = [np.median(x), np.median(y), np.median(z)]\n",
    "                ax.scatter3D(median_centroid[0], median_centroid[1], median_centroid[2], c='r')\n",
    "\n",
    "            # Create cubic bounding box to simulate equal aspect ratio\n",
    "            max_range = np.array([x.max()-x.min(), y.max()-y.min(), z.max()-z.min()]).max()\n",
    "            Xb = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][0].flatten() + 0.5*(x.max()+x.min())\n",
    "            Yb = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][1].flatten() + 0.5*(y.max()+y.min())\n",
    "            Zb = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][2].flatten() + 0.5*(z.max()+z.min())\n",
    "            # Comment or uncomment following both lines to test the fake bounding box:\n",
    "            for xb, yb, zb in zip(Xb, Yb, Zb):\n",
    "                ax.plot([xb], [yb], [zb], 'w')\n",
    "\n",
    "            return plt.show()\n",
    "        \n",
    "    \n",
    "    # class for high level functionality, premade workflow...\n",
    "    class high_level():\n",
    "        \n",
    "        # automatically infer peptide lenght\n",
    "        def coordinate_dict_from_gro(gro_file):\n",
    "            \n",
    "            cleaned = morphoscanner.read.clean_gro(gro_file)\n",
    "            \n",
    "            coordinate = morphoscanner.read.get_coordinate_dict_from_cleaned_gro(cleaned)\n",
    "            \n",
    "            return coordinate\n",
    "        \n",
    "        \n",
    "        #specify peptide lenght\n",
    "        def coordinate_dict_from_gro_fix_len_peptide(gro_file, peptide_lenght):\n",
    "            \n",
    "            cleaned = morphoscanner.read.clean_gro(gro_file)\n",
    "            \n",
    "            coordinate = morphoscanner.read.get_coordinate_dict_from_cleaned_gro_for_fixed_lenght_peptides(cleaned, peptide_lenght)\n",
    "            \n",
    "            return coordinate\n",
    "        \n",
    "        \n",
    "        # compute distance maps, fast with torch.cuda\n",
    "        def compute_distance_maps_fast_from_gro(gro_file):\n",
    "            \n",
    "            coordinate_dict = morphoscanner.high_level.coordinate_dict_from_gro(gro_file)\n",
    "            \n",
    "            coordinate_tens = morphoscanner.distance_tensor.get_coordinate_tensor(coordinate_dict)\n",
    "            \n",
    "            distance_maps = morphoscanner.distance_tensor.compute_euclidean_norm_torch(coordinate_tens)\n",
    "            \n",
    "            return distance_maps\n",
    "        \n",
    "        \n",
    "        # make full graph from distance maps\n",
    "        def graph_full_from_distance_maps(distance_maps):\n",
    "            \n",
    "            contact_maps = morphoscanner.distance.compute_contact_maps_as_array(distance_maps)\n",
    "            \n",
    "            denoised = morphoscanner.denoise.denoise_contact_maps(contact_maps)\n",
    "            \n",
    "            graph = morphoscanner.graph.full_graph(denoised)\n",
    "            \n",
    "            return graph\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    #class trajectory:\n",
    "    class aggregate:\n",
    "\n",
    "        '''Class to operate on trajectory files.\n",
    "\n",
    "        It makes a'''\n",
    "\n",
    "\n",
    "\n",
    "        def __init__(self, trj_gro, trj_xtc):\n",
    "\n",
    "            self.trj_gro = trj_gro\n",
    "            self.trj_xtc = trj_xtc\n",
    "            self.universe = morphoscanner.topology.make_universe(self.trj_gro, self.trj_xtc)\n",
    "            self.peptide_length_list = morphoscanner.topology.get_peptide_length_list(self.trj_gro)\n",
    "            self.number_of_frames = len(self.universe.trajectory)\n",
    "\n",
    "            self.frames = {}\n",
    "\n",
    "\n",
    "\n",
    "        def compose_database(self, peptide_length=None, start_from=0, interval=0):\n",
    "\n",
    "            self.peptide_length = peptide_length\n",
    "            self.start_from = start_from\n",
    "            self.interval = interval\n",
    "\n",
    "            self.data = morphoscanner.topology.get_coordinate_dict_from_trajectory(self.trj_gro, self.trj_xtc, peptide_length=self.peptide_length, start_from=self.start_from, interval=self.interval)\n",
    "\n",
    "            self.sampled_frames = [key for key in self.data.keys()]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        def analysis(self, frame):\n",
    "\n",
    "            self.frame = frame        \n",
    "\n",
    "            self.frame_dict = self.data[self.frame]\n",
    "\n",
    "            self.frame_tensor = morphoscanner.distance_tensor.get_coordinate_tensor_from_dict(self.frame_dict)\n",
    "\n",
    "            self.frame_distance_maps = morphoscanner.distance_tensor.compute_euclidean_norm_torch(self.frame_tensor)\n",
    "\n",
    "            self.frame_contact = morphoscanner.distance.compute_contact_maps_as_array(self.frame_distance_maps)\n",
    "\n",
    "            self.frame_denoised, self.df = morphoscanner.denoise.denoise_contact_maps(self.frame_contact)\n",
    "\n",
    "            self.frame_graph = morphoscanner.graph.nx_graph_search(self.frame_denoised)\n",
    "\n",
    "            self.frame_graph_full = morphoscanner.graph.full_graph(self.frame_denoised)\n",
    "\n",
    "            if self.frame not in self.frames:\n",
    "\n",
    "                self.frames[self.frame] = {'frame_dict': self.frame_dict,\n",
    "                                              'frame_data' : self.df,\n",
    "                                              'frame_graph' : self.frame_graph,\n",
    "                                              'frame_graph_full' : self.frame_graph_full}\n",
    "            \n",
    "        \n",
    "        \n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with class library\n",
    "cleaned = morphoscanner.read.clean_gro(trj_gro)\n",
    "coordinate_dict = morphoscanner.read.get_coordinate_dict_from_cleaned_gro(cleaned)\n",
    "trj0_coordinate = morphoscanner.read.get_coordinate_dict_from_cleaned_gro_for_fixed_lenght_peptides(cleaned, 12)\n",
    "#trj0_distance_maps = morphoscanner.distance.compute_distance_maps_from_coordinate_dict(trj0_coordinate)\n",
    "#trj0_contact_maps = morphoscanner.distance.compute_contact_maps_as_array(trj0_distance_maps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj0_denoised_dict = morphoscanner.denoise.denoise_contact_maps(trj0_contact_maps)\n",
    "trj0_graph = morphoscanner.graph.nx_graph_search(trj0_denoised_dict)\n",
    "trj0_subgraph = morphoscanner.graph.find_subgraph(trj0_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot_peptide_list(trj0_coordinate, [e for e in trj0_coordinate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute distance maps and return a n_peptide x n_peptide x n_res x n_res array ## from .gro coordinate dict\n",
    "start = timer()\n",
    "distance_maps_seed_1 = compute_distance_maps_from_coordinate_dict(coordinate_dict_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "# compute contact maps from distance maps\n",
    "start = timer()\n",
    "contact_maps_seed_1 = compute_contact_maps_as_array(distance_maps_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "# compute cross correlation and get values\n",
    "start = timer()\n",
    "normalized_cross_correlation_results_seed_1 = normalized_cross_correlation_for_dataset(contact_maps_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "# denoise dataset\n",
    "start = timer()\n",
    "denoised_dict_seed_1 = denoise_full_dataset(contact_maps_seed_1, normalized_cross_correlation_results_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "# recreate full contact map dataset mirroring the upper triangle\n",
    "# return dict\n",
    "start = timer()\n",
    "full_denoised_dict_seed_1 = reconstruct_full_matrix(denoised_dict_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "#create graph\n",
    "start = timer()\n",
    "graph_seed_1 = nx_graph_search(full_denoised_dict_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "#search subgraph\n",
    "start = timer()\n",
    "subgrap_list_seed_1 = find_subgraph(graph_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "#find mean distance map\n",
    "start = timer()\n",
    "mean_distance_map_seed_1 = get_mean_distance_map(distance_maps_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "# decompose mean distance matrix\n",
    "start = timer()\n",
    "decomposed_mean_distance_map = decompose_distance_map(mean_distance_map_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "      \n",
    "# get coordinate from distance map      \n",
    "start = timer()\n",
    "reconstructed_coordinate_dict = get_coordinate_from_decomposition(decomposed_mean_distance_map)\n",
    "end = timer()\n",
    "print(end-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj0_mean_distance = morphoscanner.distance.get_mean_distance_map(trj0_distance_maps)\n",
    "\n",
    "plt.imshow(trj0_mean_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = u.select_atoms('name BB')\n",
    "    #trajectory_dict = {}\n",
    "    #for index, time_steps in enumerate(u.trajectory):\n",
    "     #   trajectory_dict[index] = bb.positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj0_coordinate[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nx.draw_networkx(trj0_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj0_subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with class library\n",
    "\n",
    "cleaned = morphoscanner.read.clean_gro(trj_gro)\n",
    "coordinate_dict = morphoscanner.read.get_coordinate_dict_from_cleaned_gro(cleaned)\n",
    "trj0_coordinate = morphoscanner.read.get_coordinate_dict_from_cleaned_gro_for_fixed_lenght_peptides(cleaned, 12)\n",
    "trj0_distance_maps = morphoscanner.distance.compute_distance_maps_from_coordinate_dict(trj0_coordinate)\n",
    "trj0_contact_maps = morphoscanner.distance.compute_contact_maps_as_array(trj0_distance_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = morphoscanner.read.clean_gro(trj_gro)\n",
    "coordinate_dict = morphoscanner.read.get_coordinate_dict_from_cleaned_gro(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinate_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with class library\n",
    "cleaned = morphoscanner.read.clean_gro(path)\n",
    "coordinate_dict = morphoscanner.read.get_coordinate_dict_from_cleaned_gro(cleaned)\n",
    "trj0_coordinate = morphoscanner.read.get_coordinate_dict_from_cleaned_gro_for_fixed_lenght_peptides(cleaned, 12)\n",
    "\n",
    "start = timer()\n",
    "trj0_distance_maps = morphoscanner.distance.compute_distance_maps_from_coordinate_dict(trj0_coordinate)\n",
    "end = timer()\n",
    "print(end - start)\n",
    "\n",
    "trj0_contact_maps = morphoscanner.distance.compute_contact_maps_as_array(trj0_distance_maps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj0_denoised_dict = morphoscanner.denoise.denoise_contact_maps(trj0_contact_maps)\n",
    "trj0_graph = morphoscanner.graph.nx_graph_search(trj0_denoised_dict)\n",
    "trj0_subgraph = morphoscanner.graph.find_subgraph(trj0_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj0_mean_distance = morphoscanner.distance.get_mean_distance_map(trj0_distance_maps)\n",
    "trj0_decomposition = morphoscanner.distance.decompose_distance_map(trj0_mean_distance)\n",
    "trj0_mean_coordinate = morphoscanner.distance.get_coordinate_from_decomposition(trj0_decomposition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot_peptide_list(trj0_coordinate,[0,1,2,3,4,5,6,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#morphoscanner.plot.plot_single_peptide(trj0_mean_coordinate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = morphoscanner.high_level.coordinate_dict_from_gro(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot_peptide_list(t, [e for e in t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinate_dict = morphoscanner.high_level.coordinate_dict_from_gro(path)\n",
    "coordinate_tens = morphoscanner.distance_tensor.get_coordinate_tensor(coordinate_dict)\n",
    "start = timer()\n",
    "distance_tens = morphoscanner.distance_tensor.compute_euclidean_norm_torch(coordinate_tens)\n",
    "end = timer()\n",
    "print(end-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contact_maps = morphoscanner.distance.compute_contact_maps_as_array(distance_tens)\n",
    "denoised_map = morphoscanner.denoise.denoise_contact_maps(contact_maps)\n",
    "graph_full = morphoscanner.graph.full_graph(denoised_map)\n",
    "#graph = morphoscanner.graph.nx_graph_search(denoised_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph = morphoscanner.graph.find_subgraph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = morphoscanner.graph.get_not_in_subgraph(coordinate_dict, subgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_dataframe_from_trajectory(trj_gro, trj_xtc, peptide_length = None):\n",
    "\n",
    "    universe = morphoscanner.topology.make_universe(trj_gro, trj_xtc)\n",
    "\n",
    "    topology = trj_gro\n",
    "\n",
    "    peptides_list = morphoscanner.topology.get_peptide_length_list(trj_gro)\n",
    "\n",
    "\n",
    "    if peptide_length == None:\n",
    "    \n",
    "\n",
    "        n_pep = len(peptides_list)\n",
    "\n",
    "\n",
    "    else:\n",
    "\n",
    "        n_pep = sum([(e//peptide_length) for e in peptides_list])\n",
    "\n",
    "    #columns_name = ['atom_number','peptide_number', 'residue_name', 'residue_position', 'coordinates']\n",
    "    columns_name = ['time_step','peptide_number', 'residue_position', 'residue_name', 'atom_position', 'atom_type', 'coordinates']\n",
    "\n",
    "    # create list for a pd.DataFrame\n",
    "    # as suggested in https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.append.html\n",
    "    for_pandas = []\n",
    "\n",
    "    trj_dict = {}\n",
    "\n",
    "    #for index_ts, ts in tqdm.tqdm(enumerate(universe.trajectory)):\n",
    "    for index_ts, ts in enumerate(universe.trajectory):\n",
    "\n",
    "        trj_dict[index_ts] = {}\n",
    "\n",
    "        for peptide in range(n_pep):\n",
    "\n",
    "            trj_dict[index_ts][peptide] = {}\n",
    "\n",
    "            if peptide != 0:\n",
    "                \n",
    "                # if to check peptide_length\n",
    "                \n",
    "                if peptide_length == None:\n",
    "\n",
    "                    counter += peptides_list[peptide - 1]\n",
    "                \n",
    "                else:\n",
    "                    counter += peptide_length\n",
    "        \n",
    "\n",
    "            else:\n",
    "                counter = 0\n",
    "            \n",
    "            \n",
    "            \n",
    "            if peptide_length == None:\n",
    "\n",
    "                for res in range(peptides_list[peptide]):\n",
    "\n",
    "                    res_name = (str(universe.residues[res + counter]).split()[1].split(',')[0])#.split(',')[0])\n",
    "                    res_position = int(str(universe.residues[res + counter]).split()[2].split('>')[0])#.split(',')[0])\n",
    "                    res_id = str(res_position) + '_' + res_name\n",
    "\n",
    "                    #print(str(universe.residues[res + counter]))\n",
    "\n",
    "                    for index, atom in enumerate(universe.residues[res + (counter)].atoms):\n",
    "\n",
    "                        #print(atom)\n",
    "\n",
    "                        atom_number = (int(str(atom).split()[1].split(':')[0]) - 1)\n",
    "\n",
    "                        atom_type = str(atom).split()[2]\n",
    "\n",
    "                        coordinate = universe.atoms[atom_number].position\n",
    "\n",
    "                        position = len(trj_dict[index_ts][peptide])\n",
    "\n",
    "                        trj_dict[index_ts][peptide][position] = coordinate\n",
    "\n",
    "                        #features = [atom_number,peptide, res_name, position, coordinate]\n",
    "                        features = [index_ts, peptide, res_position, res_name, position, atom_type, coordinate]\n",
    "\n",
    "                        for_pandas.append(features)\n",
    "                        \n",
    "            else:\n",
    "                \n",
    "                for res in range(peptide_length):\n",
    "\n",
    "                    res_name = (str(universe.residues[res + counter]).split()[1].split(',')[0])#.split(',')[0])\n",
    "                    res_position = int(str(universe.residues[res + counter]).split()[2].split('>')[0])#.split(',')[0])\n",
    "                    res_id = str(res_position) + '_' + res_name\n",
    "\n",
    "                    #print(str(universe.residues[res + counter]))\n",
    "\n",
    "                    for index, atom in enumerate(universe.residues[res + (counter)].atoms):\n",
    "\n",
    "                        #print(atom)\n",
    "\n",
    "                        atom_number = (int(str(atom).split()[1].split(':')[0]) - 1)\n",
    "\n",
    "                        atom_type = str(atom).split()[2]\n",
    "\n",
    "                        coordinate = universe.atoms[atom_number].position\n",
    "\n",
    "                        position = len(trj_dict[index_ts][peptide])\n",
    "\n",
    "                        trj_dict[index_ts][peptide][position] = coordinate\n",
    "\n",
    "                        #features = [atom_number,peptide, res_name, position, coordinate]\n",
    "                        features = [index_ts, peptide, res_position, res_name, position, atom_type, coordinate]\n",
    "\n",
    "                        for_pandas.append(features)\n",
    "                \n",
    "\n",
    "\n",
    "    #start = timer()\n",
    "    df = pd.DataFrame(for_pandas,columns=columns_name)\n",
    "    #end = timer()\n",
    "    #print(end-start)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pep_list = morphoscanner.topology.get_peptide_lenght_list(trj_gro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = morphoscanner.dataframe.get_dataframe_from_trajectory(trj_gro, trj_xtc,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa.groupby('time_step').get_group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbb = get_dataframe_from_trajectory(trj_gro, trj_xtc, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uu = torch.stack((coordinate_tens[0], coordinate_tens[1]),dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPUTE CONTACT MAPS\n",
    "# TO DO: parametrize the threshold distance in a better way (e.g. )\n",
    "def compute_contact_maps_as_array(distance_maps_array):\n",
    "\n",
    "    # distance between the first and the second aminoacid of the first chain\n",
    "    intrapeptide_minimum_distance = distance_maps_array[0][0][0][1] \n",
    "\n",
    "    contact_map_list = []\n",
    "\n",
    "    # contact is in a distance up to 150% of the intrapeptide_minimum_distance [TO IMPROVE!!!]\n",
    "    threshold_distance = (intrapeptide_minimum_distance * 1.5)\n",
    "\n",
    "    for model_1 in range(distance_maps_array.shape[0]):\n",
    "        contact_map_list.append([])\n",
    "        for model_2 in range(distance_maps_array[model_1].shape[0]):\n",
    "\n",
    "            contact_map_list[model_1].append([])\n",
    "\n",
    "            if model_1 == model_2:\n",
    "\n",
    "                contact_map_list[model_1][model_2].extend(np.zeros((distance_maps_array.shape[2], distance_maps_array.shape[3])))\n",
    "\n",
    "            else:\n",
    "\n",
    "                contact_map = np.zeros((distance_maps_array.shape[2], distance_maps_array.shape[3]))\n",
    "\n",
    "                for chain_1 in range(distance_maps_array[model_1][model_2].shape[0]):\n",
    "\n",
    "                    for chain_2 in range(distance_maps_array[model_1][model_2][chain_1].shape[0]):\n",
    "\n",
    "                        distance = distance_maps_array[model_1][model_2][chain_1][chain_2]\n",
    "\n",
    "                        if distance < threshold_distance:\n",
    "                            contact_map[chain_1][chain_2] = 1 #True\n",
    "                        else:\n",
    "                            pass\n",
    "\n",
    "                contact_map_list[model_1][model_2].extend(contact_map)\n",
    "\n",
    "    contact_array = np.asarray(contact_map_list)\n",
    "\n",
    "    return contact_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a full graph\n",
    "def full_graph(denoised_dict):\n",
    "    ''' Create a full graph of all the peptides in the frame.\n",
    "    \n",
    "    Every peptide is a node in the graph.\n",
    "    Edges join contacting peptides.\n",
    "    Edges have attribute 'length' that gives you the number of contact between the peptides\n",
    "    \n",
    "    Useful for peptides behaviour analysis during molecular dynamics\n",
    "    \n",
    "    Arguments: denoised contact maps dict\n",
    "    return: networkx.MultiGraph\n",
    "    \n",
    "    '''\n",
    "    graph = nx.MultiGraph()\n",
    "\n",
    "    for peptide_1 in denoised_dict:\n",
    "        for peptide_2 in denoised_dict[peptide_1]:\n",
    "            \n",
    "            array_1 = denoised_dict[peptide_1][peptide_2]\n",
    "\n",
    "            graph.add_node(peptide_1)\n",
    "            graph.add_node(peptide_2)\n",
    "\n",
    "            number_of_contacts = array_1.sum()\n",
    "\n",
    "            if number_of_contacts >= 1:\n",
    "\n",
    "                graph.add_edge(peptide_1, peptide_2, length = number_of_contacts)\n",
    "    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinate_dict = morphoscanner.high_level.coordinate_dict_from_gro_fix_len_peptide(trj_gro,12)\n",
    "coordinate_tens = morphoscanner.distance_tensor.get_coordinate_tensor(coordinate_dict)\n",
    "start = timer()\n",
    "distance_tens = morphoscanner.distance_tensor.compute_euclidean_norm_torch(coordinate_tens)\n",
    "end = timer()\n",
    "print(end-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinate_dict = morphoscanner.high_level.coordinate_dict_from_gro(trj_gro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRAJECTORY\n",
    "\n",
    "# using mdanalysis module\n",
    "\n",
    "\n",
    "#create Universe from a .gro with coordinates and an .xtc with the trajectory data\n",
    "u = mda.Universe(trj_gro,trj_xtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dict from a Universe in which each entry is a timestep of the MD simulation\n",
    "def create_trajectory_dict(universe):\n",
    "    bb = universe.select_atoms('name BB')\n",
    "    trajectory_dict = {}\n",
    "    for index, time_steps in enumerate(universe.trajectory):\n",
    "        trajectory_dict[index] = bb.positions\n",
    "    return trajectory_dict\n",
    "\n",
    "# make trajectory dict\n",
    "trajectory_dict = create_trajectory_dict(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trajectory_dict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_universe(trj_gro, trj_xtc):\n",
    "    ''' Leverage MDAnalysis.Universe() to parse trajectory file from gromacs output.\n",
    "    \n",
    "    Intput: string: system path of gro file (topology) and\n",
    "                    system path of xtc file (trajectory)\n",
    "                    of the file to analyze\n",
    "                    \n",
    "    return: MDAnalysis.Universe()'''\n",
    "    \n",
    "    \n",
    "    universe = mda.Universe(trj_gro,trj_xtc)\n",
    "    \n",
    "    return universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot_peptide_list(coordinate_dict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot_peptide_list(coordinate_dict, [e for e in coordinate_dict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinate_from_gro_all_atom(topology, universe):\n",
    "    \n",
    "    \n",
    "    peptides_list = morphoscanner.topology.get_peptide_lenght_list(topology)\n",
    "\n",
    "    trj_dict = {}\n",
    "\n",
    "    for peptide, n_res in enumerate(peptides_list[:]):\n",
    "\n",
    "        trj_dict[peptide] = {}\n",
    "\n",
    "        if peptide != 0:\n",
    "\n",
    "            counter += peptides_list[peptide-1]\n",
    "\n",
    "        else:\n",
    "            counter = 0\n",
    "\n",
    "\n",
    "        for res in range(n_res):\n",
    "\n",
    "            res_name = (str(universe.residues[res + counter]).split()[1].split(',')[0])#.split(',')[0])\n",
    "            res_position = (str(universe.residues[res + counter]).split()[2].split('>')[0])#.split(',')[0])\n",
    "            res_id = res_position + '_' + res_name\n",
    "            \n",
    "            trj_dict[peptide][res_id] = {}\n",
    "\n",
    "            for index, atom in enumerate(universe.residues[res + counter].atoms):\n",
    "\n",
    "                atom_type = str(atom).split()[2]\n",
    "\n",
    "                atom_number = int(str(atom).split()[1].split(':')[0])\n",
    "\n",
    "                coordinate = universe.atoms[atom_number].position\n",
    "\n",
    "                trj_dict[peptide][res_id][atom_type] = coordinate\n",
    "                \n",
    "    return trj_dict\n",
    "\n",
    "\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinate_dict_for_fixed_lenght_topology(topology, universe, n_residues = int):\n",
    "\n",
    "    peptides_list = morphoscanner.topology.get_peptide_lenght_list(trj_gro)\n",
    "\n",
    "    #n_residues = 12\n",
    "\n",
    "    n_pep = sum([(e//n_residues) for e in peptides_list])\n",
    "\n",
    "    trj_dict = {}\n",
    "\n",
    "    for peptide in range(n_pep):\n",
    "\n",
    "        trj_dict[peptide] = {}\n",
    "\n",
    "        if peptide != 0:\n",
    "\n",
    "            counter += n_residues\n",
    "\n",
    "        else:\n",
    "            counter = 0\n",
    "\n",
    "\n",
    "        for res in range(n_residues):\n",
    "\n",
    "            res_name = (str(universe.residues[res + counter]).split()[1].split(',')[0])#.split(',')[0])\n",
    "            res_position = (str(universe.residues[res + counter]).split()[2].split('>')[0])#.split(',')[0])\n",
    "            res_id = res_position + '_' + res_name\n",
    "\n",
    "\n",
    "            for index, atom in enumerate(universe.residues[res + (counter)].atoms):\n",
    "\n",
    "                atom_number = (int(str(atom).split()[1].split(':')[0]) - 1)\n",
    "\n",
    "                coordinate = universe.atoms[atom_number].position\n",
    "                position = len(trj_dict[peptide])\n",
    "                \n",
    "                trj_dict[peptide][position] = coordinate\n",
    "                \n",
    "    return trj_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinate_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj_dict = get_coordinate_dict_for_fixed_lenght_topology(trj_gro, u, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj_dict = get_coordinate_from_gro_all_atom(trj_gro, u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_peptide_lenght_list(topology):\n",
    "    \n",
    "    peptide_lenght_list = []\n",
    "\n",
    "    temporary_list = []\n",
    "\n",
    "    # iterate trough topology\n",
    "    for residue in topology:\n",
    "\n",
    "        # if temporary list just started, add aminoacid position in chain\n",
    "        if len(temporary_list) == 0:\n",
    "            temporary_list.append(int(residue[1]))\n",
    "\n",
    "        else:\n",
    "            # if position of actual residue is less than last residue\n",
    "            if temporary_list[-1] > int(residue[1]):\n",
    "\n",
    "                # append lenght of last peptide to peptide lenght list\n",
    "                peptide_lenght_list.append(len(temporary_list))\n",
    "\n",
    "                # empty temporary list\n",
    "                temporary_list = []\n",
    "\n",
    "                # append actual residue position\n",
    "                temporary_list.append(int(residue[1]))\n",
    "\n",
    "            # if position of actual residue is higher than last residue, ad current residue position\n",
    "            else:\n",
    "                temporary_list.append(int(residue[1]))\n",
    "\n",
    "    # append last peptide lenght to lenght stack\n",
    "    peptide_lenght_list.append(len(temporary_list))\n",
    "\n",
    "    return peptide_lenght_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "u = morphoscanner.topology.make_universe(trj_gro, trj_xtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot_peptide_list(trj_dict, [0,1,2,3,4,5,6,7,8,9,10,11,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = morphoscanner.read.get_peptide_lenght_list(trj_gro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj_dict = get_coordinate_dict_for_fixed_lenght_topology(trj_gro, u, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_tens = morphoscanner.distance_tensor.get_coordinate_tensor(trj_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trj_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_tens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "distances = morphoscanner.distance_tensor.compute_euclidean_norm_torch(coord_tens)\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(distances[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('__Number CUDA Devices:', torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coordinate_dict = morphoscanner.high_level.coordinate_dict_from_gro(trj_gro)\n",
    "coordinate_dict = morphoscanner.topology.\n",
    "coordinate_tens = morphoscanner.distance_tensor.get_coordinate_tensor(coordinate_dict)\n",
    "start = timer()\n",
    "distance_tens = morphoscanner.distance_tensor.compute_euclidean_norm_torch(coordinate_tens)\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory_dict = {}\n",
    "for index, ts in enumerate(universe.trajectory):\n",
    "    print(\"Frame: {0:5d}, Time: {1:8.3f} ps\".format(ts.frame, universe.trajectory.time))\n",
    "    print(\"Rgyr: {0:g} A\".format(universe.atoms.radius_of_gyration()))\n",
    "    print(universe.atoms.positions)\n",
    "    positions = universe.atoms.positions\n",
    "    trajectory_dict[index] = positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df.groupby('time_step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribute python libraryfor i in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trj_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " for i in a.coordinates:\n",
    "        i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot_peptide_from_tensor(trajectory_dict[0], [122])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = a.get_group(2)['coordinates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_dataframe_from_trajectory(trj_gro, trj_xtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bb(dataframe, frame):\n",
    "    \n",
    "    bb_dataframe = dataframe.groupby('time_step').get_group(frame).groupby('atom_type').get_group('BB')\n",
    "    \n",
    "    return bb_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.get_group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.peptide_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_2d_from_0(point):\n",
    "        \n",
    "    \n",
    "    point_0 = [0,0]\n",
    "    \n",
    "    distance = (point_0[0]-point[0])**2 + (point0[1]-point[1])**2\n",
    "    \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = morphoscanner.dataframe.get_dataframe_from_trajectory(trj_gro, trj_xtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "df = morphoscanner.dataframe.get_dataframe_from_trajectory(trj_gro, trj_xtc)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinate_dict = morphoscanner.high_level.coordinate_dict_from_gro_fix_len_peptide(trj_gro, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinate_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('time_step').get_group(0).groupby('peptide_number').get_group(0).groupby('atom_type').get_group('BB').coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate 3d tensor with shape n_peptides * n_residues * n_dimension\n",
    "        def get_coordinate_tensor_dataframe(dataframe):\n",
    "    \n",
    "            #variables wit dict dimension\n",
    "            dim0 = len(dataframe.groupby('time_step'))\n",
    "            dim1 = len(coordinate_dict[0])\n",
    "            dim2 = len(coordinate_dict[0][0])\n",
    "\n",
    "            #initialize a 0s tensor\n",
    "            if torch.cuda.is_available() == True:\n",
    "                \n",
    "                zero = torch.zeros([dim0,dim1,dim2], dtype=torch.float32, device='cuda')\n",
    "\n",
    "            else:\n",
    "                zero = torch.zeros([dim0,dim1,dim2], dtype=torch.float32)\n",
    "\n",
    "\n",
    "            for peptide in coordinate_dict:\n",
    "\n",
    "                for aminoacid in coordinate_dict[peptide]:\n",
    "                    \n",
    "                    \n",
    "                    if torch.cuda.is_available() == True:\n",
    "                        # create torch tensor on cuda device with cordinate [x,y,z...]\n",
    "                        zero[peptide][aminoacid] = torch.cuda.FloatTensor(coordinate_dict[peptide][aminoacid])\n",
    "\n",
    "                    else:\n",
    "                        zero[peptide][aminoacid] = torch.FloatTensor(coordinate_dict[peptide][aminoacid])\n",
    "\n",
    "                        \n",
    "                        \n",
    "            return zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = 0\n",
    "peptide = 0\n",
    "\n",
    "number_of_time_steps = len(df.groupby('time_step'))\n",
    "\n",
    "number_of_atoms = len(df.groupby('time_step').get_group(frame))\n",
    "\n",
    "number_of_peptides = len(df.groupby('time_step').get_group(frame).groupby('peptide_number'))\n",
    "\n",
    "number_of_residues = len(df.groupby('time_step').get_group(frame).groupby('peptide_number').get_group(0))\n",
    "\n",
    "len(df.groupby('time_step').get_group(frame).groupby('peptide_number').get_group(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('time_step').get_group(frame).groupby('peptide_number').get_group(0).coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "\n",
    "#number_of_time_steps = len(df.groupby('time_step'))\n",
    "\n",
    "#number_of_atoms_in_a_step = len(df.groupby('time_step').get_group(step))\n",
    "\n",
    "#number_of_peptides = len(df.groupby('time_step').get_group(step).groupby('peptide_number'))\n",
    "\n",
    "#number_of_atoms_in_peptide = len(df.groupby('time_step').get_group(step).groupby('peptide_number').get_group(peptide))\n",
    "\n",
    "\n",
    "\n",
    "#for step in range(number_of_time_steps):\n",
    "    \n",
    "#    number_of_peptides = len(df.groupby('time_step').get_group(step).groupby('peptide_number'))\n",
    "    \n",
    "for peptide in range(number_of_peptides):\n",
    "\n",
    "    number_of_atoms_in_peptide = len(df.groupby('time_step').get_group(step).groupby('peptide_number').get_group(peptide))\n",
    "\n",
    "    peptide_tensor = torch.tensor(df.groupby('time_step').get_group(step).groupby('peptide_number').get_group(peptide).coordinates, device=device)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('time_step').get_group(0).groupby('peptide_number').get_group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cicle on peptide\n",
    "#for index1, peptide1 in tqdm.tqdm(enumerate(coordinate_tensor)):\n",
    "\n",
    "def distance_maps_from_dataframe(dataframe, time_step):\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    number_of_peptides = len(dataframe.groupby('time_step').get_group(time_step).groupby('peptide_number'))\n",
    "    #number_of_peptides = 5\n",
    "\n",
    "    distance_dict = {}\n",
    "    # iterate trought all peptides in a frame\n",
    "    for peptide1 in range(number_of_peptides):\n",
    "\n",
    "        if peptide1 not in distance_dict.keys():\n",
    "\n",
    "            distance_dict[peptide1] = {}\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        number_of_atoms_in_peptide1 = len(dataframe.groupby('time_step').get_group(time_step).groupby('peptide_number').get_group(peptide1))\n",
    "\n",
    "\n",
    "\n",
    "        peptide1_tensor = morphoscanner.dataframe.get_peptide_tensor_from_dataframe(dataframe, time_step, peptide1)\n",
    "\n",
    "        # iterate trought peptide in the upper triangle only\n",
    "        for peptide2 in range(peptide1, number_of_peptides):\n",
    "\n",
    "\n",
    "            number_of_atoms_in_peptide2 = len(dataframe.groupby('time_step').get_group(time_step).groupby('peptide_number').get_group(peptide2))\n",
    "\n",
    "\n",
    "            peptide2_tensor = morphoscanner.dataframe.get_peptide_tensor_from_dataframe(dataframe, time_step, peptide2)\n",
    "\n",
    "\n",
    "            distance_map = morphoscanner.distance_tensor.distance_matrix_from_2d_tensor(peptide1_tensor, peptide2_tensor)\n",
    "            distance_dict[peptide1][peptide2] = distance_map.cpu().numpy()\n",
    "\n",
    "            if peptide2 in distance_dict.keys():\n",
    "\n",
    "                #distance_dict[peptide2] = {}\n",
    "                distance_dict[peptide2][peptide1] = distance_map.transpose(1,0).cpu().numpy()\n",
    "\n",
    "            else:\n",
    "                distance_dict[peptide2] = {}\n",
    "                distance_dict[peptide2][peptide1] = distance_map.transpose(1,0).cpu().numpy()\n",
    "                \n",
    "    return distance_dict\n",
    "        \n",
    "        # SO YOU CAN CALCULATE DISTANCE MAPS\n",
    "        # NOW YOU HAVE TO PUT THOSE IN A DATAFRAME\n",
    "\n",
    "    #return dist\n",
    "\n",
    "#https://discuss.pytorch.org/t/efficient-distance-matrix-computation/9065\n",
    "#https://www.dropbox.com/h?preview=Parallel+Euclidean+distance+matrix+computation+on+big+datasets.pdf  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(len(distance_dict)-1):\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "step = 0\n",
    "peptide1 = 0\n",
    "peptide2 = 1\n",
    "\n",
    "#peptide_tensor1 = torch.tensor(df.groupby('time_step').get_group(step).groupby('peptide_number').get_group(peptide1).coordinates, device=device)\n",
    "#peptide_tensor2 = torch.tensor(df.groupby('time_step').get_group(step).groupby('peptide_number').get_group(peptide2).coordinates, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(distance_dict[0][4].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(distance_dict[4][0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_dict[4][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.transpose(1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = distance_dict[0][1].cpu().transpose(1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(distance_dict[1][0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = timer()\n",
    "data = morphoscanner.dataframe.get_dataframe_from_trajectory(trj_gro, trj_xtc)\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "maps = distance_maps_from_dataframe(data, 0)\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(maps[2][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(maps[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(216)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(maps[1][8]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe = morphoscanner.topology.make_universe(prod_gro, prod_xtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.topology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe.trajectory.n_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bb_coordinate_from_gro_and_universe(topology, universe): #, bb=True):\n",
    "    \n",
    "    \n",
    "    peptides_list = morphoscanner.topology.get_peptide_length_list(topology)\n",
    "\n",
    "    trj_dict = {}\n",
    "\n",
    "    for peptide, n_res in enumerate(peptides_list[:]):\n",
    "\n",
    "        trj_dict[peptide] = {}\n",
    "\n",
    "        if peptide != 0:\n",
    "\n",
    "            counter += peptides_list[peptide-1]\n",
    "\n",
    "        else:\n",
    "            counter = 0\n",
    "\n",
    "\n",
    "        for res in range(n_res):\n",
    "            \n",
    "            #if bb == True:\n",
    "                \n",
    "                #res_name = (str(universe.residues[res + counter]).split()[1].split(',')[0])#.split(',')[0])\n",
    "            \n",
    "            res_position = int(str(universe.residues[res + counter]).split()[2].split('>')[0]) - 1  #.split(',')[0])\n",
    "            \n",
    "            #res_id = res_position + '_' + res_name\n",
    "            \n",
    "            trj_dict[peptide][res_position] = {}\n",
    "\n",
    "            for index, atom in enumerate(universe.residues[res + counter].atoms):\n",
    "                \n",
    "            #if bb == True:\n",
    "\n",
    "                atom_type = str(atom).split()[2]\n",
    "\n",
    "                if atom_type == 'BB':\n",
    "\n",
    "                    atom_number = int(str(atom).split()[1].split(':')[0])\n",
    "\n",
    "                    coordinate = universe.atoms[atom_number].position\n",
    "\n",
    "                    trj_dict[peptide][res_position] = coordinate\n",
    "\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "            #else:\n",
    "                #atom_type = str(atom).split()[2]\n",
    "                #atom_number = int(str(atom).split()[1].split(':')[0])\n",
    "                #coordinate = universe.atoms[atom_number].position\n",
    "                #trj_dict[peptide][res_position][atom_type]\n",
    "\n",
    "                trj_dict[peptide][res_position] = coordinate\n",
    "\n",
    "\n",
    "                #print(peptide, res_position, coordinate)\n",
    "                \n",
    "    return trj_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dati = []\n",
    "for i in universe.trajectory:\n",
    "    \n",
    "    dati.append(universe.atoms.positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dati[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # COMPUTE CONTACT MAPS\n",
    "# TO DO: parametrize the threshold distance in a better way (e.g. )\n",
    "def compute_contact_maps_as_array(distance_maps_array):\n",
    "\n",
    "    # distance between the first and the second aminoacid of the first chain\n",
    "    intrapeptide_minimum_distance = distance_maps_array[0][0][0][1] \n",
    "\n",
    "    contact_map_list = []\n",
    "\n",
    "    # contact is in a distance up to 150% of the intrapeptide_minimum_distance [TO IMPROVE!!!]\n",
    "    threshold_distance = (intrapeptide_minimum_distance * 1.5)\n",
    "\n",
    "    for model_1 in range(distance_maps_array.shape[0]):\n",
    "        contact_map_list.append([])\n",
    "        for model_2 in range(distance_maps_array[model_1].shape[0]):\n",
    "\n",
    "            contact_map_list[model_1].append([])\n",
    "\n",
    "            if model_1 == model_2:\n",
    "\n",
    "                contact_map_list[model_1][model_2].extend(np.zeros((distance_maps_array.shape[2], distance_maps_array.shape[3])))\n",
    "\n",
    "            else:\n",
    "\n",
    "                contact_map = np.zeros((distance_maps_array.shape[2], distance_maps_array.shape[3]))\n",
    "\n",
    "                for chain_1 in range(distance_maps_array[model_1][model_2].shape[0]):\n",
    "\n",
    "                    for chain_2 in range(distance_maps_array[model_1][model_2][chain_1].shape[0]):\n",
    "\n",
    "                        distance = distance_maps_array[model_1][model_2][chain_1][chain_2]\n",
    "\n",
    "                        if distance < threshold_distance:\n",
    "                            contact_map[chain_1][chain_2] = 1 #True\n",
    "                        else:\n",
    "                            pass\n",
    "\n",
    "                contact_map_list[model_1][model_2].extend(contact_map)\n",
    "\n",
    "    contact_array = np.asarray(contact_map_list)\n",
    "\n",
    "    return contact_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps[0][0][0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dict from a Universe in which each entry is a timestep of the MD simulation\n",
    "def create_trajectory_dict(universe):\n",
    "    bb = universe.select_atoms('name BB')\n",
    "    trajectory_dict = {}\n",
    "    for index, time_steps in enumerate(universe.trajectory):\n",
    "        trajectory_dict[index] = bb.positions\n",
    "    return trajectory_dict\n",
    "\n",
    "# make trajectory dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "trajectory_dict = create_trajectory_dict(universe)\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = get_coordinate_from_gro_topology(trj_gro, universe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe.atoms[0].position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_tens = morphoscanner.distance_tensor.get_coordinate_tensor_from_dict(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_dist = morphoscanner.distance_tensor.compute_euclidean_norm_torch(e_tens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(e_dist[12][12][:12,:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "\n",
    "# DEVI FARE IN MODO DA ORGANIZZARE LE DISTANCE MAP SECONDO LA DIMENSIONE DELLA MATRICE\n",
    "# IN MODO DA POTER FARE UN TENSORE PER SIZE DELLE DISTANCE MAP TRAMITE STACKING\n",
    "\n",
    "# PER ESEMPIO, METTI INSIEME TENSORE CON DISTANCE MAPS DI PROTEINE CON 12 AMINOACIDI,\n",
    "# UN ALTRO TENSORE PER PROTEINE DA 16 AMINOACIDI, E COSÃ VIA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def compute_euclidean_norm_torch(coordinate_tensor):\n",
    "#'''Use matrix to compute euclidean distance dataset wise\n",
    "#    and return a set of distance matrix for everi couple of peptides\n",
    "#\n",
    "#****Runs in parallel on CUDA devices.\n",
    "#\n",
    "#Argument: tensor of shape n_peptide * n_residue * number of dimension (3 for 3d)\n",
    "#\n",
    "#return: tensor of shape n_peptide * n_peptide * n_residue * n_peptide\n",
    "\n",
    "#'''\n",
    "\n",
    "#create tensor of 0s with shape n_pep x n_pep * n_res + n_res\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "zero = torch.zeros((coordinate_tensor.shape[0], coordinate_tensor.shape[0], coordinate_tensor.shape[1], coordinate_tensor.shape[1]), device=device)\n",
    "\n",
    "#cicle on peptide\n",
    "for index1, peptide1 in tqdm.tqdm(enumerate(coordinate_tensor)):\n",
    "\n",
    "    #cicle on peptide (upper triangle + diagonal)\n",
    "    for index2 in range(index1, coordinate_tensor.shape[0]):\n",
    "    #for index2 in range(coordinate_tens.shape[0]):\n",
    "\n",
    "        #coordinate vector\n",
    "        peptide2 = coordinate_tensor[index2]\n",
    "\n",
    "        x_norm = torch.pow(peptide1, 2).sum(1).view(-1,1)\n",
    "        y_t = torch.transpose(peptide2, 0, 1)\n",
    "        y_norm = torch.pow(peptide2, 2).sum(1).view(1,-1)\n",
    "\n",
    "        dist = torch.sqrt(x_norm + y_norm - 2.0 * torch.mm(peptide1, y_t))\n",
    "\n",
    "        #dist = x_norm + y_norm - 2.0 * torch.mm(peptide1, y_t)\n",
    "        #fine = torch.clamp(dist, 0.0, np.inf) #should be there, but is not working somehow\n",
    "\n",
    "        # add distance map in the right position of the 0s tensor\n",
    "        zero[index1][index2] = dist\n",
    "\n",
    "        # if mesuring between different peptides\n",
    "        if index1 != index2:\n",
    "            # put transpose of distance map in lower triangle\n",
    "            zero[index2][index1] = dist.transpose(1,0)\n",
    "\n",
    "#convert nan to 0  (using this instead of torch.clamp())       \n",
    "zero[torch.isnan(zero)] = 0\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    # move to system memory and cast to numpy array\n",
    "    zero = zero.cpu().numpy()\n",
    "\n",
    "return zero\n",
    "\n",
    "#https://discuss.pytorch.org/t/efficient-distance-matrix-computation/9065\n",
    "#https://www.dropbox.com/h?preview=Parallel+Euclidean+distance+matrix+computation+on+big+datasets.pdf     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = mda.coordinates.TRR.TRRReader(trr_prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = a.trajectory[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in a.trajectory():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod = morphoscanner.topology.make_universe(prod_gro, prod_xtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nv.show_mdanalysis(prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_peptide(peptide_coordinate_dict, centroid=False):\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "    \n",
    "    for residue in peptide_coordinate_dict:\n",
    "        point = peptide_coordinate_dict[residue]\n",
    "        x.append(point[0])\n",
    "        y.append(point[1])\n",
    "        z.append(point[2])\n",
    "\n",
    "    \n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    z = np.asarray(z)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    \n",
    "    ax = fig.add_subplot(111, projection = '3d')\n",
    "    ax.plot(x,y,z, c='b')\n",
    "    \n",
    "    if centroid == True:\n",
    "            median_centroid = [np.median(x), np.median(y), np.median(z)]\n",
    "            ax.scatter(median_centroid[0], median_centroid[1], median_centroid[2], c='r')\n",
    "    \n",
    "        # Create cubic bounding box to simulate equal aspect ratio\n",
    "    max_range = np.array([x.max()-x.min(), y.max()-y.min(), z.max()-z.min()]).max()\n",
    "    Xb = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][0].flatten() + 0.5*(x.max()+x.min())\n",
    "    Yb = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][1].flatten() + 0.5*(y.max()+y.min())\n",
    "    Zb = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][2].flatten() + 0.5*(z.max()+z.min())\n",
    "    # Comment or uncomment following both lines to test the fake bounding box:\n",
    "    #for xb, yb, zb in zip(Xb, Yb, Zb):\n",
    "     #   ax.plot([xb], [yb], [zb], 'w')\n",
    "            \n",
    "    return plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = morphoscanner.high_level.coordinate_dict_from_gro(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_single_peptide(test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot_single_peptide(a_dict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dict = morphoscanner.high_level.coordinate_dict_from_gro(prod_gro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot_peptide_list(a_dict, [e for e in a_dict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "prod_df = morphoscanner.dataframe.get_dataframe_from_trajectory(prod_gro, prod_xtc)\n",
    "end = timer()\n",
    "print(end-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dict = create_trajectory_dict(prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "a_dict = morphoscanner.topology.create_trajectory_dict(prod)\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dict[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(u_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot_peptide_from_tensor(a_dict[2000], [e for e in range(a_dict[2000].shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe = morphoscanner.topology.make_universe(prod_gro, prod_xtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe.trajectory[:20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_mini = universe.trajectory[:20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict_from_trajectory(trj_gro, trj_xtc, peptide_length = None):\n",
    "\n",
    "    universe = morphoscanner.topology.make_universe(trj_gro, trj_xtc)\n",
    "\n",
    "    topology = trj_gro\n",
    "\n",
    "    peptides_list = morphoscanner.topology.get_peptide_length_list(trj_gro)\n",
    "\n",
    "\n",
    "    if peptide_length == None:\n",
    "    \n",
    "\n",
    "        n_pep = len(peptides_list)\n",
    "\n",
    "\n",
    "    else:\n",
    "\n",
    "        n_pep = sum([(e//peptide_length) for e in peptides_list])\n",
    "\n",
    "    #columns_name = ['atom_number','peptide_number', 'residue_name', 'residue_position', 'coordinates']\n",
    "    #columns_name = ['time_step','peptide_number', 'residue_position', 'residue_name', 'atom_position', 'atom_type', 'coordinates']\n",
    "\n",
    "    # create list for a pd.DataFrame\n",
    "    # as suggested in https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.append.html\n",
    "    #for_pandas = []\n",
    "\n",
    "    trj_dict = {}\n",
    "\n",
    "    #for index_ts, ts in tqdm.tqdm(enumerate(universe.trajectory)):\n",
    "    for index_ts, ts in enumerate(universe.trajectory):\n",
    "\n",
    "        trj_dict[index_ts] = {}\n",
    "\n",
    "        for peptide in range(n_pep):\n",
    "\n",
    "            trj_dict[index_ts][peptide] = {}\n",
    "\n",
    "            if peptide != 0:\n",
    "                \n",
    "                # if to check peptide_length\n",
    "                \n",
    "                if peptide_length == None:\n",
    "\n",
    "                    counter += peptides_list[peptide - 1]\n",
    "                \n",
    "                else:\n",
    "                    counter += peptide_length\n",
    "        \n",
    "\n",
    "            else:\n",
    "                counter = 0\n",
    "            \n",
    "            \n",
    "            \n",
    "            if peptide_length == None:\n",
    "\n",
    "                for res in range(peptides_list[peptide]):\n",
    "\n",
    "                    res_name = (str(universe.residues[res + counter]).split()[1].split(',')[0])#.split(',')[0])\n",
    "                    res_position = int(str(universe.residues[res + counter]).split()[2].split('>')[0])#.split(',')[0])\n",
    "                    res_id = str(res_position) + '_' + res_name\n",
    "\n",
    "                    #print(str(universe.residues[res + counter]))\n",
    "\n",
    "                    for index, atom in enumerate(universe.residues[res + (counter)].atoms):\n",
    "\n",
    "                        #print(atom)\n",
    "\n",
    "                        atom_number = (int(str(atom).split()[1].split(':')[0]) - 1)\n",
    "\n",
    "                        #atom_type = str(atom).split()[2]\n",
    "\n",
    "                        coordinate = universe.atoms[atom_number].position\n",
    "\n",
    "                        position = len(trj_dict[index_ts][peptide])\n",
    "\n",
    "                        trj_dict[index_ts][peptide][position] = coordinate\n",
    "\n",
    "                        #features = [atom_number,peptide, res_name, position, coordinate]\n",
    "                        #features = [index_ts, peptide, res_position, res_name, position, atom_type, coordinate]\n",
    "\n",
    "                        #for_pandas.append(features)\n",
    "                        \n",
    "            else:\n",
    "                \n",
    "                for res in range(peptide_length):\n",
    "\n",
    "                    #res_name = (str(universe.residues[res + counter]).split()[1].split(',')[0])#.split(',')[0])\n",
    "                    #res_position = int(str(universe.residues[res + counter]).split()[2].split('>')[0])#.split(',')[0])\n",
    "                    #res_id = str(res_position) + '_' + res_name\n",
    "\n",
    "                    #print(str(universe.residues[res + counter]))\n",
    "\n",
    "                    for index, atom in enumerate(universe.residues[res + (counter)].atoms):\n",
    "\n",
    "                        #print(atom)\n",
    "\n",
    "                        atom_number = (int(str(atom).split()[1].split(':')[0]) - 1)\n",
    "\n",
    "                        #atom_type = str(atom).split()[2]\n",
    "\n",
    "                        coordinate = universe.atoms[atom_number].position\n",
    "\n",
    "                        position = len(trj_dict[index_ts][peptide])\n",
    "\n",
    "                        trj_dict[index_ts][peptide][position] = coordinate\n",
    "\n",
    "                        #features = [atom_number,peptide, res_name, position, coordinate]\n",
    "                        #features = [index_ts, peptide, res_position, res_name, position, atom_type, coordinate]\n",
    "\n",
    "                        #for_pandas.append(features)\n",
    "                \n",
    "\n",
    "\n",
    "    #start = timer()\n",
    "    #df = pd.DataFrame(for_pandas,columns=columns_name)\n",
    "    #end = timer()\n",
    "    #print(end-start)\n",
    "    return trj_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "a_new = get_dict_from_trajectory(prod_gro, prod_xtc)\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#start_from = 0\n",
    "#interval = 200\n",
    "\n",
    "#peptide_length = None\n",
    "#peptides_list = morphoscanner.topology.get_peptide_length_list(prod_gro)\n",
    "\n",
    "\n",
    "#n_pep = len(peptides_list)\n",
    "\n",
    "\n",
    "#else:\n",
    "\n",
    " #   n_pep = sum([(e//peptide_length) for e in peptides_list])\n",
    "\n",
    "#columns_name = ['atom_number','peptide_number', 'residue_name', 'residue_position', 'coordinates']\n",
    "#columns_name = ['time_step','peptide_number', 'residue_position', 'residue_name', 'atom_position', 'atom_type', 'coordinates']\n",
    "\n",
    "# create list for a pd.DataFrame\n",
    "# as suggested in https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.append.html\n",
    "#for_pandas = []\n",
    "\n",
    "def get_coordinate_dict_from_trajectory(trj_gro, trj_xtc, peptide_length=None, start_from=0, interval=0):\n",
    "\n",
    "    peptides_list = morphoscanner.topology.get_peptide_length_list(trj_gro)\n",
    "\n",
    "    universe = morphoscanner.topology.make_universe(trj_gro, trj_xtc)\n",
    "\n",
    "\n",
    "    if peptide_length == None:\n",
    "    \n",
    "\n",
    "        n_pep = len(peptides_list)\n",
    "\n",
    "\n",
    "    else:\n",
    "\n",
    "        n_pep = sum([(e//peptide_length) for e in peptides_list])\n",
    "\n",
    "\n",
    "    trj_dict = {}\n",
    "\n",
    "    for index_ts, ts in tqdm.tqdm(enumerate(universe.trajectory)):\n",
    "    #for index_ts, ts in enumerate(universe.trajectory):\n",
    "    \n",
    "        updated_index = (index_ts + start_from)\n",
    "\n",
    "        if (updated_index % interval) == 0:\n",
    "\n",
    "            trj_dict[updated_index] = {}\n",
    "\n",
    "            for peptide in range(n_pep):\n",
    "\n",
    "                trj_dict[updated_index][peptide] = {}\n",
    "\n",
    "\n",
    "                if peptide != 0:\n",
    "\n",
    "                    # if to check peptide_length\n",
    "\n",
    "                    if peptide_length == None:\n",
    "\n",
    "                        counter += peptides_list[peptide - 1]\n",
    "\n",
    "                    else:\n",
    "                        counter += peptide_length\n",
    "\n",
    "\n",
    "                else:\n",
    "                    counter = 0\n",
    "\n",
    "\n",
    "\n",
    "                if peptide_length == None:\n",
    "\n",
    "                    for res in range(peptides_list[peptide]):\n",
    "\n",
    "                        for index, atom in enumerate(universe.residues[res + (counter)].atoms):\n",
    "\n",
    "\n",
    "                            atom_type = str(atom).split()[2]\n",
    "                            \n",
    "                            if atom_type == 'BB':\n",
    "\n",
    "                                atom_number = (int(str(atom).split()[1].split(':')[0]) - 1)\n",
    "\n",
    "                                coordinate = universe.atoms[atom_number].position\n",
    "\n",
    "                                position = len(trj_dict[updated_index][peptide])\n",
    "\n",
    "\n",
    "                                trj_dict[updated_index][peptide][position] = coordinate\n",
    "\n",
    "               \n",
    "                else:\n",
    "\n",
    "                    for res in range(peptide_length):\n",
    "\n",
    "                        for index, atom in enumerate(universe.residues[res + (counter)].atoms):\n",
    "\n",
    "              \n",
    "                            atom_type = str(atom).split()[2]\n",
    "\n",
    "\n",
    "                            if atom_type == 'BB':\n",
    "\n",
    "                                atom_number = (int(str(atom).split()[1].split(':')[0]) - 1)\n",
    "\n",
    "                                coordinate = universe.atoms[atom_number].position\n",
    "\n",
    "                                position = len(trj_dict[updated_index][peptide])\n",
    "\n",
    "\n",
    "                                trj_dict[updated_index][peptide][position] = coordinate\n",
    "\n",
    "                            else:\n",
    "                                pass\n",
    "    \n",
    "    \n",
    "    return trj_dict\n",
    "\n",
    "\n",
    "                        \n",
    "                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "\n",
    "trj_dict = get_coordinate_dict_from_trajectory(prod_gro, prod_xtc)\n",
    "                        \n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "\n",
    "trj_dict_18mer = get_coordinate_dict_from_trajectory(prod_gro, prod_xtc, peptide_length=18)\n",
    "                       \n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot_peptide_list(trj_dict_18mer[0], [e for e in range(6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trj_dict_18mer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot_single_peptide(pep_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trj_dict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pep_dict = {}\n",
    "for i in range(12):\n",
    "    pep_dict[i] = trj_dict[0][0][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame20_fine_distance_maps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frame20_fine_distance_maps[18][18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frame20_fine_distance_maps[0][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame20_dict = trj_dict_6mer[4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame20_tens = morphoscanner.distance_tensor.get_coordinate_tensor_from_dict(frame20_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame20_distance = morphoscanner.distance_tensor.compute_euclidean_norm_torch(frame20_tens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frame20_distance[15][16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_20_contact_maps = morphoscanner.distance.compute_contact_maps_as_array(frame20_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frame_20_contact_maps[0][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_20_contact_maps = morphoscanner.distance.compute_contact_maps_as_array(frame20_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frame_20_contact_maps[15][26])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame20_denoised_contact = morphoscanner.denoise.denoise_contact_maps(frame_20_contact_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = morphoscanner.graph.nx_graph_search(frame20_denoised_contact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph = morphoscanner.graph.find_subgraph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot_peptide_list(frame20_dict, [469,468,473])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[i for e in subgraph for i in e]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_graph = morphoscanner.graph.full_graph(frame20_denoised_contact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(full_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_subraph = morphoscanner.graph.find_subgraph(full_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "frame20_gross_dict = trj_dict[4000]\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "\n",
    "start = timer()\n",
    "frame20_gross_distance_tens = morphoscanner.distance_tensor.get_coordinate_tensor_from_dict(frame20_gross_dict)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "\n",
    "start = timer()\n",
    "frame20_gross_distance_maps = morphoscanner.distance_tensor.compute_euclidean_norm_torch(frame20_gross_distance_tens)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "\n",
    "start = timer()\n",
    "frame20_gross_contact = morphoscanner.distance.compute_contact_maps_as_array(frame20_gross_distance_maps)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "\n",
    "start = timer()\n",
    "frame20_gross_denoised = morphoscanner.denoise.denoise_contact_maps(frame20_gross_contact)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#frame20_graph = morphoscanner.graph.nx_graph_search(frame20_denoised_contact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frame20_gross_denoised[15][16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "frame20_gross_graph = morphoscanner.graph.full_graph(frame20_gross_denoised)\n",
    "end = timer()\n",
    "print(end-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.trj_dict[4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(frame20_gross_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame20_gross_subgraph = morphoscanner.graph.find_subgraph(frame20_gross_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame20_gross_subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot_peptide_list(frame20_gross_dict, [e for e in frame20_gross_subgraph[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame20_gross_out = morphoscanner.graph.get_not_in_subgraph(frame20_gross_graph, frame20_gross_subgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame20_gross_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "trj_gross_dict = trj_dict[0]\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "\n",
    "start = timer()\n",
    "trj_gross_distance_tens = morphoscanner.distance_tensor.get_coordinate_tensor_from_dict(trj_gross_dict)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "\n",
    "start = timer()\n",
    "trj_gross_distance_maps = morphoscanner.distance_tensor.compute_euclidean_norm_torch(trj_gross_distance_tens)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "\n",
    "start = timer()\n",
    "trj_gross_contact = morphoscanner.distance.compute_contact_maps_as_array(trj_gross_distance_maps)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "\n",
    "start = timer()\n",
    "trj_gross_denoised = morphoscanner.denoise.denoise_contact_maps(trj_gross_contact)\n",
    "end = timer()\n",
    "print(end-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj_graph = morphoscanner.graph.full_graph(trj_gross_denoised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(trj_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "trj_pep_gross_dict = trj_dict_12mer[0]\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "\n",
    "start = timer()\n",
    "trj_pep_gross_distance_tens = morphoscanner.distance_tensor.get_coordinate_tensor_from_dict(trj_pep_gross_dict)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "\n",
    "start = timer()\n",
    "trj_pep_gross_distance_maps = morphoscanner.distance_tensor.compute_euclidean_norm_torch(trj_pep_gross_distance_tens)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "\n",
    "start = timer()\n",
    "trj_pep_gross_contact = morphoscanner.distance.compute_contact_maps_as_array(trj_pep_gross_distance_maps)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "\n",
    "start = timer()\n",
    "trj_pep_gross_denoised = morphoscanner.denoise.denoise_contact_maps(trj_pep_gross_contact)\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj_pep_graph = morphoscanner.graph.full_graph(trj_pep_gross_denoised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(trj_pep_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot_peptide_list(trj_dict[0], [e for e in trj_dict[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(trj_gross_distance_maps[26][24][:12,:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj_gross_distance_tens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "\n",
    "trj_dict_18mer = get_coordinate_dict_from_trajectory(prod_gro, prod_xtc, peptide_length=18)\n",
    "                        \n",
    "end = timer()\n",
    "print(end - start)\n",
    "\n",
    "start = timer()\n",
    "frame20_fine_tensor = morphoscanner.distance_tensor.get_coordinate_tensor_from_dict(trj_dict_18mer[4000])\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "\n",
    "start = timer()\n",
    "frame20_fine_distance_maps = morphoscanner.distance_tensor.compute_euclidean_norm_torch(frame20_fine_tensor)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "\n",
    "start = timer()\n",
    "frame20_fine_contact = morphoscanner.distance.compute_contact_maps_as_array(frame20_fine_distance_maps)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "\n",
    "start = timer()\n",
    "frame20_fine_denoised = morphoscanner.denoise.denoise_contact_maps(frame20_fine_contact)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "\n",
    "start = timer()\n",
    "frame20_fine_graph = morphoscanner.graph.nx_graph_search(frame20_fine_denoised)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "\n",
    "start = timer()\n",
    "frame20_fine_graph_full = morphoscanner.graph.full_graph(frame20_fine_denoised)\n",
    "end = timer()\n",
    "print(end-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "\n",
    "trj_dict_gross = get_coordinate_dict_from_trajectory(proclassd_gro, prod_xtc)\n",
    "                        \n",
    "end = timer()\n",
    "print(end - start)\n",
    "\n",
    "start = timer()\n",
    "frame20_gross_tensor = morphoscanner.distance_tensor.get_coordinate_tensor_from_dict(trj_dict_gross[4000])\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "\n",
    "start = timer()\n",
    "frame20_gross_distance_maps = morphoscanner.distance_tensor.compute_euclidean_norm_torch(frame20_gross_tensor)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "\n",
    "start = timer()\n",
    "frame20_gross_contact = morphoscanner.distance.compute_contact_maps_as_array(frame20_gross_distance_maps)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "\n",
    "start = timer()\n",
    "frame20_gross_denoised = morphoscanner.denoise.denoise_contact_maps(frame20_gross_contact)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "\n",
    "start = timer()\n",
    "frame20_gross_graph = morphoscanner.graph.nx_graph_search(frame20_gross_denoised)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "\n",
    "start = timer()\n",
    "frame20_gross_graph_full = morphoscanner.graph.full_graph(frame20_gross_denoised)\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(frame20_fine_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(frame20_fine_graph_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot_single_peptide(trj_dict_18mer[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(frame20_gross_graph_full)class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(frame20_gross_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame20_gross_subgraph = morphoscanner.graph.find_subgraph(frame20_gross_graph_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame20_gross_subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_analysis(frame_dict):\n",
    "    \n",
    "    #trj_dict= get_coordinate_dict_from_trajectory(prod_gro, prod_xtc, peptide_length)\n",
    "\n",
    "    frame_tensor = morphoscanner.distance_tensor.get_coordinate_tensor_from_dict(frame_dict)\n",
    "\n",
    "    frame_distance_maps = morphoscanner.distance_tensor.compute_euclidean_norm_torch(frame_tensor)\n",
    "\n",
    "    frame_contact = morphoscanner.distance.compute_contact_maps_as_array(frame_distance_maps)\n",
    "\n",
    "    frame_denoised = morphoscanner.denoise.denoise_contact_maps(frame_contact)\n",
    "\n",
    "    frame_graph = morphoscanner.graph.nx_graph_search(frame_denoised)\n",
    "\n",
    "    frame_graph_full = morphoscanner.graph.full_graph(frame_denoised)\n",
    "    \n",
    "    return frame_graph, frame_contact\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj_dict= morphoscanner.topology.get_coordinate_dict_from_trajectory(prod_gro, prod_xtc, peptide_length=18, interval=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_dict = trj_dict[4000]\n",
    "\n",
    "frame_tensor = morphoscanner.distance_tensor.get_coordinate_tensor_from_dict(frame_dict)\n",
    "\n",
    "frame_distance_maps = morphoscanner.distance_tensor.compute_euclidean_norm_torch(frame_tensor)\n",
    "\n",
    "frame_contact = morphoscanner.distance.compute_contact_maps_as_array(frame_distance_maps)\n",
    "\n",
    "frame_denoised, df = morphoscanner.denoise.denoise_contact_maps(frame_contact)\n",
    "\n",
    "frame_graph = morphoscanner.graph.nx_graph_search(frame_denoised)\n",
    "\n",
    "frame_graph_full = morphoscanner.graph.full_graph(frame_denoised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_names = ['Normalized Cross Correlation Value', 'shift index', 'contacts', 'sense']\n",
    "\n",
    "df = pd.DataFrame(max_val, columns=columns_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[e for e in max_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        #def normalized_cross_correlation_for_dataset(contact_array):\n",
    "            #'''Calculate normalized cross correlation function between the full contacts map and and the .\n",
    "\n",
    "#            Arguments : contact map, as output from get_contact_maps function\n",
    "#                        shift_matrix_stack, as output from shift_matrix_maker function\n",
    "#\n",
    "#            Return : a list [ncc_value, index (in the shift_matrix_stack) of the shift matrix that is matching the contact map'''\n",
    "#\n",
    "contact_array = frame_contact\n",
    "        \n",
    "contact_dict = {}\n",
    "\n",
    "#for row in tqdm.tqdm(range(contact_array.shape[0])):\n",
    "for row in range(contact_array.shape[0]):\n",
    "\n",
    "    for col in range((row+1), contact_array.shape[1]):\n",
    "        \n",
    "        best_match = []\n",
    "        best_match = morphoscanner.cross_correlation.normalized_cross_correlation_function(contact_array[row][col])\n",
    "\n",
    "        if len(best_match) == 0:\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "            if row in contact_dict:\n",
    "                contact_dict[row].append([row, col, best_match])\n",
    "\n",
    "            else:\n",
    "                contact_dict[row] = [[row, col, best_match]]\n",
    "\n",
    "#return contact_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contact_array = frame_contact\n",
    "def cross_correlation_function_for_dataset_with_dataframe(contact_array):\n",
    "    '''Perform Normalized Cross Correlation function on the dataset\n",
    "        to check for contact. Get a dict for processing and a pandas.DataFrame\n",
    "        for data analysis\n",
    "        \n",
    "        Input: contact maps\n",
    "        \n",
    "        Output: contact_dict,         for further processing\n",
    "                pandas.DataFrame,     for data analysis\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    contact_dict = {}\n",
    "\n",
    "    for row in range(contact_array.shape[0]):\n",
    "\n",
    "        for col in range((row+1), contact_array.shape[1]):\n",
    "            best_match = []\n",
    "            best_match = morphoscanner.cross_correlation.normalized_cross_correlation_function(contact_array[row][col])\n",
    "\n",
    "            if len(best_match) == 0:\n",
    "                pass\n",
    "\n",
    "            else:\n",
    "                if row in contact_dict:\n",
    "                    contact_dict[row].append([row, col, best_match])\n",
    "\n",
    "                else:\n",
    "                    contact_dict[row] = [[row, col, best_match]]\n",
    "\n",
    "    contact_list = contact_list_from_dict(contact_dict)\n",
    "\n",
    "    columns_names = ['peptide1', 'peptide2', 'NCC Value', 'shift index', 'contacts', 'sense']\n",
    "\n",
    "    df = pd.DataFrame(contact_list, columns=columns_names)\n",
    "    \n",
    "    return contact_dict, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contact_dict, df = cross_correlation_function_for_dataset(frame_contact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('sense').get_group('antiparallel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contact_list = []\n",
    "for peptide in contact_dict:\n",
    "    \n",
    "    for contact in contact_dict[peptide]:\n",
    "        \n",
    "        contact_list.append(contact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contact_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_names = ['peptide1', 'peptide2', 'NCC Value', 'shift index', 'contacts', 'sense']\n",
    "\n",
    "df = pd.DataFrame(contact_list, columns=columns_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df.groupby(['peptide1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = df.groupby(['peptide2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.groups.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contact_list_from_dict(contact_dict):\n",
    "    contact_list = []\n",
    "    for peptide in contact_dict:\n",
    "\n",
    "        for contact in contact_dict[peptide]:\n",
    "\n",
    "            new_data = [contact[0], contact[1], contact[2][0], contact[2][1], contact[2][2], contact[2][3]]\n",
    "            contact_list.append(new_data)\n",
    "    return contact_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contact_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(contact_array[0][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(contact_array[3][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = morphoscanner.cross_correlation.shift_library_maker(contact_array[0][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(matrix['antiparallel'][29])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = morphoscanner.cross_correlation.normalized_cross_correlation_function(contact_array[3][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class aggregate(object):\n",
    "    \n",
    "    trj_dict= morphoscanner.topology.get_coordinate_dict_from_trajectory(prod_gro, prod_xtc, peptide_length=18, interval=200)\n",
    "    frame_dict = trj_dict[4000]\n",
    "\n",
    "    frame_tensor = morphoscanner.distance_tensor.get_coordinate_tensor_from_dict(frame_dict)\n",
    "\n",
    "    frame_distance_maps = morphoscanner.distance_tensor.compute_euclidean_norm_torch(frame_tensor)\n",
    "\n",
    "    frame_contact = morphoscanner.distance.compute_contact_maps_as_array(frame_distance_maps)\n",
    "\n",
    "    frame_denoised, df = morphoscanner.denoise.denoise_contact_maps(frame_contact)\n",
    "\n",
    "    frame_graph = morphoscanner.graph.nx_graph_search(frame_denoised)\n",
    "\n",
    "    frame_graph_full = morphoscanner.graph.full_graph(frame_denoised)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(aggregate.frame_distance_maps[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate.frame_graph_full.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class aggregate:\n",
    "    \n",
    "    '''Class to operate on trajectory files.\n",
    "    \n",
    "    It makes a'''\n",
    "    \n",
    "    \n",
    "\n",
    "    def __init__(self, trj_gro, trj_xtc):\n",
    "        \n",
    "        self.trj_gro = trj_gro\n",
    "        self.trj_xtc = trj_xtc\n",
    "        self.universe = morphoscanner.topology.make_universe(self.trj_gro, self.trj_xtc)\n",
    "        self.peptide_length_list = morphoscanner.topology.get_peptide_length_list(self.trj_gro)\n",
    "        self.number_of_frames = len(self.universe.trajectory)\n",
    "        \n",
    "        self.frames = {}\n",
    "\n",
    "        \n",
    "    \n",
    "    def compose_database(self, peptide_length=None, start_from=0, interval=0):\n",
    "        \n",
    "        self.peptide_length = peptide_length\n",
    "        self.start_from = start_from\n",
    "        self.interval = interval\n",
    "        \n",
    "        self.data = morphoscanner.topology.get_coordinate_dict_from_trajectory(self.trj_gro, self.trj_xtc, peptide_length=self.peptide_length, start_from=self.start_from, interval=self.interval)\n",
    "\n",
    "        self.sampled_frames = [key for key in self.data.keys()]\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def analysis(self, frame):\n",
    "        \n",
    "        self.frame = frame        \n",
    "    \n",
    "        self.frame_dict = self.data[self.frame]\n",
    "\n",
    "        self.frame_tensor = morphoscanner.distance_tensor.get_coordinate_tensor_from_dict(self.frame_dict)\n",
    "\n",
    "        self.frame_distance_maps = morphoscanner.distance_tensor.compute_euclidean_norm_torch(self.frame_tensor)\n",
    "\n",
    "        self.frame_contact = morphoscanner.distance.compute_contact_maps_as_array(self.frame_distance_maps)\n",
    "\n",
    "        self.frame_denoised, self.df = morphoscanner.denoise.denoise_contact_maps(self.frame_contact)\n",
    "\n",
    "        self.frame_graph = morphoscanner.graph.nx_graph_search(self.frame_denoised)\n",
    "\n",
    "        self.frame_graph_full = morphoscanner.graph.full_graph(self.frame_denoised)\n",
    "        \n",
    "        if self.frame not in self.frames:\n",
    "            \n",
    "            self.frames[self.frame] = {'frame_dict': self.frame_dict,\n",
    "                                          'frame_data' : self.df,\n",
    "                                          'frame_graph' : self.frame_graph,\n",
    "                                          'frame_graph_full' : self.frame_graph_full}\n",
    "            \n",
    "    \n",
    "    \n",
    "    def get_sense(self):\n",
    "    \n",
    "        sense_dict = {}\n",
    "\n",
    "        for e in self.frames:\n",
    "\n",
    "            parallel = len(self.frames[e]['frame_data'].groupby('sense').get_group('parallel'))\n",
    "            antiparallel = len(self.frames[e]['frame_data'].groupby('sense').get_group('antiparallel'))\n",
    "\n",
    "            sense_dict[e] = {'parallel' : parallel,\n",
    "                            'antiparallel' : antiparallel}\n",
    "\n",
    "        return sense_dict\n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    #class frame():\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = aggregate(trj_gro=prod_gro, trj_xtc=prod_xtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = morphoscanner.trajectory(trj_gro=prod_gro, trj_xtc=prod_xtc, peptide_length=18, interval=200, frame=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(a.universe.trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(a.frames[4000]['frame_graph'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  3.10it/s]\u001b[A\n",
      "8it [00:00,  4.35it/s]\u001b[A\n",
      "15it [00:00,  6.05it/s]\u001b[A\n",
      "22it [00:00,  8.33it/s]\u001b[A\n",
      "29it [00:00, 11.27it/s]\u001b[A\n",
      "37it [00:00, 15.08it/s]\u001b[A\n",
      "44it [00:00, 19.67it/s]\u001b[A\n",
      "51it [00:01, 24.96it/s]\u001b[A\n",
      "59it [00:01, 30.98it/s]\u001b[A\n",
      "67it [00:01, 37.30it/s]\u001b[A\n",
      "74it [00:01, 43.33it/s]\u001b[A\n",
      "81it [00:01, 48.90it/s]\u001b[A\n",
      "88it [00:01, 53.50it/s]\u001b[A\n",
      "96it [00:01, 57.70it/s]\u001b[A\n",
      "103it [00:01, 60.42it/s]\u001b[A\n",
      "110it [00:01, 62.14it/s]\u001b[A\n",
      "117it [00:02, 63.39it/s]\u001b[A\n",
      "124it [00:02, 64.05it/s]\u001b[A\n",
      "132it [00:02, 65.99it/s]\u001b[A\n",
      "140it [00:02, 67.48it/s]\u001b[A\n",
      "148it [00:02, 68.67it/s]\u001b[A\n",
      "156it [00:02, 69.48it/s]\u001b[A\n",
      "164it [00:02, 70.06it/s]\u001b[A\n",
      "172it [00:02, 70.73it/s]\u001b[A\n",
      "180it [00:02, 70.54it/s]\u001b[A\n",
      "188it [00:03, 69.69it/s]\u001b[A\n",
      "195it [00:03, 69.38it/s]\u001b[A\n",
      "202it [00:03, 35.71it/s]\u001b[A\n",
      "209it [00:03, 41.47it/s]\u001b[A\n",
      "216it [00:03, 46.74it/s]\u001b[A\n",
      "224it [00:03, 51.96it/s]\u001b[A\n",
      "231it [00:03, 55.25it/s]\u001b[A\n",
      "238it [00:04, 58.82it/s]\u001b[A\n",
      "245it [00:04, 60.45it/s]\u001b[A\n",
      "253it [00:04, 63.35it/s]\u001b[A\n",
      "260it [00:04, 65.15it/s]\u001b[A\n",
      "268it [00:04, 66.83it/s]\u001b[A\n",
      "275it [00:04, 67.70it/s]\u001b[A\n",
      "283it [00:04, 68.62it/s]\u001b[A\n",
      "290it [00:04, 67.67it/s]\u001b[A\n",
      "298it [00:04, 68.64it/s]\u001b[A\n",
      "306it [00:05, 69.18it/s]\u001b[A\n",
      "313it [00:05, 68.05it/s]\u001b[A\n",
      "321it [00:05, 68.82it/s]\u001b[A\n",
      "328it [00:05, 69.13it/s]\u001b[A\n",
      "336it [00:05, 69.56it/s]\u001b[A\n",
      "343it [00:05, 69.61it/s]\u001b[A\n",
      "351it [00:05, 69.86it/s]\u001b[A\n",
      "358it [00:05, 69.90it/s]\u001b[A\n",
      "366it [00:05, 70.08it/s]\u001b[A\n",
      "374it [00:06, 70.15it/s]\u001b[A\n",
      "382it [00:06, 70.21it/s]\u001b[A\n",
      "390it [00:06, 70.01it/s]\u001b[A\n",
      "398it [00:06, 70.08it/s]\u001b[A\n",
      "406it [00:06, 35.74it/s]\u001b[A\n",
      "414it [00:06, 42.01it/s]\u001b[A\n",
      "421it [00:07, 47.42it/s]\u001b[A\n",
      "428it [00:07, 52.14it/s]\u001b[A\n",
      "435it [00:07, 56.38it/s]\u001b[A\n",
      "443it [00:07, 60.22it/s]\u001b[A\n",
      "450it [00:07, 62.78it/s]\u001b[A\n",
      "458it [00:07, 64.88it/s]\u001b[A\n",
      "466it [00:07, 66.44it/s]\u001b[A\n",
      "473it [00:07, 66.98it/s]\u001b[A\n",
      "480it [00:07, 67.20it/s]\u001b[A\n",
      "487it [00:08, 67.86it/s]\u001b[A\n",
      "494it [00:08, 68.36it/s]\u001b[A\n",
      "501it [00:08, 67.63it/s]\u001b[A\n",
      "508it [00:08, 67.01it/s]\u001b[A\n",
      "515it [00:08, 67.50it/s]\u001b[A\n",
      "522it [00:08, 68.00it/s]\u001b[A\n",
      "530it [00:08, 68.74it/s]\u001b[A\n",
      "538it [00:08, 69.25it/s]\u001b[A\n",
      "545it [00:08, 69.11it/s]\u001b[A\n",
      "552it [00:08, 69.21it/s]\u001b[A\n",
      "559it [00:09, 69.14it/s]\u001b[A\n",
      "567it [00:09, 69.59it/s]\u001b[A\n",
      "575it [00:09, 69.74it/s]\u001b[A\n",
      "582it [00:09, 69.67it/s]\u001b[A\n",
      "590it [00:09, 70.27it/s]\u001b[A\n",
      "598it [00:09, 70.24it/s]\u001b[A\n",
      "606it [00:10, 39.47it/s]\u001b[A\n",
      "613it [00:10, 45.40it/s]\u001b[A\n",
      "621it [00:10, 50.94it/s]\u001b[A\n",
      "628it [00:10, 55.36it/s]\u001b[A\n",
      "636it [00:10, 59.07it/s]\u001b[A\n",
      "643it [00:10, 61.91it/s]\u001b[A\n",
      "650it [00:10, 64.00it/s]\u001b[A\n",
      "657it [00:10, 65.32it/s]\u001b[A\n",
      "664it [00:10, 65.69it/s]\u001b[A\n",
      "671it [00:10, 66.00it/s]\u001b[A\n",
      "678it [00:11, 66.44it/s]\u001b[A\n",
      "686it [00:11, 67.64it/s]\u001b[A\n",
      "694it [00:11, 68.65it/s]\u001b[A\n",
      "701it [00:11, 68.88it/s]\u001b[A\n",
      "709it [00:11, 69.56it/s]\u001b[A\n",
      "716it [00:11, 69.33it/s]\u001b[A\n",
      "723it [00:11, 66.75it/s]\u001b[A\n",
      "730it [00:11, 65.99it/s]\u001b[A\n",
      "738it [00:11, 67.39it/s]\u001b[A\n",
      "746it [00:12, 68.31it/s]\u001b[A\n",
      "754it [00:12, 69.02it/s]\u001b[A\n",
      "761it [00:12, 69.11it/s]\u001b[A\n",
      "768it [00:12, 69.17it/s]\u001b[A\n",
      "776it [00:12, 69.75it/s]\u001b[A\n",
      "784it [00:12, 70.02it/s]\u001b[A\n",
      "792it [00:12, 69.19it/s]\u001b[A\n",
      "800it [00:12, 69.59it/s]\u001b[A\n",
      "807it [00:13, 36.85it/s]\u001b[A\n",
      "814it [00:13, 42.78it/s]\u001b[A\n",
      "821it [00:13, 47.78it/s]\u001b[A\n",
      "828it [00:13, 51.65it/s]\u001b[A\n",
      "835it [00:13, 55.06it/s]\u001b[A\n",
      "842it [00:13, 58.25it/s]\u001b[A\n",
      "849it [00:13, 61.11it/s]\u001b[A\n",
      "856it [00:13, 62.16it/s]\u001b[A\n",
      "863it [00:14, 63.86it/s]\u001b[A\n",
      "870it [00:14, 64.94it/s]\u001b[A\n",
      "877it [00:14, 65.72it/s]\u001b[A\n",
      "884it [00:14, 66.31it/s]\u001b[A\n",
      "891it [00:14, 63.07it/s]\u001b[A\n",
      "898it [00:14, 63.90it/s]\u001b[A\n",
      "905it [00:14, 65.19it/s]\u001b[A\n",
      "913it [00:14, 66.60it/s]\u001b[A\n",
      "920it [00:14, 66.64it/s]\u001b[A\n",
      "927it [00:15, 66.53it/s]\u001b[A\n",
      "934it [00:15, 66.80it/s]\u001b[A\n",
      "941it [00:15, 67.64it/s]\u001b[A\n",
      "949it [00:15, 68.58it/s]\u001b[A\n",
      "956it [00:15, 68.97it/s]\u001b[A\n",
      "963it [00:15, 67.77it/s]\u001b[A\n",
      "970it [00:15, 67.59it/s]\u001b[A\n",
      "977it [00:15, 67.25it/s]\u001b[A\n",
      "984it [00:15, 67.59it/s]\u001b[A\n",
      "991it [00:15, 67.85it/s]\u001b[A\n",
      "998it [00:16, 66.88it/s]\u001b[A\n",
      "1005it [00:16, 35.72it/s]\u001b[A\n",
      "1012it [00:16, 41.72it/s]\u001b[A\n",
      "1019it [00:16, 47.09it/s]\u001b[A\n",
      "1026it [00:16, 51.74it/s]\u001b[A\n",
      "1033it [00:16, 55.82it/s]\u001b[A\n",
      "1040it [00:17, 59.21it/s]\u001b[A\n",
      "1047it [00:17, 61.73it/s]\u001b[A\n",
      "1054it [00:17, 63.16it/s]\u001b[A\n",
      "1061it [00:17, 63.95it/s]\u001b[A\n",
      "1068it [00:17, 64.89it/s]\u001b[A\n",
      "1075it [00:17, 65.70it/s]\u001b[A\n",
      "1082it [00:17, 66.58it/s]\u001b[A\n",
      "1089it [00:17, 66.21it/s]\u001b[A\n",
      "1097it [00:17, 67.49it/s]\u001b[A\n",
      "1104it [00:17, 68.22it/s]\u001b[A\n",
      "1112it [00:18, 69.00it/s]\u001b[A\n",
      "1120it [00:18, 69.40it/s]\u001b[A\n",
      "1128it [00:18, 69.90it/s]\u001b[A\n",
      "1136it [00:18, 70.00it/s]\u001b[A\n",
      "1144it [00:18, 70.20it/s]\u001b[A\n",
      "1152it [00:18, 70.28it/s]\u001b[A\n",
      "1160it [00:18, 70.13it/s]\u001b[A\n",
      "1168it [00:18, 70.53it/s]\u001b[A\n",
      "1176it [00:18, 70.47it/s]\u001b[A\n",
      "1184it [00:19, 69.82it/s]\u001b[A\n",
      "1192it [00:19, 70.12it/s]\u001b[A\n",
      "1200it [00:19, 69.99it/s]\u001b[A\n",
      "1208it [00:19, 39.11it/s]\u001b[A\n",
      "1216it [00:19, 45.30it/s]\u001b[A\n",
      "1224it [00:19, 50.85it/s]\u001b[A\n",
      "1231it [00:20, 54.88it/s]\u001b[A\n",
      "1238it [00:20, 57.94it/s]\u001b[A\n",
      "1245it [00:20, 60.51it/s]\u001b[A\n",
      "1253it [00:20, 63.50it/s]\u001b[A\n",
      "1261it [00:20, 65.75it/s]\u001b[A\n",
      "1269it [00:20, 67.30it/s]\u001b[A\n",
      "1276it [00:20, 67.95it/s]\u001b[A\n",
      "1284it [00:20, 68.87it/s]\u001b[A\n",
      "1292it [00:20, 69.86it/s]\u001b[A\n",
      "1300it [00:21, 70.28it/s]\u001b[A\n",
      "1308it [00:21, 70.68it/s]\u001b[A\n",
      "1316it [00:21, 71.00it/s]\u001b[A\n",
      "1324it [00:21, 71.23it/s]\u001b[A\n",
      "1332it [00:21, 71.20it/s]\u001b[A\n",
      "1340it [00:21, 71.26it/s]\u001b[A\n",
      "1348it [00:21, 71.24it/s]\u001b[A\n",
      "1356it [00:21, 71.25it/s]\u001b[A\n",
      "1364it [00:21, 71.28it/s]\u001b[A\n",
      "1372it [00:22, 71.12it/s]\u001b[A\n",
      "1380it [00:22, 71.38it/s]\u001b[A\n",
      "1388it [00:22, 71.35it/s]\u001b[A\n",
      "1396it [00:22, 71.24it/s]\u001b[A\n",
      "1404it [00:22, 39.44it/s]\u001b[A\n",
      "1412it [00:22, 45.45it/s]\u001b[A\n",
      "1420it [00:23, 50.95it/s]\u001b[A\n",
      "1428it [00:23, 55.70it/s]\u001b[A\n",
      "1435it [00:23, 59.16it/s]\u001b[A\n",
      "1443it [00:23, 62.20it/s]\u001b[A\n",
      "1451it [00:23, 64.41it/s]\u001b[A\n",
      "1458it [00:23, 65.55it/s]\u001b[A\n",
      "1465it [00:23, 66.14it/s]\u001b[A\n",
      "1472it [00:23, 66.15it/s]\u001b[A\n",
      "1480it [00:23, 67.74it/s]\u001b[A\n",
      "1488it [00:24, 68.97it/s]\u001b[A\n",
      "1496it [00:24, 69.80it/s]\u001b[A\n",
      "1504it [00:24, 70.18it/s]\u001b[A\n",
      "1512it [00:24, 70.39it/s]\u001b[A\n",
      "1520it [00:24, 70.42it/s]\u001b[A\n",
      "1528it [00:24, 70.59it/s]\u001b[A\n",
      "1536it [00:24, 70.84it/s]\u001b[A\n",
      "1544it [00:24, 70.92it/s]\u001b[A\n",
      "1552it [00:24, 70.97it/s]\u001b[A\n",
      "1560it [00:25, 71.30it/s]\u001b[A\n",
      "1568it [00:25, 70.96it/s]\u001b[A\n",
      "1576it [00:25, 71.15it/s]\u001b[A\n",
      "1584it [00:25, 71.00it/s]\u001b[A\n",
      "1592it [00:25, 71.32it/s]\u001b[A\n",
      "1600it [00:25, 71.11it/s]\u001b[A\n",
      "1608it [00:25, 39.57it/s]\u001b[A\n",
      "1615it [00:26, 45.21it/s]\u001b[A\n",
      "1622it [00:26, 50.12it/s]\u001b[A\n",
      "1629it [00:26, 54.35it/s]\u001b[A\n",
      "1636it [00:26, 57.71it/s]\u001b[A\n",
      "1643it [00:26, 60.60it/s]\u001b[A\n",
      "1651it [00:26, 63.40it/s]\u001b[A\n",
      "1659it [00:26, 65.39it/s]\u001b[A\n",
      "1666it [00:26, 66.59it/s]\u001b[A\n",
      "1673it [00:26, 67.33it/s]\u001b[A\n",
      "1680it [00:27, 67.95it/s]\u001b[A\n",
      "1687it [00:27, 68.39it/s]\u001b[A\n",
      "1695it [00:27, 69.14it/s]\u001b[A\n",
      "1703it [00:27, 69.65it/s]\u001b[A\n",
      "1711it [00:27, 70.22it/s]\u001b[A\n",
      "1719it [00:27, 70.46it/s]\u001b[A\n",
      "1727it [00:27, 70.66it/s]\u001b[A\n",
      "1735it [00:27, 70.57it/s]\u001b[A\n",
      "1743it [00:27, 70.56it/s]\u001b[A\n",
      "1751it [00:28, 70.72it/s]\u001b[A\n",
      "1759it [00:28, 71.04it/s]\u001b[A\n",
      "1767it [00:28, 71.22it/s]\u001b[A\n",
      "1775it [00:28, 70.30it/s]\u001b[A\n",
      "1783it [00:28, 69.96it/s]\u001b[A\n",
      "1790it [00:28, 69.75it/s]\u001b[A\n",
      "1798it [00:28, 70.41it/s]\u001b[A\n",
      "1806it [00:29, 39.33it/s]\u001b[A\n",
      "1814it [00:29, 45.62it/s]\u001b[A\n",
      "1822it [00:29, 51.05it/s]\u001b[A\n",
      "1830it [00:29, 55.85it/s]\u001b[A\n",
      "1838it [00:29, 59.77it/s]\u001b[A\n",
      "1846it [00:29, 62.97it/s]\u001b[A\n",
      "1854it [00:29, 65.05it/s]\u001b[A\n",
      "1862it [00:29, 66.70it/s]\u001b[A\n",
      "1870it [00:30, 68.00it/s]\u001b[A\n",
      "1878it [00:30, 68.91it/s]\u001b[A\n",
      "1886it [00:30, 69.75it/s]\u001b[A\n",
      "1894it [00:30, 70.19it/s]\u001b[A\n",
      "1902it [00:30, 70.80it/s]\u001b[A\n",
      "1910it [00:30, 70.92it/s]\u001b[A\n",
      "1918it [00:30, 71.16it/s]\u001b[A\n",
      "1926it [00:30, 71.42it/s]\u001b[A\n",
      "1934it [00:30, 71.49it/s]\u001b[A\n",
      "1942it [00:31, 71.36it/s]\u001b[A\n",
      "1950it [00:31, 71.22it/s]\u001b[A\n",
      "1958it [00:31, 71.47it/s]\u001b[A\n",
      "1966it [00:31, 71.33it/s]\u001b[A\n",
      "1974it [00:31, 71.45it/s]\u001b[A\n",
      "1982it [00:31, 71.59it/s]\u001b[A\n",
      "1990it [00:31, 71.58it/s]\u001b[A\n",
      "1998it [00:31, 71.26it/s]\u001b[A\n",
      "2006it [00:32, 39.30it/s]\u001b[A\n",
      "2014it [00:32, 45.42it/s]\u001b[A\n",
      "2022it [00:32, 51.03it/s]\u001b[A\n",
      "2030it [00:32, 55.76it/s]\u001b[A\n",
      "2038it [00:32, 59.73it/s]\u001b[A\n",
      "2046it [00:32, 62.97it/s]\u001b[A\n",
      "2054it [00:32, 65.31it/s]\u001b[A\n",
      "2062it [00:33, 67.02it/s]\u001b[A\n",
      "2070it [00:33, 67.75it/s]\u001b[A\n",
      "2078it [00:33, 68.71it/s]\u001b[A\n",
      "2086it [00:33, 69.37it/s]\u001b[A\n",
      "2094it [00:33, 70.02it/s]\u001b[A\n",
      "2102it [00:33, 69.17it/s]\u001b[A\n",
      "2110it [00:33, 69.99it/s]\u001b[A\n",
      "2118it [00:33, 70.63it/s]\u001b[A\n",
      "2126it [00:33, 70.74it/s]\u001b[A\n",
      "2134it [00:34, 71.00it/s]\u001b[A\n",
      "2142it [00:34, 70.41it/s]\u001b[A\n",
      "2150it [00:34, 69.68it/s]\u001b[A\n",
      "2158it [00:34, 70.28it/s]\u001b[A\n",
      "2166it [00:34, 70.72it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2174it [00:34, 71.06it/s]\u001b[A\n",
      "2182it [00:34, 71.27it/s]\u001b[A\n",
      "2190it [00:34, 71.37it/s]\u001b[A\n",
      "2198it [00:34, 71.18it/s]\u001b[A\n",
      "2206it [00:35, 38.47it/s]\u001b[A\n",
      "2214it [00:35, 44.72it/s]\u001b[A\n",
      "2222it [00:35, 50.43it/s]\u001b[A\n",
      "2230it [00:35, 55.42it/s]\u001b[A\n",
      "2238it [00:35, 59.61it/s]\u001b[A\n",
      "2245it [00:35, 62.38it/s]\u001b[A\n",
      "2253it [00:36, 65.05it/s]\u001b[A\n",
      "2261it [00:36, 66.98it/s]\u001b[A\n",
      "2269it [00:36, 68.14it/s]\u001b[A\n",
      "2277it [00:36, 69.03it/s]\u001b[A\n",
      "2285it [00:36, 69.74it/s]\u001b[A\n",
      "2293it [00:36, 70.29it/s]\u001b[A\n",
      "2301it [00:36, 69.58it/s]\u001b[A\n",
      "2309it [00:36, 70.37it/s]\u001b[A\n",
      "2317it [00:36, 70.65it/s]\u001b[A\n",
      "2325it [00:37, 70.98it/s]\u001b[A\n",
      "2333it [00:37, 71.00it/s]\u001b[A\n",
      "2341it [00:37, 70.92it/s]\u001b[A\n",
      "2349it [00:37, 70.93it/s]\u001b[A\n",
      "2357it [00:37, 71.13it/s]\u001b[A\n",
      "2365it [00:37, 71.23it/s]\u001b[A\n",
      "2373it [00:37, 71.16it/s]\u001b[A\n",
      "2381it [00:37, 70.94it/s]\u001b[A\n",
      "2389it [00:37, 70.92it/s]\u001b[A\n",
      "2397it [00:38, 71.27it/s]\u001b[A\n",
      "2405it [00:38, 38.11it/s]\u001b[A\n",
      "2412it [00:38, 43.80it/s]\u001b[A\n",
      "2419it [00:38, 48.98it/s]\u001b[A\n",
      "2426it [00:38, 53.50it/s]\u001b[A\n",
      "2433it [00:38, 57.34it/s]\u001b[A\n",
      "2440it [00:38, 59.95it/s]\u001b[A\n",
      "2447it [00:39, 61.63it/s]\u001b[A\n",
      "2454it [00:39, 63.71it/s]\u001b[A\n",
      "2462it [00:39, 65.59it/s]\u001b[A\n",
      "2470it [00:39, 67.28it/s]\u001b[A\n",
      "2478it [00:39, 68.59it/s]\u001b[A\n",
      "2485it [00:39, 68.40it/s]\u001b[A\n",
      "2493it [00:39, 69.19it/s]\u001b[A\n",
      "2500it [00:39, 68.64it/s]\u001b[A\n",
      "2507it [00:39, 68.58it/s]\u001b[A\n",
      "2514it [00:40, 68.85it/s]\u001b[A\n",
      "2521it [00:40, 69.00it/s]\u001b[A\n",
      "2529it [00:40, 69.87it/s]\u001b[A\n",
      "2537it [00:40, 69.58it/s]\u001b[A\n",
      "2545it [00:40, 69.82it/s]\u001b[A\n",
      "2552it [00:40, 69.04it/s]\u001b[A\n",
      "2560it [00:40, 69.51it/s]\u001b[A\n",
      "2567it [00:40, 69.26it/s]\u001b[A\n",
      "2575it [00:40, 69.70it/s]\u001b[A\n",
      "2582it [00:41, 69.34it/s]\u001b[A\n",
      "2589it [00:41, 68.89it/s]\u001b[A\n",
      "2596it [00:41, 68.63it/s]\u001b[A\n",
      "2603it [00:41, 36.04it/s]\u001b[A\n",
      "2610it [00:41, 41.84it/s]\u001b[A\n",
      "2617it [00:41, 47.24it/s]\u001b[A\n",
      "2624it [00:41, 51.09it/s]\u001b[A\n",
      "2631it [00:42, 54.44it/s]\u001b[A\n",
      "2638it [00:42, 57.86it/s]\u001b[A\n",
      "2645it [00:42, 60.54it/s]\u001b[A\n",
      "2652it [00:42, 61.85it/s]\u001b[A\n",
      "2659it [00:42, 63.46it/s]\u001b[A\n",
      "2666it [00:42, 64.81it/s]\u001b[A\n",
      "2673it [00:42, 65.42it/s]\u001b[A\n",
      "2681it [00:42, 66.87it/s]\u001b[A\n",
      "2688it [00:42, 67.59it/s]\u001b[A\n",
      "2696it [00:43, 68.72it/s]\u001b[A\n",
      "2703it [00:43, 69.06it/s]\u001b[A\n",
      "2710it [00:43, 68.85it/s]\u001b[A\n",
      "2717it [00:43, 68.32it/s]\u001b[A\n",
      "2724it [00:43, 67.26it/s]\u001b[A\n",
      "2731it [00:43, 66.88it/s]\u001b[A\n",
      "2738it [00:43, 67.04it/s]\u001b[A\n",
      "2745it [00:43, 67.70it/s]\u001b[A\n",
      "2753it [00:43, 68.96it/s]\u001b[A\n",
      "2761it [00:43, 69.46it/s]\u001b[A\n",
      "2768it [00:44, 69.61it/s]\u001b[A\n",
      "2776it [00:44, 70.07it/s]\u001b[A\n",
      "2784it [00:44, 68.60it/s]\u001b[A\n",
      "2792it [00:44, 69.10it/s]\u001b[A\n",
      "2799it [00:44, 69.08it/s]\u001b[A\n",
      "2806it [00:44, 36.23it/s]\u001b[A\n",
      "2813it [00:45, 42.09it/s]\u001b[A\n",
      "2820it [00:45, 46.84it/s]\u001b[A\n",
      "2827it [00:45, 51.80it/s]\u001b[A\n",
      "2834it [00:45, 55.40it/s]\u001b[A\n",
      "2841it [00:45, 58.02it/s]\u001b[A\n",
      "2848it [00:45, 59.88it/s]\u001b[A\n",
      "2855it [00:45, 61.68it/s]\u001b[A\n",
      "2862it [00:45, 63.03it/s]\u001b[A\n",
      "2869it [00:45, 63.92it/s]\u001b[A\n",
      "2876it [00:46, 64.14it/s]\u001b[A\n",
      "2883it [00:46, 65.23it/s]\u001b[A\n",
      "2890it [00:46, 64.92it/s]\u001b[A\n",
      "2897it [00:46, 65.58it/s]\u001b[A\n",
      "2904it [00:46, 66.82it/s]\u001b[A\n",
      "2911it [00:46, 66.71it/s]\u001b[A\n",
      "2918it [00:46, 67.51it/s]\u001b[A\n",
      "2925it [00:46, 67.78it/s]\u001b[A\n",
      "2932it [00:46, 67.50it/s]\u001b[A\n",
      "2939it [00:46, 68.05it/s]\u001b[A\n",
      "2947it [00:47, 69.14it/s]\u001b[A\n",
      "2954it [00:47, 68.73it/s]\u001b[A\n",
      "2961it [00:47, 67.57it/s]\u001b[A\n",
      "2968it [00:47, 67.14it/s]\u001b[A\n",
      "2975it [00:47, 67.87it/s]\u001b[A\n",
      "2982it [00:47, 68.04it/s]\u001b[A\n",
      "2990it [00:47, 69.08it/s]\u001b[A\n",
      "2998it [00:47, 70.00it/s]\u001b[A\n",
      "3006it [00:48, 38.95it/s]\u001b[A\n",
      "3014it [00:48, 45.14it/s]\u001b[A\n",
      "3021it [00:48, 50.52it/s]\u001b[A\n",
      "3028it [00:48, 54.99it/s]\u001b[A\n",
      "3036it [00:48, 58.97it/s]\u001b[A\n",
      "3044it [00:48, 61.50it/s]\u001b[A\n",
      "3051it [00:48, 63.39it/s]\u001b[A\n",
      "3059it [00:48, 65.45it/s]\u001b[A\n",
      "3067it [00:49, 66.90it/s]\u001b[A\n",
      "3074it [00:49, 67.75it/s]\u001b[A\n",
      "3081it [00:49, 67.92it/s]\u001b[A\n",
      "3088it [00:49, 67.89it/s]\u001b[A\n",
      "3095it [00:49, 67.69it/s]\u001b[A\n",
      "3103it [00:49, 68.52it/s]\u001b[A\n",
      "3110it [00:49, 68.57it/s]\u001b[A\n",
      "3117it [00:49, 68.59it/s]\u001b[A\n",
      "3124it [00:49, 68.73it/s]\u001b[A\n",
      "3131it [00:50, 68.76it/s]\u001b[A\n",
      "3138it [00:50, 68.62it/s]\u001b[A\n",
      "3146it [00:50, 69.79it/s]\u001b[A\n",
      "3153it [00:50, 68.63it/s]\u001b[A\n",
      "3160it [00:50, 68.95it/s]\u001b[A\n",
      "3168it [00:50, 69.63it/s]\u001b[A\n",
      "3175it [00:50, 69.56it/s]\u001b[A\n",
      "3183it [00:50, 70.13it/s]\u001b[A\n",
      "3191it [00:50, 70.48it/s]\u001b[A\n",
      "3199it [00:50, 70.61it/s]\u001b[A\n",
      "3207it [00:51, 39.00it/s]\u001b[A\n",
      "3214it [00:51, 44.68it/s]\u001b[A\n",
      "3221it [00:51, 49.54it/s]\u001b[A\n",
      "3228it [00:51, 53.19it/s]\u001b[A\n",
      "3235it [00:51, 55.13it/s]\u001b[A\n",
      "3242it [00:51, 58.41it/s]\u001b[A\n",
      "3249it [00:52, 61.13it/s]\u001b[A\n",
      "3256it [00:52, 62.87it/s]\u001b[A\n",
      "3264it [00:52, 65.13it/s]\u001b[A\n",
      "3272it [00:52, 66.65it/s]\u001b[A\n",
      "3279it [00:52, 65.61it/s]\u001b[A\n",
      "3286it [00:52, 65.15it/s]\u001b[A\n",
      "3293it [00:52, 65.55it/s]\u001b[A\n",
      "3300it [00:52, 65.72it/s]\u001b[A\n",
      "3307it [00:52, 66.19it/s]\u001b[A\n",
      "3314it [00:53, 66.34it/s]\u001b[A\n",
      "3321it [00:53, 65.11it/s]\u001b[A\n",
      "3328it [00:53, 62.90it/s]\u001b[A\n",
      "3335it [00:53, 62.04it/s]\u001b[A\n",
      "3342it [00:53, 63.00it/s]\u001b[A\n",
      "3349it [00:53, 63.44it/s]\u001b[A\n",
      "3356it [00:53, 63.39it/s]\u001b[A\n",
      "3363it [00:53, 64.01it/s]\u001b[A\n",
      "3370it [00:53, 64.56it/s]\u001b[A\n",
      "3377it [00:53, 64.91it/s]\u001b[A\n",
      "3384it [00:54, 65.14it/s]\u001b[A\n",
      "3391it [00:54, 65.54it/s]\u001b[A\n",
      "3398it [00:54, 65.87it/s]\u001b[A\n",
      "3405it [00:54, 34.44it/s]\u001b[A\n",
      "3411it [00:54, 39.10it/s]\u001b[A\n",
      "3418it [00:54, 44.00it/s]\u001b[A\n",
      "3424it [00:55, 47.07it/s]\u001b[A\n",
      "3431it [00:55, 51.29it/s]\u001b[A\n",
      "3438it [00:55, 54.58it/s]\u001b[A\n",
      "3445it [00:55, 57.04it/s]\u001b[A\n",
      "3452it [00:55, 59.66it/s]\u001b[A\n",
      "3459it [00:55, 61.42it/s]\u001b[A\n",
      "3466it [00:55, 62.07it/s]\u001b[A\n",
      "3473it [00:55, 62.42it/s]\u001b[A\n",
      "3480it [00:55, 61.76it/s]\u001b[A\n",
      "3487it [00:56, 63.08it/s]\u001b[A\n",
      "3494it [00:56, 64.30it/s]\u001b[A\n",
      "3501it [00:56, 65.17it/s]\u001b[A\n",
      "3508it [00:56, 65.39it/s]\u001b[A\n",
      "3515it [00:56, 65.55it/s]\u001b[A\n",
      "3523it [00:56, 67.05it/s]\u001b[A\n",
      "3531it [00:56, 68.28it/s]\u001b[A\n",
      "3539it [00:56, 69.28it/s]\u001b[A\n",
      "3546it [00:56, 67.06it/s]\u001b[A\n",
      "3553it [00:57, 66.60it/s]\u001b[A\n",
      "3560it [00:57, 66.66it/s]\u001b[A\n",
      "3567it [00:57, 66.98it/s]\u001b[A\n",
      "3575it [00:57, 67.98it/s]\u001b[A\n",
      "3583it [00:57, 68.99it/s]\u001b[A\n",
      "3590it [00:57, 69.20it/s]\u001b[A\n",
      "3598it [00:57, 69.60it/s]\u001b[A\n",
      "3605it [00:58, 35.44it/s]\u001b[A\n",
      "3613it [00:58, 41.65it/s]\u001b[A\n",
      "3620it [00:58, 47.00it/s]\u001b[A\n",
      "3628it [00:58, 52.28it/s]\u001b[A\n",
      "3636it [00:58, 56.72it/s]\u001b[A\n",
      "3644it [00:58, 60.43it/s]\u001b[A\n",
      "3652it [00:58, 63.22it/s]\u001b[A\n",
      "3660it [00:58, 65.45it/s]\u001b[A\n",
      "3667it [00:58, 66.46it/s]\u001b[A\n",
      "3674it [00:59, 66.95it/s]\u001b[A\n",
      "3681it [00:59, 67.25it/s]\u001b[A\n",
      "3689it [00:59, 68.50it/s]\u001b[A\n",
      "3696it [00:59, 68.90it/s]\u001b[A\n",
      "3704it [00:59, 69.34it/s]\u001b[A\n",
      "3711it [00:59, 69.17it/s]\u001b[A\n",
      "3718it [00:59, 69.28it/s]\u001b[A\n",
      "3725it [00:59, 69.35it/s]\u001b[A\n",
      "3733it [00:59, 69.82it/s]\u001b[A\n",
      "3740it [01:00, 69.50it/s]\u001b[A\n",
      "3748it [01:00, 69.86it/s]\u001b[A\n",
      "3756it [01:00, 70.32it/s]\u001b[A\n",
      "3764it [01:00, 70.39it/s]\u001b[A\n",
      "3772it [01:00, 70.39it/s]\u001b[A\n",
      "3780it [01:00, 70.21it/s]\u001b[A\n",
      "3788it [01:00, 70.39it/s]\u001b[A\n",
      "3796it [01:00, 70.62it/s]\u001b[A\n",
      "3804it [01:01, 39.08it/s]\u001b[A\n",
      "3811it [01:01, 45.04it/s]\u001b[A\n",
      "3819it [01:01, 50.60it/s]\u001b[A\n",
      "3826it [01:01, 55.06it/s]\u001b[A\n",
      "3833it [01:01, 58.75it/s]\u001b[A\n",
      "3841it [01:01, 61.79it/s]\u001b[A\n",
      "3848it [01:01, 63.92it/s]\u001b[A\n",
      "3856it [01:01, 65.75it/s]\u001b[A\n",
      "3863it [01:02, 66.59it/s]\u001b[A\n",
      "3871it [01:02, 67.73it/s]\u001b[A\n",
      "3879it [01:02, 68.67it/s]\u001b[A\n",
      "3886it [01:02, 68.98it/s]\u001b[A\n",
      "3894it [01:02, 69.51it/s]\u001b[A\n",
      "3902it [01:02, 69.41it/s]\u001b[A\n",
      "3910it [01:02, 70.04it/s]\u001b[A\n",
      "3918it [01:02, 69.72it/s]\u001b[A\n",
      "3925it [01:02, 69.61it/s]\u001b[A\n",
      "3932it [01:03, 69.44it/s]\u001b[A\n",
      "3939it [01:03, 69.51it/s]\u001b[A\n",
      "3947it [01:03, 70.01it/s]\u001b[A\n",
      "3955it [01:03, 70.35it/s]\u001b[A\n",
      "3963it [01:03, 70.63it/s]\u001b[A\n",
      "3971it [01:03, 70.60it/s]\u001b[A\n",
      "3979it [01:03, 70.91it/s]\u001b[A\n",
      "3987it [01:03, 71.17it/s]\u001b[A\n",
      "3995it [01:03, 71.00it/s]\u001b[A\n",
      "4003it [01:04, 38.68it/s]\u001b[A\n",
      "4016it [01:04, 62.18it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "a.compose_database(peptide_length=18, interval=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "start = timer()\n",
    "for frame in aggregate.sampled_frames:\n",
    "    start_an = timer()\n",
    "    aggregate.analysis(frame)\n",
    "    end_an = timer()\n",
    "    text= 'Time needed to analyze frame %d is %f seconds' % (frame, (end_an-start_an))\n",
    "\n",
    "    print(text)\n",
    "    \n",
    "end = timer()\n",
    "\n",
    "\n",
    "print('Total time to analyze dataset is %f seconds' % (end -start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.analysis(4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.frames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in a.sampled_frames:\n",
    "    print(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a.frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.frames[0]['frame_graph']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.graph.find_subgraph(a.frames[0]['frame_graph'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analysis of frame 0 is 1.111000\n"
     ]
    }
   ],
   "source": [
    "frm = 0\n",
    "tme = 1.111\n",
    "text= 'analysis of frame %d is %f' % (frm, tme)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nx.draw_networkx(a.frames[2800]['frame_graph_full'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph = find_subgraph(a.frames[2800]['frame_graph_full'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([e for i in subgraph for e in i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_subgraph_disordered(graph):\n",
    "    '''\n",
    "    Find subgraph of joined peptides that have no node in common.\n",
    "    It start to search from always from peptide 0, and from that does depth first search.\n",
    "    The peptide of the subgraph that are touching are in consequential order in the sublist\n",
    "\n",
    "    Argument: NetworkX MultiGraph\n",
    "\n",
    "    Return: list of subgraph ordered from one end to the other\n",
    "\n",
    "    '''\n",
    "\n",
    "    subgraph_list = []\n",
    "\n",
    "    for node in graph:\n",
    "\n",
    "        # don't explore node that are already in subgraph_list\n",
    "        if node not in set(nod for nod_list in subgraph_list for nod in nod_list):\n",
    "\n",
    "            # tree is the list of nodes joined to node, starting from node\n",
    "            # using depht first search\n",
    "            tree = [e for e in nx.algorithms.traversal.depth_first_search.dfs_tree(graph, node)]\n",
    "\n",
    "            # check if the first node of the tree has adjiacency == 1\n",
    "            # so it checks if it is the first or last node of the subgraph\n",
    "            #if len(graph[tree[0]]) == 1:\n",
    "\n",
    "            if len(subgraph_list) == 0:\n",
    "                subgraph_list.append(tree)\n",
    "\n",
    "            else:\n",
    "                # use generator to check if the tree is already in the subgraph\n",
    "                if set(tree) not in (set(i) for i in subgraph_list):\n",
    "                    subgraph_list.append(tree)\n",
    "\n",
    "    return subgraph_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "old = aggregate(trj_gro, trj_xtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  7.02it/s]\u001b[A\n",
      "7it [00:00,  9.49it/s]\u001b[A\n",
      "13it [00:00, 12.58it/s]\u001b[A\n",
      "19it [00:00, 16.26it/s]\u001b[A\n",
      "25it [00:00, 20.45it/s]\u001b[A\n",
      "31it [00:00, 21.67it/s]\u001b[A\n",
      "37it [00:00, 26.38it/s]\u001b[A\n",
      "43it [00:01, 30.94it/s]\u001b[A\n",
      "49it [00:01, 35.22it/s]\u001b[A\n",
      "55it [00:01, 38.96it/s]\u001b[A\n",
      "61it [00:01, 33.49it/s]\u001b[A\n",
      "66it [00:01, 37.09it/s]\u001b[A\n",
      "72it [00:01, 40.57it/s]\u001b[A\n",
      "78it [00:01, 43.53it/s]\u001b[A\n",
      "84it [00:01, 45.37it/s]\u001b[A\n",
      "90it [00:02, 46.94it/s]\u001b[A\n",
      "95it [00:02, 35.39it/s]\u001b[A\n",
      "101it [00:02, 39.14it/s]\u001b[A\n",
      "107it [00:02, 42.12it/s]\u001b[A\n",
      "112it [00:02, 44.15it/s]\u001b[A\n",
      "118it [00:02, 46.26it/s]\u001b[A\n",
      "123it [00:03, 34.89it/s]\u001b[A\n",
      "129it [00:03, 38.66it/s]\u001b[A\n",
      "135it [00:03, 41.87it/s]\u001b[A\n",
      "141it [00:03, 44.62it/s]\u001b[A\n",
      "151it [00:03, 40.91it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "old.compose_database(peptide_length=12, interval=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 30, 60, 90, 120, 150]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old.sampled_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_inLoop(aggregate):\n",
    "\n",
    "    start = timer()\n",
    "    for frame in aggregate.sampled_frames:\n",
    "        start_an = timer()\n",
    "        aggregate.analysis(frame)\n",
    "        end_an = timer()\n",
    "        text= 'Time needed to analyze frame %d is %f seconds' % (frame, (end_an-start_an))\n",
    "\n",
    "        print(text)\n",
    "\n",
    "    end = timer()\n",
    "\n",
    "\n",
    "    print('Total time to analyze dataset is %f seconds' % (end -start))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "5it [00:00, 49.77it/s]\u001b[A\n",
      "11it [00:00, 51.10it/s]\u001b[A\n",
      "17it [00:00, 51.93it/s]\u001b[A\n",
      "24it [00:00, 54.36it/s]\u001b[A\n",
      "31it [00:00, 57.64it/s]\u001b[A\n",
      "39it [00:00, 61.50it/s]\u001b[A\n",
      "48it [00:00, 66.54it/s]\u001b[A\n",
      "59it [00:00, 74.73it/s]\u001b[A\n",
      "100it [00:01, 96.00it/s][A\n",
      "\n",
      "100%|ââââââââââ| 37/37 [00:00<00:00, 277123.66it/s]\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "6it [00:00, 51.61it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time needed to analyze frame 0 is 5.567260 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "11it [00:00, 50.51it/s]\u001b[A\n",
      "17it [00:00, 51.78it/s]\u001b[A\n",
      "24it [00:00, 54.27it/s]\u001b[A\n",
      "31it [00:00, 57.31it/s]\u001b[A\n",
      "39it [00:00, 61.24it/s]\u001b[A\n",
      "48it [00:00, 67.38it/s]\u001b[A\n",
      "59it [00:00, 75.32it/s]\u001b[A\n",
      "100it [00:01, 95.23it/s][A\n",
      "\n",
      "100%|ââââââââââ| 59/59 [00:00<00:00, 384858.38it/s]\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "6it [00:00, 50.68it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time needed to analyze frame 30 is 5.638495 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "12it [00:00, 50.75it/s]\u001b[A\n",
      "18it [00:00, 52.41it/s]\u001b[A\n",
      "24it [00:00, 54.14it/s]\u001b[A\n",
      "31it [00:00, 57.70it/s]\u001b[A\n",
      "39it [00:00, 61.18it/s]\u001b[A\n",
      "48it [00:00, 66.40it/s]\u001b[A\n",
      "58it [00:00, 73.74it/s]\u001b[A\n",
      "100it [00:01, 93.82it/s][A\n",
      "\n",
      "100%|ââââââââââ| 69/69 [00:00<00:00, 499839.34it/s]\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "6it [00:00, 51.26it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time needed to analyze frame 60 is 5.577047 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "12it [00:00, 50.79it/s]\u001b[A\n",
      "18it [00:00, 51.83it/s]\u001b[A\n",
      "24it [00:00, 53.86it/s]\u001b[A\n",
      "31it [00:00, 57.24it/s]\u001b[A\n",
      "39it [00:00, 61.95it/s]\u001b[A\n",
      "48it [00:00, 67.69it/s]\u001b[A\n",
      "59it [00:00, 75.98it/s]\u001b[A\n",
      "100it [00:01, 96.28it/s][A\n",
      "\n",
      "100%|ââââââââââ| 63/63 [00:00<00:00, 278441.68it/s]\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "6it [00:00, 51.42it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time needed to analyze frame 90 is 5.688862 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "12it [00:00, 52.02it/s]\u001b[A\n",
      "17it [00:00, 51.24it/s]\u001b[A\n",
      "23it [00:00, 53.31it/s]\u001b[A\n",
      "30it [00:00, 56.29it/s]\u001b[A\n",
      "38it [00:00, 60.15it/s]\u001b[A\n",
      "47it [00:00, 65.19it/s]\u001b[A\n",
      "57it [00:00, 71.95it/s]\u001b[A\n",
      "100it [00:01, 93.52it/s][A\n",
      "\n",
      "100%|ââââââââââ| 73/73 [00:00<00:00, 488332.04it/s]\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "5it [00:00, 47.67it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time needed to analyze frame 120 is 5.756376 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10it [00:00, 47.37it/s]\u001b[A\n",
      "16it [00:00, 48.58it/s]\u001b[A\n",
      "22it [00:00, 50.49it/s]\u001b[A\n",
      "29it [00:00, 53.41it/s]\u001b[A\n",
      "36it [00:00, 56.94it/s]\u001b[A\n",
      "44it [00:00, 61.72it/s]\u001b[A\n",
      "53it [00:00, 67.63it/s]\u001b[A\n",
      "65it [00:00, 76.80it/s]\u001b[A\n",
      "100it [00:01, 90.63it/s][A\n",
      "\n",
      "100%|ââââââââââ| 71/71 [00:00<00:00, 237098.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time needed to analyze frame 150 is 5.568902 seconds\n",
      "Total time to analyze dataset is 33.797471 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "analyze_inLoop(old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nx.draw_networkx(old.frames[150]['frame_graph_full'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1 = morphoscanner.graph.find_subgraph(old.frames[150]['frame_graph_full'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub2 = find_subgraph_disordered(old.frames[150]['frame_graph_full'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if set(tree) not in (set(i) for i in subgraph_list):\n",
    "                    subgraph_list.append(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[set(e) for e in sub1] == [set(i) for i in sub2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def subgraph_length(aggregate):\n",
    "    '''Get information about the size of the aggregates in the trajectory\n",
    "    \n",
    "    Argument: aggregate\n",
    "    \n",
    "    return: dict, keys = frame number,\n",
    "                  value = a sorted list (big to small) of the aggregate size in that frame\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    subgraph_len_dict = {}\n",
    "\n",
    "    for key in aggregate.frames.keys():\n",
    "\n",
    "        subgraph_dict[key] = morphoscanner.graph.find_subgraph(aggregate.frames[key]['frame_graph_full'])\n",
    "\n",
    "        len_list = []\n",
    "\n",
    "        for i in subgraph_dict[key]:\n",
    "\n",
    "            len_list.append(len(i))\n",
    "\n",
    "        len_list.sort(reverse=True)\n",
    "\n",
    "        subgraph_len_dict[key] = len_list\n",
    "        \n",
    "        return subgraph_len_dict\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_list = []\n",
    "\n",
    "for i in subgraph_dict[0]:\n",
    "    \n",
    "    len_list.append(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_list.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3],\n",
       " 30: [27, 12, 11, 11, 5, 4, 4, 4, 4, 4, 4, 4, 4],\n",
       " 60: [32, 13, 11, 11, 9, 6, 6, 4, 4, 4],\n",
       " 90: [54, 12, 10, 6, 5, 4, 4, 4],\n",
       " 120: [50, 12, 11, 11, 4, 4, 4, 4],\n",
       " 150: [45, 12, 11, 9, 6, 5, 4, 4, 4]}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subgraph_len_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(old.frames[0]['frame_data'].groupby('sense').get_group('antiparallel'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sense(aggregate):\n",
    "    \n",
    "    sense_dict = {}\n",
    "\n",
    "    for e in aggregate.frames:\n",
    "\n",
    "        parallel = len(aggregate.frames[e]['frame_data'].groupby('sense').get_group('parallel'))\n",
    "        antiparallel = len(aggregate.frames[e]['frame_data'].groupby('sense').get_group('antiparallel'))\n",
    "\n",
    "        sense_dict[e] = {'parallel' : parallel,\n",
    "                        'antiparallel' : antiparallel}\n",
    "    \n",
    "    return sense_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'parallel': 10, 'antiparallel': 47},\n",
       " 30: {'parallel': 21, 'antiparallel': 70},\n",
       " 60: {'parallel': 23, 'antiparallel': 73},\n",
       " 90: {'parallel': 28, 'antiparallel': 74},\n",
       " 120: {'parallel': 35, 'antiparallel': 79},\n",
       " 150: {'parallel': 31, 'antiparallel': 74}}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sense_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

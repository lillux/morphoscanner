{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bfb2223d5d04bc3a1944a360af38c2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_ColormakerRegistry()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "#import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import plotly\n",
    "#import plotly.express as px\n",
    "\n",
    "from mpl_toolkits import mplot3d\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "#from functools import lru_cache\n",
    "#import re\n",
    "import networkx as nx\n",
    "#from networkx.algorithms import approximation\n",
    "\n",
    "\n",
    "import MDAnalysis as mda\n",
    "\n",
    "#import scipy\n",
    "#import sklearn\n",
    "#import skimage\n",
    "\n",
    "#import xml.etree.ElementTree as et\n",
    "#from Bio.PDB import *\n",
    "import nglview as nv\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "import dask\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# database to handle data\n",
    "\n",
    "# in function, use dataframe and then pick right data\n",
    "\n",
    "\n",
    "# http://nglviewer.org/nglview/latest/api.html\n",
    "# https://biopython.org/wiki/The_Biopython_Structural_Bioinformatics_FAQ\n",
    "# https://ambermd.org/tutorials/analysis/tutorial_notebooks/nglview_notebook/index.html\n",
    "# https://amber-md.github.io/pytraj/latest/_api/pytraj.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contact_matrix = np.loadtxt('/home/lillo/TesiCNTE/CNTE/dataset/contact_matrix.txt')   #laptop\n",
    "#contact_matrix = np.loadtxt('/home/lillo/Code/Tesi/dataset/contact_matrix.txt')        #fisso\n",
    "#contact_matrix_single = contact_matrix.reshape(100,100,12,12)\n",
    "\n",
    "#gromacs_output = open('/home/lillo/Code/Tesi/dataset/dm4500Compl_mix1_K2_1%4500ns.gro') #fisso\n",
    "#gromacs_output = open('/home/lillo/TesiCNTE/CNTE/dataset/dm4500Compl_mix1_K2_1%4500ns.gro') #laptop\n",
    "\n",
    "#path = '/home/lillo/Code/Tesi/dataset/dm4500Compl_mix1_K2_1%4500ns.gro' #fisso\n",
    "#path = '/home/lillo/TesiCNTE/CNTE/dataset/dm4500Compl_mix1_K2_1%4500ns.gro' #laptop\n",
    "\n",
    "# import 2mxu file (beta sheet)\n",
    "\n",
    "#path_to_mmCIF = open('/home/lillo/TesiCNTE/pdb/2mxu/2mxu.cif')  ## laptop\n",
    "#path_to_pdb = '/home/lillo/TesiCNTE/pdb/2mxu/2mxu.pdb'  ## laptop\n",
    "#pa_to_pdb = '/home/lillo/TesiCNTE/pdb/2mxu/2mxu.pdb'  ## laptop\n",
    "\n",
    "#path_to_mmCIF = open('/home/lillo/Code/Tesi/pdb/2mxu/2mxu.cif')  ## fisso\n",
    "#path_to_pdb = '/home/lillo/Code/Tesi/pdb/2mxu/2mxu.pdb'  ## fisso\n",
    "#pa_to_pdb = '/home/lillo/Code/Tesi/pdb/2mxu/2mxu.pdb'  ## fisso\n",
    "\n",
    "# aggregate blob\n",
    "\n",
    "#seed_1_path = '/home/lillo/TesiCNTE/from_cluster/aggregate1.gro' # laptop\n",
    "#seed_1_path = '/home/lillo/Code/Tesi/dataset/aggregate1.gro' # Fisso\n",
    "\n",
    "# Trajectory with aggregate seed\n",
    "#trj_xtc = '/home/lillo/TesiCNTE/CNTE/trajectory/prd-LDLK12-100mer-out-mol.xtc'  #laptop\n",
    "#trj_gro = '/home/lillo/TesiCNTE/CNTE/trajectory/min-LDLK12-100mer-out-c.gro'  #laptop\n",
    "\n",
    "#n_trj_xtc = '/home/lillo/Code/Tesi/dataset/trajectory_6_12_19/prd-LDLK12-100mer-out-mol.xtc'  #fisso\n",
    "#n_trj_gro = '/home/lillo/Code/Tesi/dataset/trajectory_6_12_19/min-LDLK12-100mer-out-c.gro'  #fisso\n",
    "\n",
    "\n",
    "#prod_trr = '/home/lillo/TesiCNTE/from_cluster/prod/prod.trr'   # laptop\n",
    "#prod_tpr = '/home/lillo/TesiCNTE/from_cluster/prod/prod.tpr'   # laptop\n",
    "\n",
    "# part 1\n",
    "prod_xtc = '/home/lillo/TesiCNTE/from_cluster/prod/prod_part1/prod.xtc'   # laptop\n",
    "prod_gro = '/home/lillo/TesiCNTE/from_cluster/prod/prod_part1/min.gro'    # laptop\n",
    "\n",
    "# part 2\n",
    "prod1_xtc = '/home/lillo/TesiCNTE/from_cluster/prod/prod_part2/prod-compl.xtc' #laptop\n",
    "prod1_gro = '/home/lillo/TesiCNTE/from_cluster/prod/prod_part2/prod-compl.gro' #laptop\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ .gro FILE AND PREPROCESSING\n",
    "\n",
    "def clean_gro(path):\n",
    "    \n",
    "    \n",
    "        # open file .gro and return a list with one element per line of the .gro file\n",
    "    def read_gro(path):\n",
    "        gromacs_output = open(path)\n",
    "\n",
    "        gro_file = []\n",
    "        for line in tqdm.tqdm(gromacs_output):\n",
    "            gro_file.append(line)\n",
    "\n",
    "\n",
    "\n",
    "        gromacs_output.close()        \n",
    "\n",
    "        return gro_file\n",
    "\n",
    "\n",
    "\n",
    "    # return string in a string with numbers\n",
    "    def return_if_string(string):\n",
    "        digits = []\n",
    "        for i in string:\n",
    "            if not i.isdigit():\n",
    "                digits.append(i)\n",
    "\n",
    "        string = ''.join(digits)\n",
    "\n",
    "        return string\n",
    "\n",
    "\n",
    "    # return numbers in a string with numbers\n",
    "    def return_if_digit(string):\n",
    "        digits = []\n",
    "        for i in string:\n",
    "            if i.isdigit():\n",
    "                digits.append(i)\n",
    "\n",
    "        string = ''.join(digits)\n",
    "\n",
    "        return string\n",
    "\n",
    "\n",
    "    # remove first, second and last lines from gro_file and reorder information\n",
    "    # FIX OPTION TO GET ENTRY RELATED TO A LABEL (as 'bb' or 'ca')\n",
    "    def clean_gro_file(gro_file):\n",
    "        cleaned_gro_file = []\n",
    "        for aminoacid in tqdm.tqdm(gro_file[2:-1]):\n",
    "            splitted = aminoacid.split()\n",
    "            if splitted[1] == 'BB':\n",
    "                position_in_peptide = return_if_digit(splitted[0])\n",
    "                residue = return_if_string(splitted[0])\n",
    "                index = splitted[2]\n",
    "                x = splitted[3]\n",
    "                y = splitted[4]\n",
    "                z = splitted[5]\n",
    "                cleaned_gro_file.append([index, position_in_peptide, residue, x, y, z])\n",
    "        return cleaned_gro_file\n",
    "    \n",
    "    \n",
    "    gro_file = read_gro(path)\n",
    "    cleaned_gro_file = clean_gro_file(gro_file)\n",
    "\n",
    "    return cleaned_gro_file\n",
    "\n",
    "\n",
    "# create coordinate dict from cleaned_gro_file\n",
    "def get_coordinate_dict_from_cleaned_gro(cleaned_gro_file):\n",
    "    \n",
    "    peptide_lenght_list = []\n",
    "\n",
    "    temporary_list = []\n",
    "\n",
    "    # iterate trough cleaned_gro_file\n",
    "    for residue in cleaned_gro_file:\n",
    "\n",
    "        # if temporary list just started, add aminoacid position in chain\n",
    "        if len(temporary_list) == 0:\n",
    "            temporary_list.append(int(residue[1]))\n",
    "\n",
    "        else:\n",
    "            # if position of actual residue is less than last residue\n",
    "            if temporary_list[-1] > int(residue[1]):\n",
    "\n",
    "                # append lenght of last peptide to peptide lenght list\n",
    "                peptide_lenght_list.append(len(temporary_list))\n",
    "\n",
    "                # empty temporary list\n",
    "                temporary_list = []\n",
    "\n",
    "                # append actual residue position\n",
    "                temporary_list.append(int(residue[1]))\n",
    "\n",
    "            # if position of actual residue is higher than last residue, ad current residue position\n",
    "            else:\n",
    "                temporary_list.append(int(residue[1]))\n",
    "\n",
    "    # append last peptide lenght to lenght stack\n",
    "    peptide_lenght_list.append(len(temporary_list))\n",
    "\n",
    "    # create empty dict for coordinate\n",
    "    peptide_coordinate_dict = {}\n",
    "\n",
    "    # create an entry in dict for every peptide in the file\n",
    "    for peptide in range(len(peptide_lenght_list)):\n",
    "        peptide_coordinate_dict[peptide] = {}\n",
    "\n",
    "        # for every residue in lenght peptide, add coordinate x, y, z\n",
    "        for residue in range(peptide_lenght_list[peptide]):\n",
    "            peptide_coordinate_dict[peptide][residue] = [float(coordinate) for coordinate in cleaned_gro_file[(peptide * peptide_lenght_list[peptide])+residue][3:]]\n",
    "\n",
    "    return peptide_coordinate_dict\n",
    "\n",
    "\n",
    "# compute euclidean distance\n",
    "def get_euclidean_distance(point_1, point_2):\n",
    "    \n",
    "    euclidean_distance = np.sqrt(np.sum([((point_1[0] - point_2[0])**2), ((point_1[1] - point_2[1])**2), ((point_1[2] - point_2[2])**2)]))\n",
    "\n",
    "    return euclidean_distance\n",
    "\n",
    "# compute distance map between two peptides\n",
    "def compute_distance_map(coordinate_dict, peptide_1, peptide_2):\n",
    "\n",
    "    distance_map = []\n",
    "    for amino_1 in coordinate_dict[peptide_1]:\n",
    "        coordinate_1 = coordinate_dict[peptide_1][amino_1]\n",
    "        \n",
    "        distance_map.append([amino_1])\n",
    "        \n",
    "        for amino_2 in coordinate_dict[peptide_2]:\n",
    "            coordinate_2 = coordinate_dict[peptide_2][amino_2]\n",
    "            \n",
    "            euclidean_distance = get_euclidean_distance(coordinate_1, coordinate_2)\n",
    "            distance_map[amino_1].append(euclidean_distance)\n",
    "        \n",
    "        del distance_map[amino_1][0]\n",
    "\n",
    "    distance_map = np.asarray(distance_map)\n",
    "    \n",
    "    return distance_map\n",
    "\n",
    "# compute distance map and return a n_peptide x n_peptide x n_res x n_res array\n",
    "def compute_distance_maps_from_coordinate_dict(coordinate_dict):\n",
    "    \n",
    "    aggregate_distance_map = []\n",
    "\n",
    "    #for peptide_1 in tqdm.tqdm(coordinate_dict):\n",
    "    for peptide_1 in coordinate_dict:\n",
    "        aggregate_distance_map.append([peptide_1])\n",
    "        \n",
    "        #for peptide_2 in tqdm.tqdm(coordinate_dict):\n",
    "        for peptide_2 in coordinate_dict:\n",
    "            distance_map = compute_distance_map(coordinate_dict, peptide_1, peptide_2)\n",
    "            \n",
    "            aggregate_distance_map[peptide_1].append(distance_map)\n",
    "\n",
    "        del aggregate_distance_map[peptide_1][0]\n",
    "\n",
    "    aggregate_distance_array = np.asarray(aggregate_distance_map)\n",
    "    \n",
    "    return aggregate_distance_array\n",
    "\n",
    "\n",
    "# COMPUTE CONTACT MAPS\n",
    "# TO DO: parametrize the threshold distance in a better way (e.g. )\n",
    "def compute_contact_maps_as_array(distance_maps_array):\n",
    "    \n",
    "    # distance between the first and the second aminoacid of the first chain\n",
    "    intrapeptide_minimum_distance = distance_maps_array[0][0][0][1] \n",
    "\n",
    "    contact_map_list = []\n",
    "\n",
    "    # contact is in a distance up to 150% of the intrapeptide_minimum_distance [TO IMPROVE!!!]\n",
    "    threshold_distance = (intrapeptide_minimum_distance * 1.5)\n",
    "\n",
    "    for model_1 in range(distance_maps_array.shape[0]):\n",
    "        contact_map_list.append([])\n",
    "        for model_2 in range(distance_maps_array[model_1].shape[0]):\n",
    "\n",
    "            contact_map_list[model_1].append([])\n",
    "\n",
    "            if model_1 == model_2:\n",
    "\n",
    "                contact_map_list[model_1][model_2].extend(np.zeros((distance_maps_array.shape[2], distance_maps_array.shape[3])))\n",
    "\n",
    "            else:\n",
    "\n",
    "                contact_map = np.zeros((distance_maps_array.shape[2], distance_maps_array.shape[3]))\n",
    "\n",
    "                for chain_1 in range(distance_maps_array[model_1][model_2].shape[0]):\n",
    "\n",
    "                    for chain_2 in range(distance_maps_array[model_1][model_2][chain_1].shape[0]):\n",
    "\n",
    "                        distance = distance_maps_array[model_1][model_2][chain_1][chain_2]\n",
    "\n",
    "                        if distance < threshold_distance:\n",
    "                            contact_map[chain_1][chain_2] = 1 #True\n",
    "                        else:\n",
    "                            pass\n",
    "\n",
    "                contact_map_list[model_1][model_2].extend(contact_map)\n",
    "    \n",
    "    contact_array = np.asarray(contact_map_list)\n",
    "            \n",
    "    return contact_array\n",
    "\n",
    "\n",
    "#### ANALYSIS\n",
    "\n",
    "def shift_library_maker(contact_map_to_analyze):\n",
    "    \n",
    "    ''' riceve numero di righe e di colonne\n",
    "    restituisce un array shape((((row + col)*2)-2),row,col).\n",
    "    ogni slice è una diagonale. Lo stack copre le diagonali su tutta la matrice'''\n",
    "    \n",
    "    row = contact_map_to_analyze.shape[0]\n",
    "    col = contact_map_to_analyze.shape[1]\n",
    "    \n",
    "    kron_dict = {}\n",
    "    kron_list_parallel = []\n",
    "    kron_list_antiparallel = []\n",
    "    \n",
    "    for e in range(-row+1, col):\n",
    "        array = np.eye(row, col, e)\n",
    "        kron_list_parallel.append(array)\n",
    "        kron_list_antiparallel.append(np.fliplr(array))\n",
    "        \n",
    "    kron_array_parallel = np.asarray(kron_list_parallel)\n",
    "    kron_array_antiparallel = np.asarray(kron_list_antiparallel)\n",
    "    \n",
    "    kron_dict['parallel'] = kron_array_parallel\n",
    "    kron_dict['antiparallel'] = kron_array_antiparallel\n",
    "    \n",
    "    return kron_dict\n",
    "\n",
    "\n",
    "def normalized_cross_correlation_function(contact_map):\n",
    "    '''\n",
    "    Calculate normalized cross correlation function between a contact map and an ideal map.\n",
    "    \n",
    "    Arguments : contact map, as output from get_contact_maps function\n",
    "                shift_matrix_stack, as output from shift_matrix_maker function\n",
    "                \n",
    "    Return : a list [ncc_value, index (in the shift_matrix_stack) of the shift matrix\n",
    "                that is matching the contact map\n",
    "            \n",
    "            '''\n",
    "    shift_matrix_library = shift_library_maker(contact_map)\n",
    "    \n",
    "    cross_correlation_values = []\n",
    "    max_val = []\n",
    "    sum_contact_map = np.sum(contact_map)\n",
    "    \n",
    "    if sum_contact_map < 2:\n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "        for sense in shift_matrix_library:\n",
    "            for index, z in enumerate(shift_matrix_library[sense]):\n",
    "\n",
    "                shift_matrix = shift_matrix_library[sense][index]\n",
    "                sum_shift_matrix = np.sum(shift_matrix)\n",
    "                ncc_value = (np.sum((contact_map * shift_matrix))/((np.sqrt(sum_contact_map))*(np.sqrt(sum_shift_matrix))))  # normalized cross correlation function of contact matrix and shift matrix\n",
    "                cross_correlation_values.append([ncc_value, index, sum_contact_map, sense])\n",
    "\n",
    "            max_val = max(cross_correlation_values) # get only the best match (highest value of ncc)\n",
    "\n",
    "    return max_val\n",
    "\n",
    "\n",
    "\n",
    "def normalized_cross_correlation_for_dataset(contact_array):\n",
    "    '''Calculate normalized cross correlation function between the full contacts map and and the .\n",
    "    \n",
    "    Arguments : contact map, as output from get_contact_maps function\n",
    "                shift_matrix_stack, as output from shift_matrix_maker function\n",
    "                \n",
    "    Return : a list [ncc_value, index (in the shift_matrix_stack) of the shift matrix that is matching the contact map'''\n",
    "    \n",
    "    contact_dict = {}\n",
    "    \n",
    "    #for row in tqdm.tqdm(range(contact_array.shape[0])):\n",
    "    for row in range(contact_array.shape[0]):\n",
    "    \n",
    "        for col in range((row+1), contact_array.shape[1]):\n",
    "        #for col in range(contact_array.shape[1]):\n",
    "\n",
    "            best_match = []\n",
    "            best_match = normalized_cross_correlation_function(contact_array[row][col])\n",
    "            \n",
    "            if len(best_match) == 0:\n",
    "                pass\n",
    "            \n",
    "            else:\n",
    "                if row in contact_dict:\n",
    "                    contact_dict[row].append([row, col, best_match])\n",
    "                \n",
    "                else:\n",
    "                    contact_dict[row] = [[row, col, best_match]]\n",
    "    \n",
    "    return contact_dict\n",
    "\n",
    "\n",
    "#denoise dataset\n",
    "def denoise_full_dataset(contact_maps, normalized_cross_correlation_results):\n",
    "    \n",
    "    '''Denoise the contact_maps dataset using the shift_matrix\n",
    "    \n",
    "    Arguments : contact_maps, normalized_cross_correlation_result\n",
    "    \n",
    "    return : a dict with key:value = row : row, col, denoised_map\n",
    "    \n",
    "    '''\n",
    "\n",
    "    denoised_dict = {}\n",
    "\n",
    "    for peptide_1 in normalized_cross_correlation_results:\n",
    "        denoised_dict[peptide_1] = {}\n",
    "        for index, peptide_2 in enumerate(normalized_cross_correlation_results[peptide_1]):\n",
    "\n",
    "            row = peptide_2[0]\n",
    "            col = peptide_2[1]\n",
    "\n",
    "\n",
    "\n",
    "            contact_map = contact_maps[row][col]\n",
    "            sense = peptide_2[2][3]\n",
    "            shift_matrix_index = normalized_cross_correlation_results[peptide_1][index][2][1]\n",
    "\n",
    "            shift_matrix = shift_library_maker(contact_map)\n",
    "            shift_matrix = shift_matrix[sense][shift_matrix_index]\n",
    "            denoised_map = contact_map * shift_matrix\n",
    "\n",
    "            denoised_dict[row][col] = denoised_map\n",
    "            \n",
    "    return denoised_dict\n",
    "\n",
    "\n",
    "#create a dict that contains the peptide couples contact and the specular peptide couples contact\n",
    "def reconstruct_full_matrix(denoised_dict):\n",
    "    full_denoised_dict = {}\n",
    "    for peptide_1 in tqdm.tqdm(denoised_dict):\n",
    "        for peptide_2 in denoised_dict[peptide_1]:\n",
    "            contact_map = denoised_dict[peptide_1][peptide_2]\n",
    "\n",
    "            if peptide_1 in full_denoised_dict:\n",
    "                full_denoised_dict[peptide_1][peptide_2] = contact_map\n",
    "\n",
    "            if peptide_1 not in full_denoised_dict:\n",
    "                full_denoised_dict[peptide_1] = {peptide_2:contact_map}\n",
    "\n",
    "            if peptide_2 in full_denoised_dict:\n",
    "                full_denoised_dict[peptide_2][peptide_1] = contact_map.T\n",
    "\n",
    "            if peptide_2 not in full_denoised_dict:\n",
    "                full_denoised_dict[peptide_2] = {peptide_1:contact_map.T}\n",
    "    \n",
    "    return full_denoised_dict\n",
    "\n",
    "\n",
    "# take array, return vector with sum along columns\n",
    "def get_row_vector(array):\n",
    "    row_vector = np.sum(array, axis=0)\n",
    "    return row_vector\n",
    "\n",
    "# take array, return vector with sum along row\n",
    "def get_col_vector(array):\n",
    "    col_vector = np.sum(array, axis=1)\n",
    "    return col_vector\n",
    "\n",
    "# graph clustering\n",
    "def nx_graph_search(denoised_dict):\n",
    "    \n",
    "    graph = nx.MultiGraph()\n",
    "    \n",
    "    for peptide_1 in denoised_dict:\n",
    "        for peptide_2 in denoised_dict[peptide_1]:\n",
    "            array_1 = denoised_dict[peptide_1][peptide_2]\n",
    "            for peptide_3 in denoised_dict[peptide_2]:\n",
    "                if peptide_3 != peptide_1:\n",
    "                    array_2 = denoised_dict[peptide_2][peptide_3]\n",
    "\n",
    "                    vect_1 = get_row_vector(array_1)\n",
    "                    vect_2 = get_col_vector(array_2)\n",
    "\n",
    "                    contacts = np.dot(vect_1, vect_2)\n",
    "                    \n",
    "                    if contacts >= 3:\n",
    "\n",
    "                        graph.add_edge(peptide_1, peptide_2)\n",
    "                     \n",
    "                        graph.add_edge(peptide_2, peptide_3)\n",
    "\n",
    "    return graph\n",
    "\n",
    "#A novel graph clustering algorithm based on discrete-time quantum random walk\n",
    "#S.G. Roya, A. Chakrabarti\n",
    "\n",
    "\n",
    "# working with networkX\n",
    "# if contacts >= target\n",
    "\n",
    "# when you add_edge, nodes are created if they are not there\n",
    "# you can put info in edge (as distance, n of contacts, contact map)\n",
    "# you HAVE TO (but you can not also) put key to index multiple nodes that are joined with a single node\n",
    "# \n",
    "# add edge from pep1 to pep2 (you HAVE TO (###to explore utility of key) put key to index multiple nodes that are joined with a single node)\n",
    "# add edge from pep3 to pep3 ( same as before with key)\n",
    "\n",
    "\n",
    "#FIND SUBGRAPH\n",
    "def find_subgraph(graph):\n",
    "    '''\n",
    "    Find subgraph that have no node in common.\n",
    "    \n",
    "    Argument: NetworkX MultiGraph\n",
    "    \n",
    "    Return: list of subgraph ordered from one end to the other\n",
    "    \n",
    "    '''\n",
    "\n",
    "    subgraph_list = []\n",
    "    \n",
    "    for node in graph:\n",
    "        \n",
    "        # don't explore node that are already in subgraph_list\n",
    "        if node not in set(nod for nod_list in subgraph_list for nod in nod_list):\n",
    "            \n",
    "            # tree is the list of nodes joined to node, starting from node\n",
    "            # using depht first search\n",
    "            tree = [e for e in nx.algorithms.traversal.depth_first_search.dfs_tree(graph, node)]\n",
    "            \n",
    "            # check if the first node of the tree has adjiacency == 1\n",
    "            # so it checks if it is the first or last node of the subgraph\n",
    "            if len(graph[tree[0]]) == 1:\n",
    "                \n",
    "                if len(subgraph_list) == 0:\n",
    "                    subgraph_list.append(tree)\n",
    "                    \n",
    "                else:\n",
    "                    # use generator to check if the tree is already in the subgraph\n",
    "                    if set(tree) not in (set(i) for i in subgraph_list):\n",
    "                        subgraph_list.append(tree)\n",
    "                        \n",
    "    return subgraph_list\n",
    "\n",
    "\n",
    "########## PLOT PEPTIDE LIST\n",
    "# plot a list of peptide point cloud in 3d space.\n",
    "# The box axis have arbitrary scale dependent on the aminoacids distance\n",
    "# you can select to show the centroid\n",
    "def plot_peptide_list(coordinate_dict, peptide_list, centroid=False):\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "    x_median = float\n",
    "    y_median = float\n",
    "    z_median = float\n",
    "    \n",
    "\n",
    "    for peptide in range(len(peptide_list)):\n",
    "        x.append([peptide])\n",
    "        y.append([peptide])\n",
    "        z.append([peptide])\n",
    "        for aminoacid in coordinate_dict[peptide_list[peptide]]:\n",
    "\n",
    "            point = coordinate_dict[peptide_list[peptide]][aminoacid]\n",
    "            x[peptide].append(point[0])\n",
    "            y[peptide].append(point[1])\n",
    "            z[peptide].append(point[2])\n",
    "\n",
    "        del x[peptide][0]\n",
    "        del y[peptide][0]\n",
    "        del z[peptide][0]\n",
    "        \n",
    "    if centroid == True:\n",
    "        \n",
    "        def assemble_coordinate(axis_coordinate_list):\n",
    "            median_list = []\n",
    "            for coordinate_set in axis_coordinate_list:\n",
    "                median = np.median(coordinate_set)\n",
    "                median_list.append(median)\n",
    "            return median_list\n",
    "        \n",
    "        x_median = assemble_coordinate(x)\n",
    "        y_median = assemble_coordinate(y)\n",
    "        z_median = assemble_coordinate(z)\n",
    "        \n",
    "\n",
    "    #%matplotlib notebook\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes(projection='3d')\n",
    "    \n",
    "    for pep in range(len(x)):\n",
    "       \n",
    "        ax.scatter3D(x[pep],y[pep],z[pep])\n",
    "        \n",
    "        if centroid == True:\n",
    "            \n",
    "            ax.scatter3D(x_median[pep], y_median[pep], z_median[pep], c='red')\n",
    "            \n",
    "        \n",
    "    #return  plt.show(), [x,y,z], [x_median, y_median, z_median]\n",
    "    return  plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# get average distance map from distance maps set\n",
    "def get_mean_distance_map(distance_maps):\n",
    "    '''\n",
    "    Calculate mean distance map from distance maps set\n",
    "    \n",
    "    Argument: distance maps set\n",
    "    \n",
    "    return: np.array with average intrapeptide distance\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # create array of zeros of shape number_of_residues * number_of_residues\n",
    "    # depending on peptide residue number ### TO FIX FOR MULTIMONOMERIC ASSEMBLY\n",
    "    base = np.zeros((distance_maps[0][0].shape[0], distance_maps[0][0].shape[1]))\n",
    "    \n",
    "    # initialize counter\n",
    "    counter = 0\n",
    "    \n",
    "    # iterate throught peptides in the aggregate\n",
    "    for peptide_1 in range(distance_maps.shape[0]):\n",
    "        for peptide_2 in range(distance_maps.shape[1]):\n",
    "             \n",
    "            # if peptide index are the same (intrapeptide distance map)\n",
    "            if peptide_1 == peptide_2:\n",
    "                \n",
    "                # intrapeptide distance map\n",
    "                actual_distance_map = distance_maps[peptide_1][peptide_2]\n",
    "                \n",
    "                # sum base and current distance map\n",
    "                base = base + actual_distance_map\n",
    "                \n",
    "                #update counter\n",
    "                counter += 1\n",
    "\n",
    "    #for element in base (every element is the sum of distance_map(i,j) for every distance map)\n",
    "    for row in range(len(base)):\n",
    "        for col in range(len(base)):\n",
    "            \n",
    "            # find the mean for every element of the cumulative distance map\n",
    "            base[row][col] = (base[row][col])/counter\n",
    "            \n",
    "    return base\n",
    "\n",
    "\n",
    "def decompose_distance_map(distance_map):\n",
    "    '''Use Singular value decomposition to get\n",
    "    \n",
    "    distance_map.shape[1] dimensional coordinate\n",
    "    (same n of dimension as the peptide n of residue)\n",
    "    \n",
    "    As described in:\n",
    "    Mathematical Modeling of Protein Structure Using Distance Geometry\n",
    "    Jeong-Mi Yoon, Yash Gad, Zhijun Wu\n",
    "    \n",
    "    Argument: distance map (numpy.array 2D)\n",
    "    return: X : actual decomposition\n",
    "            \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # initialize a zeros matrix of same shape as the input map\n",
    "    D = np.zeros(distance_map.shape)\n",
    "    \n",
    "    #iterate trought row\n",
    "    for i in range(distance_map.shape[0]):\n",
    "        \n",
    "        # iterate trought cols\n",
    "        for j in range(distance_map.shape[1]):\n",
    "            \n",
    "            # distance between point point i and point j \n",
    "            dij = distance_map[i][j]\n",
    "            \n",
    "            # distance between point 0 and point j\n",
    "            d0j = distance_map[0][j]\n",
    "            \n",
    "            #distance between point i and point 0\n",
    "            di0 = distance_map[i][0]\n",
    "\n",
    "            #fill the zeros matrix with the value obtained with this formula\n",
    "            D[i][j] = (d0j**2 + di0**2 - dij**2)/2\n",
    "            \n",
    "    # check rank of matrix (should be of rank 3, but it is of rank distance_map.shape[1])\n",
    "    rank = np.linalg.matrix_rank(D)\n",
    "    \n",
    "    # Singular value decomposition on the D matrix\n",
    "    #svd = np.linalg.svd(D)\n",
    "    \n",
    "    svd = np.linalg.svd(D, full_matrices=False)\n",
    "    \n",
    "    # Calculate distance_map.shape[1] dimensional coordinate, but you need 3\n",
    "    # the non necessary dimension can give data to better reconstruct the peptide structure\n",
    "    X = svd[0]*np.sqrt(svd[1])\n",
    "\n",
    "    \n",
    "    #return X, svd, D, rank\n",
    "    return X\n",
    "\n",
    "def get_coordinate_from_decomposition(decomposition):\n",
    "    '''Take decomposition result and convert it into a coordinate vectors dict\n",
    "    \n",
    "    Argument: decomposition results\n",
    "    \n",
    "    return: dict with reconstructed 3d coordinate vector\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # take only the first three value to compose a 3D coordinate vector\n",
    "    coordinate = [e[:3] for e in decomposition]\n",
    "    \n",
    "    # initialize empty dict\n",
    "    reconstructed_coordinate_dict = {}\n",
    "    \n",
    "    # fill the dict with the ccordinate vectors\n",
    "    for index,coordinate_vector in enumerate(coordinate):\n",
    "        reconstructed_coordinate_dict[index] = coordinate_vector\n",
    "    \n",
    "    return reconstructed_coordinate_dict\n",
    "\n",
    "\n",
    "# \n",
    "def get_coordinate_from_distance_map(distance_map):\n",
    "    ''' compute 3d coordinate from distance map\n",
    "    \n",
    "    Argument: distance_map (numpy.array)\n",
    "    \n",
    "    return: dict with 3d coordinate for every alpha-carbon of a peptide\n",
    "    \n",
    "    '''\n",
    "    # perform singular value decomposition on distance_map (preprocessed)\n",
    "    decomposed_mean_distance_map = decompose_distance_map(distance_map)\n",
    "    \n",
    "    \n",
    "    # get 3D coordinate\n",
    "    reconstructed_coordinate_dict = get_coordinate_from_decomposition(decomposed_mean_distance_map)\n",
    "    \n",
    "    return reconstructed_coordinate_dict\n",
    "\n",
    "    \n",
    "    \n",
    "def plot_single_peptide(peptide_coordinate_dict, centroid=False):\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "    \n",
    "    for residue in peptide_coordinate_dict:\n",
    "        point = peptide_coordinate_dict[residue]\n",
    "        x.append(point[0])\n",
    "        y.append(point[1])\n",
    "        z.append(point[2])\n",
    "\n",
    "\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    z = np.asarray(z)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes(projection='3d')\n",
    "    ax.scatter3D(x,y,z, c='b')\n",
    "    \n",
    "    if centroid == True:\n",
    "            median_centroid = [np.median(x), np.median(y), np.median(z)]\n",
    "            ax.scatter3D(median_centroid[0], median_centroid[1], median_centroid[2], c='r')\n",
    "            \n",
    "    return plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open and clean .gro file\n",
    "# return list with an entry for every residue plus info\n",
    "start = timer()\n",
    "cleaned_gro_seed_1 = clean_gro(seed_1_path)\n",
    "end = timer()\n",
    "print(end - start)\n",
    "\n",
    "# return a dict with residue coordinate\n",
    "start = timer()\n",
    "coordinate_dict_seed_1 = get_coordinate_dict_from_cleaned_gro(cleaned_gro_seed_1)\n",
    "end = timer()\n",
    "print(end - start)\n",
    "\n",
    "# compute distance maps and return a n_peptide x n_peptide x n_res x n_res array ## from .gro coordinate dict\n",
    "start = timer()\n",
    "distance_maps_seed_1 = compute_distance_maps_from_coordinate_dict(coordinate_dict_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "# compute contact maps from distance maps\n",
    "start = timer()\n",
    "contact_maps_seed_1 = compute_contact_maps_as_array(distance_maps_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "# compute cross correlation and get values\n",
    "start = timer()\n",
    "normalized_cross_correlation_results_seed_1 = normalized_cross_correlation_for_dataset(contact_maps_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "# denoise dataset\n",
    "start = timer()\n",
    "denoised_dict_seed_1 = denoise_full_dataset(contact_maps_seed_1, normalized_cross_correlation_results_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "# recreate full contact map dataset mirrroring the upper triangle\n",
    "# return dict\n",
    "start = timer()\n",
    "full_denoised_dict_seed_1 = reconstruct_full_matrix(denoised_dict_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "#create graph\n",
    "start = timer()\n",
    "graph_seed_1 = nx_graph_search(full_denoised_dict_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "#search subgraph\n",
    "start = timer()\n",
    "subgrap_list_seed_1 = find_subgraph(graph_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "#find mean distance map\n",
    "start = timer()\n",
    "mean_distance_map_seed_1 = get_mean_distance_map(distance_maps_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "# decompose mean distance matrix\n",
    "start = timer()\n",
    "decomposed_mean_distance_map = decompose_distance_map(mean_distance_map_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "      \n",
    "# get coordinate from distance map      \n",
    "start = timer()\n",
    "reconstructed_coordinate_dict = get_coordinate_from_decomposition(decomposed_mean_distance_map)\n",
    "end = timer()\n",
    "print(end-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS FOR 3D VIEW OF PLOT\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS TO CLOSE ALL PLOT (run multiple time this cell if it does not work)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the reconstructed average peptide \n",
    "plot_single_peptide(reconstructed_coordinate_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot full coordinate from dict\n",
    "plot_peptide_list(coordinate_dict_seed_1, [e for e in coordinate_dict_seed_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRAJECTORY\n",
    "\n",
    "# using mdanalysis module\n",
    "\n",
    "\n",
    "#create Universe from a .gro with coordinates and an .xtc with the trajectory data\n",
    "u = mda.Universe(trj_gro,trj_xtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dict from a Universe in which each entry is a timestep of the MD simulation\n",
    "def create_trajectory_dict(u):\n",
    "    bb = u.select_atoms('name BB')\n",
    "    trajectory_dict = {}\n",
    "    for index, time_steps in enumerate(u.trajectory):\n",
    "        trajectory_dict[index] = bb.positions\n",
    "    return trajectory_dict\n",
    "\n",
    "# make trajectory dict\n",
    "trajectory_dict = create_trajectory_dict(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you change the number in the first parentesis, you change timestep\n",
    "#second parentesis are the bb grains\n",
    "pep = trajectory_dict[0][:1200] # this are all the coordinate of bb grains of timestep 0, as an array\n",
    "\n",
    "#cast coordinate from array to dict\n",
    "zero_c = get_coordinate_from_decomposition(pep)\n",
    "\n",
    "#plot dict as a single object\n",
    "plot_single_peptide(zero_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see the trajectory you need to install ngl-view\n",
    "# https://github.com/arose/nglview\n",
    "#\n",
    "# pay attention to this:\n",
    "#   pip install nglview\n",
    "#\n",
    "# in a terminal, in the env where ngl-view is installed, send this:\n",
    "# jupyter-nbextension enable nglview --py --sys-prefix\n",
    "#\n",
    "\n",
    "\n",
    "view = nv.show_mdanalysis(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class morphoscanner():\n",
    "    \n",
    "    \n",
    "    \n",
    "    class math_utility():\n",
    "\n",
    "        # take array, return vector with sum along columns\n",
    "        def get_row_vector(array):\n",
    "            row_vector = np.sum(array, axis=0)\n",
    "            return row_vector\n",
    "\n",
    "        # take array, return vector with sum along row\n",
    "        def get_col_vector(array):\n",
    "            col_vector = np.sum(array, axis=1)\n",
    "            return col_vector\n",
    "        \n",
    "        \n",
    "    class utility():\n",
    "        \n",
    "        def get_coordinate_dict_from_array(array):\n",
    "            '''Take decomposition result and convert it into a coordinate vectors dict\n",
    "\n",
    "            Argument: decomposition results\n",
    "\n",
    "            return: dict with reconstructed 3d coordinate vector\n",
    "\n",
    "            '''\n",
    "\n",
    "            # make list with n == array.shape[0]\n",
    "            coordinate = [e for e in array]\n",
    "\n",
    "            # initialize empty dict\n",
    "            reconstructed_coordinate_dict = {}\n",
    "\n",
    "            # fill the dict with the ccordinate vectors\n",
    "            for index,coordinate_vector in enumerate(coordinate):\n",
    "                reconstructed_coordinate_dict[index] = coordinate_vector\n",
    "\n",
    "            return reconstructed_coordinate_dict\n",
    "        \n",
    "        \n",
    "        \n",
    "        def contact_list_from_dict(contact_dict):\n",
    "            \n",
    "            contact_list = []\n",
    "            for peptide in contact_dict:\n",
    "\n",
    "                for contact in contact_dict[peptide]:\n",
    "\n",
    "                    new_data = [contact[0], contact[1], contact[2][0], contact[2][1], contact[2][2], contact[2][3]]\n",
    "                    contact_list.append(new_data)\n",
    "            return contact_list\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    class read():\n",
    "        \n",
    "        # READ .gro FILE AND PREPROCESSING\n",
    "\n",
    "        def clean_gro(path):\n",
    "\n",
    "\n",
    "                # open file .gro and return a list with one element per line of the .gro file\n",
    "            def read_gro(path):\n",
    "                gromacs_output = open(path)\n",
    "\n",
    "                gro_file = []\n",
    "                for line in gromacs_output:\n",
    "                    gro_file.append(line)\n",
    "\n",
    "\n",
    "\n",
    "                gromacs_output.close()        \n",
    "\n",
    "                return gro_file\n",
    "\n",
    "\n",
    "\n",
    "            # return string in a string with numbers\n",
    "            def return_if_string(string):\n",
    "                digits = []\n",
    "                for i in string:\n",
    "                    if not i.isdigit():\n",
    "                        digits.append(i)\n",
    "\n",
    "                string = ''.join(digits)\n",
    "\n",
    "                return string\n",
    "\n",
    "\n",
    "            # return numbers in a string with numbers\n",
    "            def return_if_digit(string):\n",
    "                digits = []\n",
    "                for i in string:\n",
    "                    if i.isdigit():\n",
    "                        digits.append(i)\n",
    "\n",
    "                string = ''.join(digits)\n",
    "\n",
    "                return string\n",
    "\n",
    "\n",
    "            # remove first, second and last lines from gro_file and reorder information\n",
    "            # FIX OPTION TO GET ENTRY RELATED TO A LABEL (as 'bb' or 'ca')\n",
    "            def clean_gro_file(gro_file):\n",
    "                cleaned_gro_file = []\n",
    "                for aminoacid in gro_file[2:-1]:\n",
    "                    splitted = aminoacid.split()\n",
    "                    if splitted[1] == 'BB':\n",
    "                        position_in_peptide = return_if_digit(splitted[0])\n",
    "                        residue = return_if_string(splitted[0])\n",
    "                        index = splitted[2]\n",
    "                        x = splitted[3]\n",
    "                        y = splitted[4]\n",
    "                        z = splitted[5]\n",
    "                        cleaned_gro_file.append([index, position_in_peptide, residue, x, y, z])\n",
    "                return cleaned_gro_file\n",
    "\n",
    "\n",
    "            gro_file = read_gro(path)\n",
    "            cleaned_gro_file = clean_gro_file(gro_file)\n",
    "\n",
    "            return cleaned_gro_file\n",
    "        \n",
    "        # create coordinate dict from cleaned_gro_file\n",
    "        def get_coordinate_dict_from_cleaned_gro(cleaned_gro_file):\n",
    "\n",
    "            peptide_lenght_list = []\n",
    "\n",
    "            temporary_list = []\n",
    "\n",
    "            # iterate trough cleaned_gro_file\n",
    "            for residue in cleaned_gro_file:\n",
    "\n",
    "                # if temporary list just started, add aminoacid position in chain\n",
    "                if len(temporary_list) == 0:\n",
    "                    temporary_list.append(int(residue[1]))\n",
    "\n",
    "                else:\n",
    "                    # if position of actual residue is less than last residue\n",
    "                    if temporary_list[-1] > int(residue[1]):\n",
    "\n",
    "                        # append lenght of last peptide to peptide lenght list\n",
    "                        peptide_lenght_list.append(len(temporary_list))\n",
    "\n",
    "                        # empty temporary list\n",
    "                        temporary_list = []\n",
    "\n",
    "                        # append actual residue position\n",
    "                        temporary_list.append(int(residue[1]))\n",
    "\n",
    "                    # if position of actual residue is higher than last residue, ad current residue position\n",
    "                    else:\n",
    "                        temporary_list.append(int(residue[1]))\n",
    "\n",
    "            # append last peptide lenght to lenght stack\n",
    "            peptide_lenght_list.append(len(temporary_list))\n",
    "\n",
    "            # create empty dict for coordinate\n",
    "            peptide_coordinate_dict = {}\n",
    "\n",
    "            # create an entry in dict for every peptide in the file\n",
    "            for peptide in range(len(peptide_lenght_list)):\n",
    "                peptide_coordinate_dict[peptide] = {}\n",
    "\n",
    "                # for every residue in lenght peptide, add coordinate x, y, z\n",
    "                for residue in range(peptide_lenght_list[peptide]):\n",
    "                    peptide_coordinate_dict[peptide][residue] = [float(coordinate) for coordinate in cleaned_gro_file[(peptide * peptide_lenght_list[peptide])+residue][3:]]\n",
    "\n",
    "            return peptide_coordinate_dict #, peptide_lenght_list\n",
    "        \n",
    "        \n",
    "        def get_coordinate_dict_from_cleaned_gro_for_fixed_lenght_peptides(cleaned_gro_file, peptide_lenght):\n",
    "            '''Works only with system made of peptide of equal peptide length\n",
    "                (the peptide in the trajectory have all the same number of aminoacids).\n",
    "\n",
    "            Usefull to disassemble premade aggregate in a system of omogenous peptide lenght'''\n",
    "\n",
    "            peptide_coordinate_dict = {}\n",
    "\n",
    "            for peptide in range(len(cleaned_gro_file)//peptide_lenght):\n",
    "\n",
    "                peptide_coordinate_dict[peptide] = {}\n",
    "\n",
    "                peptide_data = cleaned_gro_file[(peptide*peptide_lenght):((peptide*peptide_lenght)+peptide_lenght)]\n",
    "\n",
    "                for index, amino in enumerate(peptide_data):\n",
    "\n",
    "                    peptide_coordinate_dict[peptide][index] = [float(amino[3]), float(amino[4]), float(amino[5])] ## can you generalize this 3? Maybe with re or isdigit function??\n",
    "\n",
    "            return peptide_coordinate_dict\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    class dataframe():\n",
    "        \n",
    "        \n",
    "        def get_dataframe_from_trajectory(trj_gro, trj_xtc, peptide_length = None):\n",
    "            \n",
    "            '''Create pandas.DataFrame from trajectory files\n",
    "            \n",
    "            Arguments: str(.gro topology path),\n",
    "                       str(.xtc trajectory path),\n",
    "                       int (optional)\n",
    "                       \n",
    "            output: pandas.DataFrame\n",
    "            \n",
    "            The 3rd argument (peptide_length) is optional. If you leave it empty the\n",
    "            function will use the topology file to dynamically group residues into peptides,\n",
    "            strictly following the topology. It adapt to different peptide lengths (aminoacids number in the peptide)\n",
    "            \n",
    "            \n",
    "            If you do molecular dynamics simulation with peptide of fixed residues number,\n",
    "            you can insert the residues number and the function will parse the residues to\n",
    "            compose the peptides unsing that number.\n",
    "            \n",
    "            for example, you use peptides with 12 aminoacids each, but you start your simulation\n",
    "            using a premade seed of 4 peptides forming a beta-sheet. The gromacs topology file will\n",
    "            consider this as a 64 residues peptide. But it is actually made of 4 peptides of 12 aminoacid each.\n",
    "            If you set the peptide_length to 12, it will parse the premade beta sheet \n",
    "            as 4 peptides of 12 aminoacids each.\n",
    "            \n",
    "            '''\n",
    "\n",
    "            universe = morphoscanner.topology.make_universe(trj_gro, trj_xtc)\n",
    "\n",
    "            topology = trj_gro\n",
    "\n",
    "            peptides_list = morphoscanner.topology.get_peptide_length_list(trj_gro)\n",
    "\n",
    "\n",
    "            if peptide_length == None:\n",
    "\n",
    "\n",
    "                n_pep = len(peptides_list)\n",
    "\n",
    "\n",
    "            else:\n",
    "\n",
    "                n_pep = sum([(e//peptide_length) for e in peptides_list])\n",
    "\n",
    "            #columns_name = ['atom_number','peptide_number', 'residue_name', 'residue_position', 'coordinates']\n",
    "            columns_name = ['time_step','peptide_number', 'residue_position', 'residue_name', 'atom_position', 'atom_type', 'coordinates']\n",
    "\n",
    "            # create list for a pd.DataFrame\n",
    "            # as suggested in https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.append.html\n",
    "            for_pandas = []\n",
    "\n",
    "            trj_dict = {}\n",
    "\n",
    "            for index_ts, ts in enumerate(universe.trajectory):\n",
    "\n",
    "                trj_dict[index_ts] = {}\n",
    "\n",
    "                for peptide in range(n_pep):\n",
    "\n",
    "                    trj_dict[index_ts][peptide] = {}\n",
    "\n",
    "                    if peptide != 0:\n",
    "\n",
    "                        # if to check peptide_length\n",
    "\n",
    "                        if peptide_length == None:\n",
    "\n",
    "                            counter += peptides_list[peptide - 1]\n",
    "\n",
    "                        else:\n",
    "                            counter += peptide_length\n",
    "\n",
    "\n",
    "                    else:\n",
    "                        counter = 0\n",
    "\n",
    "\n",
    "                    if peptide_length == None:\n",
    "\n",
    "                        for res in range(peptides_list[peptide]):\n",
    "\n",
    "                            res_name = (str(universe.residues[res + counter]).split()[1].split(',')[0])#.split(',')[0])\n",
    "                            res_position = int(str(universe.residues[res + counter]).split()[2].split('>')[0])#.split(',')[0])\n",
    "                            res_id = str(res_position) + '_' + res_name\n",
    "\n",
    "                            #print(str(universe.residues[res + counter]))\n",
    "\n",
    "                            for index, atom in enumerate(universe.residues[res + (counter)].atoms):\n",
    "\n",
    "                                #print(atom)\n",
    "\n",
    "                                atom_number = (int(str(atom).split()[1].split(':')[0]) - 1)\n",
    "\n",
    "                                atom_type = str(atom).split()[2]\n",
    "\n",
    "                                coordinate = universe.atoms[atom_number].position\n",
    "\n",
    "                                position = len(trj_dict[index_ts][peptide])\n",
    "\n",
    "                                trj_dict[index_ts][peptide][position] = coordinate\n",
    "\n",
    "                                #features = [atom_number,peptide, res_name, position, coordinate]\n",
    "                                features = [index_ts, peptide, res_position, res_name, position, atom_type, coordinate]\n",
    "\n",
    "                                for_pandas.append(features)\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        for res in range(peptide_length):\n",
    "\n",
    "                            res_name = (str(universe.residues[res + counter]).split()[1].split(',')[0])#.split(',')[0])\n",
    "                            res_position = int(str(universe.residues[res + counter]).split()[2].split('>')[0]) - 1 # -1 to start index from 0\n",
    "                            res_id = str(res_position) + '_' + res_name\n",
    "\n",
    "                            #print(str(universe.residues[res + counter]))\n",
    "\n",
    "                            for index, atom in enumerate(universe.residues[res + (counter)].atoms):\n",
    "\n",
    "                                #print(atom)\n",
    "\n",
    "                                atom_number = (int(str(atom).split()[1].split(':')[0]) - 1)\n",
    "\n",
    "                                atom_type = str(atom).split()[2]\n",
    "\n",
    "                                coordinate = universe.atoms[atom_number].position\n",
    "\n",
    "                                position = len(trj_dict[index_ts][peptide])\n",
    "\n",
    "                                trj_dict[index_ts][peptide][position] = coordinate\n",
    "\n",
    "                                #features = [atom_number,peptide, res_name, position, coordinate]\n",
    "                                features = [index_ts, peptide, res_position, res_name, position, atom_type, coordinate]\n",
    "\n",
    "                                for_pandas.append(features)\n",
    "\n",
    "\n",
    "\n",
    "            #start = timer()\n",
    "            df = pd.DataFrame(for_pandas, columns=columns_name)\n",
    "            #end = timer()\n",
    "            #print(end-start)\n",
    "            return df\n",
    "\n",
    "    \n",
    "    \n",
    "        # get dataframe of bb grains for a frame ()\n",
    "        def get_bb(dataframe, frame):\n",
    "    \n",
    "            bb_dataframe = dataframe.groupby('time_step').get_group(frame).groupby('atom_type').get_group('BB')\n",
    "\n",
    "            return bb_dataframe\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        def get_peptide_tensor_from_dataframe(dataframe, step, peptide):\n",
    "            \n",
    "            '''Get 2d tensor with the coordinate of every atom (or grain) of a peptide, from a dataframe\n",
    "            \n",
    "            \n",
    "            Input:  dataframe, (the dataframe where your data are).\n",
    "            \n",
    "                    step, (frame of the trajectory from which you want to take the coordinate)\n",
    "                    \n",
    "                    peptide, (the peptide of which you want the coordinate)\n",
    "                    \n",
    "            Output: torch.tensor, of shape(n,3), where n is the number of atoms in the peptide\n",
    "            that you are considering. And 3 are the coordinate x, y, z of the atom.\n",
    "            '''\n",
    "        \n",
    "            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "            peptide_data = dataframe.groupby('time_step').get_group(step).groupby('peptide_number').get_group(peptide)\n",
    "\n",
    "            peptide_tensor = torch.tensor([vector for vector in peptide_data.coordinates.values], device=device)\n",
    "\n",
    "            return peptide_tensor\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        def distance_maps_from_dataframe(dataframe, time_step):\n",
    "            \n",
    "            '''Calculate distance maps for all the peptides in a step of the md simulation.\n",
    "            \n",
    "            Input:  pandas.DataFrame. Made with morphoscanner.dataframe.get_dataframe_from_trajectory()\n",
    "                    \n",
    "                    int. Timestep of the simulation\n",
    "                    \n",
    "                    \n",
    "            Output: dict of tensor. len(dict)==number of peptide in the simulation\n",
    "                                    len(dict[i])== number of peptide in the simulation\n",
    "                                    tensor.shape == (number of residue in peptide1, number of residue in peptide2)\n",
    "                                    \n",
    "            '''\n",
    "            \n",
    "            \n",
    "    \n",
    "            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "            number_of_peptides = len(dataframe.groupby('time_step').get_group(time_step).groupby('peptide_number'))\n",
    "            #number_of_peptides = 5\n",
    "\n",
    "            distance_dict = {}\n",
    "            # iterate trought all peptides in a frame\n",
    "            for peptide1 in range(number_of_peptides):\n",
    "\n",
    "                if peptide1 not in distance_dict.keys():\n",
    "\n",
    "                    distance_dict[peptide1] = {}\n",
    "\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "                number_of_atoms_in_peptide1 = len(dataframe.groupby('time_step').get_group(time_step).groupby('peptide_number').get_group(peptide1))\n",
    "\n",
    "\n",
    "\n",
    "                peptide1_tensor = morphoscanner.dataframe.get_peptide_tensor_from_dataframe(dataframe, time_step, peptide1)\n",
    "\n",
    "                # iterate trought peptide in the upper triangle only\n",
    "                for peptide2 in range(peptide1, number_of_peptides):\n",
    "\n",
    "\n",
    "                    number_of_atoms_in_peptide2 = len(dataframe.groupby('time_step').get_group(time_step).groupby('peptide_number').get_group(peptide2))\n",
    "\n",
    "\n",
    "                    peptide2_tensor = morphoscanner.dataframe.get_peptide_tensor_from_dataframe(dataframe, time_step, peptide2)\n",
    "\n",
    "\n",
    "                    distance_map = morphoscanner.distance_tensor.distance_matrix_from_2d_tensor(peptide1_tensor, peptide2_tensor)\n",
    "                    distance_dict[peptide1][peptide2] = distance_map\n",
    "\n",
    "                    if peptide2 in distance_dict.keys():\n",
    "\n",
    "                        #distance_dict[peptide2] = {}\n",
    "                        distance_dict[peptide2][peptide1] = distance_map.transpose(1,0)\n",
    "\n",
    "                    else:\n",
    "                        distance_dict[peptide2] = {}\n",
    "                        distance_dict[peptide2][peptide1] = distance_map.transpose(1,0)\n",
    "\n",
    "            return distance_dict\n",
    "        \n",
    "        # SO YOU CAN CALCULATE DISTANCE MAPS\n",
    "        # NOW YOU HAVE TO PUT THOSE IN A DATAFRAME\n",
    "\n",
    "    #return dist\n",
    "\n",
    "#https://discuss.pytorch.org/t/efficient-distance-matrix-computation/9065\n",
    "#https://www.dropbox.com/h?preview=Parallel+Euclidean+distance+matrix+computation+on+big+datasets.pdf  \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    class topology():\n",
    "    \n",
    "        \n",
    "        #get a list of the number of residues of every peptide in the topology\n",
    "        def get_peptide_length_list(topology):\n",
    "            \n",
    "            topology = morphoscanner.read.clean_gro(topology)\n",
    "    \n",
    "            peptide_lenght_list = []\n",
    "\n",
    "            temporary_list = []\n",
    "\n",
    "            # iterate trough topology\n",
    "            for residue in topology:\n",
    "\n",
    "                # if temporary list just started, add aminoacid position in chain\n",
    "                if len(temporary_list) == 0:\n",
    "                    temporary_list.append(int(residue[1]))\n",
    "\n",
    "                else:\n",
    "                    # if position of actual residue is less than last residue\n",
    "                    if temporary_list[-1] > int(residue[1]):\n",
    "\n",
    "                        # append lenght of last peptide to peptide lenght list\n",
    "                        peptide_lenght_list.append(len(temporary_list))\n",
    "\n",
    "                        # empty temporary list\n",
    "                        temporary_list = []\n",
    "\n",
    "                        # append actual residue position\n",
    "                        temporary_list.append(int(residue[1]))\n",
    "\n",
    "                    # if position of actual residue is higher than last residue, ad current residue position\n",
    "                    else:\n",
    "                        temporary_list.append(int(residue[1]))\n",
    "\n",
    "            # append last peptide lenght to lenght stack\n",
    "            peptide_lenght_list.append(len(temporary_list))\n",
    "\n",
    "            return peptide_lenght_list\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        def make_universe(trj_gro, trj_xtc):\n",
    "            ''' Leverage MDAnalysis.Universe() to parse trajectory file from gromacs output.\n",
    "\n",
    "            Intput: string: system path of gro file (topology) and\n",
    "                            system path of xtc file (trajectory)\n",
    "                            of the file to analyze\n",
    "\n",
    "            return: MDAnalysis.Universe()'''\n",
    "\n",
    "            universe = mda.Universe(trj_gro,trj_xtc)\n",
    "\n",
    "            return universe\n",
    "        \n",
    "          \n",
    "        \n",
    "        \n",
    "        \n",
    "        # create a dict from a Universe in which each entry is a timestep of the MD simulation\n",
    "        def create_trajectory_dict(universe):\n",
    "            bb = universe.select_atoms('name BB')\n",
    "            trajectory_dict = {}\n",
    "            \n",
    "            for index, time_steps in enumerate(universe.trajectory):\n",
    "                trajectory_dict[index] = bb.positions\n",
    "            \n",
    "            return trajectory_dict\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        # make trajectory dict\n",
    "        \n",
    "        def get_coordinate_dict_from_trajectory(trj_gro, trj_xtc, peptide_length=None, start_from=0, interval=0):\n",
    "            '''Parse coordinate from a .gro topology and a .xtc trajectory.\n",
    "            \n",
    "            Arguments:  .gro topology file path,\n",
    "                    \n",
    "                        .xtc trajectory file path,\n",
    "                        \n",
    "                        \n",
    "                        optional:\n",
    "                            \n",
    "                            peptide_length, default=None.   You can set the length of the peptide\n",
    "                                                            Usefull if you hae to analyze simulation in which\n",
    "                                                            there are premade aggregate\n",
    "                                            \n",
    "                            start_from, default=0.    You can chose from which frame start the counter.\n",
    "                                                        Usefull if you are working with a simulation\n",
    "                                                        made of different part. Eg. If part 1 end at\n",
    "                                                        frame 500, you can set start_from=500 and analyze\n",
    "                                                        part 2 of the simulation. Use it expecially\n",
    "                                                        if you are sampling (interval != 1)\n",
    "                                                        \n",
    "                            interval, default=0     Interval between sample. If you want all the frame,\n",
    "                                                    interval=1.\n",
    "                                                    If you want to skip sample, this parameter let you\n",
    "                                                    choose the interval between 2 sample frame.\n",
    "            \n",
    "            \n",
    "            '''\n",
    "\n",
    "            peptides_list = morphoscanner.topology.get_peptide_length_list(trj_gro)\n",
    "\n",
    "            universe = morphoscanner.topology.make_universe(trj_gro, trj_xtc)\n",
    "\n",
    "\n",
    "            if peptide_length == None:\n",
    "\n",
    "\n",
    "                n_pep = len(peptides_list)\n",
    "\n",
    "\n",
    "            else:\n",
    "\n",
    "                n_pep = sum([(e//peptide_length) for e in peptides_list])\n",
    "\n",
    "\n",
    "            trj_dict = {}\n",
    "\n",
    "            for index_ts, ts in tqdm.tqdm(enumerate(universe.trajectory)):\n",
    "\n",
    "                updated_index = (index_ts + start_from)\n",
    "\n",
    "                if (updated_index % interval) == 0:\n",
    "\n",
    "                    trj_dict[updated_index] = {}\n",
    "\n",
    "                    for peptide in range(n_pep):\n",
    "\n",
    "                        trj_dict[updated_index][peptide] = {}\n",
    "\n",
    "\n",
    "                        if peptide != 0:\n",
    "\n",
    "                            # if to check peptide_length\n",
    "                            if peptide_length == None:\n",
    "\n",
    "                                counter += peptides_list[peptide - 1]\n",
    "\n",
    "                            else:\n",
    "                                counter += peptide_length\n",
    "\n",
    "\n",
    "                        else:\n",
    "                            counter = 0\n",
    "\n",
    "\n",
    "\n",
    "                        if peptide_length == None:\n",
    "\n",
    "                            for res in range(peptides_list[peptide]):\n",
    "\n",
    "                                for index, atom in enumerate(universe.residues[res + (counter)].atoms):\n",
    "\n",
    "\n",
    "                                    atom_type = str(atom).split()[2]\n",
    "\n",
    "                                    if atom_type == 'BB':\n",
    "\n",
    "                                        atom_number = (int(str(atom).split()[1].split(':')[0]) - 1)\n",
    "\n",
    "                                        coordinate = universe.atoms[atom_number].position\n",
    "\n",
    "                                        position = len(trj_dict[updated_index][peptide])\n",
    "\n",
    "\n",
    "                                        trj_dict[updated_index][peptide][position] = coordinate\n",
    "\n",
    "\n",
    "                        else:\n",
    "\n",
    "                            for res in range(peptide_length):\n",
    "\n",
    "                                for index, atom in enumerate(universe.residues[res + (counter)].atoms):\n",
    "\n",
    "\n",
    "                                    atom_type = str(atom).split()[2]\n",
    "\n",
    "\n",
    "                                    if atom_type == 'BB':\n",
    "\n",
    "                                        atom_number = (int(str(atom).split()[1].split(':')[0]) - 1)\n",
    "\n",
    "                                        coordinate = universe.atoms[atom_number].position\n",
    "\n",
    "                                        position = len(trj_dict[updated_index][peptide])\n",
    "\n",
    "\n",
    "                                        trj_dict[updated_index][peptide][position] = coordinate\n",
    "\n",
    "                                    else:\n",
    "                                        pass\n",
    "\n",
    "\n",
    "            return trj_dict\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    class distance():\n",
    "        \n",
    "        \n",
    "        # compute euclidean distance\n",
    "        def get_euclidean_distance(point_1, point_2):\n",
    "\n",
    "            euclidean_distance = np.sqrt(np.sum([((point_1[0] - point_2[0])**2), ((point_1[1] - point_2[1])**2), ((point_1[2] - point_2[2])**2)]))\n",
    "\n",
    "            return euclidean_distance\n",
    "        \n",
    "        \n",
    "\n",
    "        # compute distance map between two peptides\n",
    "        def compute_distance_map(coordinate_dict, peptide_1, peptide_2):\n",
    "\n",
    "            distance_map = []\n",
    "            for amino_1 in coordinate_dict[peptide_1]:\n",
    "                coordinate_1 = coordinate_dict[peptide_1][amino_1]\n",
    "\n",
    "                distance_map.append([amino_1])\n",
    "\n",
    "                for amino_2 in coordinate_dict[peptide_2]:\n",
    "                    coordinate_2 = coordinate_dict[peptide_2][amino_2]\n",
    "\n",
    "                    euclidean_distance = morphoscanner.distance.get_euclidean_distance(coordinate_1, coordinate_2)\n",
    "                    distance_map[amino_1].append(euclidean_distance)\n",
    "\n",
    "                del distance_map[amino_1][0]\n",
    "\n",
    "            distance_map = np.asarray(distance_map)\n",
    "\n",
    "            return distance_map\n",
    "\n",
    "        \n",
    "        \n",
    "        # compute distance map and return a n_peptide x n_peptide x n_res x n_res array\n",
    "        def compute_distance_maps_from_coordinate_dict(coordinate_dict):\n",
    "\n",
    "            aggregate_distance_map = []\n",
    "\n",
    "            for peptide_1 in tqdm.tqdm(coordinate_dict):\n",
    "            #for peptide_1 in coordinate_dict:\n",
    "                aggregate_distance_map.append([peptide_1])\n",
    "\n",
    "                #for peptide_2 in tqdm.tqdm(coordinate_dict):\n",
    "                for peptide_2 in coordinate_dict:\n",
    "                    distance_map = morphoscanner.distance.compute_distance_map(coordinate_dict, peptide_1, peptide_2)\n",
    "\n",
    "                    aggregate_distance_map[peptide_1].append(distance_map)\n",
    "\n",
    "                del aggregate_distance_map[peptide_1][0]\n",
    "\n",
    "            aggregate_distance_array = np.asarray(aggregate_distance_map)\n",
    "\n",
    "            return aggregate_distance_array\n",
    "\n",
    "\n",
    "        # COMPUTE CONTACT MAPS\n",
    "        # TO DO: parametrize the threshold distance in a better way (e.g. )\n",
    "        # DISTANCE MAP ARRAY WILL NOT EXIST IN DISTINCT PEPTIDE SIZE SIMULATION\n",
    "        def compute_contact_maps_as_array(distance_maps_array, radius_multiplier=1.5):\n",
    "\n",
    "            # median consecutive residue distance from first peptide\n",
    "            distances_pep_1 = []\n",
    "            for i in range(distance_maps_array[0][0].shape[0] - 1): # there was a -1, and len(denoised_dict) was len(coordinate_dict)-1\n",
    "                distances_pep_1.append(distance_maps_array[0][0][i][i+1])\n",
    "\n",
    "            intrapeptide_minimum_distance = np.median(distances_pep_1)\n",
    "\n",
    "            #temporary list\n",
    "            contact_map_list = []\n",
    "\n",
    "            # contact is in a distance up to 150% of the intrapeptide_minimum_distance [TO IMPROVE!!!]\n",
    "            threshold_distance = (intrapeptide_minimum_distance * radius_multiplier)\n",
    "\n",
    "            for model_1 in range(distance_maps_array.shape[0]):\n",
    "                contact_map_list.append([])\n",
    "                for model_2 in range(distance_maps_array[model_1].shape[0]):\n",
    "\n",
    "                    contact_map_list[model_1].append([])\n",
    "\n",
    "                    if model_1 == model_2:\n",
    "\n",
    "                        contact_map_list[model_1][model_2].extend(np.zeros((distance_maps_array.shape[2], distance_maps_array.shape[3])))\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        contact_map = np.zeros((distance_maps_array.shape[2], distance_maps_array.shape[3]))\n",
    "\n",
    "                        for chain_1 in range(distance_maps_array[model_1][model_2].shape[0]):\n",
    "\n",
    "                            for chain_2 in range(distance_maps_array[model_1][model_2][chain_1].shape[0]):\n",
    "\n",
    "                                distance = distance_maps_array[model_1][model_2][chain_1][chain_2]\n",
    "\n",
    "                                if distance < threshold_distance:\n",
    "                                    contact_map[chain_1][chain_2] = 1 #True\n",
    "                                else:\n",
    "                                    pass\n",
    "\n",
    "                        contact_map_list[model_1][model_2].extend(contact_map)\n",
    "\n",
    "            contact_array = np.asarray(contact_map_list)\n",
    "\n",
    "            return contact_array\n",
    "        \n",
    "        \n",
    "        \n",
    "        # get average distance map from distance maps set\n",
    "        # THIS SHOULD BE FUNCTION OF AN OBJECT. YOU WILL NEED A MAP FOR EACH PEPTIDE SIZE OF THE SIMULATION\n",
    "        # AND PEPTIDE COMPOSITION? HOW WILL YOU ACCOUNT FOR PEPTIDE OF SAME SIZE BUT MADE OF DIFFE???\n",
    "        def get_mean_distance_map(distance_maps):\n",
    "            '''\n",
    "            Calculate mean distance map from distance maps set\n",
    "\n",
    "            Argument: distance maps set\n",
    "\n",
    "            return: np.array with average intrapeptide distance\n",
    "\n",
    "            '''\n",
    "\n",
    "            # create array of zeros of shape number_of_residues * number_of_residues\n",
    "            # depending on peptide residue number ### TO FIX FOR MULTIMONOMERIC ASSEMBLY\n",
    "            base = np.zeros((distance_maps[0][0].shape[0], distance_maps[0][0].shape[1]))\n",
    "\n",
    "            # initialize counter\n",
    "            counter = 0\n",
    "\n",
    "            # iterate throught peptides in the aggregate\n",
    "            for peptide_1 in range(distance_maps.shape[0]):\n",
    "                for peptide_2 in range(distance_maps.shape[1]):\n",
    "\n",
    "                    # if peptide index are the same (intrapeptide distance map)\n",
    "                    if peptide_1 == peptide_2:\n",
    "\n",
    "                        # intrapeptide distance map\n",
    "                        actual_distance_map = distance_maps[peptide_1][peptide_2]\n",
    "\n",
    "                        # sum base and current distance map\n",
    "                        base = base + actual_distance_map\n",
    "\n",
    "                        #update counter\n",
    "                        counter += 1\n",
    "\n",
    "            #for element in base (every element is the sum of distance_map(i,j) for every distance map)\n",
    "            for row in range(len(base)):\n",
    "                for col in range(len(base)):\n",
    "\n",
    "                    # find the mean for every element of the cumulative distance map\n",
    "                    base[row][col] = (base[row][col])/counter\n",
    "\n",
    "            return base\n",
    "\n",
    "        # Singolar Value Decomposition of distance_map\n",
    "        def decompose_distance_map(distance_map):\n",
    "            '''Use Singular value decomposition to get\n",
    "\n",
    "            distance_map.shape[1] dimensional coordinate\n",
    "            (same n of dimension as the peptide n of residue)\n",
    "\n",
    "            As described in:\n",
    "            Mathematical Modeling of Protein Structure Using Distance Geometry\n",
    "            Jeong-Mi Yoon, Yash Gad, Zhijun Wu\n",
    "\n",
    "            Argument: distance map (numpy.array 2D)\n",
    "            return: X : actual decomposition\n",
    "\n",
    "\n",
    "            '''\n",
    "\n",
    "            # initialize a zeros matrix of same shape as the input map\n",
    "            D = np.zeros(distance_map.shape)\n",
    "\n",
    "            #iterate trought row\n",
    "            for i in range(distance_map.shape[0]):\n",
    "\n",
    "                # iterate trought cols\n",
    "                for j in range(distance_map.shape[1]):\n",
    "\n",
    "                    # distance between point point i and point j \n",
    "                    dij = distance_map[i][j]\n",
    "\n",
    "                    # distance between point 0 and point j\n",
    "                    d0j = distance_map[0][j]\n",
    "\n",
    "                    #distance between point i and point 0\n",
    "                    di0 = distance_map[i][0]\n",
    "\n",
    "                    #fill the zeros matrix with the value obtained with this formula\n",
    "                    D[i][j] = (d0j**2 + di0**2 - dij**2)/2\n",
    "\n",
    "            # check rank of matrix (should be of rank 3, but it is of rank distance_map.shape[1])\n",
    "            #rank = np.linalg.matrix_rank(D)\n",
    "\n",
    "            # Singular value decomposition on the D matrix\n",
    "            #svd = np.linalg.svd(D)\n",
    "\n",
    "            svd = np.linalg.svd(D, full_matrices=False)\n",
    "\n",
    "            # Calculate distance_map.shape[1] dimensional coordinate, but you need 3\n",
    "            # the non necessary dimension can give data to better reconstruct the peptide structure\n",
    "            X = svd[0]*np.sqrt(svd[1])\n",
    "\n",
    "\n",
    "            #return X, svd, D, rank\n",
    "            return X\n",
    "\n",
    "        def get_coordinate_from_decomposition(decomposition):\n",
    "            '''Take decomposition result and convert it into a coordinate vectors dict\n",
    "\n",
    "            Argument: decomposition results\n",
    "\n",
    "            return: dict with reconstructed 3d coordinate vector\n",
    "\n",
    "            '''\n",
    "\n",
    "            # take only the first three value to compose a 3D coordinate vector\n",
    "            coordinate = [e[:3] for e in decomposition]\n",
    "\n",
    "            # initialize empty dict\n",
    "            reconstructed_coordinate_dict = {}\n",
    "\n",
    "            # fill the dict with the ccordinate vectors\n",
    "            for index,coordinate_vector in enumerate(coordinate):\n",
    "                reconstructed_coordinate_dict[index] = coordinate_vector\n",
    "\n",
    "            return reconstructed_coordinate_dict\n",
    "\n",
    "\n",
    "        # reconstruct 3d coordinate from a distance map\n",
    "        def get_coordinate_from_distance_map(distance_map):\n",
    "            ''' compute 3d coordinate from distance map\n",
    "\n",
    "            Argument: distance_map (numpy.array)\n",
    "\n",
    "            return: dict with 3d coordinate for every alpha-carbon of a peptide\n",
    "\n",
    "            '''\n",
    "            # perform singular value decomposition on distance_map (preprocessed)\n",
    "            decomposed_mean_distance_map = decompose_distance_map(distance_map)\n",
    "\n",
    "\n",
    "            # get 3D coordinate\n",
    "            reconstructed_coordinate_dict = get_coordinate_from_decomposition(decomposed_mean_distance_map)\n",
    "\n",
    "            return reconstructed_coordinate_dict\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    class distance_tensor():\n",
    "        \n",
    "        # instantiate 3d tensor with shape n_peptides * n_residues * n_dimension\n",
    "        def get_coordinate_tensor_from_dict(coordinate_dict):\n",
    "    \n",
    "            #variables wit dict dimension\n",
    "            dim0 = len(coordinate_dict)\n",
    "            dim1 = len(coordinate_dict[0])\n",
    "            dim2 = len(coordinate_dict[0][0])\n",
    "\n",
    "            #initialize a 0s tensor\n",
    "            if torch.cuda.is_available() == True:\n",
    "                \n",
    "                zero = torch.zeros([dim0,dim1,dim2], dtype=torch.float32, device='cuda')\n",
    "\n",
    "            else:\n",
    "                zero = torch.zeros([dim0,dim1,dim2], dtype=torch.float32)\n",
    "\n",
    "\n",
    "            for peptide in coordinate_dict:\n",
    "\n",
    "                for aminoacid in coordinate_dict[peptide]:\n",
    "                    \n",
    "                    \n",
    "                    if torch.cuda.is_available() == True:\n",
    "                        # create torch tensor on cuda device with cordinate [x,y,z...]\n",
    "                        zero[peptide][aminoacid] = torch.cuda.FloatTensor(coordinate_dict[peptide][aminoacid])\n",
    "\n",
    "                    else:\n",
    "                        zero[peptide][aminoacid] = torch.FloatTensor(coordinate_dict[peptide][aminoacid])\n",
    "\n",
    "                        \n",
    "                        \n",
    "            return zero\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        #compute euclidean norm, fast\n",
    "        def compute_euclidean_norm_torch(coordinate_tensor):\n",
    "            '''Use matrix to compute euclidean distance dataset wise\n",
    "                and return a set of distance matrix for everi couple of peptides\n",
    "\n",
    "            ****Runs in parallel on CUDA devices.\n",
    "\n",
    "            Argument: tensor of shape n_peptide * n_residue * number of dimension (3 for 3d)\n",
    "\n",
    "            return: tensor of shape n_peptide * n_peptide * n_residue * n_peptide\n",
    "\n",
    "            '''\n",
    "\n",
    "            #create tensor of 0s with shape n_pep x n_pep * n_res + n_res\n",
    "            if torch.cuda.is_available() == True:\n",
    "                zero = torch.zeros((coordinate_tensor.shape[0], coordinate_tensor.shape[0], coordinate_tensor.shape[1], coordinate_tensor.shape[1]), dtype=torch.float32, device='cuda')\n",
    "            else:\n",
    "                zero = torch.zeros((coordinate_tensor.shape[0], coordinate_tensor.shape[0], coordinate_tensor.shape[1], coordinate_tensor.shape[1]), dtype=torch.float32)\n",
    "            \n",
    "            #cicle on peptide\n",
    "            for index1, peptide1 in tqdm.tqdm(enumerate(coordinate_tensor)):\n",
    "\n",
    "                #cicle on peptide (upper triangle + diagonal)\n",
    "                for index2 in range(index1, coordinate_tensor.shape[0]):\n",
    "                #for index2 in range(coordinate_tens.shape[0]):\n",
    "\n",
    "                    #coordinate vector\n",
    "                    peptide2 = coordinate_tensor[index2]\n",
    "\n",
    "                    x_norm = torch.pow(peptide1, 2).sum(1).view(-1,1)\n",
    "                    y_t = torch.transpose(peptide2, 0, 1)\n",
    "                    y_norm = torch.pow(peptide2, 2).sum(1).view(1,-1)\n",
    "\n",
    "                    dist = torch.sqrt(x_norm + y_norm - 2.0 * torch.mm(peptide1, y_t))\n",
    "\n",
    "                    #dist = x_norm + y_norm - 2.0 * torch.mm(peptide1, y_t)\n",
    "                    #fine = torch.clamp(dist, 0.0, np.inf) #should be there, but is not working somehow\n",
    "\n",
    "                    # add distance map in the right position of the 0s tensor\n",
    "                    zero[index1][index2] = dist\n",
    "\n",
    "                    # if mesuring between different peptides\n",
    "                    if index1 != index2:\n",
    "                        # put transpose of distance map in lower triangle\n",
    "                        zero[index2][index1] = dist.transpose(1,0)\n",
    "\n",
    "            #convert nan to 0  (using this instead of torch.clamp())       \n",
    "            zero[torch.isnan(zero)] = 0\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                # move to system memory and cast to numpy array\n",
    "                zero = zero.cpu().numpy()\n",
    "    \n",
    "            return zero\n",
    "    \n",
    "        #https://discuss.pytorch.org/t/efficient-distance-matrix-computation/9065\n",
    "        #https://www.dropbox.com/h?preview=Parallel+Euclidean+distance+matrix+computation+on+big+datasets.pdf      \n",
    "        \n",
    "        \n",
    "        \n",
    "        def distance_matrix_from_2d_tensor(peptide1_tensor, peptide2_tensor):\n",
    "            '''Minimal function to calculate euclidean distance between two set of points\n",
    "            using quadratic expansion. Thanks to:\n",
    "            https://discuss.pytorch.org/t/efficient-distance-matrix-computation/9065\n",
    "            \n",
    "            Input: 2d tensor of shape (n,3), 2d tensor of shape (m,3)\n",
    "            \n",
    "            Output: 2d tensor of shape (n,m)\n",
    "                    \n",
    "             '''\n",
    "\n",
    "            # calculate distance\n",
    "            x_norm = torch.pow(peptide1_tensor, 2).sum(1).view(-1,1)\n",
    "            y_t = torch.transpose(peptide2_tensor, 0, 1)\n",
    "            y_norm = torch.pow(peptide2_tensor, 2).sum(1).view(1,-1)\n",
    "\n",
    "            distance_map = torch.sqrt(x_norm + y_norm - 2.0 * torch.mm(peptide1_tensor, y_t))\n",
    "\n",
    "            # put transpose of distance map in lower triangle   \n",
    "            #convert nan to 0  (using this instead of torch.clamp())       \n",
    "            distance_map[torch.isnan(distance_map)] = 0\n",
    "\n",
    "            return distance_map\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    class cross_correlation():\n",
    "        \n",
    "        #### ANALYSIS\n",
    "\n",
    "        def shift_library_maker(contact_map_to_analyze):\n",
    "\n",
    "            ''' riceve numero di righe e di colonne\n",
    "            restituisce un array shape((((row + col)*2)-2),row,col).\n",
    "            ogni slice è una diagonale. Lo stack copre le diagonali su tutta la matrice'''\n",
    "\n",
    "            row = contact_map_to_analyze.shape[0]\n",
    "            col = contact_map_to_analyze.shape[1]\n",
    "\n",
    "            kron_dict = {}\n",
    "            kron_list_parallel = []\n",
    "            kron_list_antiparallel = []\n",
    "\n",
    "            for e in range(-row+1, col):\n",
    "                array = np.eye(row, col, e)\n",
    "                kron_list_parallel.append(array)\n",
    "                kron_list_antiparallel.append(np.fliplr(array))\n",
    "\n",
    "            kron_array_parallel = np.asarray(kron_list_parallel)\n",
    "            kron_array_antiparallel = np.asarray(kron_list_antiparallel)\n",
    "\n",
    "            kron_dict['parallel'] = kron_array_parallel\n",
    "            kron_dict['antiparallel'] = kron_array_antiparallel\n",
    "\n",
    "            return kron_dict\n",
    "\n",
    "\n",
    "        def normalized_cross_correlation_function(contact_map, minimum_contact=2):\n",
    "            '''\n",
    "            Calculate normalized cross correlation function between a contact map and an ideal map.\n",
    "\n",
    "            Arguments : contact map, as output from get_contact_maps function\n",
    "                        shift_matrix_stack, as output from shift_matrix_maker function\n",
    "\n",
    "            Return : a list [ncc_value, index (in the shift_matrix_stack) of the shift matrix\n",
    "                        that is matching the contact map\n",
    "\n",
    "                    '''\n",
    "            shift_matrix_library = morphoscanner.cross_correlation.shift_library_maker(contact_map)\n",
    "\n",
    "            cross_correlation_values = []\n",
    "            max_val = []\n",
    "            sum_contact_map = np.sum(contact_map)\n",
    "\n",
    "            if sum_contact_map < minimum_contact:\n",
    "                pass\n",
    "\n",
    "            else:\n",
    "                for sense in shift_matrix_library:\n",
    "                    for index, z in enumerate(shift_matrix_library[sense]):\n",
    "\n",
    "                        shift_matrix = shift_matrix_library[sense][index]\n",
    "                        sum_shift_matrix = np.sum(shift_matrix)\n",
    "                        ncc_value = (np.sum((contact_map * shift_matrix))/((np.sqrt(sum_contact_map))*(np.sqrt(sum_shift_matrix))))  # normalized cross correlation function of contact matrix and shift matrix\n",
    "                        cross_correlation_values.append([ncc_value, index, sum_contact_map, sense])\n",
    "\n",
    "                    max_val = max(cross_correlation_values) # get only the best match (highest value of ncc)\n",
    "\n",
    "            return max_val\n",
    "\n",
    "\n",
    "\n",
    "        def normalized_cross_correlation_for_dataset(contact_array):\n",
    "            '''Calculate normalized cross correlation function between the full contacts map and\n",
    "            the shift matrix.\n",
    "\n",
    "            Arguments : contact map, as output from get_contact_maps function\n",
    "                        shift_matrix_stack, as output from shift_matrix_maker function\n",
    "\n",
    "            Return : a list [ncc_value, index (in the shift_matrix_stack) of the shift matrix that is matching the contact map'''\n",
    "\n",
    "            contact_dict = {}\n",
    "\n",
    "            #for row in tqdm.tqdm(range(contact_array.shape[0])):\n",
    "            for row in range(contact_array.shape[0]):\n",
    "\n",
    "                for col in range((row+1), contact_array.shape[1]):\n",
    "                #for col in range(contact_array.shape[1]):\n",
    "\n",
    "                    best_match = []\n",
    "                    best_match = morphoscanner.cross_correlation.normalized_cross_correlation_function(contact_array[row][col])\n",
    "\n",
    "                    if len(best_match) == 0:\n",
    "                        pass\n",
    "\n",
    "                    else:\n",
    "                        if row in contact_dict:\n",
    "                            contact_dict[row].append([row, col, best_match])\n",
    "\n",
    "                        else:\n",
    "                            contact_dict[row] = [[row, col, best_match]]\n",
    "\n",
    "            return contact_dict\n",
    "        \n",
    "        \n",
    "        \n",
    "        #contact_array = frame_contact\n",
    "        def cross_correlation_function_for_dataset_with_dataframe(contact_array):\n",
    "            '''Perform Normalized Cross Correlation function on the dataset\n",
    "                to check for contact. Get a dict for processing and a pandas.DataFrame\n",
    "                for data analysis\n",
    "\n",
    "                Input: contact maps\n",
    "\n",
    "                Output: contact_dict,         for further processing\n",
    "                        pandas.DataFrame,     for data analysis\n",
    "\n",
    "\n",
    "            '''\n",
    "            contact_dict = {}\n",
    "\n",
    "            for row in range(contact_array.shape[0]):\n",
    "\n",
    "                for col in range((row+1), contact_array.shape[1]):\n",
    "                    best_match = []\n",
    "                    best_match = morphoscanner.cross_correlation.normalized_cross_correlation_function(contact_array[row][col])\n",
    "\n",
    "                    if len(best_match) == 0:\n",
    "                        pass\n",
    "\n",
    "                    else:\n",
    "                        if row in contact_dict:\n",
    "                            contact_dict[row].append([row, col, best_match])\n",
    "\n",
    "                        else:\n",
    "                            contact_dict[row] = [[row, col, best_match]]\n",
    "\n",
    "            contact_list = morphoscanner.utility.contact_list_from_dict(contact_dict)\n",
    "\n",
    "            columns_names = ['peptide1', 'peptide2', 'NCC Value', 'shift index', 'contacts', 'sense']\n",
    "\n",
    "            df = pd.DataFrame(contact_list, columns=columns_names)\n",
    "\n",
    "            return contact_dict, df\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    class denoise():\n",
    "        \n",
    "        \n",
    "        #denoise dataset. GET SENSE 'PARALLEL' OR 'ANTIPARALLEL'....'NEED TO KNOW AMINOACID OF PEPTIDES'\n",
    "        def denoise_contact_maps(contact_maps):\n",
    "            \n",
    "            '''Denoise the contact_maps dataset using the shift_matrix\n",
    "            \n",
    "            Arguments : contact_maps, normalized_cross_correlation_result\n",
    "            \n",
    "            return : a dict with key:value = row : row, col, denoised_map\n",
    "            \n",
    "            '''\n",
    "        \n",
    "            normalized_cross_correlation_results, df = morphoscanner.cross_correlation.cross_correlation_function_for_dataset_with_dataframe(contact_maps)\n",
    "        \n",
    "        \n",
    "            denoised_dict = {}\n",
    "        \n",
    "            for peptide_1 in normalized_cross_correlation_results:\n",
    "                denoised_dict[peptide_1] = {}\n",
    "                for index, peptide_2 in enumerate(normalized_cross_correlation_results[peptide_1]):\n",
    "        \n",
    "                    row = peptide_2[0]\n",
    "                    col = peptide_2[1]\n",
    "        \n",
    "        \n",
    "        \n",
    "                    contact_map = contact_maps[row][col]\n",
    "                    sense = peptide_2[2][3]\n",
    "                    shift_matrix_index = normalized_cross_correlation_results[peptide_1][index][2][1]\n",
    "        \n",
    "                    shift_matrix = morphoscanner.cross_correlation.shift_library_maker(contact_map)\n",
    "                    shift_matrix = shift_matrix[sense][shift_matrix_index]\n",
    "                    denoised_map = contact_map * shift_matrix\n",
    "        \n",
    "                    denoised_dict[row][col] = denoised_map\n",
    "                    \n",
    "                    \n",
    "            full_denoised_dict = {}\n",
    "            for peptide_1 in tqdm.tqdm(denoised_dict):\n",
    "                for peptide_2 in denoised_dict[peptide_1]:\n",
    "                    contact_map = denoised_dict[peptide_1][peptide_2]\n",
    "        \n",
    "                    if peptide_1 in full_denoised_dict:\n",
    "                        full_denoised_dict[peptide_1][peptide_2] = contact_map\n",
    "        \n",
    "                    if peptide_1 not in full_denoised_dict:\n",
    "                        full_denoised_dict[peptide_1] = {peptide_2:contact_map}\n",
    "        \n",
    "                    if peptide_2 in full_denoised_dict:\n",
    "                        full_denoised_dict[peptide_2][peptide_1] = contact_map.T\n",
    "        \n",
    "                    if peptide_2 not in full_denoised_dict:\n",
    "                        full_denoised_dict[peptide_2] = {peptide_1:contact_map.T}\n",
    "            \n",
    "            return full_denoised_dict, df\n",
    "         \n",
    "        \n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    class graph():\n",
    "        \n",
    "        # graph clustering\n",
    "        def nx_graph_search(denoised_dict, minimum_contacts = 3):\n",
    "            \n",
    "            ''' Graph clustering of peptides in the aggregate.\n",
    "            \n",
    "            Input: denoised contact maps dict\n",
    "            \n",
    "            return: networkx.MultiGraph\n",
    "            \n",
    "            #######\n",
    "            \n",
    "            Search for group of minimum 3 peptides (beta_sheet),\n",
    "            joined at least with 'minimum_contacts'. default = 3\n",
    "            \n",
    "            '''\n",
    "            # Instantiate graph\n",
    "            graph = nx.MultiGraph()\n",
    "            \n",
    "            #iter on peptide\n",
    "            for peptide_1 in denoised_dict:\n",
    "                \n",
    "                #iter on peptide joined to peptide1\n",
    "                for peptide_2 in denoised_dict[peptide_1]:\n",
    "                    #retrieve contact_map of peptide1 and peptide2\n",
    "                    array_1 = denoised_dict[peptide_1][peptide_2]\n",
    "                    \n",
    "                    #iter on peptide joined to peptide2\n",
    "                    for peptide_3 in denoised_dict[peptide_2]:\n",
    "                        if peptide_3 != peptide_1:\n",
    "                            #retrieve contact_map of peptide1 and peptide2\n",
    "                            array_2 = denoised_dict[peptide_2][peptide_3]\n",
    "                            \n",
    "                            # create row and column vector from contact maps\n",
    "                            vect_1 = morphoscanner.math_utility.get_row_vector(array_1)\n",
    "                            vect_2 = morphoscanner.math_utility.get_col_vector(array_2)\n",
    "                            \n",
    "                            #check for contact\n",
    "                            contacts = np.dot(vect_1, vect_2)\n",
    "                            \n",
    "                            #add edge only if there are enough contacts\n",
    "                            if contacts >= minimum_contacts:\n",
    "\n",
    "                                graph.add_edge(peptide_1, peptide_2)\n",
    "\n",
    "                                graph.add_edge(peptide_2, peptide_3)\n",
    "\n",
    "            return graph\n",
    "\n",
    "        #A novel graph clustering algorithm based on discrete-time quantum random walk\n",
    "        #S.G. Roya, A. Chakrabarti\n",
    "\n",
    "        # working with networkX\n",
    " \n",
    "        # when you add_edge, nodes are created if they are not there\n",
    "        # you can put info in edge (as distance, n of contacts, contact map)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        # create a full graph\n",
    "        def full_graph(denoised_dict):\n",
    "            ''' Create a full graph of all the peptides in the frame.\n",
    "\n",
    "            Every peptide is a node in the graph.\n",
    "            Edges join contacting peptides.\n",
    "            Edges have attribute 'length' that gives you the number of contact between the peptides\n",
    "\n",
    "            Useful for peptides behaviour analysis during molecular dynamics\n",
    "\n",
    "            Arguments: denoised contact maps dict\n",
    "            return: networkx.MultiGraph\n",
    "\n",
    "            '''\n",
    "            graph = nx.MultiGraph()\n",
    "\n",
    "            for peptide_1 in denoised_dict:\n",
    "                for peptide_2 in denoised_dict[peptide_1]:\n",
    "\n",
    "                    array_1 = denoised_dict[peptide_1][peptide_2]\n",
    "\n",
    "                    graph.add_node(peptide_1)\n",
    "                    graph.add_node(peptide_2)\n",
    "\n",
    "                    number_of_contacts = array_1.sum()\n",
    "\n",
    "                    if number_of_contacts >= 1:\n",
    "\n",
    "                        graph.add_edge(peptide_1, peptide_2, length = number_of_contacts)\n",
    "\n",
    "            return graph\n",
    "        \n",
    "        \n",
    "        \n",
    "        ## THIS IS WORKING in object trajectory\n",
    "\n",
    "        def graph_v1(denoised_dict, df):\n",
    "\n",
    "            graph = nx.MultiGraph()\n",
    "\n",
    "            for group in df.index:\n",
    "\n",
    "                peptide_1 = df.iloc[group]['peptide1']\n",
    "                peptide_2 = df.iloc[group]['peptide2']\n",
    "\n",
    "                array_1 = denoised_dict[peptide_1][peptide_2]\n",
    "\n",
    "                graph.add_node(peptide_1)\n",
    "                graph.add_node(peptide_2)\n",
    "\n",
    "                number_of_contacts = array_1.sum()\n",
    "\n",
    "                if number_of_contacts >= 1:\n",
    "\n",
    "                    sense = df.iloc[group]['sense']\n",
    "\n",
    "                    graph.add_edge(peptide_1, peptide_2, length = number_of_contacts, sense=sense)\n",
    "\n",
    "            return graph\n",
    "        #return graph\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        #FIND SUBGRAPH\n",
    "        def find_subgraph_in_order(graph):\n",
    "            '''\n",
    "            Find subgraph of joined peptides that have no node in common,\n",
    "            starting from a node (peptide) with degree==1 (first or last node of the subgraph).\n",
    "            The node are in order from start to end of the beta-sheet.\n",
    "            \n",
    "            DOES NOT WORK IF EACH PEPTIDE IS TOUCHING MORE THAN ONE OTHER PEPTIDE\n",
    "            \n",
    "            so if adjacency > 1, or degree > 1 for each node in the graph, it does not work.\n",
    "            \n",
    "            Argument: NetworkX MultiGraph\n",
    "\n",
    "            Return: list of subgraph ordered from one end to the other\n",
    "\n",
    "            '''\n",
    "\n",
    "            subgraph_list = []\n",
    "\n",
    "            for node in graph:\n",
    "\n",
    "                # don't explore node that are already in subgraph_list\n",
    "                if node not in set(nod for nod_list in subgraph_list for nod in nod_list):\n",
    "\n",
    "                    # tree is the list of nodes joined to node, starting from node\n",
    "                    # using depht first search\n",
    "                    tree = [e for e in nx.algorithms.traversal.depth_first_search.dfs_tree(graph, node)]\n",
    "\n",
    "                    # check if the first node of the tree has adjiacency == 1\n",
    "                    # so it checks if it is the first or last node of the subgraph\n",
    "                    if len(graph[tree[0]]) == 1:\n",
    "\n",
    "                        if len(subgraph_list) == 0:\n",
    "                            subgraph_list.append(tree)\n",
    "\n",
    "                        else:\n",
    "                            # use generator to check if the tree is already in the subgraph\n",
    "                            if set(tree) not in (set(i) for i in subgraph_list):\n",
    "                                subgraph_list.append(tree)\n",
    "\n",
    "            return subgraph_list\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        def find_subgraph(graph):\n",
    "            '''\n",
    "            Find subgraph of joined peptides that have no node in common.\n",
    "            It start to search from always from peptide 0, and from that does depth first search.\n",
    "            The peptide of the subgraph that are touching are in consequential order in the sublist\n",
    "\n",
    "            Argument: NetworkX MultiGraph\n",
    "\n",
    "            Return: list of subgraph\n",
    "\n",
    "            '''\n",
    "\n",
    "            subgraph_list = []\n",
    "\n",
    "            for node in graph:\n",
    "\n",
    "                # don't explore node that are already in subgraph_list\n",
    "                if node not in set(nod for nod_list in subgraph_list for nod in nod_list):\n",
    "\n",
    "                    # tree is the list of nodes joined to node, starting from node\n",
    "                    # using depht first search\n",
    "                    tree = [e for e in nx.algorithms.traversal.depth_first_search.dfs_tree(graph, node)]\n",
    "\n",
    "                    # check if the first node of the tree has adjiacency == 1\n",
    "                    # so it checks if it is the first or last node of the subgraph\n",
    "                    #if len(graph[tree[0]]) == 1:\n",
    "\n",
    "                    if len(subgraph_list) == 0:\n",
    "                        subgraph_list.append(tree)\n",
    "\n",
    "                    else:\n",
    "                        # use generator to check if the tree is already in the subgraph\n",
    "                        if set(tree) not in (set(i) for i in subgraph_list):\n",
    "                            subgraph_list.append(tree)\n",
    "            \n",
    "            subgraph_list.sort(key=len, reverse=True)\n",
    "\n",
    "            return subgraph_list\n",
    "        \n",
    "      \n",
    "        \n",
    "        \n",
    "        \n",
    "        def get_not_in_subgraph(coordinate_dict, subgraph):\n",
    "            '''Get peptide alone or in cluster of 2 in a frame.\n",
    "            \n",
    "            Input: coordinate_dict, output of 'find_subgraph' function            \n",
    "            \n",
    "            Output: list\n",
    "            \n",
    "            #####\n",
    "            \n",
    "            Basically this function gives you all the node left out\n",
    "            from the 'find_subgraph' function. That are all the node\n",
    "            with 0 or 1 neighbour if you leave the 'minimum_contact' parameter\n",
    "            of the nx_graph_search funtion to the default value of 3.\n",
    "            \n",
    "            '''\n",
    "            # one line function # don't use clever shit my friend\n",
    "            #out = [e for e in coordinate_dict if e not in [a for i in subgraph for a in i]]\n",
    "\n",
    "            out = []\n",
    "            \n",
    "            # get a list with all the node in subgraph\n",
    "            subgraph = [a for i in subgraph for a in i]\n",
    "\n",
    "            # iter on all element and get the one that are not in subgraph\n",
    "            for e in coordinate_dict:\n",
    "\n",
    "                if e not in subgraph:\n",
    "\n",
    "                    out.append(e)\n",
    "\n",
    "            return out\n",
    "        \n",
    "        \n",
    "        \n",
    "        def subgraph_length(aggregate):\n",
    "            '''Get information about the size of the aggregates in the trajectory\n",
    "\n",
    "            Argument: aggregate\n",
    "\n",
    "            return: dict, keys = frame number,\n",
    "                          value = a sorted list (big to small) of the aggregate size in that frame\n",
    "\n",
    "\n",
    "            '''\n",
    "\n",
    "            subgraph_len_dict = {}\n",
    "\n",
    "            for key in aggregate.frames.keys():\n",
    "\n",
    "                subgraph_dict[key] = morphoscanner.graph.find_subgraph(aggregate.frames[key]['frame_graph_full'])\n",
    "\n",
    "                len_list = []\n",
    "\n",
    "                for i in subgraph_dict[key]:\n",
    "\n",
    "                    len_list.append(len(i))\n",
    "\n",
    "                len_list.sort(reverse=True)\n",
    "\n",
    "                subgraph_len_dict[key] = len_list\n",
    "\n",
    "                return subgraph_len_dict\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        def contact_sense_in_subgraph(graph, subgraph_list):\n",
    "            '''Get information about the orientation of the contact between contacting node in the graph.\n",
    "            \n",
    "            \"subgraph_list\" is similar to an \"n_bunch\" in NetworkX definition,\n",
    "            but works if the node in the n_bunch are joined by an edge.'''\n",
    "\n",
    "            subgraph_sense_dict = {}\n",
    "\n",
    "            for index, subgraph in enumerate(subgraph_list):\n",
    "\n",
    "                subgraph_sense_dict[index] = {}\n",
    "\n",
    "                sense_list = []\n",
    "\n",
    "                for i in graph.edges(subgraph):\n",
    "\n",
    "                    #print(i[0], i[1])\n",
    "                    sense = graph[i[0]][i[1]][0]['sense']\n",
    "                    sense_list.append(graph[i[0]][i[1]][0]['sense'])\n",
    "\n",
    "                    subgraph_sense_dict[index] = sense_list\n",
    "\n",
    "            return subgraph_sense_dict\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        def sense_in_subgraph(graph, subgraphs_list):\n",
    "            '''Get number of contact per sense in subgraph.\n",
    "            \n",
    "            Arguments: NetworkX.MultiGraph, as output from morphoscanner.graph.graph_v1.\n",
    "            \n",
    "            Output = dict, with number of parallels and antiparallels contact per aggregate'''                   \n",
    "        \n",
    "            subgraphs = morphoscanner.graph.contact_sense_in_subgraph(graph, subgraphs_list)\n",
    "\n",
    "            sense_counter_dict = {}\n",
    "\n",
    "            for index, subgraph in enumerate(subgraphs):\n",
    "\n",
    "                sense_counter_dict[index] = {}\n",
    "\n",
    "                parallel = 0\n",
    "                antiparallel = 0\n",
    "\n",
    "                for sense in subgraphs[index]:\n",
    "\n",
    "                    if sense == 'parallel':\n",
    "                        parallel += 1\n",
    "\n",
    "                    elif sense == 'antiparallel':\n",
    "                        antiparallel += 1\n",
    "\n",
    "                sense_counter_dict[index] = { 'parallel' : parallel,\n",
    "                                               'antiparallel' : antiparallel}\n",
    "                \n",
    "                \n",
    "\n",
    "            return sense_counter_dict\n",
    "\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "  \n",
    "        \n",
    "        \n",
    "        \n",
    "    class plot():\n",
    "        \n",
    "        \n",
    "        ########## PLOT PEPTIDE LIST\n",
    "        # plot a list of peptide point cloud in 3d space.\n",
    "        # The box axis have arbitrary scale dependent on the aminoacids distance\n",
    "        # you can select to show the centroid\n",
    "        def plot_peptide_list(coordinate_dict, peptide_list, centroid=False):\n",
    "            \n",
    "            \n",
    "            if len(peptide_list) == 1:\n",
    "                \n",
    "                return morphoscanner.plot.plot_single_peptide(coordinate_dict[peptide_list[0]])\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                x = []\n",
    "                y = []\n",
    "                z = []\n",
    "                x_median = float\n",
    "                y_median = float\n",
    "                z_median = float\n",
    "\n",
    "\n",
    "                for peptide in range(len(peptide_list)):\n",
    "                    x.append([peptide])\n",
    "                    y.append([peptide])\n",
    "                    z.append([peptide])\n",
    "                    for aminoacid in coordinate_dict[peptide_list[peptide]]:\n",
    "\n",
    "                        point = coordinate_dict[peptide_list[peptide]][aminoacid]\n",
    "                        x[peptide].append(point[0])\n",
    "                        y[peptide].append(point[1])\n",
    "                        z[peptide].append(point[2])\n",
    "\n",
    "                    del x[peptide][0]\n",
    "                    del y[peptide][0]\n",
    "                    del z[peptide][0]\n",
    "\n",
    "                if centroid == True:\n",
    "\n",
    "                    def assemble_coordinate(axis_coordinate_list):\n",
    "                        median_list = []\n",
    "                        for coordinate_set in axis_coordinate_list:\n",
    "                            median = np.median(coordinate_set)\n",
    "                            median_list.append(median)\n",
    "                        return median_list\n",
    "\n",
    "                    x_median = assemble_coordinate(x)\n",
    "                    y_median = assemble_coordinate(y)\n",
    "                    z_median = assemble_coordinate(z)\n",
    "\n",
    "\n",
    "                #%matplotlib notebook\n",
    "\n",
    "                fig = plt.figure()\n",
    "\n",
    "                ax = plt.axes(projection='3d')\n",
    "\n",
    "\n",
    "                for pep in range(len(x)):\n",
    "\n",
    "                    ax.scatter3D(x[pep],y[pep],z[pep])\n",
    "\n",
    "                    if centroid == True:\n",
    "\n",
    "                        ax.scatter3D(x_median[pep], y_median[pep], z_median[pep], c='red')\n",
    "\n",
    "\n",
    "                #return  plt.show(), [x,y,z], [x_median, y_median, z_median]         \n",
    "            return plt.show()\n",
    "        \n",
    "        \n",
    "        \n",
    "        #plot from tensor\n",
    "        def plot_peptide_from_tensor(coordinate_dict, peptide_list, centroid=False):\n",
    "\n",
    "            x = []\n",
    "            y = []\n",
    "            z = []\n",
    "            x_median = float\n",
    "            y_median = float\n",
    "            z_median = float\n",
    "\n",
    "\n",
    "            for peptide in range(len(peptide_list)):\n",
    "                x.append([peptide])\n",
    "                y.append([peptide])\n",
    "                z.append([peptide])\n",
    "                for index, aminoacid in enumerate(coordinate_dict[peptide_list[peptide]]):\n",
    "\n",
    "                    point = coordinate_dict[peptide_list[peptide]][index]\n",
    "                    x[peptide].append(point[0])\n",
    "                    y[peptide].append(point[1])\n",
    "                    z[peptide].append(point[2])\n",
    "\n",
    "                del x[peptide][0]\n",
    "                del y[peptide][0]\n",
    "                del z[peptide][0]\n",
    "\n",
    "            x = torch.FloatTensor(x)\n",
    "            y = torch.FloatTensor(y)\n",
    "            z = torch.FloatTensor(z)\n",
    "\n",
    "            if centroid == True:\n",
    "\n",
    "                def assemble_coordinate(axis_coordinate_list):\n",
    "                    median_list = []\n",
    "                    for coordinate_set in axis_coordinate_list:\n",
    "                        median = torch.median(torch.FloatTensor(coordinate_set))\n",
    "                        print(median)\n",
    "                        median_list.append(median)\n",
    "                    return median_list\n",
    "\n",
    "                x_median = assemble_coordinate(x)\n",
    "                y_median = assemble_coordinate(y)\n",
    "                z_median = assemble_coordinate(z)\n",
    "\n",
    "            #%matplotlib notebook\n",
    "\n",
    "            fig = plt.figure()\n",
    "\n",
    "            ax = plt.axes(projection='3d')\n",
    "\n",
    "\n",
    "            for pep in range(len(x)):\n",
    "\n",
    "                # scatter points, making list from torch tensor item\n",
    "                ax.scatter3D([e.item() for e in x[pep]],[e.item() for e in y[pep]],[e.item() for e in z[pep]])\n",
    "\n",
    "                if centroid == True:\n",
    "\n",
    "                    ax.scatter3D(x_median[pep].item(), y_median[pep].item(), z_median[pep].item(), c='red')\n",
    "\n",
    "\n",
    "            #return  plt.show(), [x,y,z], [x_median, y_median, z_median]         \n",
    "            return plt.show()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # plot single peptide (with autoscaling of axes)\n",
    "        def plot_single_peptide(peptide_coordinate_dict, centroid=False):\n",
    "            x = []\n",
    "            y = []\n",
    "            z = []\n",
    "\n",
    "            for residue in peptide_coordinate_dict:\n",
    "                point = peptide_coordinate_dict[residue]\n",
    "                x.append(point[0])\n",
    "                y.append(point[1])\n",
    "                z.append(point[2])\n",
    "\n",
    "\n",
    "            x = np.asarray(x)\n",
    "            y = np.asarray(y)\n",
    "            z = np.asarray(z)\n",
    "\n",
    "            fig = plt.figure()\n",
    "            ax = plt.axes(projection='3d')\n",
    "            ax.scatter3D(x,y,z, c='b')\n",
    "\n",
    "\n",
    "            if centroid == True:\n",
    "                median_centroid = [np.median(x), np.median(y), np.median(z)]\n",
    "                ax.scatter3D(median_centroid[0], median_centroid[1], median_centroid[2], c='r')\n",
    "\n",
    "            # Create cubic bounding box to simulate equal aspect ratio\n",
    "            max_range = np.array([x.max()-x.min(), y.max()-y.min(), z.max()-z.min()]).max()\n",
    "            Xb = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][0].flatten() + 0.5*(x.max()+x.min())\n",
    "            Yb = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][1].flatten() + 0.5*(y.max()+y.min())\n",
    "            Zb = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][2].flatten() + 0.5*(z.max()+z.min())\n",
    "            # Comment or uncomment following both lines to test the fake bounding box:\n",
    "            for xb, yb, zb in zip(Xb, Yb, Zb):\n",
    "                ax.plot([xb], [yb], [zb], 'w')\n",
    "\n",
    "            return plt.show()\n",
    "        \n",
    "    \n",
    "    # class for high level functionality, premade workflow...\n",
    "    class high_level():\n",
    "        \n",
    "        # automatically infer peptide lenght\n",
    "        def coordinate_dict_from_gro(gro_file):\n",
    "            \n",
    "            cleaned = morphoscanner.read.clean_gro(gro_file)\n",
    "            \n",
    "            coordinate = morphoscanner.read.get_coordinate_dict_from_cleaned_gro(cleaned)\n",
    "            \n",
    "            return coordinate\n",
    "        \n",
    "        \n",
    "        #specify peptide lenght\n",
    "        def coordinate_dict_from_gro_fix_len_peptide(gro_file, peptide_lenght):\n",
    "            \n",
    "            cleaned = morphoscanner.read.clean_gro(gro_file)\n",
    "            \n",
    "            coordinate = morphoscanner.read.get_coordinate_dict_from_cleaned_gro_for_fixed_lenght_peptides(cleaned, peptide_lenght)\n",
    "            \n",
    "            return coordinate\n",
    "        \n",
    "        \n",
    "        # compute distance maps, fast with torch.cuda\n",
    "        def compute_distance_maps_fast_from_gro(gro_file):\n",
    "            \n",
    "            coordinate_dict = morphoscanner.high_level.coordinate_dict_from_gro(gro_file)\n",
    "            \n",
    "            coordinate_tens = morphoscanner.distance_tensor.get_coordinate_tensor_from_dict(coordinate_dict)\n",
    "            \n",
    "            distance_maps = morphoscanner.distance_tensor.compute_euclidean_norm_torch(coordinate_tens)\n",
    "            \n",
    "            return distance_maps\n",
    "        \n",
    "        \n",
    "        # make full graph from distance maps\n",
    "        def graph_full_from_distance_maps(distance_maps):\n",
    "            \n",
    "            contact_maps = morphoscanner.distance.compute_contact_maps_as_array(distance_maps)\n",
    "            \n",
    "            denoised = morphoscanner.denoise.denoise_contact_maps(contact_maps)\n",
    "            \n",
    "            graph = morphoscanner.graph.full_graph(denoised)\n",
    "            \n",
    "            return graph\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    class trajectory:\n",
    "\n",
    "        '''Class to operate on trajectory files.\n",
    "\n",
    "        It makes an object that contain the trajectory of the simulation'''\n",
    "\n",
    "\n",
    "\n",
    "        def __init__(self, trj_gro, trj_xtc):\n",
    "\n",
    "            self.trj_gro = trj_gro\n",
    "            self.trj_xtc = trj_xtc\n",
    "            self.universe = morphoscanner.topology.make_universe(self.trj_gro, self.trj_xtc)\n",
    "            self.peptide_length_list = morphoscanner.topology.get_peptide_length_list(self.trj_gro)\n",
    "            #self.topology = morphoscanner.topology.get_peptide_length_list(self.trj_gro)\n",
    "            self.number_of_frames = len(self.universe.trajectory)\n",
    "\n",
    "            self.frames = {}\n",
    "\n",
    "\n",
    "\n",
    "        def compose_database(self, peptide_length=None, start_from=0, interval=0):\n",
    "\n",
    "            self.peptide_length = peptide_length\n",
    "            self.start_from = start_from\n",
    "            self.interval = interval\n",
    "\n",
    "            self.data = morphoscanner.topology.get_coordinate_dict_from_trajectory(self.trj_gro, self.trj_xtc, peptide_length=self.peptide_length, start_from=self.start_from, interval=self.interval)\n",
    "            self.sampled_frames = [key for key in self.data.keys()]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        def analysis(self, frame):\n",
    "\n",
    "            # WHY len(frame_denoised) is len(frame_dict)-1 ???????\n",
    "\n",
    "            self.frame = frame        \n",
    "\n",
    "            self.frame_dict = self.data[self.frame]\n",
    "\n",
    "            self.frame_tensor = morphoscanner.distance_tensor.get_coordinate_tensor_from_dict(self.frame_dict)\n",
    "\n",
    "            self.frame_distance_maps = morphoscanner.distance_tensor.compute_euclidean_norm_torch(self.frame_tensor)\n",
    "\n",
    "            self.frame_contact = morphoscanner.distance.compute_contact_maps_as_array(self.frame_distance_maps)\n",
    "\n",
    "            self.frame_denoised, self.df = morphoscanner.denoise.denoise_contact_maps(self.frame_contact)\n",
    "\n",
    "            self.frame_graph = morphoscanner.graph.nx_graph_search(self.frame_denoised)\n",
    "\n",
    "            self.frame_graph_full = morphoscanner.graph.graph_v1(self.frame_denoised, self.df)\n",
    "\n",
    "            self.subgraphs = morphoscanner.graph.find_subgraph(self.frame_graph_full)\n",
    "\n",
    "            if self.frame not in self.frames:\n",
    "\n",
    "                self.frames[self.frame] = {'frame_dict': self.frame_dict,\n",
    "                                           'frame_denoised': self.frame_denoised,\n",
    "                                              'frame_data' : self.df,\n",
    "                                              'frame_graph' : self.frame_graph,\n",
    "                                              'frame_graph_full' : self.frame_graph_full,\n",
    "                                              'subgraphs_full' : self.subgraphs}            \n",
    "\n",
    "\n",
    "        def analyze_inLoop(self):\n",
    "\n",
    "            if hasattr(self, 'sampled_frames'):\n",
    "                print('processing started...')\n",
    "                start = timer()\n",
    "                for frame in self.sampled_frames:\n",
    "                    start_an = timer()\n",
    "                    self.analysis(frame)\n",
    "                    end_an = timer()\n",
    "                    text= 'Time needed to analyze frame %d is %f seconds' % (frame, (end_an-start_an))\n",
    "                    print(text)\n",
    "\n",
    "                end = timer()\n",
    "\n",
    "\n",
    "                print('Total time to analyze dataset is %f seconds' % (end -start))\n",
    "\n",
    "            else:\n",
    "                print('You have to compose the database before analyze it.')\n",
    "\n",
    "                print('Use \"compose_database\" attribute to make a database first!')\n",
    "\n",
    "            return\n",
    "\n",
    "\n",
    "\n",
    "        def get_sense(self):\n",
    "\n",
    "\n",
    "            sense_dict = {}\n",
    "\n",
    "            for e in self.frames:\n",
    "\n",
    "                parallel = len(self.frames[e]['frame_data'].groupby('sense').get_group('parallel'))\n",
    "                antiparallel = len(self.frames[e]['frame_data'].groupby('sense').get_group('antiparallel'))\n",
    "\n",
    "                sense_dict[e] = {  'parallel' : parallel,\n",
    "                                   'antiparallel' : antiparallel}\n",
    "\n",
    "\n",
    "            self.sense_df = pd.DataFrame.from_dict(sense_dict, orient='index')\n",
    "\n",
    "\n",
    "            return\n",
    "\n",
    "\n",
    "\n",
    "        def subgraph_length_peptide(self):\n",
    "            '''Get information about the size of the aggregates in the trajectory\n",
    "\n",
    "            Argument: aggregate\n",
    "\n",
    "            return: dict, keys = frame number,\n",
    "                          value = a sorted list (big to small) of the aggregate size in that frame\n",
    "\n",
    "\n",
    "            '''\n",
    "\n",
    "            if len(self.frames) > 0:\n",
    "\n",
    "\n",
    "                self.subgraph_size_peptide = {}\n",
    "\n",
    "                for key in self.frames.keys():\n",
    "\n",
    "                    subgraph_dict = {}\n",
    "\n",
    "                    subgraph_dict[key] = morphoscanner.graph.find_subgraph(self.frames[key]['frame_graph_full'])\n",
    "\n",
    "                    len_list = []\n",
    "\n",
    "                    for i in subgraph_dict[key]:\n",
    "\n",
    "                        len_list.append(len(i))\n",
    "\n",
    "                    len_list.sort(reverse=True)\n",
    "\n",
    "                    self.subgraph_size_peptide[key] = [len_list]\n",
    "\n",
    "\n",
    "            self.subgraph_len_pep_df = pd.DataFrame.from_dict(self.subgraph_size_peptide, orient='index', columns=['n° of peptides in macroaggregates'])\n",
    "\n",
    "            #else:\n",
    "             #   print('You have to analyze one or more frame before analyze the results.')\n",
    "             #   print('Use \"Analyze\" or \"AnalyzeInLoop\" on the dataset first!')\n",
    "\n",
    "            return\n",
    "\n",
    "\n",
    "\n",
    "        def subgraph_length_seed(self):\n",
    "            '''Get information about the size of the aggregates in the trajectory\n",
    "\n",
    "            Argument: aggregate\n",
    "\n",
    "            return: dict, keys = frame number,\n",
    "                          value = a sorted list (big to small) of the aggregate size in that frame\n",
    "\n",
    "\n",
    "            '''\n",
    "            if len(self.frames) > 0:\n",
    "\n",
    "                self.subgraph_size_seed = {}\n",
    "\n",
    "                for key in self.frames.keys():\n",
    "\n",
    "                    subgraph_dict = {}\n",
    "\n",
    "                    subgraph_dict[key] = morphoscanner.graph.find_subgraph(self.frames[key]['frame_graph'])\n",
    "\n",
    "                    len_list = []\n",
    "\n",
    "                    for i in subgraph_dict[key]:\n",
    "\n",
    "                        len_list.append(len(i))\n",
    "\n",
    "                    len_list.sort(reverse=True)\n",
    "\n",
    "                    self.subgraph_size_seed[key] = [len_list]\n",
    "\n",
    "                #return self.seed_subgraph_len\n",
    "\n",
    "            #else:\n",
    "               # print('You have to analyze one or more frame before analyze the results.')\n",
    "                #print('Use \"Analyze\" or \"AnalyzeInLoop\" on the dataset first!'')\n",
    "\n",
    "            return\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        def macroaggregate_sense_data(self):\n",
    "\n",
    "            macroaggregate_sense_dict = {}\n",
    "\n",
    "            for frame in self.frames:\n",
    "                graph = self.frames[frame]['frame_graph_full']\n",
    "                subs = self.frames[frame]['subgraphs_full']\n",
    "                #senses = contact_sense_in_subgraph(graph, subs)\n",
    "                #sense_counter = count_sense_in_subgraph(senses)\n",
    "                sense_counter = morphoscanner.graph.sense_in_subgraph(graph, subs)\n",
    "                macroaggregate_sense_dict[frame] = sense_counter\n",
    "\n",
    "            self.macroaggregate_df = pd.DataFrame.from_dict(macroaggregate_sense_dict, orient='index')\n",
    "\n",
    "            return\n",
    "        \n",
    "        \n",
    "        \n",
    "        def number_of_macroaggregate_per_frame(self):\n",
    "            number_of_peptide = {}\n",
    "            for i in self.subgraph_size_peptide:\n",
    "                number_of_peptide[i] = len(self.subgraph_size_peptide[i][0])\n",
    "\n",
    "            self.number_of_peptide_df = pd.DataFrame.from_dict(number_of_peptide, orient='index', columns=['n° of macroaggreates'])\n",
    "\n",
    "            return\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        def get_data(self):\n",
    "            self.get_sense()\n",
    "            self.subgraph_length_peptide()\n",
    "            self.macroaggregate_sense_data()\n",
    "            self.number_of_macroaggregate_per_frame()\n",
    "            \n",
    "            return\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        def get_database(self):\n",
    "            \n",
    "            self.database = pd.concat((self.subgraph_len_pep_df, self.sense_df, self.number_of_peptide_df, self.macroaggregate_df), axis=1)\n",
    "\n",
    "            return\n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with class library\n",
    "cleaned = morphoscanner.read.clean_gro(trj_gro)\n",
    "coordinate_dict = morphoscanner.read.get_coordinate_dict_from_cleaned_gro(cleaned)\n",
    "trj0_coordinate = morphoscanner.read.get_coordinate_dict_from_cleaned_gro_for_fixed_lenght_peptides(cleaned, 12)\n",
    "#trj0_distance_maps = morphoscanner.distance.compute_distance_maps_from_coordinate_dict(trj0_coordinate)\n",
    "#trj0_contact_maps = morphoscanner.distance.compute_contact_maps_as_array(trj0_distance_maps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj0_denoised_dict = morphoscanner.denoise.denoise_contact_maps(trj0_contact_maps)\n",
    "trj0_graph = morphoscanner.graph.nx_graph_search(trj0_denoised_dict)\n",
    "trj0_subgraph = morphoscanner.graph.find_subgraph(trj0_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot_peptide_list(trj0_coordinate, [e for e in trj0_coordinate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute distance maps and return a n_peptide x n_peptide x n_res x n_res array ## from .gro coordinate dict\n",
    "start = timer()\n",
    "distance_maps_seed_1 = compute_distance_maps_from_coordinate_dict(coordinate_dict_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "# compute contact maps from distance maps\n",
    "start = timer()\n",
    "contact_maps_seed_1 = compute_contact_maps_as_array(distance_maps_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "# compute cross correlation and get values\n",
    "start = timer()\n",
    "normalized_cross_correlation_results_seed_1 = normalized_cross_correlation_for_dataset(contact_maps_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "# denoise dataset\n",
    "start = timer()\n",
    "denoised_dict_seed_1 = denoise_full_dataset(contact_maps_seed_1, normalized_cross_correlation_results_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "# recreate full contact map dataset mirroring the upper triangle\n",
    "# return dict\n",
    "start = timer()\n",
    "full_denoised_dict_seed_1 = reconstruct_full_matrix(denoised_dict_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "#create graph\n",
    "start = timer()\n",
    "graph_seed_1 = nx_graph_search(full_denoised_dict_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "#search subgraph\n",
    "start = timer()\n",
    "subgrap_list_seed_1 = find_subgraph(graph_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "#find mean distance map\n",
    "start = timer()\n",
    "mean_distance_map_seed_1 = get_mean_distance_map(distance_maps_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "# decompose mean distance matrix\n",
    "start = timer()\n",
    "decomposed_mean_distance_map = decompose_distance_map(mean_distance_map_seed_1)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "      \n",
    "# get coordinate from distance map      \n",
    "start = timer()\n",
    "reconstructed_coordinate_dict = get_coordinate_from_decomposition(decomposed_mean_distance_map)\n",
    "end = timer()\n",
    "print(end-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj0_mean_distance = morphoscanner.distance.get_mean_distance_map(trj0_distance_maps)\n",
    "\n",
    "plt.imshow(trj0_mean_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#workflow with object trajectory\n",
    "\n",
    "prodio = morphoscanner.trajectory(prod_gro, prod_xtc)\n",
    "prodio.compose_database(peptide_length=18, interval=2000)\n",
    "prodio.analyze_inLoop()\n",
    "prodio.get_data()\n",
    "prodio.get_database()\n",
    "prodio.database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with class library\n",
    "\n",
    "cleaned = morphoscanner.read.clean_gro(trj_gro)\n",
    "coordinate_dict = morphoscanner.read.get_coordinate_dict_from_cleaned_gro(cleaned)\n",
    "trj0_coordinate = morphoscanner.read.get_coordinate_dict_from_cleaned_gro_for_fixed_lenght_peptides(cleaned, 12)\n",
    "trj0_distance_maps = morphoscanner.distance.compute_distance_maps_from_coordinate_dict(trj0_coordinate)\n",
    "trj0_contact_maps = morphoscanner.distance.compute_contact_maps_as_array(trj0_distance_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = morphoscanner.read.clean_gro(trj_gro)\n",
    "coordinate_dict = morphoscanner.read.get_coordinate_dict_from_cleaned_gro(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinate_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with class library\n",
    "cleaned = morphoscanner.read.clean_gro(path)\n",
    "coordinate_dict = morphoscanner.read.get_coordinate_dict_from_cleaned_gro(cleaned)\n",
    "trj0_coordinate = morphoscanner.read.get_coordinate_dict_from_cleaned_gro_for_fixed_lenght_peptides(cleaned, 12)\n",
    "\n",
    "start = timer()\n",
    "trj0_distance_maps = morphoscanner.distance.compute_distance_maps_from_coordinate_dict(trj0_coordinate)\n",
    "end = timer()\n",
    "print(end - start)\n",
    "\n",
    "trj0_contact_maps = morphoscanner.distance.compute_contact_maps_as_array(trj0_distance_maps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj0_denoised_dict = morphoscanner.denoise.denoise_contact_maps(trj0_contact_maps)\n",
    "trj0_graph = morphoscanner.graph.nx_graph_search(trj0_denoised_dict)\n",
    "trj0_subgraph = morphoscanner.graph.find_subgraph(trj0_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj0_mean_distance = morphoscanner.distance.get_mean_distance_map(trj0_distance_maps)\n",
    "trj0_decomposition = morphoscanner.distance.decompose_distance_map(trj0_mean_distance)\n",
    "trj0_mean_coordinate = morphoscanner.distance.get_coordinate_from_decomposition(trj0_decomposition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot_peptide_list(trj0_coordinate,[0,1,2,3,4,5,6,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#morphoscanner.plot.plot_single_peptide(trj0_mean_coordinate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = morphoscanner.high_level.coordinate_dict_from_gro(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot_peptide_list(t, [e for e in t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinate_dict = morphoscanner.high_level.coordinate_dict_from_gro(path)\n",
    "coordinate_tens = morphoscanner.distance_tensor.get_coordinate_tensor(coordinate_dict)\n",
    "start = timer()\n",
    "distance_tens = morphoscanner.distance_tensor.compute_euclidean_norm_torch(coordinate_tens)\n",
    "end = timer()\n",
    "print(end-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contact_maps = morphoscanner.distance.compute_contact_maps_as_array(distance_tens)\n",
    "denoised_map = morphoscanner.denoise.denoise_contact_maps(contact_maps)\n",
    "graph_full = morphoscanner.graph.full_graph(denoised_map)\n",
    "#graph = morphoscanner.graph.nx_graph_search(denoised_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph = morphoscanner.graph.find_subgraph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = morphoscanner.graph.get_not_in_subgraph(coordinate_dict, subgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_dataframe_from_trajectory(trj_gro, trj_xtc, peptide_length = None):\n",
    "\n",
    "    universe = morphoscanner.topology.make_universe(trj_gro, trj_xtc)\n",
    "\n",
    "    topology = trj_gro\n",
    "\n",
    "    peptides_list = morphoscanner.topology.get_peptide_length_list(trj_gro)\n",
    "\n",
    "\n",
    "    if peptide_length == None:\n",
    "    \n",
    "\n",
    "        n_pep = len(peptides_list)\n",
    "\n",
    "\n",
    "    else:\n",
    "\n",
    "        n_pep = sum([(e//peptide_length) for e in peptides_list])\n",
    "\n",
    "    #columns_name = ['atom_number','peptide_number', 'residue_name', 'residue_position', 'coordinates']\n",
    "    columns_name = ['time_step','peptide_number', 'residue_position', 'residue_name', 'atom_position', 'atom_type', 'coordinates']\n",
    "\n",
    "    # create list for a pd.DataFrame\n",
    "    # as suggested in https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.append.html\n",
    "    for_pandas = []\n",
    "\n",
    "    trj_dict = {}\n",
    "\n",
    "    #for index_ts, ts in tqdm.tqdm(enumerate(universe.trajectory)):\n",
    "    for index_ts, ts in enumerate(universe.trajectory):\n",
    "\n",
    "        trj_dict[index_ts] = {}\n",
    "\n",
    "        for peptide in range(n_pep):\n",
    "\n",
    "            trj_dict[index_ts][peptide] = {}\n",
    "\n",
    "            if peptide != 0:\n",
    "                \n",
    "                # if to check peptide_length\n",
    "                \n",
    "                if peptide_length == None:\n",
    "\n",
    "                    counter += peptides_list[peptide - 1]\n",
    "                \n",
    "                else:\n",
    "                    counter += peptide_length\n",
    "        \n",
    "\n",
    "            else:\n",
    "                counter = 0\n",
    "            \n",
    "            \n",
    "            \n",
    "            if peptide_length == None:\n",
    "\n",
    "                for res in range(peptides_list[peptide]):\n",
    "\n",
    "                    res_name = (str(universe.residues[res + counter]).split()[1].split(',')[0])#.split(',')[0])\n",
    "                    res_position = int(str(universe.residues[res + counter]).split()[2].split('>')[0])#.split(',')[0])\n",
    "                    res_id = str(res_position) + '_' + res_name\n",
    "\n",
    "                    #print(str(universe.residues[res + counter]))\n",
    "\n",
    "                    for index, atom in enumerate(universe.residues[res + (counter)].atoms):\n",
    "\n",
    "                        #print(atom)\n",
    "\n",
    "                        atom_number = (int(str(atom).split()[1].split(':')[0]) - 1)\n",
    "\n",
    "                        atom_type = str(atom).split()[2]\n",
    "\n",
    "                        coordinate = universe.atoms[atom_number].position\n",
    "\n",
    "                        position = len(trj_dict[index_ts][peptide])\n",
    "\n",
    "                        trj_dict[index_ts][peptide][position] = coordinate\n",
    "\n",
    "                        #features = [atom_number,peptide, res_name, position, coordinate]\n",
    "                        features = [index_ts, peptide, res_position, res_name, position, atom_type, coordinate]\n",
    "\n",
    "                        for_pandas.append(features)\n",
    "                        \n",
    "            else:\n",
    "                \n",
    "                for res in range(peptide_length):\n",
    "\n",
    "                    res_name = (str(universe.residues[res + counter]).split()[1].split(',')[0])#.split(',')[0])\n",
    "                    res_position = int(str(universe.residues[res + counter]).split()[2].split('>')[0])#.split(',')[0])\n",
    "                    res_id = str(res_position) + '_' + res_name\n",
    "\n",
    "                    #print(str(universe.residues[res + counter]))\n",
    "\n",
    "                    for index, atom in enumerate(universe.residues[res + (counter)].atoms):\n",
    "\n",
    "                        #print(atom)\n",
    "\n",
    "                        atom_number = (int(str(atom).split()[1].split(':')[0]) - 1)\n",
    "\n",
    "                        atom_type = str(atom).split()[2]\n",
    "\n",
    "                        coordinate = universe.atoms[atom_number].position\n",
    "\n",
    "                        position = len(trj_dict[index_ts][peptide])\n",
    "\n",
    "                        trj_dict[index_ts][peptide][position] = coordinate\n",
    "\n",
    "                        #features = [atom_number,peptide, res_name, position, coordinate]\n",
    "                        features = [index_ts, peptide, res_position, res_name, position, atom_type, coordinate]\n",
    "\n",
    "                        for_pandas.append(features)\n",
    "                \n",
    "\n",
    "\n",
    "    #start = timer()\n",
    "    df = pd.DataFrame(for_pandas,columns=columns_name)\n",
    "    #end = timer()\n",
    "    #print(end-start)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pep_list = morphoscanner.topology.get_peptide_lenght_list(trj_gro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = morphoscanner.dataframe.get_dataframe_from_trajectory(trj_gro, trj_xtc,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa.groupby('time_step').get_group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbb = get_dataframe_from_trajectory(trj_gro, trj_xtc, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uu = torch.stack((coordinate_tens[0], coordinate_tens[1]),dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPUTE CONTACT MAPS\n",
    "# TO DO: parametrize the threshold distance in a better way (e.g. )\n",
    "def compute_contact_maps_as_array(distance_maps_array):\n",
    "\n",
    "    # distance between the first and the second aminoacid of the first chain\n",
    "    intrapeptide_minimum_distance = distance_maps_array[0][0][0][1] \n",
    "\n",
    "    contact_map_list = []\n",
    "\n",
    "    # contact is in a distance up to 150% of the intrapeptide_minimum_distance [TO IMPROVE!!!]\n",
    "    threshold_distance = (intrapeptide_minimum_distance * 1.5)\n",
    "\n",
    "    for model_1 in range(distance_maps_array.shape[0]):\n",
    "        contact_map_list.append([])\n",
    "        for model_2 in range(distance_maps_array[model_1].shape[0]):\n",
    "\n",
    "            contact_map_list[model_1].append([])\n",
    "\n",
    "            if model_1 == model_2:\n",
    "\n",
    "                contact_map_list[model_1][model_2].extend(np.zeros((distance_maps_array.shape[2], distance_maps_array.shape[3])))\n",
    "\n",
    "            else:\n",
    "\n",
    "                contact_map = np.zeros((distance_maps_array.shape[2], distance_maps_array.shape[3]))\n",
    "\n",
    "                for chain_1 in range(distance_maps_array[model_1][model_2].shape[0]):\n",
    "\n",
    "                    for chain_2 in range(distance_maps_array[model_1][model_2][chain_1].shape[0]):\n",
    "\n",
    "                        distance = distance_maps_array[model_1][model_2][chain_1][chain_2]\n",
    "\n",
    "                        if distance < threshold_distance:\n",
    "                            contact_map[chain_1][chain_2] = 1 #True\n",
    "                        else:\n",
    "                            pass\n",
    "\n",
    "                contact_map_list[model_1][model_2].extend(contact_map)\n",
    "\n",
    "    contact_array = np.asarray(contact_map_list)\n",
    "\n",
    "    return contact_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a full graph\n",
    "def full_graph(denoised_dict):\n",
    "    ''' Create a full graph of all the peptides in the frame.\n",
    "    \n",
    "    Every peptide is a node in the graph.\n",
    "    Edges join contacting peptides.\n",
    "    Edges have attribute 'length' that gives you the number of contact between the peptides\n",
    "    \n",
    "    Useful for peptides behaviour analysis during molecular dynamics\n",
    "    \n",
    "    Arguments: denoised contact maps dict\n",
    "    return: networkx.MultiGraph\n",
    "    \n",
    "    '''\n",
    "    graph = nx.MultiGraph()\n",
    "\n",
    "    for peptide_1 in denoised_dict:\n",
    "        for peptide_2 in denoised_dict[peptide_1]:\n",
    "            \n",
    "            array_1 = denoised_dict[peptide_1][peptide_2]\n",
    "\n",
    "            graph.add_node(peptide_1)\n",
    "            graph.add_node(peptide_2)\n",
    "\n",
    "            number_of_contacts = array_1.sum()\n",
    "\n",
    "            if number_of_contacts >= 1:\n",
    "\n",
    "                graph.add_edge(peptide_1, peptide_2, length = number_of_contacts)\n",
    "    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinate_dict = morphoscanner.high_level.coordinate_dict_from_gro_fix_len_peptide(trj_gro,12)\n",
    "coordinate_tens = morphoscanner.distance_tensor.get_coordinate_tensor(coordinate_dict)\n",
    "start = timer()\n",
    "distance_tens = morphoscanner.distance_tensor.compute_euclidean_norm_torch(coordinate_tens)\n",
    "end = timer()\n",
    "print(end-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinate_dict = morphoscanner.high_level.coordinate_dict_from_gro(trj_gro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRAJECTORY\n",
    "\n",
    "# using mdanalysis module\n",
    "\n",
    "\n",
    "#create Universe from a .gro with coordinates and an .xtc with the trajectory data\n",
    "u = mda.Universe(trj_gro,trj_xtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dict from a Universe in which each entry is a timestep of the MD simulation\n",
    "def create_trajectory_dict(universe):\n",
    "    bb = universe.select_atoms('name BB')\n",
    "    trajectory_dict = {}\n",
    "    for index, time_steps in enumerate(universe.trajectory):\n",
    "        trajectory_dict[index] = bb.positions\n",
    "    return trajectory_dict\n",
    "\n",
    "# make trajectory dict\n",
    "trajectory_dict = create_trajectory_dict(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trajectory_dict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_universe(trj_gro, trj_xtc):\n",
    "    ''' Leverage MDAnalysis.Universe() to parse trajectory file from gromacs output.\n",
    "    \n",
    "    Intput: string: system path of gro file (topology) and\n",
    "                    system path of xtc file (trajectory)\n",
    "                    of the file to analyze\n",
    "                    \n",
    "    return: MDAnalysis.Universe()'''\n",
    "    \n",
    "    \n",
    "    universe = mda.Universe(trj_gro,trj_xtc)\n",
    "    \n",
    "    return universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot_peptide_list(coordinate_dict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot_peptide_list(coordinate_dict, [e for e in coordinate_dict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinate_from_gro_all_atom(topology, universe):\n",
    "    \n",
    "    \n",
    "    peptides_list = morphoscanner.topology.get_peptide_lenght_list(topology)\n",
    "\n",
    "    trj_dict = {}\n",
    "\n",
    "    for peptide, n_res in enumerate(peptides_list[:]):\n",
    "\n",
    "        trj_dict[peptide] = {}\n",
    "\n",
    "        if peptide != 0:\n",
    "\n",
    "            counter += peptides_list[peptide-1]\n",
    "\n",
    "        else:\n",
    "            counter = 0\n",
    "\n",
    "\n",
    "        for res in range(n_res):\n",
    "\n",
    "            res_name = (str(universe.residues[res + counter]).split()[1].split(',')[0])#.split(',')[0])\n",
    "            res_position = (str(universe.residues[res + counter]).split()[2].split('>')[0])#.split(',')[0])\n",
    "            res_id = res_position + '_' + res_name\n",
    "            \n",
    "            trj_dict[peptide][res_id] = {}\n",
    "\n",
    "            for index, atom in enumerate(universe.residues[res + counter].atoms):\n",
    "\n",
    "                atom_type = str(atom).split()[2]\n",
    "\n",
    "                atom_number = int(str(atom).split()[1].split(':')[0])\n",
    "\n",
    "                coordinate = universe.atoms[atom_number].position\n",
    "\n",
    "                trj_dict[peptide][res_id][atom_type] = coordinate\n",
    "                \n",
    "    return trj_dict\n",
    "\n",
    "\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinate_dict_for_fixed_lenght_topology(topology, universe, n_residues = int):\n",
    "\n",
    "    peptides_list = morphoscanner.topology.get_peptide_lenght_list(trj_gro)\n",
    "\n",
    "    #n_residues = 12\n",
    "\n",
    "    n_pep = sum([(e//n_residues) for e in peptides_list])\n",
    "\n",
    "    trj_dict = {}\n",
    "\n",
    "    for peptide in range(n_pep):\n",
    "\n",
    "        trj_dict[peptide] = {}\n",
    "\n",
    "        if peptide != 0:\n",
    "\n",
    "            counter += n_residues\n",
    "\n",
    "        else:\n",
    "            counter = 0\n",
    "\n",
    "\n",
    "        for res in range(n_residues):\n",
    "\n",
    "            res_name = (str(universe.residues[res + counter]).split()[1].split(',')[0])#.split(',')[0])\n",
    "            res_position = (str(universe.residues[res + counter]).split()[2].split('>')[0])#.split(',')[0])\n",
    "            res_id = res_position + '_' + res_name\n",
    "\n",
    "\n",
    "            for index, atom in enumerate(universe.residues[res + (counter)].atoms):\n",
    "\n",
    "                atom_number = (int(str(atom).split()[1].split(':')[0]) - 1)\n",
    "\n",
    "                coordinate = universe.atoms[atom_number].position\n",
    "                position = len(trj_dict[peptide])\n",
    "                \n",
    "                trj_dict[peptide][position] = coordinate\n",
    "                \n",
    "    return trj_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinate_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj_dict = get_coordinate_dict_for_fixed_lenght_topology(trj_gro, u, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj_dict = get_coordinate_from_gro_all_atom(trj_gro, u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_peptide_lenght_list(topology):\n",
    "    \n",
    "    peptide_lenght_list = []\n",
    "\n",
    "    temporary_list = []\n",
    "\n",
    "    # iterate trough topology\n",
    "    for residue in topology:\n",
    "\n",
    "        # if temporary list just started, add aminoacid position in chain\n",
    "        if len(temporary_list) == 0:\n",
    "            temporary_list.append(int(residue[1]))\n",
    "\n",
    "        else:\n",
    "            # if position of actual residue is less than last residue\n",
    "            if temporary_list[-1] > int(residue[1]):\n",
    "\n",
    "                # append lenght of last peptide to peptide lenght list\n",
    "                peptide_lenght_list.append(len(temporary_list))\n",
    "\n",
    "                # empty temporary list\n",
    "                temporary_list = []\n",
    "\n",
    "                # append actual residue position\n",
    "                temporary_list.append(int(residue[1]))\n",
    "\n",
    "            # if position of actual residue is higher than last residue, ad current residue position\n",
    "            else:\n",
    "                temporary_list.append(int(residue[1]))\n",
    "\n",
    "    # append last peptide lenght to lenght stack\n",
    "    peptide_lenght_list.append(len(temporary_list))\n",
    "\n",
    "    return peptide_lenght_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "u = morphoscanner.topology.make_universe(trj_gro, trj_xtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot_peptide_list(trj_dict, [0,1,2,3,4,5,6,7,8,9,10,11,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = morphoscanner.read.get_peptide_lenght_list(trj_gro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj_dict = get_coordinate_dict_for_fixed_lenght_topology(trj_gro, u, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_tens = morphoscanner.distance_tensor.get_coordinate_tensor(trj_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trj_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_tens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "distances = morphoscanner.distance_tensor.compute_euclidean_norm_torch(coord_tens)\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(distances[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('__Number CUDA Devices:', torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coordinate_dict = morphoscanner.high_level.coordinate_dict_from_gro(trj_gro)\n",
    "coordinate_dict = morphoscanner.topology.\n",
    "coordinate_tens = morphoscanner.distance_tensor.get_coordinate_tensor(coordinate_dict)\n",
    "start = timer()\n",
    "distance_tens = morphoscanner.distance_tensor.compute_euclidean_norm_torch(coordinate_tens)\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory_dict = {}\n",
    "for index, ts in enumerate(universe.trajectory):\n",
    "    print(\"Frame: {0:5d}, Time: {1:8.3f} ps\".format(ts.frame, universe.trajectory.time))\n",
    "    print(\"Rgyr: {0:g} A\".format(universe.atoms.radius_of_gyration()))\n",
    "    print(universe.atoms.positions)\n",
    "    positions = universe.atoms.positions\n",
    "    trajectory_dict[index] = positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df.groupby('time_step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribute python libraryfor i in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trj_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " for i in a.coordinates:\n",
    "        i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot_peptide_from_tensor(trajectory_dict[0], [122])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = a.get_group(2)['coordinates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_dataframe_from_trajectory(trj_gro, trj_xtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bb(dataframe, frame):\n",
    "    \n",
    "    bb_dataframe = dataframe.groupby('time_step').get_group(frame).groupby('atom_type').get_group('BB')\n",
    "    \n",
    "    return bb_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.get_group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.peptide_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_2d_from_0(point):\n",
    "        \n",
    "    \n",
    "    point_0 = [0,0]\n",
    "    \n",
    "    distance = (point_0[0]-point[0])**2 + (point0[1]-point[1])**2\n",
    "    \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = morphoscanner.dataframe.get_dataframe_from_trajectory(trj_gro, trj_xtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "df = morphoscanner.dataframe.get_dataframe_from_trajectory(trj_gro, trj_xtc)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinate_dict = morphoscanner.high_level.coordinate_dict_from_gro_fix_len_peptide(trj_gro, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinate_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('time_step').get_group(0).groupby('peptide_number').get_group(0).groupby('atom_type').get_group('BB').coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate 3d tensor with shape n_peptides * n_residues * n_dimension\n",
    "        def get_coordinate_tensor_dataframe(dataframe):\n",
    "    \n",
    "            #variables wit dict dimension\n",
    "            dim0 = len(dataframe.groupby('time_step'))\n",
    "            dim1 = len(coordinate_dict[0])\n",
    "            dim2 = len(coordinate_dict[0][0])\n",
    "\n",
    "            #initialize a 0s tensor\n",
    "            if torch.cuda.is_available() == True:\n",
    "                \n",
    "                zero = torch.zeros([dim0,dim1,dim2], dtype=torch.float32, device='cuda')\n",
    "\n",
    "            else:\n",
    "                zero = torch.zeros([dim0,dim1,dim2], dtype=torch.float32)\n",
    "\n",
    "\n",
    "            for peptide in coordinate_dict:\n",
    "\n",
    "                for aminoacid in coordinate_dict[peptide]:\n",
    "                    \n",
    "                    \n",
    "                    if torch.cuda.is_available() == True:\n",
    "                        # create torch tensor on cuda device with cordinate [x,y,z...]\n",
    "                        zero[peptide][aminoacid] = torch.cuda.FloatTensor(coordinate_dict[peptide][aminoacid])\n",
    "\n",
    "                    else:\n",
    "                        zero[peptide][aminoacid] = torch.FloatTensor(coordinate_dict[peptide][aminoacid])\n",
    "\n",
    "                        \n",
    "                        \n",
    "            return zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = 0\n",
    "peptide = 0\n",
    "\n",
    "number_of_time_steps = len(df.groupby('time_step'))\n",
    "\n",
    "number_of_atoms = len(df.groupby('time_step').get_group(frame))\n",
    "\n",
    "number_of_peptides = len(df.groupby('time_step').get_group(frame).groupby('peptide_number'))\n",
    "\n",
    "number_of_residues = len(df.groupby('time_step').get_group(frame).groupby('peptide_number').get_group(0))\n",
    "\n",
    "len(df.groupby('time_step').get_group(frame).groupby('peptide_number').get_group(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('time_step').get_group(frame).groupby('peptide_number').get_group(0).coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "\n",
    "#number_of_time_steps = len(df.groupby('time_step'))\n",
    "\n",
    "#number_of_atoms_in_a_step = len(df.groupby('time_step').get_group(step))\n",
    "\n",
    "#number_of_peptides = len(df.groupby('time_step').get_group(step).groupby('peptide_number'))\n",
    "\n",
    "#number_of_atoms_in_peptide = len(df.groupby('time_step').get_group(step).groupby('peptide_number').get_group(peptide))\n",
    "\n",
    "\n",
    "\n",
    "#for step in range(number_of_time_steps):\n",
    "    \n",
    "#    number_of_peptides = len(df.groupby('time_step').get_group(step).groupby('peptide_number'))\n",
    "    \n",
    "for peptide in range(number_of_peptides):\n",
    "\n",
    "    number_of_atoms_in_peptide = len(df.groupby('time_step').get_group(step).groupby('peptide_number').get_group(peptide))\n",
    "\n",
    "    peptide_tensor = torch.tensor(df.groupby('time_step').get_group(step).groupby('peptide_number').get_group(peptide).coordinates, device=device)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('time_step').get_group(0).groupby('peptide_number').get_group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cicle on peptide\n",
    "#for index1, peptide1 in tqdm.tqdm(enumerate(coordinate_tensor)):\n",
    "\n",
    "def distance_maps_from_dataframe(dataframe, time_step):\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    number_of_peptides = len(dataframe.groupby('time_step').get_group(time_step).groupby('peptide_number'))\n",
    "    #number_of_peptides = 5\n",
    "\n",
    "    distance_dict = {}\n",
    "    # iterate trought all peptides in a frame\n",
    "    for peptide1 in range(number_of_peptides):\n",
    "\n",
    "        if peptide1 not in distance_dict.keys():\n",
    "\n",
    "            distance_dict[peptide1] = {}\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        number_of_atoms_in_peptide1 = len(dataframe.groupby('time_step').get_group(time_step).groupby('peptide_number').get_group(peptide1))\n",
    "\n",
    "\n",
    "\n",
    "        peptide1_tensor = morphoscanner.dataframe.get_peptide_tensor_from_dataframe(dataframe, time_step, peptide1)\n",
    "\n",
    "        # iterate trought peptide in the upper triangle only\n",
    "        for peptide2 in range(peptide1, number_of_peptides):\n",
    "\n",
    "\n",
    "            number_of_atoms_in_peptide2 = len(dataframe.groupby('time_step').get_group(time_step).groupby('peptide_number').get_group(peptide2))\n",
    "\n",
    "\n",
    "            peptide2_tensor = morphoscanner.dataframe.get_peptide_tensor_from_dataframe(dataframe, time_step, peptide2)\n",
    "\n",
    "\n",
    "            distance_map = morphoscanner.distance_tensor.distance_matrix_from_2d_tensor(peptide1_tensor, peptide2_tensor)\n",
    "            distance_dict[peptide1][peptide2] = distance_map.cpu().numpy()\n",
    "\n",
    "            if peptide2 in distance_dict.keys():\n",
    "\n",
    "                #distance_dict[peptide2] = {}\n",
    "                distance_dict[peptide2][peptide1] = distance_map.transpose(1,0).cpu().numpy()\n",
    "\n",
    "            else:\n",
    "                distance_dict[peptide2] = {}\n",
    "                distance_dict[peptide2][peptide1] = distance_map.transpose(1,0).cpu().numpy()\n",
    "                \n",
    "    return distance_dict\n",
    "        \n",
    "        # SO YOU CAN CALCULATE DISTANCE MAPS\n",
    "        # NOW YOU HAVE TO PUT THOSE IN A DATAFRAME\n",
    "\n",
    "    #return dist\n",
    "\n",
    "#https://discuss.pytorch.org/t/efficient-distance-matrix-computation/9065\n",
    "#https://www.dropbox.com/h?preview=Parallel+Euclidean+distance+matrix+computation+on+big+datasets.pdf  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(len(distance_dict)-1):\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "step = 0\n",
    "peptide1 = 0\n",
    "peptide2 = 1\n",
    "\n",
    "#peptide_tensor1 = torch.tensor(df.groupby('time_step').get_group(step).groupby('peptide_number').get_group(peptide1).coordinates, device=device)\n",
    "#peptide_tensor2 = torch.tensor(df.groupby('time_step').get_group(step).groupby('peptide_number').get_group(peptide2).coordinates, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(distance_dict[0][4].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(distance_dict[4][0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_dict[4][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.transpose(1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = distance_dict[0][1].cpu().transpose(1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(distance_dict[1][0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = timer()\n",
    "data = morphoscanner.dataframe.get_dataframe_from_trajectory(trj_gro, trj_xtc)\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "maps = distance_maps_from_dataframe(data, 0)\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(maps[2][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(maps[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(216)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(maps[1][8]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe = morphoscanner.topology.make_universe(prod_gro, prod_xtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.topology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe.trajectory.n_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bb_coordinate_from_gro_and_universe(topology, universe): #, bb=True):\n",
    "    \n",
    "    \n",
    "    peptides_list = morphoscanner.topology.get_peptide_length_list(topology)\n",
    "\n",
    "    trj_dict = {}\n",
    "\n",
    "    for peptide, n_res in enumerate(peptides_list[:]):\n",
    "\n",
    "        trj_dict[peptide] = {}\n",
    "\n",
    "        if peptide != 0:\n",
    "\n",
    "            counter += peptides_list[peptide-1]\n",
    "\n",
    "        else:\n",
    "            counter = 0\n",
    "\n",
    "\n",
    "        for res in range(n_res):\n",
    "            \n",
    "            #if bb == True:\n",
    "                \n",
    "                #res_name = (str(universe.residues[res + counter]).split()[1].split(',')[0])#.split(',')[0])\n",
    "            \n",
    "            res_position = int(str(universe.residues[res + counter]).split()[2].split('>')[0]) - 1  #.split(',')[0])\n",
    "            \n",
    "            #res_id = res_position + '_' + res_name\n",
    "            \n",
    "            trj_dict[peptide][res_position] = {}\n",
    "\n",
    "            for index, atom in enumerate(universe.residues[res + counter].atoms):\n",
    "                \n",
    "            #if bb == True:\n",
    "\n",
    "                atom_type = str(atom).split()[2]\n",
    "\n",
    "                if atom_type == 'BB':\n",
    "\n",
    "                    atom_number = int(str(atom).split()[1].split(':')[0])\n",
    "\n",
    "                    coordinate = universe.atoms[atom_number].position\n",
    "\n",
    "                    trj_dict[peptide][res_position] = coordinate\n",
    "\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "            #else:\n",
    "                #atom_type = str(atom).split()[2]\n",
    "                #atom_number = int(str(atom).split()[1].split(':')[0])\n",
    "                #coordinate = universe.atoms[atom_number].position\n",
    "                #trj_dict[peptide][res_position][atom_type]\n",
    "\n",
    "                trj_dict[peptide][res_position] = coordinate\n",
    "\n",
    "\n",
    "                #print(peptide, res_position, coordinate)\n",
    "                \n",
    "    return trj_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dati = []\n",
    "for i in universe.trajectory:\n",
    "    \n",
    "    dati.append(universe.atoms.positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dati[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # COMPUTE CONTACT MAPS\n",
    "# TO DO: parametrize the threshold distance in a better way (e.g. )\n",
    "def compute_contact_maps_as_array(distance_maps_array):\n",
    "\n",
    "    # distance between the first and the second aminoacid of the first chain\n",
    "    intrapeptide_minimum_distance = distance_maps_array[0][0][0][1] \n",
    "\n",
    "    contact_map_list = []\n",
    "\n",
    "    # contact is in a distance up to 150% of the intrapeptide_minimum_distance [TO IMPROVE!!!]\n",
    "    threshold_distance = (intrapeptide_minimum_distance * 1.5)\n",
    "\n",
    "    for model_1 in range(distance_maps_array.shape[0]):\n",
    "        contact_map_list.append([])\n",
    "        for model_2 in range(distance_maps_array[model_1].shape[0]):\n",
    "\n",
    "            contact_map_list[model_1].append([])\n",
    "\n",
    "            if model_1 == model_2:\n",
    "\n",
    "                contact_map_list[model_1][model_2].extend(np.zeros((distance_maps_array.shape[2], distance_maps_array.shape[3])))\n",
    "\n",
    "            else:\n",
    "\n",
    "                contact_map = np.zeros((distance_maps_array.shape[2], distance_maps_array.shape[3]))\n",
    "\n",
    "                for chain_1 in range(distance_maps_array[model_1][model_2].shape[0]):\n",
    "\n",
    "                    for chain_2 in range(distance_maps_array[model_1][model_2][chain_1].shape[0]):\n",
    "\n",
    "                        distance = distance_maps_array[model_1][model_2][chain_1][chain_2]\n",
    "\n",
    "                        if distance < threshold_distance:\n",
    "                            contact_map[chain_1][chain_2] = 1 #True\n",
    "                        else:\n",
    "                            pass\n",
    "\n",
    "                contact_map_list[model_1][model_2].extend(contact_map)\n",
    "\n",
    "    contact_array = np.asarray(contact_map_list)\n",
    "\n",
    "    return contact_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps[0][0][0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dict from a Universe in which each entry is a timestep of the MD simulation\n",
    "def create_trajectory_dict(universe):\n",
    "    bb = universe.select_atoms('name BB')\n",
    "    trajectory_dict = {}\n",
    "    for index, time_steps in enumerate(universe.trajectory):\n",
    "        trajectory_dict[index] = bb.positions\n",
    "    return trajectory_dict\n",
    "\n",
    "# make trajectory dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "trajectory_dict = create_trajectory_dict(universe)\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = get_coordinate_from_gro_topology(trj_gro, universe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe.atoms[0].position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_tens = morphoscanner.distance_tensor.get_coordinate_tensor_from_dict(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_dist = morphoscanner.distance_tensor.compute_euclidean_norm_torch(e_tens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(e_dist[12][12][:12,:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "\n",
    "# DEVI FARE IN MODO DA ORGANIZZARE LE DISTANCE MAP SECONDO LA DIMENSIONE DELLA MATRICE\n",
    "# IN MODO DA POTER FARE UN TENSORE PER SIZE DELLE DISTANCE MAP TRAMITE STACKING\n",
    "\n",
    "# PER ESEMPIO, METTI INSIEME TENSORE CON DISTANCE MAPS DI PROTEINE CON 12 AMINOACIDI,\n",
    "# UN ALTRO TENSORE PER PROTEINE DA 16 AMINOACIDI, E COSÌ VIA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def compute_euclidean_norm_torch(coordinate_tensor):\n",
    "#'''Use matrix to compute euclidean distance dataset wise\n",
    "#    and return a set of distance matrix for everi couple of peptides\n",
    "#\n",
    "#****Runs in parallel on CUDA devices.\n",
    "#\n",
    "#Argument: tensor of shape n_peptide * n_residue * number of dimension (3 for 3d)\n",
    "#\n",
    "#return: tensor of shape n_peptide * n_peptide * n_residue * n_peptide\n",
    "\n",
    "#'''\n",
    "\n",
    "#create tensor of 0s with shape n_pep x n_pep * n_res + n_res\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "zero = torch.zeros((coordinate_tensor.shape[0], coordinate_tensor.shape[0], coordinate_tensor.shape[1], coordinate_tensor.shape[1]), device=device)\n",
    "\n",
    "#cicle on peptide\n",
    "for index1, peptide1 in tqdm.tqdm(enumerate(coordinate_tensor)):\n",
    "\n",
    "    #cicle on peptide (upper triangle + diagonal)\n",
    "    for index2 in range(index1, coordinate_tensor.shape[0]):\n",
    "    #for index2 in range(coordinate_tens.shape[0]):\n",
    "\n",
    "        #coordinate vector\n",
    "        peptide2 = coordinate_tensor[index2]\n",
    "\n",
    "        x_norm = torch.pow(peptide1, 2).sum(1).view(-1,1)\n",
    "        y_t = torch.transpose(peptide2, 0, 1)\n",
    "        y_norm = torch.pow(peptide2, 2).sum(1).view(1,-1)\n",
    "\n",
    "        dist = torch.sqrt(x_norm + y_norm - 2.0 * torch.mm(peptide1, y_t))\n",
    "\n",
    "        #dist = x_norm + y_norm - 2.0 * torch.mm(peptide1, y_t)\n",
    "        #fine = torch.clamp(dist, 0.0, np.inf) #should be there, but is not working somehow\n",
    "\n",
    "        # add distance map in the right position of the 0s tensor\n",
    "        zero[index1][index2] = dist\n",
    "\n",
    "        # if mesuring between different peptides\n",
    "        if index1 != index2:\n",
    "            # put transpose of distance map in lower triangle\n",
    "            zero[index2][index1] = dist.transpose(1,0)\n",
    "\n",
    "#convert nan to 0  (using this instead of torch.clamp())       \n",
    "zero[torch.isnan(zero)] = 0\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    # move to system memory and cast to numpy array\n",
    "    zero = zero.cpu().numpy()\n",
    "\n",
    "return zero\n",
    "\n",
    "#https://discuss.pytorch.org/t/efficient-distance-matrix-computation/9065\n",
    "#https://www.dropbox.com/h?preview=Parallel+Euclidean+distance+matrix+computation+on+big+datasets.pdf     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = mda.coordinates.TRR.TRRReader(trr_prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = a.trajectory[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in a.trajectory():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod = morphoscanner.topology.make_universe(prod_gro, prod_xtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nv.show_mdanalysis(prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_peptide(peptide_coordinate_dict, centroid=False):\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "    \n",
    "    for residue in peptide_coordinate_dict:\n",
    "        point = peptide_coordinate_dict[residue]\n",
    "        x.append(point[0])\n",
    "        y.append(point[1])\n",
    "        z.append(point[2])\n",
    "\n",
    "    \n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    z = np.asarray(z)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    \n",
    "    ax = fig.add_subplot(111, projection = '3d')\n",
    "    ax.plot(x,y,z, c='b')\n",
    "    \n",
    "    if centroid == True:\n",
    "            median_centroid = [np.median(x), np.median(y), np.median(z)]\n",
    "            ax.scatter(median_centroid[0], median_centroid[1], median_centroid[2], c='r')\n",
    "    \n",
    "        # Create cubic bounding box to simulate equal aspect ratio\n",
    "    max_range = np.array([x.max()-x.min(), y.max()-y.min(), z.max()-z.min()]).max()\n",
    "    Xb = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][0].flatten() + 0.5*(x.max()+x.min())\n",
    "    Yb = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][1].flatten() + 0.5*(y.max()+y.min())\n",
    "    Zb = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][2].flatten() + 0.5*(z.max()+z.min())\n",
    "    # Comment or uncomment following both lines to test the fake bounding box:\n",
    "    #for xb, yb, zb in zip(Xb, Yb, Zb):\n",
    "     #   ax.plot([xb], [yb], [zb], 'w')\n",
    "            \n",
    "    return plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = morphoscanner.high_level.coordinate_dict_from_gro(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_single_peptide(test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot_single_peptide(a_dict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dict = morphoscanner.high_level.coordinate_dict_from_gro(prod_gro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot_peptide_list(a_dict, [e for e in a_dict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "prod_df = morphoscanner.dataframe.get_dataframe_from_trajectory(prod_gro, prod_xtc)\n",
    "end = timer()\n",
    "print(end-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dict = create_trajectory_dict(prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "a_dict = morphoscanner.topology.create_trajectory_dict(prod)\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dict[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(u_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot_peptide_from_tensor(a_dict[2000], [e for e in range(a_dict[2000].shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe = morphoscanner.topology.make_universe(prod_gro, prod_xtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe.trajectory[:20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_mini = universe.trajectory[:20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict_from_trajectory(trj_gro, trj_xtc, peptide_length = None):\n",
    "\n",
    "    universe = morphoscanner.topology.make_universe(trj_gro, trj_xtc)\n",
    "\n",
    "    topology = trj_gro\n",
    "\n",
    "    peptides_list = morphoscanner.topology.get_peptide_length_list(trj_gro)\n",
    "\n",
    "\n",
    "    if peptide_length == None:\n",
    "    \n",
    "\n",
    "        n_pep = len(peptides_list)\n",
    "\n",
    "\n",
    "    else:\n",
    "\n",
    "        n_pep = sum([(e//peptide_length) for e in peptides_list])\n",
    "\n",
    "    #columns_name = ['atom_number','peptide_number', 'residue_name', 'residue_position', 'coordinates']\n",
    "    #columns_name = ['time_step','peptide_number', 'residue_position', 'residue_name', 'atom_position', 'atom_type', 'coordinates']\n",
    "\n",
    "    # create list for a pd.DataFrame\n",
    "    # as suggested in https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.append.html\n",
    "    #for_pandas = []\n",
    "\n",
    "    trj_dict = {}\n",
    "\n",
    "    #for index_ts, ts in tqdm.tqdm(enumerate(universe.trajectory)):\n",
    "    for index_ts, ts in enumerate(universe.trajectory):\n",
    "\n",
    "        trj_dict[index_ts] = {}\n",
    "\n",
    "        for peptide in range(n_pep):\n",
    "\n",
    "            trj_dict[index_ts][peptide] = {}\n",
    "\n",
    "            if peptide != 0:\n",
    "                \n",
    "                # if to check peptide_length\n",
    "                \n",
    "                if peptide_length == None:\n",
    "\n",
    "                    counter += peptides_list[peptide - 1]\n",
    "                \n",
    "                else:\n",
    "                    counter += peptide_length\n",
    "        \n",
    "\n",
    "            else:\n",
    "                counter = 0\n",
    "            \n",
    "            \n",
    "            \n",
    "            if peptide_length == None:\n",
    "\n",
    "                for res in range(peptides_list[peptide]):\n",
    "\n",
    "                    res_name = (str(universe.residues[res + counter]).split()[1].split(',')[0])#.split(',')[0])\n",
    "                    res_position = int(str(universe.residues[res + counter]).split()[2].split('>')[0])#.split(',')[0])\n",
    "                    res_id = str(res_position) + '_' + res_name\n",
    "\n",
    "                    #print(str(universe.residues[res + counter]))\n",
    "\n",
    "                    for index, atom in enumerate(universe.residues[res + (counter)].atoms):\n",
    "\n",
    "                        #print(atom)\n",
    "\n",
    "                        atom_number = (int(str(atom).split()[1].split(':')[0]) - 1)\n",
    "\n",
    "                        #atom_type = str(atom).split()[2]\n",
    "\n",
    "                        coordinate = universe.atoms[atom_number].position\n",
    "\n",
    "                        position = len(trj_dict[index_ts][peptide])\n",
    "\n",
    "                        trj_dict[index_ts][peptide][position] = coordinate\n",
    "\n",
    "                        #features = [atom_number,peptide, res_name, position, coordinate]\n",
    "                        #features = [index_ts, peptide, res_position, res_name, position, atom_type, coordinate]\n",
    "\n",
    "                        #for_pandas.append(features)\n",
    "                        \n",
    "            else:\n",
    "                \n",
    "                for res in range(peptide_length):\n",
    "\n",
    "                    #res_name = (str(universe.residues[res + counter]).split()[1].split(',')[0])#.split(',')[0])\n",
    "                    #res_position = int(str(universe.residues[res + counter]).split()[2].split('>')[0])#.split(',')[0])\n",
    "                    #res_id = str(res_position) + '_' + res_name\n",
    "\n",
    "                    #print(str(universe.residues[res + counter]))\n",
    "\n",
    "                    for index, atom in enumerate(universe.residues[res + (counter)].atoms):\n",
    "\n",
    "                        #print(atom)\n",
    "\n",
    "                        atom_number = (int(str(atom).split()[1].split(':')[0]) - 1)\n",
    "\n",
    "                        #atom_type = str(atom).split()[2]\n",
    "\n",
    "                        coordinate = universe.atoms[atom_number].position\n",
    "\n",
    "                        position = len(trj_dict[index_ts][peptide])\n",
    "\n",
    "                        trj_dict[index_ts][peptide][position] = coordinate\n",
    "\n",
    "                        #features = [atom_number,peptide, res_name, position, coordinate]\n",
    "                        #features = [index_ts, peptide, res_position, res_name, position, atom_type, coordinate]\n",
    "\n",
    "                        #for_pandas.append(features)\n",
    "                \n",
    "\n",
    "\n",
    "    #start = timer()\n",
    "    #df = pd.DataFrame(for_pandas,columns=columns_name)\n",
    "    #end = timer()\n",
    "    #print(end-start)\n",
    "    return trj_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "a_new = get_dict_from_trajectory(prod_gro, prod_xtc)\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#start_from = 0\n",
    "#interval = 200\n",
    "\n",
    "#peptide_length = None\n",
    "#peptides_list = morphoscanner.topology.get_peptide_length_list(prod_gro)\n",
    "\n",
    "\n",
    "#n_pep = len(peptides_list)\n",
    "\n",
    "\n",
    "#else:\n",
    "\n",
    " #   n_pep = sum([(e//peptide_length) for e in peptides_list])\n",
    "\n",
    "#columns_name = ['atom_number','peptide_number', 'residue_name', 'residue_position', 'coordinates']\n",
    "#columns_name = ['time_step','peptide_number', 'residue_position', 'residue_name', 'atom_position', 'atom_type', 'coordinates']\n",
    "\n",
    "# create list for a pd.DataFrame\n",
    "# as suggested in https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.append.html\n",
    "#for_pandas = []\n",
    "\n",
    "def get_coordinate_dict_from_trajectory(trj_gro, trj_xtc, peptide_length=None, start_from=0, interval=0):\n",
    "\n",
    "    peptides_list = morphoscanner.topology.get_peptide_length_list(trj_gro)\n",
    "\n",
    "    universe = morphoscanner.topology.make_universe(trj_gro, trj_xtc)\n",
    "\n",
    "\n",
    "    if peptide_length == None:\n",
    "    \n",
    "\n",
    "        n_pep = len(peptides_list)\n",
    "\n",
    "\n",
    "    else:\n",
    "\n",
    "        n_pep = sum([(e//peptide_length) for e in peptides_list])\n",
    "\n",
    "\n",
    "    trj_dict = {}\n",
    "\n",
    "    for index_ts, ts in tqdm.tqdm(enumerate(universe.trajectory)):\n",
    "    #for index_ts, ts in enumerate(universe.trajectory):\n",
    "    \n",
    "        updated_index = (index_ts + start_from)\n",
    "\n",
    "        if (updated_index % interval) == 0:\n",
    "\n",
    "            trj_dict[updated_index] = {}\n",
    "\n",
    "            for peptide in range(n_pep):\n",
    "\n",
    "                trj_dict[updated_index][peptide] = {}\n",
    "\n",
    "\n",
    "                if peptide != 0:\n",
    "\n",
    "                    # if to check peptide_length\n",
    "\n",
    "                    if peptide_length == None:\n",
    "\n",
    "                        counter += peptides_list[peptide - 1]\n",
    "\n",
    "                    else:\n",
    "                        counter += peptide_length\n",
    "\n",
    "\n",
    "                else:\n",
    "                    counter = 0\n",
    "\n",
    "\n",
    "\n",
    "                if peptide_length == None:\n",
    "\n",
    "                    for res in range(peptides_list[peptide]):\n",
    "\n",
    "                        for index, atom in enumerate(universe.residues[res + (counter)].atoms):\n",
    "\n",
    "\n",
    "                            atom_type = str(atom).split()[2]\n",
    "                            \n",
    "                            if atom_type == 'BB':\n",
    "\n",
    "                                atom_number = (int(str(atom).split()[1].split(':')[0]) - 1)\n",
    "\n",
    "                                coordinate = universe.atoms[atom_number].position\n",
    "\n",
    "                                position = len(trj_dict[updated_index][peptide])\n",
    "\n",
    "\n",
    "                                trj_dict[updated_index][peptide][position] = coordinate\n",
    "\n",
    "               \n",
    "                else:\n",
    "\n",
    "                    for res in range(peptide_length):\n",
    "\n",
    "                        for index, atom in enumerate(universe.residues[res + (counter)].atoms):\n",
    "\n",
    "              \n",
    "                            atom_type = str(atom).split()[2]\n",
    "\n",
    "\n",
    "                            if atom_type == 'BB':\n",
    "\n",
    "                                atom_number = (int(str(atom).split()[1].split(':')[0]) - 1)\n",
    "\n",
    "                                coordinate = universe.atoms[atom_number].position\n",
    "\n",
    "                                position = len(trj_dict[updated_index][peptide])\n",
    "\n",
    "\n",
    "                                trj_dict[updated_index][peptide][position] = coordinate\n",
    "\n",
    "                            else:\n",
    "                                pass\n",
    "    \n",
    "    \n",
    "    return trj_dict\n",
    "\n",
    "\n",
    "                        \n",
    "                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "\n",
    "trj_dict = get_coordinate_dict_from_trajectory(prod_gro, prod_xtc)\n",
    "                        \n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "\n",
    "trj_dict_18mer = get_coordinate_dict_from_trajectory(prod_gro, prod_xtc, peptide_length=18)\n",
    "                       \n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot_peptide_list(trj_dict_18mer[0], [e for e in range(6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trj_dict_18mer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot_single_peptide(pep_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trj_dict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pep_dict = {}\n",
    "for i in range(12):\n",
    "    pep_dict[i] = trj_dict[0][0][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame20_fine_distance_maps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frame20_fine_distance_maps[18][18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frame20_fine_distance_maps[0][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame20_dict = trj_dict_6mer[4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame20_tens = morphoscanner.distance_tensor.get_coordinate_tensor_from_dict(frame20_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame20_distance = morphoscanner.distance_tensor.compute_euclidean_norm_torch(frame20_tens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frame20_distance[15][16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_20_contact_maps = morphoscanner.distance.compute_contact_maps_as_array(frame20_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frame_20_contact_maps[0][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_20_contact_maps = morphoscanner.distance.compute_contact_maps_as_array(frame20_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frame_20_contact_maps[15][26])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame20_denoised_contact = morphoscanner.denoise.denoise_contact_maps(frame_20_contact_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = morphoscanner.graph.nx_graph_search(frame20_denoised_contact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph = morphoscanner.graph.find_subgraph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot_peptide_list(frame20_dict, [469,468,473])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[i for e in subgraph for i in e]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_graph = morphoscanner.graph.full_graph(frame20_denoised_contact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(full_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_subraph = morphoscanner.graph.find_subgraph(full_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "frame20_gross_dict = trj_dict[4000]\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "\n",
    "start = timer()\n",
    "frame20_gross_distance_tens = morphoscanner.distance_tensor.get_coordinate_tensor_from_dict(frame20_gross_dict)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "\n",
    "start = timer()\n",
    "frame20_gross_distance_maps = morphoscanner.distance_tensor.compute_euclidean_norm_torch(frame20_gross_distance_tens)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "\n",
    "start = timer()\n",
    "frame20_gross_contact = morphoscanner.distance.compute_contact_maps_as_array(frame20_gross_distance_maps)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "\n",
    "start = timer()\n",
    "frame20_gross_denoised = morphoscanner.denoise.denoise_contact_maps(frame20_gross_contact)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#frame20_graph = morphoscanner.graph.nx_graph_search(frame20_denoised_contact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frame20_gross_denoised[15][16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "frame20_gross_graph = morphoscanner.graph.full_graph(frame20_gross_denoised)\n",
    "end = timer()\n",
    "print(end-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.trj_dict[4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(frame20_gross_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame20_gross_subgraph = morphoscanner.graph.find_subgraph(frame20_gross_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame20_gross_subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot_peptide_list(frame20_gross_dict, [e for e in frame20_gross_subgraph[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame20_gross_out = morphoscanner.graph.get_not_in_subgraph(frame20_gross_graph, frame20_gross_subgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame20_gross_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "trj_gross_dict = trj_dict[0]\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "\n",
    "start = timer()\n",
    "trj_gross_distance_tens = morphoscanner.distance_tensor.get_coordinate_tensor_from_dict(trj_gross_dict)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "\n",
    "start = timer()\n",
    "trj_gross_distance_maps = morphoscanner.distance_tensor.compute_euclidean_norm_torch(trj_gross_distance_tens)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "\n",
    "start = timer()\n",
    "trj_gross_contact = morphoscanner.distance.compute_contact_maps_as_array(trj_gross_distance_maps)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "\n",
    "start = timer()\n",
    "trj_gross_denoised = morphoscanner.denoise.denoise_contact_maps(trj_gross_contact)\n",
    "end = timer()\n",
    "print(end-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj_graph = morphoscanner.graph.full_graph(trj_gross_denoised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(trj_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "trj_pep_gross_dict = trj_dict_12mer[0]\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "\n",
    "start = timer()\n",
    "trj_pep_gross_distance_tens = morphoscanner.distance_tensor.get_coordinate_tensor_from_dict(trj_pep_gross_dict)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "\n",
    "start = timer()\n",
    "trj_pep_gross_distance_maps = morphoscanner.distance_tensor.compute_euclidean_norm_torch(trj_pep_gross_distance_tens)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "\n",
    "start = timer()\n",
    "trj_pep_gross_contact = morphoscanner.distance.compute_contact_maps_as_array(trj_pep_gross_distance_maps)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "\n",
    "start = timer()\n",
    "trj_pep_gross_denoised = morphoscanner.denoise.denoise_contact_maps(trj_pep_gross_contact)\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj_pep_graph = morphoscanner.graph.full_graph(trj_pep_gross_denoised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(trj_pep_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot_peptide_list(trj_dict[0], [e for e in trj_dict[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(trj_gross_distance_maps[26][24][:12,:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj_gross_distance_tens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "\n",
    "trj_dict_18mer = get_coordinate_dict_from_trajectory(prod_gro, prod_xtc, peptide_length=18)\n",
    "                        \n",
    "end = timer()\n",
    "print(end - start)\n",
    "\n",
    "start = timer()\n",
    "frame20_fine_tensor = morphoscanner.distance_tensor.get_coordinate_tensor_from_dict(trj_dict_18mer[4000])\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "\n",
    "start = timer()\n",
    "frame20_fine_distance_maps = morphoscanner.distance_tensor.compute_euclidean_norm_torch(frame20_fine_tensor)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "\n",
    "start = timer()\n",
    "frame20_fine_contact = morphoscanner.distance.compute_contact_maps_as_array(frame20_fine_distance_maps)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "\n",
    "start = timer()\n",
    "frame20_fine_denoised = morphoscanner.denoise.denoise_contact_maps(frame20_fine_contact)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "\n",
    "start = timer()\n",
    "frame20_fine_graph = morphoscanner.graph.nx_graph_search(frame20_fine_denoised)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "\n",
    "start = timer()\n",
    "frame20_fine_graph_full = morphoscanner.graph.full_graph(frame20_fine_denoised)\n",
    "end = timer()\n",
    "print(end-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "\n",
    "trj_dict_gross = get_coordinate_dict_from_trajectory(proclassd_gro, prod_xtc)\n",
    "                        \n",
    "end = timer()\n",
    "print(end - start)\n",
    "\n",
    "start = timer()\n",
    "frame20_gross_tensor = morphoscanner.distance_tensor.get_coordinate_tensor_from_dict(trj_dict_gross[4000])\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "\n",
    "start = timer()\n",
    "frame20_gross_distance_maps = morphoscanner.distance_tensor.compute_euclidean_norm_torch(frame20_gross_tensor)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "\n",
    "start = timer()\n",
    "frame20_gross_contact = morphoscanner.distance.compute_contact_maps_as_array(frame20_gross_distance_maps)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "\n",
    "start = timer()\n",
    "frame20_gross_denoised = morphoscanner.denoise.denoise_contact_maps(frame20_gross_contact)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "\n",
    "start = timer()\n",
    "frame20_gross_graph = morphoscanner.graph.nx_graph_search(frame20_gross_denoised)\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "\n",
    "start = timer()\n",
    "frame20_gross_graph_full = morphoscanner.graph.full_graph(frame20_gross_denoised)\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(frame20_fine_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(frame20_fine_graph_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot_single_peptide(trj_dict_18mer[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(frame20_gross_graph_full)class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(frame20_gross_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame20_gross_subgraph = morphoscanner.graph.find_subgraph(frame20_gross_graph_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame20_gross_subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_analysis(frame_dict):\n",
    "    \n",
    "    #trj_dict= get_coordinate_dict_from_trajectory(prod_gro, prod_xtc, peptide_length)\n",
    "\n",
    "    frame_tensor = morphoscanner.distance_tensor.get_coordinate_tensor_from_dict(frame_dict)\n",
    "\n",
    "    frame_distance_maps = morphoscanner.distance_tensor.compute_euclidean_norm_torch(frame_tensor)\n",
    "\n",
    "    frame_contact = morphoscanner.distance.compute_contact_maps_as_array(frame_distance_maps)\n",
    "\n",
    "    frame_denoised = morphoscanner.denoise.denoise_contact_maps(frame_contact)\n",
    "\n",
    "    frame_graph = morphoscanner.graph.nx_graph_search(frame_denoised)\n",
    "\n",
    "    frame_graph_full = morphoscanner.graph.full_graph(frame_denoised)\n",
    "    \n",
    "    return frame_graph, frame_contact\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj_dict= morphoscanner.topology.get_coordinate_dict_from_trajectory(prod_gro, prod_xtc, peptide_length=18, interval=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_dict = trj_dict[4000]\n",
    "\n",
    "frame_tensor = morphoscanner.distance_tensor.get_coordinate_tensor_from_dict(frame_dict)\n",
    "\n",
    "frame_distance_maps = morphoscanner.distance_tensor.compute_euclidean_norm_torch(frame_tensor)\n",
    "\n",
    "frame_contact = morphoscanner.distance.compute_contact_maps_as_array(frame_distance_maps)\n",
    "\n",
    "frame_denoised, df = morphoscanner.denoise.denoise_contact_maps(frame_contact)\n",
    "\n",
    "frame_graph = morphoscanner.graph.nx_graph_search(frame_denoised)\n",
    "\n",
    "frame_graph_full = morphoscanner.graph.full_graph(frame_denoised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_names = ['Normalized Cross Correlation Value', 'shift index', 'contacts', 'sense']\n",
    "\n",
    "df = pd.DataFrame(max_val, columns=columns_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[e for e in max_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        #def normalized_cross_correlation_for_dataset(contact_array):\n",
    "            #'''Calculate normalized cross correlation function between the full contacts map and and the .\n",
    "\n",
    "#            Arguments : contact map, as output from get_contact_maps function\n",
    "#                        shift_matrix_stack, as output from shift_matrix_maker function\n",
    "#\n",
    "#            Return : a list [ncc_value, index (in the shift_matrix_stack) of the shift matrix that is matching the contact map'''\n",
    "#\n",
    "contact_array = frame_contact\n",
    "        \n",
    "contact_dict = {}\n",
    "\n",
    "#for row in tqdm.tqdm(range(contact_array.shape[0])):\n",
    "for row in range(contact_array.shape[0]):\n",
    "\n",
    "    for col in range((row+1), contact_array.shape[1]):\n",
    "        \n",
    "        best_match = []\n",
    "        best_match = morphoscanner.cross_correlation.normalized_cross_correlation_function(contact_array[row][col])\n",
    "\n",
    "        if len(best_match) == 0:\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "            if row in contact_dict:\n",
    "                contact_dict[row].append([row, col, best_match])\n",
    "\n",
    "            else:\n",
    "                contact_dict[row] = [[row, col, best_match]]\n",
    "\n",
    "#return contact_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contact_array = frame_contact\n",
    "def cross_correlation_function_for_dataset_with_dataframe(contact_array):\n",
    "    '''Perform Normalized Cross Correlation function on the dataset\n",
    "        to check for contact. Get a dict for processing and a pandas.DataFrame\n",
    "        for data analysis\n",
    "        \n",
    "        Input: contact maps\n",
    "        \n",
    "        Output: contact_dict,         for further processing\n",
    "                pandas.DataFrame,     for data analysis\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    contact_dict = {}\n",
    "\n",
    "    for row in range(contact_array.shape[0]):\n",
    "\n",
    "        for col in range((row+1), contact_array.shape[1]):\n",
    "            best_match = []\n",
    "            best_match = morphoscanner.cross_correlation.normalized_cross_correlation_function(contact_array[row][col])\n",
    "\n",
    "            if len(best_match) == 0:\n",
    "                pass\n",
    "\n",
    "            else:\n",
    "                if row in contact_dict:\n",
    "                    contact_dict[row].append([row, col, best_match])\n",
    "\n",
    "                else:\n",
    "                    contact_dict[row] = [[row, col, best_match]]\n",
    "\n",
    "    contact_list = contact_list_from_dict(contact_dict)\n",
    "\n",
    "    columns_names = ['peptide1', 'peptide2', 'NCC Value', 'shift index', 'contacts', 'sense']\n",
    "\n",
    "    df = pd.DataFrame(contact_list, columns=columns_names)\n",
    "    \n",
    "    return contact_dict, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contact_dict, df = cross_correlation_function_for_dataset(frame_contact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('sense').get_group('antiparallel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contact_list = []\n",
    "for peptide in contact_dict:\n",
    "    \n",
    "    for contact in contact_dict[peptide]:\n",
    "        \n",
    "        contact_list.append(contact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contact_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_names = ['peptide1', 'peptide2', 'NCC Value', 'shift index', 'contacts', 'sense']\n",
    "\n",
    "df = pd.DataFrame(contact_list, columns=columns_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df.groupby(['peptide1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = df.groupby(['peptide2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.groups.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contact_list_from_dict(contact_dict):\n",
    "    contact_list = []\n",
    "    for peptide in contact_dict:\n",
    "\n",
    "        for contact in contact_dict[peptide]:\n",
    "\n",
    "            new_data = [contact[0], contact[1], contact[2][0], contact[2][1], contact[2][2], contact[2][3]]\n",
    "            contact_list.append(new_data)\n",
    "    return contact_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contact_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(contact_array[0][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(contact_array[3][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = morphoscanner.cross_correlation.shift_library_maker(contact_array[0][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(matrix['antiparallel'][29])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = morphoscanner.cross_correlation.normalized_cross_correlation_function(contact_array[3][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class aggregate(object):\n",
    "    \n",
    "    trj_dict= morphoscanner.topology.get_coordinate_dict_from_trajectory(prod_gro, prod_xtc, peptide_length=18, interval=200)\n",
    "    frame_dict = trj_dict[4000]\n",
    "\n",
    "    frame_tensor = morphoscanner.distance_tensor.get_coordinate_tensor_from_dict(frame_dict)\n",
    "\n",
    "    frame_distance_maps = morphoscanner.distance_tensor.compute_euclidean_norm_torch(frame_tensor)\n",
    "\n",
    "    frame_contact = morphoscanner.distance.compute_contact_maps_as_array(frame_distance_maps)\n",
    "\n",
    "    frame_denoised, df = morphoscanner.denoise.denoise_contact_maps(frame_contact)\n",
    "\n",
    "    frame_graph = morphoscanner.graph.nx_graph_search(frame_denoised)\n",
    "\n",
    "    frame_graph_full = morphoscanner.graph.full_graph(frame_denoised)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(aggregate.frame_distance_maps[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate.frame_graph_full.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class trajectory:\n",
    "    \n",
    "    '''Class to operate on trajectory files.\n",
    "    \n",
    "    It makes an object that contain the trajectory of the simulation'''\n",
    "    \n",
    "    \n",
    "\n",
    "    def __init__(self, trj_gro, trj_xtc):\n",
    "        \n",
    "        self.trj_gro = trj_gro\n",
    "        self.trj_xtc = trj_xtc\n",
    "        self.universe = morphoscanner.topology.make_universe(self.trj_gro, self.trj_xtc)\n",
    "        self.peptide_length_list = morphoscanner.topology.get_peptide_length_list(self.trj_gro)\n",
    "        #self.topology = morphoscanner.topology.get_peptide_length_list(self.trj_gro)\n",
    "        self.number_of_frames = len(self.universe.trajectory)\n",
    "        \n",
    "        self.frames = {}\n",
    "\n",
    "        \n",
    "    \n",
    "    def compose_database(self, peptide_length=None, start_from=0, interval=0):\n",
    "        \n",
    "        self.peptide_length = peptide_length\n",
    "        self.start_from = start_from\n",
    "        self.interval = interval\n",
    "        \n",
    "        self.data = morphoscanner.topology.get_coordinate_dict_from_trajectory(self.trj_gro, self.trj_xtc, peptide_length=self.peptide_length, start_from=self.start_from, interval=self.interval)\n",
    "        self.sampled_frames = [key for key in self.data.keys()]\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def analysis(self, frame):\n",
    "        \n",
    "        # WHY len(frame_denoised) is len(frame_dict)-1 ???????\n",
    "        \n",
    "        self.frame = frame        \n",
    "    \n",
    "        self.frame_dict = self.data[self.frame]\n",
    "\n",
    "        self.frame_tensor = morphoscanner.distance_tensor.get_coordinate_tensor_from_dict(self.frame_dict)\n",
    "\n",
    "        self.frame_distance_maps = morphoscanner.distance_tensor.compute_euclidean_norm_torch(self.frame_tensor)\n",
    "\n",
    "        self.frame_contact = morphoscanner.distance.compute_contact_maps_as_array(self.frame_distance_maps)\n",
    "\n",
    "        self.frame_denoised, self.df = morphoscanner.denoise.denoise_contact_maps(self.frame_contact)\n",
    "\n",
    "        self.frame_graph = morphoscanner.graph.nx_graph_search(self.frame_denoised)\n",
    "\n",
    "        self.frame_graph_full = morphoscanner.graph.graph_v1(self.frame_denoised, self.df)\n",
    "        \n",
    "        self.subgraphs = morphoscanner.graph.find_subgraph(self.frame_graph_full)\n",
    "        \n",
    "        if self.frame not in self.frames:\n",
    "            \n",
    "            self.frames[self.frame] = {'frame_dict': self.frame_dict,\n",
    "                                       'frame_denoised': self.frame_denoised,\n",
    "                                          'frame_data' : self.df,\n",
    "                                          'frame_graph' : self.frame_graph,\n",
    "                                          'frame_graph_full' : self.frame_graph_full,\n",
    "                                          'subgraphs_full' : self.subgraphs}            \n",
    "            \n",
    "            \n",
    "    def analyze_inLoop(self):\n",
    "        \n",
    "        if hasattr(self, 'sampled_frames'):\n",
    "            print('processing started...')\n",
    "            start = timer()\n",
    "            for frame in self.sampled_frames:\n",
    "                start_an = timer()\n",
    "                self.analysis(frame)\n",
    "                end_an = timer()\n",
    "                text= 'Time needed to analyze frame %d is %f seconds' % (frame, (end_an-start_an))\n",
    "                print(text)\n",
    "\n",
    "            end = timer()\n",
    "\n",
    "\n",
    "            print('Total time to analyze dataset is %f seconds' % (end -start))\n",
    "  \n",
    "        else:\n",
    "            print('You have to compose the database before analyze it.')\n",
    "            \n",
    "            print('Use \"compose_database\" attribute to make a database first!')\n",
    "            \n",
    "        return\n",
    "            \n",
    "    \n",
    "    \n",
    "    def get_sense(self):\n",
    "        \n",
    "    \n",
    "        sense_dict = {}\n",
    "\n",
    "        for e in self.frames:\n",
    "\n",
    "            parallel = len(self.frames[e]['frame_data'].groupby('sense').get_group('parallel'))\n",
    "            antiparallel = len(self.frames[e]['frame_data'].groupby('sense').get_group('antiparallel'))\n",
    "\n",
    "            sense_dict[e] = {  'parallel' : parallel,\n",
    "                               'antiparallel' : antiparallel}\n",
    "            \n",
    "            \n",
    "        self.sense_df = pd.DataFrame.from_dict(sense_dict, orient='index')\n",
    "\n",
    "\n",
    "        return\n",
    "    \n",
    "    \n",
    "    \n",
    "    def subgraph_length_peptide(self):\n",
    "        '''Get information about the size of the aggregates in the trajectory\n",
    "\n",
    "        Argument: aggregate\n",
    "\n",
    "        return: dict, keys = frame number,\n",
    "                      value = a sorted list (big to small) of the aggregate size in that frame\n",
    "\n",
    "\n",
    "        '''\n",
    "    \n",
    "        if len(self.frames) > 0:\n",
    "            \n",
    "        \n",
    "            subgraph_size_peptide = {}\n",
    "\n",
    "            for key in self.frames.keys():\n",
    "                \n",
    "                subgraph_dict = {}\n",
    "\n",
    "                subgraph_dict[key] = morphoscanner.graph.find_subgraph(self.frames[key]['frame_graph_full'])\n",
    "\n",
    "                len_list = []\n",
    "\n",
    "                for i in subgraph_dict[key]:\n",
    "\n",
    "                    len_list.append(len(i))\n",
    "\n",
    "                len_list.sort(reverse=True)\n",
    "\n",
    "                subgraph_size_peptide[key] = [len_list]\n",
    "                \n",
    "        \n",
    "        self.subgraph_len_pep_df = pd.DataFrame.from_dict(subgraph_size_peptide, orient='index', columns=['n° of peptides in macroaggregates'])\n",
    "\n",
    "        #else:\n",
    "         #   print('You have to analyze one or more frame before analyze the results.')\n",
    "         #   print('Use \"Analyze\" or \"AnalyzeInLoop\" on the dataset first!')\n",
    "        \n",
    "        return\n",
    "\n",
    "\n",
    "    \n",
    "    def subgraph_length_seed(self):\n",
    "        '''Get information about the size of the aggregates in the trajectory\n",
    "\n",
    "        Argument: aggregate\n",
    "\n",
    "        return: dict, keys = frame number,\n",
    "                      value = a sorted list (big to small) of the aggregate size in that frame\n",
    "\n",
    "\n",
    "        '''\n",
    "        if len(self.frames) > 0:\n",
    "                  \n",
    "            self.subgraph_size_seed = {}\n",
    "\n",
    "            for key in self.frames.keys():\n",
    "                \n",
    "                subgraph_dict = {}\n",
    "\n",
    "                subgraph_dict[key] = morphoscanner.graph.find_subgraph(self.frames[key]['frame_graph'])\n",
    "\n",
    "                len_list = []\n",
    "\n",
    "                for i in subgraph_dict[key]:\n",
    "\n",
    "                    len_list.append(len(i))\n",
    "\n",
    "                len_list.sort(reverse=True)\n",
    "\n",
    "                self.subgraph_size_seed[key] = [len_list]\n",
    "\n",
    "            #return self.seed_subgraph_len\n",
    "        \n",
    "        #else:\n",
    "           # print('You have to analyze one or more frame before analyze the results.')\n",
    "            #print('Use \"Analyze\" or \"AnalyzeInLoop\" on the dataset first!'')\n",
    "\n",
    "        return\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def macroaggregate_sense_data(self):\n",
    "    \n",
    "        macroaggregate_sense_dict = {}\n",
    "\n",
    "        for frame in self.frames:\n",
    "            graph = self.frames[frame]['frame_graph_full']\n",
    "            subs = self.frames[frame]['subgraphs_full']\n",
    "            #senses = contact_sense_in_subgraph(graph, subs)\n",
    "            #sense_counter = count_sense_in_subgraph(senses)\n",
    "            sense_counter = morphoscanner.graph.sense_in_subgraph(graph, subs)\n",
    "            macroaggregate_sense_dict[frame] = sense_counter\n",
    "\n",
    "        self.macroaggregate_df = pd.DataFrame.from_dict(macroaggregate_sense_dict, orient='index')\n",
    "        \n",
    "        return\n",
    "    \n",
    "    \n",
    "    def get_data(self):\n",
    "        self.get_sense()\n",
    "        self.subgraph_length_peptide()\n",
    "        self.macroaggregate_sense_data()\n",
    "\n",
    "        self.database = pd.concat((prod_test.subgraph_len_pep_df, prod_test.sense_df, prod_test.macroaggregate_df), axis=1)\n",
    "\n",
    "        return\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prod = trajectory(trj_gro=prod_gro, trj_xtc=prod_xtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = morphoscanner.trajectory(trj_gro=prod_gro, trj_xtc=prod_xtc, peptide_length=18, interval=200, frame=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(a.universe.trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(a.frames[4000]['frame_graph'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prod.compose_database(peptide_length=18, interval=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "for frame in aggregate.sampled_frames:\n",
    "    start_an = timer()\n",
    "    aggregate.analysis(frame)\n",
    "    end_an = timer()\n",
    "    text= 'Time needed to analyze frame %d is %f seconds' % (frame, (end_an-start_an))\n",
    "\n",
    "    print(text)\n",
    "    \n",
    "end = timer()\n",
    "\n",
    "\n",
    "print('Total time to analyze dataset is %f seconds' % (end -start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod.analyze_inLoop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.frames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in a.sampled_frames:\n",
    "    print(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a.frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.frames[0]['frame_graph']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.graph.find_subgraph(a.frames[0]['frame_graph'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frm = 0\n",
    "tme = 1.111\n",
    "text= 'analysis of frame %d is %f' % (frm, tme)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(a.frames[2800]['frame_graph_full'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph = find_subgraph(a.frames[2800]['frame_graph_full'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([e for i in subgraph for e in i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_subgraph_disordered(graph):\n",
    "    '''\n",
    "    Find subgraph of joined peptides that have no node in common.\n",
    "    It start to search from always from peptide 0, and from that does depth first search.\n",
    "    The peptide of the subgraph that are touching are in consequential order in the sublist\n",
    "\n",
    "    Argument: NetworkX MultiGraph\n",
    "\n",
    "    Return: list of subgraph ordered from one end to the other\n",
    "\n",
    "    '''\n",
    "\n",
    "    subgraph_list = []\n",
    "\n",
    "    for node in graph:\n",
    "\n",
    "        # don't explore node that are already in subgraph_list\n",
    "        if node not in set(nod for nod_list in subgraph_list for nod in nod_list):\n",
    "\n",
    "            # tree is the list of nodes joined to node, starting from node\n",
    "            # using depht first search\n",
    "            tree = [e for e in nx.algorithms.traversal.depth_first_search.dfs_tree(graph, node)]\n",
    "\n",
    "            # check if the first node of the tree has adjiacency == 1\n",
    "            # so it checks if it is the first or last node of the subgraph\n",
    "            #if len(graph[tree[0]]) == 1:\n",
    "\n",
    "            if len(subgraph_list) == 0:\n",
    "                subgraph_list.append(tree)\n",
    "\n",
    "            else:\n",
    "                # use generator to check if the tree is already in the subgraph\n",
    "                if set(tree) not in (set(i) for i in subgraph_list):\n",
    "                    subgraph_list.append(tree)\n",
    "\n",
    "    return subgraph_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old = aggregate(trj_gro, trj_xtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old.compose_database(peptide_length=12, interval=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old.sampled_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_inLoop(aggregate):\n",
    "\n",
    "    start = timer()\n",
    "    for frame in aggregate.sampled_frames:\n",
    "        start_an = timer()\n",
    "        aggregate.analysis(frame)\n",
    "        end_an = timer()\n",
    "        text= 'Time needed to analyze frame %d is %f seconds' % (frame, (end_an-start_an))\n",
    "\n",
    "        print(text)\n",
    "\n",
    "    end = timer()\n",
    "\n",
    "\n",
    "    print('Total time to analyze dataset is %f seconds' % (end -start))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "analyze_inLoop(old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(old.frames[150]['frame_graph_full'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1 = morphoscanner.graph.find_subgraph(old.frames[150]['frame_graph_full'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub2 = find_subgraph_disordered(old.frames[150]['frame_graph_full'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if set(tree) not in (set(i) for i in subgraph_list):\n",
    "                    subgraph_list.append(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[set(e) for e in sub1] == [set(i) for i in sub2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def subgraph_length(aggregate):\n",
    "    '''Get information about the size of the aggregates in the trajectory\n",
    "    \n",
    "    Argument: aggregate\n",
    "    \n",
    "    return: dict, keys = frame number,\n",
    "                  value = a sorted list (big to small) of the aggregate size in that frame\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    subgraph_len_dict = {}\n",
    "\n",
    "    for key in aggregate.frames.keys():\n",
    "\n",
    "        subgraph_dict[key] = morphoscanner.graph.find_subgraph(aggregate.frames[key]['frame_graph_full'])\n",
    "\n",
    "        len_list = []\n",
    "\n",
    "        for i in subgraph_dict[key]:\n",
    "\n",
    "            len_list.append(len(i))\n",
    "\n",
    "        len_list.sort(reverse=True)\n",
    "\n",
    "        subgraph_len_dict[key] = len_list\n",
    "        \n",
    "        return subgraph_len_dict\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_list = []\n",
    "\n",
    "for i in subgraph_dict[0]:\n",
    "    \n",
    "    len_list.append(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_list.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.sampled_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(old.frames[0]['frame_data'].groupby('sense').get_group('antiparallel'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sense(self):\n",
    "    \n",
    "    sense_dict = {}\n",
    "\n",
    "    for e in self.frames:\n",
    "\n",
    "        parallel = len(self.frames[e]['frame_data'].groupby('sense').get_group('parallel'))\n",
    "        antiparallel = len(self.frames[e]['frame_data'].groupby('sense').get_group('antiparallel'))\n",
    "\n",
    "        sense_dict[e] = {'parallel' : parallel,\n",
    "                        'antiparallel' : antiparallel}\n",
    "    \n",
    "    return sense_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sense_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(self.frames) > 0:\n",
    "    print('ok')\n",
    "\n",
    "else:\n",
    "    print('To find subgraph in a graph, you have to compute the graph.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(a, 'sampled_frames'):\n",
    "    print('is there! \\nciao')\n",
    "    \n",
    "else:\n",
    "    print('is not there...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod = trajectory(prod_gro, prod_xtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prod.compose_database(peptide_length=18, interval=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod.analyze_inLoop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod.frames.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod.subgraph_length_peptide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod.subgraph_length_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[e] for e in prod.subgraph_length_peptide[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_len_pep = pd.DataFrame.from_dict(prod.subgraph_length_peptide, orient='index', columns=['n° of peptides in macroaggregate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subgraph_length_peptide(self):\n",
    "    '''Get information about the size of the aggregates in the trajectory\n",
    "\n",
    "    Argument: aggregate\n",
    "\n",
    "    return: dict, keys = frame number,\n",
    "                  value = a sorted list (big to small) of the aggregate size in that frame\n",
    "\n",
    "\n",
    "    '''\n",
    "\n",
    "    if len(self.frames) > 0:\n",
    "\n",
    "\n",
    "        self.peptide_subgraph_len = {}\n",
    "\n",
    "        for key in self.frames.keys():\n",
    "            \n",
    "            subgraph_dict = {}\n",
    "\n",
    "            subgraph_dict[key] = morphoscanner.graph.find_subgraph(self.frames[key]['frame_graph_full'])\n",
    "\n",
    "            len_list = []\n",
    "\n",
    "            for i in subgraph_dict[key]:\n",
    "\n",
    "                len_list.append(len(i))\n",
    "\n",
    "            len_list.sort(reverse=True)\n",
    "\n",
    "            self.peptide_subgraph_len[key] = len_list\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making function\n",
    "\n",
    "# dataframe making from subgraph\n",
    "# single peptide\n",
    "\n",
    "sub_len_pep = pd.DataFrame.from_dict(prod.subgraph_size_peptide, orient='index', columns=['n° of peptides in macroaggregate'])\n",
    "\n",
    "# seeds\n",
    "\n",
    "sub_len_seed = pd.DataFrame.from_dict(prod.subgraph_size_seed, orient='index', columns=['n° macroaggregate'])\n",
    "# seeds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_len_pep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_len_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod.get_sense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sense = pd.DataFrame.from_dict(prod.sense_dict, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod.sense_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_len_pep.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrg = pd.concat([sub_len_pep,sub_len_seed,sense], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot_peptide_list(prod.frames[4000]['frame_dict'], [e for e in prod.frames[0]['frame_dict']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod.number_of_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod1 = trajectory(prod1_gro, prod1_xtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod1.compose_database(peptide_length=18, interval=99, start_from=prod.number_of_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod1.analyze_inLoop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot_peptide_list(prod1.frames[4356]['frame_dict'], [e for e in prod1.frames[4356]['frame_dict']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod1.sampled_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod1.subgraph_length_peptide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod1.subgraph_length_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod1.get_sense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "antiparallel = len(prod1.frames[4356]['frame_data'].groupby('sense').get_group('antiparallel'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "antiparallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod1.frames[4356]['frame_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod1.frames[4356]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err4356 = morphoscanner.topology.get_coordinate_dict_from_trajectory(prod1_gro, prod1_xtc, peptide_length=18, start_from=4016, interval=99)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in err4356[4356]:\n",
    "    print(len(err4356[4356][i]))\n",
    "    #for e in err4356[4356][i]:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_tens = morphoscanner.distance_tensor.get_coordinate_tensor_from_dict(err4356[4356])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = morphoscanner.distance_tensor.compute_euclidean_norm_torch(err_tens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contact = morphoscanner.distance.compute_contact_maps_as_array(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised, datafr = morphoscanner.denoise.denoise_contact_maps(contact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contact.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dist[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_old = morphoscanner.distance.compute_distance_maps_from_coordinate_dict(err4356[4356])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafr[150:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(contact[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_old[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot_peptide_list(err4356[4356], [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_cross_correlation_results, df = morphoscanner.cross_correlation.cross_correlation_function_for_dataset_with_dataframe(contact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(normalized_cross_correlation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_cross_correlation_function(contact_map, minimum_contact=2):\n",
    "    '''\n",
    "    Calculate normalized cross correlation function between a contact map and an ideal map.\n",
    "\n",
    "    Arguments : contact map, as output from get_contact_maps function\n",
    "                shift_matrix_stack, as output from shift_matrix_maker function\n",
    "\n",
    "    Return : a list [ncc_value, index (in the shift_matrix_stack) of the shift matrix\n",
    "                that is matching the contact map\n",
    "\n",
    "            '''\n",
    "    shift_matrix_library = morphoscanner.cross_correlation.shift_library_maker(contact_map)\n",
    "\n",
    "    cross_correlation_values = []\n",
    "    max_val = []\n",
    "    sum_contact_map = np.sum(contact_map)\n",
    "\n",
    "    if sum_contact_map < minimum_contact:\n",
    "        pass\n",
    "\n",
    "    else:\n",
    "        for sense in shift_matrix_library:\n",
    "            for index, z in enumerate(shift_matrix_library[sense]):\n",
    "\n",
    "                shift_matrix = shift_matrix_library[sense][index]\n",
    "                sum_shift_matrix = np.sum(shift_matrix)\n",
    "                ncc_value = (np.sum((contact_map * shift_matrix))/((np.sqrt(sum_contact_map))*(np.sqrt(sum_shift_matrix))))  # normalized cross correlation function of contact matrix and shift matrix\n",
    "                cross_correlation_values.append([ncc_value, index, sum_contact_map, sense])\n",
    "\n",
    "            max_val = max(cross_correlation_values) # get only the best match (highest value of ncc)\n",
    "\n",
    "    return max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  #contact_array = frame_contact\n",
    "def cross_correlation_function_for_dataset_with_dataframe(contact_array):\n",
    "    '''Perform Normalized Cross Correlation function on the dataset\n",
    "        to check for contact. Get a dict for processing and a pandas.DataFrame\n",
    "        for data analysis\n",
    "\n",
    "        Input: contact maps\n",
    "\n",
    "        Output: contact_dict,         for further processing\n",
    "                pandas.DataFrame,     for data analysis\n",
    "\n",
    "\n",
    "    '''\n",
    "    contact_dict = {}\n",
    "\n",
    "    for row in range(contact_array.shape[0]):\n",
    "\n",
    "        for col in range((row+1), contact_array.shape[1]):\n",
    "            best_match = []\n",
    "            best_match = morphoscanner.cross_correlation.normalized_cross_correlation_function(contact_array[row][col])\n",
    "\n",
    "            if len(best_match) == 0:\n",
    "                pass\n",
    "\n",
    "            else:\n",
    "                if row in contact_dict:\n",
    "                    contact_dict[row].append([row, col, best_match])\n",
    "\n",
    "                else:\n",
    "                    contact_dict[row] = [[row, col, best_match]]\n",
    "\n",
    "    contact_list = morphoscanner.utility.contact_list_from_dict(contact_dict)\n",
    "\n",
    "    columns_names = ['peptide1', 'peptide2', 'NCC Value', 'shift index', 'contacts', 'sense']\n",
    "\n",
    "    df = pd.DataFrame(contact_list, columns=columns_names)\n",
    "\n",
    "    return contact_dict, df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = cross_correlation_function_for_dataset_with_dataframe(contact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contact_array = contact\n",
    "\n",
    "contact_dict = {}\n",
    "\n",
    "for row in range(contact_array.shape[0]):\n",
    "\n",
    "    for col in range((row+1), contact_array.shape[1]):\n",
    "        best_match = []\n",
    "        best_match = morphoscanner.cross_correlation.normalized_cross_correlation_function(contact_array[row][col])\n",
    "\n",
    "        print(best_match)\n",
    "\n",
    "        if len(best_match) == 0:\n",
    "            pass\n",
    "\n",
    "        \n",
    "        else:\n",
    "            if row in contact_dict:\n",
    "                contact_dict[row].append([row, col, best_match])\n",
    "\n",
    "            else:\n",
    "                contact_dict[row] = [[row, col, best_match]]\n",
    "\n",
    "            #best_match = []\n",
    "            #best_match = morphoscanner.cross_correlation.normalized_cross_correlation_function(contact_array[row][col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contact_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contact_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dist[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uno = err4356[4356][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "due = err4356[4356][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.distance.get_euclidean_distance(uno, due)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPUTE CONTACT MAPS\n",
    "# TO DO: parametrize the threshold distance in a better way (e.g. )\n",
    "# DISTANCE MAP ARRAY WILL NOT EXIST IN DISTINCT PEPTIDE SIZE SIMULATION\n",
    "def compute_contact_maps_as_array(distance_maps_array, radius_multiplier=1.5):\n",
    "\n",
    "    # median consecutive residue distance from first peptide\n",
    "    distances_pep_1 = []\n",
    "    for i in range(aaa.frame_distance_maps[0][0].shape[0] - 1):\n",
    "        distances_pep_1.append(aaa.frame_distance_maps[0][0][i][i+1])\n",
    "\n",
    "    intrapeptide_minimum_distance = np.median(distances_pep_1)\n",
    "\n",
    "    contact_map_list = []\n",
    "\n",
    "    # contact is in a distance up to 150% of the intrapeptide_minimum_distance [TO IMPROVE!!!]\n",
    "    threshold_distance = (intrapeptide_minimum_distance * radius_multiplier)\n",
    "\n",
    "    for model_1 in range(distance_maps_array.shape[0]):\n",
    "        contact_map_list.append([])\n",
    "        for model_2 in range(distance_maps_array[model_1].shape[0]):\n",
    "\n",
    "            contact_map_list[model_1].append([])\n",
    "\n",
    "            if model_1 == model_2:\n",
    "\n",
    "                contact_map_list[model_1][model_2].extend(np.zeros((distance_maps_array.shape[2], distance_maps_array.shape[3])))\n",
    "\n",
    "            else:\n",
    "\n",
    "                contact_map = np.zeros((distance_maps_array.shape[2], distance_maps_array.shape[3]))\n",
    "\n",
    "                for chain_1 in range(distance_maps_array[model_1][model_2].shape[0]):\n",
    "\n",
    "                    for chain_2 in range(distance_maps_array[model_1][model_2][chain_1].shape[0]):\n",
    "\n",
    "                        distance = distance_maps_array[model_1][model_2][chain_1][chain_2]\n",
    "\n",
    "                        if distance < threshold_distance:\n",
    "                            contact_map[chain_1][chain_2] = 1 #True\n",
    "                        else:\n",
    "                            pass\n",
    "\n",
    "                contact_map_list[model_1][model_2].extend(contact_map)\n",
    "\n",
    "    contact_array = np.asarray(contact_map_list)\n",
    "\n",
    "    return contact_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod = trajectory(prod_gro, prod_xtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod.compose_database(peptide_length=18, interval=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod.analyze_inLoop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod1 = trajectory(prod1_gro, prod1_xtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod1.compose_database(peptide_length=18, interval=400, start_from=prod.number_of_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod1.analyze_inLoop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod1.get_sense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod.get_sense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sense_full = prod.sense_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sense_full = prod.sense_dict\n",
    "sense_full.update(prod1.sense_dict)\n",
    "sense_df = pd.DataFrame.from_dict(sense_full, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sense_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sense_df = pd.DataFrame.from_dict(sense_full, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sense_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [e for e in sense_full]\n",
    "parallel = [sense_full[e]['parallel'] for e in sense_full]\n",
    "antiparallel = [sense_full[e]['parallel'] for e in sense_full]\n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "#rects1 = ax.bar(x - width/2, parallel, width, label='Parallel')\n",
    "#rects2 = ax.bar(x + width/2, antiparallel, width, label='Antiparallel')\n",
    "rects1 = ax.bar(x - width/2, parallel, width, label='Parallel')\n",
    "rects2 = ax.bar(x + width/2, antiparallel, width, label='Antiparallel')\n",
    "\n",
    "\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Number of contact')\n",
    "ax.set_title('Sente of peptides in the trajectory')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "def autolabel(rects):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    #xy=(rect.get_x(), height),\n",
    "\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "\n",
    "#fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod.subgraph_length_peptide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod.subgraph_length_peptide()\n",
    "prod.subgraph_length_seed()\n",
    "\n",
    "prod1.subgraph_length_peptide()\n",
    "prod1.subgraph_length_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod1.subgraph_length_peptide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod1.subgraph_length_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj_subgraph_peptide = prod.subgraph_size_peptide\n",
    "trj_subgraph_peptide.update(prod1.subgraph_size_peptide)\n",
    "\n",
    "subgraph_pep_df = pd.DataFrame.from_dict(trj_subgraph_peptide, orient='index', columns=['n° of peptides in macroaggregates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj_subgraph_seed = prod.subgraph_size_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj_subgraph_seed.update(prod1.subgraph_size_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj_subgraph_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod1.frames[4800]['frame_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "morphoscanner.plot.plot_peptide_list(prod1.frames[4800]['frame_dict'], [e for e in prod1.frames[4800]['frame_dict']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph_pep_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_number = {}\n",
    "for e in subgraph_pep_df.index:\n",
    "    #print(len(subgraph_pep_df.loc[e]['n° of peptides in macroaggregates']))\n",
    "\n",
    "    agg_number[e] = len(subgraph_pep_df.loc[e]['n° of peptides in macroaggregates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_len = pd.DataFrame.from_dict(agg_number, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod = trajectory(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recap for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sense dataframe\n",
    "\n",
    "prod.get_sense()\n",
    "prod1.get_sense()\n",
    "\n",
    "sense_full = prod.sense_dict\n",
    "sense_full.update(prod1.sense_dict)\n",
    "sense_df = pd.DataFrame.from_dict(sense_full, orient='index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate size\n",
    "\n",
    "prod.subgraph_length_peptide()\n",
    "prod.subgraph_length_seed()\n",
    "\n",
    "prod1.subgraph_length_peptide()\n",
    "prod1.subgraph_length_seed()\n",
    "\n",
    "trj_subgraph_peptide = prod.subgraph_size_peptide\n",
    "trj_subgraph_peptide.update(prod1.subgraph_size_peptide)\n",
    "\n",
    "subgraph_pep_df = pd.DataFrame.from_dict(trj_subgraph_peptide, orient='index', columns=['n° of peptides in macroaggregates'])\n",
    "\n",
    "\n",
    "trj_subgraph_seed = prod.subgraph_size_seed\n",
    "trj_subgraph_seed.update(prod1.subgraph_size_seed)\n",
    "\n",
    "subgraph_seed_df = pd.DataFrame.from_dict(trj_subgraph_seed, orient='index', columns=['n° of macroaggregates'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_peptide = {}\n",
    "for i in prod.subgraph_size_peptide:\n",
    "    number_of_peptide[i] = len(prod.subgraph_size_peptide[i][0])\n",
    "    \n",
    "number_of_peptide_df = pd.DataFrame.from_dict(number_of_peptide, orient='index', columns=['n° of macroaggreates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod1.subgraph_size_peptide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in prod1.frames[5000]['frame_graph']:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sense_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.concat([subgraph_pep_df, number_of_peptide_df, sense_df], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_excel(excel_writer='/home/lillo/Documents/Code/export_test/test.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_macroaggregate_per_frame(self):\n",
    "    number_of_peptide = {}\n",
    "    for i in self.subgraph_size_peptide:\n",
    "        number_of_peptide[i] = len(self.subgraph_size_peptide[i][0])\n",
    "\n",
    "    self.number_of_peptide_df = pd.DataFrame.from_dict(number_of_peptide, orient='index', columns=['n° of macroaggreates'])\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_peptide_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod.subgraph_size_peptide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph = morphoscanner.graph.find_subgraph(prod1.frames[5000]['frame_graph_full'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod1.frames[5000]['frame_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in subgraph[0]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a full graph\n",
    "def full_graph(denoised_dict):\n",
    "    ''' Create a full graph of all the peptides in the frame.\n",
    "\n",
    "    Every peptide is a node in the graph.\n",
    "    Edges join contacting peptides.\n",
    "    Edges have attribute 'length' that gives you the number of contact between the peptides\n",
    "\n",
    "    Useful for peptides behaviour analysis during molecular dynamics\n",
    "\n",
    "    Arguments: denoised contact maps dict\n",
    "    return: networkx.MultiGraph\n",
    "\n",
    "    '''\n",
    "    graph = nx.MultiGraph()\n",
    "\n",
    "    for peptide_1 in denoised_dict:\n",
    "        for peptide_2 in denoised_dict[peptide_1]:\n",
    "\n",
    "            array_1 = denoised_dict[peptide_1][peptide_2]\n",
    "\n",
    "            graph.add_node(peptide_1)\n",
    "            graph.add_node(peptide_2)\n",
    "\n",
    "            number_of_contacts = array_1.sum()\n",
    "\n",
    "            if number_of_contacts >= 1:\n",
    "\n",
    "                graph.add_edge(peptide_1, peptide_2, length = number_of_contacts)\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(prod1.frames[5000]['frame_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(prod.frame_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = prod1.frames[4800]['frame_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(datas.groupby('peptide1').get_group(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## THIS IS WORKING\n",
    "\n",
    "def graph_v1(denoised_dict, df):\n",
    "    \n",
    "    graph = nx.MultiGraph()\n",
    "\n",
    "    for group in df.index:\n",
    "\n",
    "        peptide_1 = df.iloc[group]['peptide1']\n",
    "        peptide_2 = df.iloc[group]['peptide2']\n",
    "\n",
    "        array_1 = denoised_dict[peptide_1][peptide_2]\n",
    "\n",
    "        graph.add_node(peptide_1)\n",
    "        graph.add_node(peptide_2)\n",
    "\n",
    "        number_of_contacts = array_1.sum()\n",
    "\n",
    "        if number_of_contacts >= 1:\n",
    "\n",
    "            sense = df.iloc[group]['sense']\n",
    "\n",
    "            graph.add_edge(peptide_1, peptide_2, length = number_of_contacts, sense=sense)\n",
    "\n",
    "    return graph\n",
    "#return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod.frames.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ei.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ei_c = morphoscanner.distance.compute_contact_maps_as_array(ei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ei_d, ei_df = morphoscanner.denoise.denoise_contact_maps(ei_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_v1(ei_d, ei_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in datas.index:\n",
    "    print(datas.iloc[group])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas.iloc[3]['sense']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ei_c.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(prod1.frames[4800]['frame_graph_full'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[set(i) for i in a if set(i) in (set(e) for e in b)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[set(i) for i in a] == [set(e) for e in b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.get_edge_data(1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.get_edge_data(1, 3)[0]['sense']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.get_edge_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.get_edge_data(node1, node2)[0]['sense']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_test.frames[0]['subgraphs_full']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.edges(subgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contact_sense_in_subgraph(graph, subgraph_list):\n",
    "\n",
    "    subgraph_sense_dict = {}\n",
    "\n",
    "    for index, subgraph in enumerate(subgraph_list):\n",
    "\n",
    "        subgraph_sense_dict[index] = {}\n",
    "\n",
    "        sense_list = []\n",
    "\n",
    "        for i in graph.edges(subgraph):\n",
    "\n",
    "            #print(i[0], i[1])\n",
    "            sense = graph[i[0]][i[1]][0]['sense']\n",
    "            sense_list.append(graph[i[0]][i[1]][0]['sense'])\n",
    "\n",
    "            subgraph_sense_dict[index] = sense_list\n",
    "            \n",
    "    return subgraph_sense_dict\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph_sense_dict[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "au = contact_sense_in_subgraph(graph,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sense_in_subgraph(graph, subgraphs_list):\n",
    "    \n",
    "    \n",
    "    subgraphs = contact_sense_in_subgraph(graph, subgraphs_list)\n",
    "    \n",
    "    sense_counter_dict = {}\n",
    "\n",
    "    for index, subgraph in enumerate(subgraphs):\n",
    "\n",
    "        sense_counter_dict[index] = {}\n",
    "\n",
    "\n",
    "        parallel = 0\n",
    "        antiparallel = 0\n",
    "\n",
    "        for sense in subgraphs[index]:\n",
    "\n",
    "            if sense == 'parallel':\n",
    "                parallel += 1\n",
    "\n",
    "            elif sense == 'antiparallel':\n",
    "                antiparallel += 1\n",
    "                \n",
    "        sense_counter_dict[index] = { 'parallel' : parallel,\n",
    "                                       'antiparallel' : antiparallel}\n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    return sense_counter_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def macroaggregate_sense(self):\n",
    "    \n",
    "    macroaggregate_sense_dict = {}\n",
    "    \n",
    "    for frame in self.frames:\n",
    "        graph = self.frames[frame]['frame_graph_full']\n",
    "        subs = self.frames[frame]['subgraphs_full']\n",
    "        #senses = contact_sense_in_subgraph(graph, subs)\n",
    "        #sense_counter = count_sense_in_subgraph(senses)\n",
    "        sense_counter = sense_in_subgraph(graph, subs)\n",
    "        macroaggregate_sense_dict[frame] = sense_counter\n",
    "    \n",
    "    self.macroagg_df = pd.DataFrame.from_dict(macroaggregate_sense_dict, orient='index')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macroagg_df = pd.DataFrame.from_dict(macroaggregate_sense_dict, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macroagg_df = macroaggregate_sense(prod_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macroagg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sense_in_aggregate = {}\n",
    "for i in prod.frames:\n",
    "    print(prod.frames[i].)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = morphoscanner.graph.find_subgraph(prod.frames[0]['frame_graph_full'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sense_in_aggregate_dict = {}\n",
    "\n",
    "for frame in prod.frames:\n",
    "    \n",
    "    graph = prod.frames[frame]['frame_graph_full']\n",
    "    \n",
    "    subgraphs = morphoscanner.graph.find_subgraph(graph)\n",
    "    \n",
    "    senses = contact_sense_in_subgraph(subgraph, subgraph)\n",
    "    \n",
    "    senses_counted = count_sense_in_subgraph(senses)\n",
    "    \n",
    "    sense_in_aggregate_dict[frame] = senses_counted\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contact_sense_in_subgraph(graph, subgraph_list):\n",
    "\n",
    "    subgraph_sense_dict = {}\n",
    "\n",
    "    for index, subgraph in enumerate(a):\n",
    "\n",
    "        subgraph_sense_dict[index] = {}\n",
    "\n",
    "        sense_list = []\n",
    "\n",
    "        for i in graph.edges(subgraph):\n",
    "\n",
    "            #print(i[0], i[1])\n",
    "            sense = graph[i[0]][i[1]][0]['sense']\n",
    "            sense_list.append(graph[i[0]][i[1]][0]['sense'])\n",
    "\n",
    "            subgraph_sense_dict[index] = sense_list\n",
    "            \n",
    "    return subgraph_sense_dict\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def macroaggregate_sense_data(self):\n",
    "    \n",
    "    macroaggregate_sense_dict = {}\n",
    "\n",
    "    for frame in self.frames:\n",
    "        graph = self.frames[frame]['frame_graph_full']\n",
    "        subs = self.frames[frame]['subgraphs_full']\n",
    "        #senses = contact_sense_in_subgraph(graph, subs)\n",
    "        #sense_counter = count_sense_in_subgraph(senses)\n",
    "        sense_counter = morphoscanner.graph.sense_in_subgraph(graph, subs)\n",
    "        macroaggregate_sense_dict[frame] = sense_counter\n",
    "\n",
    "    self.macroaggregate_df = pd.DataFrame.from_dict(macroaggregate_sense_dict, orient='index')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sense_in_subgraph(graph,subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macroagg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INTEGRATE:\n",
    "\n",
    "# NEW GRAPH MAKER\n",
    "# function to count sense in aggregate\n",
    "# make dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphoscanner.graph.full_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_test = trajectory(prod_gro, prod_xtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_test.compose_database(peptide_length=18, interval=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prod_test.analyze_inLoop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trajectory_graph(self.frames):\n",
    "    \n",
    "    self.graph_dict = {}\n",
    "    for i in self.frames:\n",
    "        denoised = self.frames[i]['frame_denoised']\n",
    "        df = self.frames[i]['frame_data']\n",
    "        graph = morphoscanner.graph.graph_v1(denoised, df)\n",
    "\n",
    "        self.graph_dict[i] = graph\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(self):\n",
    "    self.get_sense()\n",
    "    self.subgraph_length_peptide()\n",
    "    self.macroaggregate_sense_data()\n",
    "    \n",
    "    self.database = pd.concat((prod_test.subgraph_len_pep_df, prod_test.sense_df, prod_test.macroaggregate_df), axis=1)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_test.macroaggregate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrg = pd.concat((prod_test.subgraph_len_pep_df, prod_test.sense_df, prod_test.macroaggregate_df), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_test.get_sense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sense_df = pd.DataFrame.from_dict(prod_test.sense_dict, orient='index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_test.subgraph_length_peptide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_test.subgraph_size_peptide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph_pep_df = pd.DataFrame.from_dict(prod_test.subgraph_size_peptide, orient='index', columns=['n° of peptides in macroaggregates'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = prod_test.frames[0]['subgraphs_full']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.sort(key=len, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod = morphoscanner.trajectory(prod_gro, prod_xtc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4016it [00:56, 71.22it/s]\n"
     ]
    }
   ],
   "source": [
    "prod.compose_database(peptide_length=18, interval=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:02, 54.13it/s]\n",
      "100%|██████████| 111/111 [00:00<00:00, 395554.58it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time needed to analyze frame 0 is 27.269382 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:02, 56.59it/s]\n",
      "100%|██████████| 124/124 [00:00<00:00, 368338.31it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time needed to analyze frame 2000 is 26.661131 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:02, 57.75it/s]\n",
      "100%|██████████| 125/125 [00:00<00:00, 421114.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time needed to analyze frame 4000 is 26.222975 seconds\n",
      "Total time to analyze dataset is 80.153872 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prod.analyze_inLoop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod.get_data()\n",
    "prod.get_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n° of peptides in macroaggregates</th>\n",
       "      <th>parallel</th>\n",
       "      <th>antiparallel</th>\n",
       "      <th>n° of macroaggreates</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...</td>\n",
       "      <td>109</td>\n",
       "      <td>74</td>\n",
       "      <td>27</td>\n",
       "      <td>{'parallel': 3, 'antiparallel': 4}</td>\n",
       "      <td>{'parallel': 4, 'antiparallel': 3}</td>\n",
       "      <td>{'parallel': 2, 'antiparallel': 4}</td>\n",
       "      <td>{'parallel': 7, 'antiparallel': 1}</td>\n",
       "      <td>{'parallel': 5, 'antiparallel': 1}</td>\n",
       "      <td>{'parallel': 5, 'antiparallel': 2}</td>\n",
       "      <td>...</td>\n",
       "      <td>{'parallel': 6, 'antiparallel': 1}</td>\n",
       "      <td>{'parallel': 4, 'antiparallel': 4}</td>\n",
       "      <td>{'parallel': 3, 'antiparallel': 4}</td>\n",
       "      <td>{'parallel': 5, 'antiparallel': 2}</td>\n",
       "      <td>{'parallel': 6, 'antiparallel': 4}</td>\n",
       "      <td>{'parallel': 5, 'antiparallel': 3}</td>\n",
       "      <td>{'parallel': 2, 'antiparallel': 3}</td>\n",
       "      <td>{'parallel': 1, 'antiparallel': 4}</td>\n",
       "      <td>{'parallel': 4, 'antiparallel': 2}</td>\n",
       "      <td>{'parallel': 4, 'antiparallel': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>[89, 24, 18, 6, 6, 6, 6, 4, 2]</td>\n",
       "      <td>135</td>\n",
       "      <td>116</td>\n",
       "      <td>9</td>\n",
       "      <td>{'parallel': 81, 'antiparallel': 77}</td>\n",
       "      <td>{'parallel': 23, 'antiparallel': 12}</td>\n",
       "      <td>{'parallel': 14, 'antiparallel': 12}</td>\n",
       "      <td>{'parallel': 2, 'antiparallel': 4}</td>\n",
       "      <td>{'parallel': 7, 'antiparallel': 0}</td>\n",
       "      <td>{'parallel': 2, 'antiparallel': 5}</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>[126, 24, 6, 5]</td>\n",
       "      <td>141</td>\n",
       "      <td>129</td>\n",
       "      <td>4</td>\n",
       "      <td>{'parallel': 115, 'antiparallel': 108}</td>\n",
       "      <td>{'parallel': 21, 'antiparallel': 12}</td>\n",
       "      <td>{'parallel': 5, 'antiparallel': 2}</td>\n",
       "      <td>{'parallel': 0, 'antiparallel': 7}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      n° of peptides in macroaggregates  parallel  \\\n",
       "0     [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...       109   \n",
       "2000                     [89, 24, 18, 6, 6, 6, 6, 4, 2]       135   \n",
       "4000                                    [126, 24, 6, 5]       141   \n",
       "\n",
       "      antiparallel  n° of macroaggreates  \\\n",
       "0               74                    27   \n",
       "2000           116                     9   \n",
       "4000           129                     4   \n",
       "\n",
       "                                           0  \\\n",
       "0         {'parallel': 3, 'antiparallel': 4}   \n",
       "2000    {'parallel': 81, 'antiparallel': 77}   \n",
       "4000  {'parallel': 115, 'antiparallel': 108}   \n",
       "\n",
       "                                         1  \\\n",
       "0       {'parallel': 4, 'antiparallel': 3}   \n",
       "2000  {'parallel': 23, 'antiparallel': 12}   \n",
       "4000  {'parallel': 21, 'antiparallel': 12}   \n",
       "\n",
       "                                         2  \\\n",
       "0       {'parallel': 2, 'antiparallel': 4}   \n",
       "2000  {'parallel': 14, 'antiparallel': 12}   \n",
       "4000    {'parallel': 5, 'antiparallel': 2}   \n",
       "\n",
       "                                       3                                   4  \\\n",
       "0     {'parallel': 7, 'antiparallel': 1}  {'parallel': 5, 'antiparallel': 1}   \n",
       "2000  {'parallel': 2, 'antiparallel': 4}  {'parallel': 7, 'antiparallel': 0}   \n",
       "4000  {'parallel': 0, 'antiparallel': 7}                                 NaN   \n",
       "\n",
       "                                       5  ...  \\\n",
       "0     {'parallel': 5, 'antiparallel': 2}  ...   \n",
       "2000  {'parallel': 2, 'antiparallel': 5}  ...   \n",
       "4000                                 NaN  ...   \n",
       "\n",
       "                                      17                                  18  \\\n",
       "0     {'parallel': 6, 'antiparallel': 1}  {'parallel': 4, 'antiparallel': 4}   \n",
       "2000                                 NaN                                 NaN   \n",
       "4000                                 NaN                                 NaN   \n",
       "\n",
       "                                      19                                  20  \\\n",
       "0     {'parallel': 3, 'antiparallel': 4}  {'parallel': 5, 'antiparallel': 2}   \n",
       "2000                                 NaN                                 NaN   \n",
       "4000                                 NaN                                 NaN   \n",
       "\n",
       "                                      21                                  22  \\\n",
       "0     {'parallel': 6, 'antiparallel': 4}  {'parallel': 5, 'antiparallel': 3}   \n",
       "2000                                 NaN                                 NaN   \n",
       "4000                                 NaN                                 NaN   \n",
       "\n",
       "                                      23                                  24  \\\n",
       "0     {'parallel': 2, 'antiparallel': 3}  {'parallel': 1, 'antiparallel': 4}   \n",
       "2000                                 NaN                                 NaN   \n",
       "4000                                 NaN                                 NaN   \n",
       "\n",
       "                                      25                                  26  \n",
       "0     {'parallel': 4, 'antiparallel': 2}  {'parallel': 4, 'antiparallel': 2}  \n",
       "2000                                 NaN                                 NaN  \n",
       "4000                                 NaN                                 NaN  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod.database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prodio.subgraph_size_peptide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prodio.subgraph_length_peptide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod1 = morphoscanner.trajectory(prod1_gro, prod1_xtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "997it [00:16, 60.93it/s]\n"
     ]
    }
   ],
   "source": [
    "prod1.compose_database(peptide_length=18, interval=400, start_from=4016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:02, 57.21it/s]\n",
      "100%|██████████| 123/123 [00:00<00:00, 361780.78it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time needed to analyze frame 4400 is 26.322914 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:02, 56.43it/s]\n",
      "100%|██████████| 131/131 [00:00<00:00, 385041.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time needed to analyze frame 4800 is 26.318650 seconds\n",
      "Total time to analyze dataset is 52.641711 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prod1.analyze_inLoop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod1.get_data()\n",
    "prod1.get_database()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n° of peptides in macroaggregates</th>\n",
       "      <th>parallel</th>\n",
       "      <th>antiparallel</th>\n",
       "      <th>n° of macroaggreates</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4400</th>\n",
       "      <td>[114, 24, 10, 6, 6, 2]</td>\n",
       "      <td>141</td>\n",
       "      <td>118</td>\n",
       "      <td>6</td>\n",
       "      <td>{'parallel': 97, 'antiparallel': 92}</td>\n",
       "      <td>{'parallel': 21, 'antiparallel': 16}</td>\n",
       "      <td>{'parallel': 12, 'antiparallel': 4}</td>\n",
       "      <td>{'parallel': 6, 'antiparallel': 2}</td>\n",
       "      <td>{'parallel': 5, 'antiparallel': 3}</td>\n",
       "      <td>{'parallel': 0, 'antiparallel': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4800</th>\n",
       "      <td>[126, 24, 6, 6]</td>\n",
       "      <td>146</td>\n",
       "      <td>137</td>\n",
       "      <td>4</td>\n",
       "      <td>{'parallel': 119, 'antiparallel': 109}</td>\n",
       "      <td>{'parallel': 19, 'antiparallel': 19}</td>\n",
       "      <td>{'parallel': 4, 'antiparallel': 5}</td>\n",
       "      <td>{'parallel': 4, 'antiparallel': 4}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     n° of peptides in macroaggregates  parallel  antiparallel  \\\n",
       "4400            [114, 24, 10, 6, 6, 2]       141           118   \n",
       "4800                   [126, 24, 6, 6]       146           137   \n",
       "\n",
       "      n° of macroaggreates                                       0  \\\n",
       "4400                     6    {'parallel': 97, 'antiparallel': 92}   \n",
       "4800                     4  {'parallel': 119, 'antiparallel': 109}   \n",
       "\n",
       "                                         1  \\\n",
       "4400  {'parallel': 21, 'antiparallel': 16}   \n",
       "4800  {'parallel': 19, 'antiparallel': 19}   \n",
       "\n",
       "                                        2                                   3  \\\n",
       "4400  {'parallel': 12, 'antiparallel': 4}  {'parallel': 6, 'antiparallel': 2}   \n",
       "4800   {'parallel': 4, 'antiparallel': 5}  {'parallel': 4, 'antiparallel': 4}   \n",
       "\n",
       "                                       4                                   5  \n",
       "4400  {'parallel': 5, 'antiparallel': 3}  {'parallel': 0, 'antiparallel': 1}  \n",
       "4800                                 NaN                                 NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod1.database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prod.database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.update(prod1.database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = pd.concat([df, prod1.database])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n° of peptides in macroaggregates</th>\n",
       "      <th>parallel</th>\n",
       "      <th>antiparallel</th>\n",
       "      <th>n° of macroaggreates</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...</td>\n",
       "      <td>109</td>\n",
       "      <td>74</td>\n",
       "      <td>27</td>\n",
       "      <td>{'parallel': 3, 'antiparallel': 4}</td>\n",
       "      <td>{'parallel': 4, 'antiparallel': 3}</td>\n",
       "      <td>{'parallel': 2, 'antiparallel': 4}</td>\n",
       "      <td>{'parallel': 7, 'antiparallel': 1}</td>\n",
       "      <td>{'parallel': 5, 'antiparallel': 1}</td>\n",
       "      <td>{'parallel': 5, 'antiparallel': 2}</td>\n",
       "      <td>...</td>\n",
       "      <td>{'parallel': 6, 'antiparallel': 1}</td>\n",
       "      <td>{'parallel': 4, 'antiparallel': 4}</td>\n",
       "      <td>{'parallel': 3, 'antiparallel': 4}</td>\n",
       "      <td>{'parallel': 5, 'antiparallel': 2}</td>\n",
       "      <td>{'parallel': 6, 'antiparallel': 4}</td>\n",
       "      <td>{'parallel': 5, 'antiparallel': 3}</td>\n",
       "      <td>{'parallel': 2, 'antiparallel': 3}</td>\n",
       "      <td>{'parallel': 1, 'antiparallel': 4}</td>\n",
       "      <td>{'parallel': 4, 'antiparallel': 2}</td>\n",
       "      <td>{'parallel': 4, 'antiparallel': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>[89, 24, 18, 6, 6, 6, 6, 4, 2]</td>\n",
       "      <td>135</td>\n",
       "      <td>116</td>\n",
       "      <td>9</td>\n",
       "      <td>{'parallel': 81, 'antiparallel': 77}</td>\n",
       "      <td>{'parallel': 23, 'antiparallel': 12}</td>\n",
       "      <td>{'parallel': 14, 'antiparallel': 12}</td>\n",
       "      <td>{'parallel': 2, 'antiparallel': 4}</td>\n",
       "      <td>{'parallel': 7, 'antiparallel': 0}</td>\n",
       "      <td>{'parallel': 2, 'antiparallel': 5}</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>[126, 24, 6, 5]</td>\n",
       "      <td>141</td>\n",
       "      <td>129</td>\n",
       "      <td>4</td>\n",
       "      <td>{'parallel': 115, 'antiparallel': 108}</td>\n",
       "      <td>{'parallel': 21, 'antiparallel': 12}</td>\n",
       "      <td>{'parallel': 5, 'antiparallel': 2}</td>\n",
       "      <td>{'parallel': 0, 'antiparallel': 7}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4400</th>\n",
       "      <td>[114, 24, 10, 6, 6, 2]</td>\n",
       "      <td>141</td>\n",
       "      <td>118</td>\n",
       "      <td>6</td>\n",
       "      <td>{'parallel': 97, 'antiparallel': 92}</td>\n",
       "      <td>{'parallel': 21, 'antiparallel': 16}</td>\n",
       "      <td>{'parallel': 12, 'antiparallel': 4}</td>\n",
       "      <td>{'parallel': 6, 'antiparallel': 2}</td>\n",
       "      <td>{'parallel': 5, 'antiparallel': 3}</td>\n",
       "      <td>{'parallel': 0, 'antiparallel': 1}</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4800</th>\n",
       "      <td>[126, 24, 6, 6]</td>\n",
       "      <td>146</td>\n",
       "      <td>137</td>\n",
       "      <td>4</td>\n",
       "      <td>{'parallel': 119, 'antiparallel': 109}</td>\n",
       "      <td>{'parallel': 19, 'antiparallel': 19}</td>\n",
       "      <td>{'parallel': 4, 'antiparallel': 5}</td>\n",
       "      <td>{'parallel': 4, 'antiparallel': 4}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      n° of peptides in macroaggregates  parallel  \\\n",
       "0     [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...       109   \n",
       "2000                     [89, 24, 18, 6, 6, 6, 6, 4, 2]       135   \n",
       "4000                                    [126, 24, 6, 5]       141   \n",
       "4400                             [114, 24, 10, 6, 6, 2]       141   \n",
       "4800                                    [126, 24, 6, 6]       146   \n",
       "\n",
       "      antiparallel  n° of macroaggreates  \\\n",
       "0               74                    27   \n",
       "2000           116                     9   \n",
       "4000           129                     4   \n",
       "4400           118                     6   \n",
       "4800           137                     4   \n",
       "\n",
       "                                           0  \\\n",
       "0         {'parallel': 3, 'antiparallel': 4}   \n",
       "2000    {'parallel': 81, 'antiparallel': 77}   \n",
       "4000  {'parallel': 115, 'antiparallel': 108}   \n",
       "4400    {'parallel': 97, 'antiparallel': 92}   \n",
       "4800  {'parallel': 119, 'antiparallel': 109}   \n",
       "\n",
       "                                         1  \\\n",
       "0       {'parallel': 4, 'antiparallel': 3}   \n",
       "2000  {'parallel': 23, 'antiparallel': 12}   \n",
       "4000  {'parallel': 21, 'antiparallel': 12}   \n",
       "4400  {'parallel': 21, 'antiparallel': 16}   \n",
       "4800  {'parallel': 19, 'antiparallel': 19}   \n",
       "\n",
       "                                         2  \\\n",
       "0       {'parallel': 2, 'antiparallel': 4}   \n",
       "2000  {'parallel': 14, 'antiparallel': 12}   \n",
       "4000    {'parallel': 5, 'antiparallel': 2}   \n",
       "4400   {'parallel': 12, 'antiparallel': 4}   \n",
       "4800    {'parallel': 4, 'antiparallel': 5}   \n",
       "\n",
       "                                       3                                   4  \\\n",
       "0     {'parallel': 7, 'antiparallel': 1}  {'parallel': 5, 'antiparallel': 1}   \n",
       "2000  {'parallel': 2, 'antiparallel': 4}  {'parallel': 7, 'antiparallel': 0}   \n",
       "4000  {'parallel': 0, 'antiparallel': 7}                                 NaN   \n",
       "4400  {'parallel': 6, 'antiparallel': 2}  {'parallel': 5, 'antiparallel': 3}   \n",
       "4800  {'parallel': 4, 'antiparallel': 4}                                 NaN   \n",
       "\n",
       "                                       5  ...  \\\n",
       "0     {'parallel': 5, 'antiparallel': 2}  ...   \n",
       "2000  {'parallel': 2, 'antiparallel': 5}  ...   \n",
       "4000                                 NaN  ...   \n",
       "4400  {'parallel': 0, 'antiparallel': 1}  ...   \n",
       "4800                                 NaN  ...   \n",
       "\n",
       "                                      17                                  18  \\\n",
       "0     {'parallel': 6, 'antiparallel': 1}  {'parallel': 4, 'antiparallel': 4}   \n",
       "2000                                 NaN                                 NaN   \n",
       "4000                                 NaN                                 NaN   \n",
       "4400                                 NaN                                 NaN   \n",
       "4800                                 NaN                                 NaN   \n",
       "\n",
       "                                      19                                  20  \\\n",
       "0     {'parallel': 3, 'antiparallel': 4}  {'parallel': 5, 'antiparallel': 2}   \n",
       "2000                                 NaN                                 NaN   \n",
       "4000                                 NaN                                 NaN   \n",
       "4400                                 NaN                                 NaN   \n",
       "4800                                 NaN                                 NaN   \n",
       "\n",
       "                                      21                                  22  \\\n",
       "0     {'parallel': 6, 'antiparallel': 4}  {'parallel': 5, 'antiparallel': 3}   \n",
       "2000                                 NaN                                 NaN   \n",
       "4000                                 NaN                                 NaN   \n",
       "4400                                 NaN                                 NaN   \n",
       "4800                                 NaN                                 NaN   \n",
       "\n",
       "                                      23                                  24  \\\n",
       "0     {'parallel': 2, 'antiparallel': 3}  {'parallel': 1, 'antiparallel': 4}   \n",
       "2000                                 NaN                                 NaN   \n",
       "4000                                 NaN                                 NaN   \n",
       "4400                                 NaN                                 NaN   \n",
       "4800                                 NaN                                 NaN   \n",
       "\n",
       "                                      25                                  26  \n",
       "0     {'parallel': 4, 'antiparallel': 2}  {'parallel': 4, 'antiparallel': 2}  \n",
       "2000                                 NaN                                 NaN  \n",
       "4000                                 NaN                                 NaN  \n",
       "4400                                 NaN                                 NaN  \n",
       "4800                                 NaN                                 NaN  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
